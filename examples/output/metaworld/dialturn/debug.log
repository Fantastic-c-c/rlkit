------------------------------  ----------------
Z mean train                         0.00885854
Z variance train                     0.010843
KL Divergence                      197.99
KL Loss                             19.799
QF Loss                              1.20577e+06
VF Loss                              7.41831
RF Loss                         459473
Policy Loss                         -2.69438
Q Predictions Mean                   0.00375449
Q Predictions Std                    0.00039523
Q Predictions Max                    0.00470039
Q Predictions Min                    0.00258996
V Predictions Mean                   0.00621048
V Predictions Std                    0.000168758
V Predictions Max                    0.00648074
V Predictions Min                    0.00576859
R Predictions Mean                   0.00351687
R Predictions Std                    0.000663438
R Predictions Max                    0.00524719
R Predictions Min                    0.00130258
Log Pis Mean                        -2.67733
Log Pis Std                          0.438247
Log Pis Max                         -1.17885
Log Pis Min                         -4.59908
Policy mu Mean                       0.000855674
Policy mu Std                        0.000567964
Policy mu Max                        0.0020891
Policy mu Min                        0.000223097
Policy log std Mean                  0.000137752
Policy log std Std                   0.00182398
Policy log std Max                   0.00323001
Policy log std Min                  -0.00206187
_task0 Rewards Mean                 10.9181
_task0 Rewards Std                  37.6484
_task0 Rewards Max                 196.355
_task0 Rewards Min                  -0.938002
_task0 Returns Mean               1637.72
_task0 Returns Std                2402.02
_task0 Returns Max                5014.99
_task0 Returns Min                -124.128
_task0 Actions Mean                 -0.475391
_task0 Actions Std                   0.823563
_task0 Actions Max                   0.996621
_task0 Actions Min                  -0.995827
Num Paths                          369
Exploration_task0 Rewards Mean     329.152
Exploration_task0 Rewards Std      696.298
Exploration_task0 Rewards Max     7872.77
Exploration_task0 Rewards Min       -9.38009
Exploration_task0 Returns Mean   49908
Exploration_task0 Returns Std    92849.5
Exploration_task0 Returns Max   564973
Exploration_task0 Returns Min    -1234.81
Exploration_task0 Actions Mean      -0.0368562
Exploration_task0 Actions Std        0.659019
Exploration_task0 Actions Max        0.999923
Exploration_task0 Actions Min       -1
AverageReturn__task0              1637.72
AverageReturn_all_train_tasks     1739.16
AverageReturn_all_test_tasks      1637.72
Number of train steps total       1000
Number of env steps total        51000
Number of rollouts total           369
Train Time (s)                      96.3719
(Previous) Eval Time (s)             0
Sample Time (s)                    109.052
Epoch Time (s)                     205.424
Total Train Time (s)               231.167
Epoch                                0
------------------------------  ----------------
2019-06-27 00:36:43.067217 UTC | [dialturn] Iteration #0 | Epoch Duration: 231.09355282783508
2019-06-27 00:36:43.067429 UTC | [dialturn] Iteration #0 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00490373
Z variance train                     0.837668
KL Divergence                        1.06698
KL Loss                              0.106698
QF Loss                              1.80339e+07
VF Loss                              2.46192e+06
RF Loss                              3.48173e+06
Policy Loss                      -3139.05
Q Predictions Mean                3365.27
Q Predictions Std                 5439.93
Q Predictions Max                17452.1
Q Predictions Min                    1.97993
V Predictions Mean                3667.68
V Predictions Std                 4386.07
V Predictions Max                14884.1
V Predictions Min                   12.7737
R Predictions Mean                1094.21
R Predictions Std                 1607.17
R Predictions Max                 3847.65
R Predictions Min                  -43.4256
Log Pis Mean                         7.58112
Log Pis Std                          3.51189
Log Pis Max                         20.092
Log Pis Min                         -7.48801
Policy mu Mean                      -0.922536
Policy mu Std                        1.85475
Policy mu Max                        2.91695
Policy mu Min                       -2.79019
Policy log std Mean                 -0.429034
Policy log std Std                   0.439866
Policy log std Max                   0.694794
Policy log std Min                  -0.810438
_task0 Rewards Mean                  0.682536
_task0 Rewards Std                   7.87836
_task0 Rewards Max                  73.5317
_task0 Rewards Min                  -0.881594
_task0 Returns Mean                102.38
_task0 Returns Std                 266.847
_task0 Returns Max                 470.909
_task0 Returns Min                -114.168
_task0 Actions Mean                 -0.148252
_task0 Actions Std                   0.963684
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean      99.7431
Exploration_task0 Rewards Std      360.685
Exploration_task0 Rewards Max     2096.69
Exploration_task0 Rewards Min       -9.3801
Exploration_task0 Returns Mean   15112.6
Exploration_task0 Returns Std    23688.7
Exploration_task0 Returns Max    53773.9
Exploration_task0 Returns Min    -1634.58
Exploration_task0 Actions Mean      -0.388025
Exploration_task0 Actions Std        0.842461
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0               102.38
AverageReturn_all_train_tasks      115.822
AverageReturn_all_test_tasks       102.38
Number of train steps total       2000
Number of env steps total       101000
Number of rollouts total           732
Train Time (s)                      96.9568
(Previous) Eval Time (s)            25.6685
Sample Time (s)                    106.555
Epoch Time (s)                     229.18
Total Train Time (s)               460.234
Epoch                                1
------------------------------  ----------------
2019-06-27 00:40:32.136281 UTC | [dialturn] Iteration #1 | Epoch Duration: 229.06868696212769
2019-06-27 00:40:32.136477 UTC | [dialturn] Iteration #1 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00447677
Z variance train                     0.839254
KL Divergence                        0.760697
KL Loss                              0.0760697
QF Loss                              2.60765e+06
VF Loss                         452560
RF Loss                         394683
Policy Loss                      -5421.55
Q Predictions Mean                5126.04
Q Predictions Std                 5409.93
Q Predictions Max                19916.6
Q Predictions Min                   81.3697
V Predictions Mean                5117.22
V Predictions Std                 5978.78
V Predictions Max                22501.7
V Predictions Min                   26.6342
R Predictions Mean                 541.284
R Predictions Std                  306.025
R Predictions Max                  994.22
R Predictions Min                  -25.5083
Log Pis Mean                        28.9085
Log Pis Std                          9.51108
Log Pis Max                         43.5476
Log Pis Min                         -1.04871
Policy mu Mean                       0.158849
Policy mu Std                       17.9898
Policy mu Max                       34.429
Policy mu Min                      -32.5757
Policy log std Mean                  0.672206
Policy log std Std                   1.35334
Policy log std Max                   2
Policy log std Min                  -0.841046
_task0 Rewards Mean                 52.3706
_task0 Rewards Std                 128.795
_task0 Rewards Max                 826.002
_task0 Rewards Min                  -1.03617
_task0 Returns Mean               7855.6
_task0 Returns Std               15150.9
_task0 Returns Max               45547.8
_task0 Returns Min                -132.8
_task0 Actions Mean                  0.29723
_task0 Actions Std                   0.72061
_task0 Actions Max                   1
_task0 Actions Min                  -0.999971
Num Paths                          363
Exploration_task0 Rewards Mean      73.7404
Exploration_task0 Rewards Std      499.606
Exploration_task0 Rewards Max     8525.28
Exploration_task0 Rewards Min      -10.3573
Exploration_task0 Returns Mean   11172.8
Exploration_task0 Returns Std    67429.9
Exploration_task0 Returns Max   672319
Exploration_task0 Returns Min    -1549.73
Exploration_task0 Actions Mean      -0.0748674
Exploration_task0 Actions Std        0.944962
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7855.6
AverageReturn_all_train_tasks     9834.19
AverageReturn_all_test_tasks      7855.6
Number of train steps total       3000
Number of env steps total       151000
Number of rollouts total          1095
Train Time (s)                      97.9723
(Previous) Eval Time (s)            25.5554
Sample Time (s)                    106.203
Epoch Time (s)                     229.73
Total Train Time (s)               689.972
Epoch                                2
------------------------------  ----------------
2019-06-27 00:44:21.875804 UTC | [dialturn] Iteration #2 | Epoch Duration: 229.7391562461853
2019-06-27 00:44:21.876026 UTC | [dialturn] Iteration #2 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00994848
Z variance train                     1.24948
KL Divergence                        2.83343
KL Loss                              0.283343
QF Loss                              2.46921e+06
VF Loss                          57178.7
RF Loss                              3.66314e+06
Policy Loss                      -7952.18
Q Predictions Mean                7347.78
Q Predictions Std                 8766.04
Q Predictions Max                30666
Q Predictions Min                  176.627
V Predictions Mean                7827.19
V Predictions Std                 9308.98
V Predictions Max                33648.4
V Predictions Min                  103.925
R Predictions Mean                  59.9881
R Predictions Std                  147.818
R Predictions Max                  705.598
R Predictions Min                  -54.7524
Log Pis Mean                        19.8553
Log Pis Std                          8.11492
Log Pis Max                         49.4658
Log Pis Min                         -0.20136
Policy mu Mean                       1.69374
Policy mu Std                        7.85126
Policy mu Max                       35.9555
Policy mu Min                      -26.8184
Policy log std Mean                 -0.50581
Policy log std Std                   0.660741
Policy log std Max                   2
Policy log std Min                  -1.74845
_task0 Rewards Mean                  8.92503
_task0 Rewards Std                  47.5932
_task0 Rewards Max                 442.648
_task0 Rewards Min                  -0.925102
_task0 Returns Mean               1338.75
_task0 Returns Std                4159.23
_task0 Returns Max               14895.8
_task0 Returns Min                -115.855
_task0 Actions Mean                  0.191963
_task0 Actions Std                   0.833754
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     739.056
Exploration_task0 Rewards Std     1563.76
Exploration_task0 Rewards Max    11253.2
Exploration_task0 Rewards Min      -10.3623
Exploration_task0 Returns Mean  111978
Exploration_task0 Returns Std   195241
Exploration_task0 Returns Max   781098
Exploration_task0 Returns Min    -1863.29
Exploration_task0 Actions Mean       0.265901
Exploration_task0 Actions Std        0.788921
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1338.75
AverageReturn_all_train_tasks     4328.14
AverageReturn_all_test_tasks      1338.75
Number of train steps total       4000
Number of env steps total       201000
Number of rollouts total          1458
Train Time (s)                      97.4336
(Previous) Eval Time (s)            25.5628
Sample Time (s)                    106.925
Epoch Time (s)                     229.922
Total Train Time (s)               920.066
Epoch                                3
------------------------------  ----------------
2019-06-27 00:48:11.973200 UTC | [dialturn] Iteration #3 | Epoch Duration: 230.09700417518616
2019-06-27 00:48:11.973414 UTC | [dialturn] Iteration #3 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00158577
Z variance train                     1.07383
KL Divergence                        0.215984
KL Loss                              0.0215984
QF Loss                              4.56361e+06
VF Loss                         127604
RF Loss                         231534
Policy Loss                     -10515.5
Q Predictions Mean                9936.23
Q Predictions Std                12504.7
Q Predictions Max                44716.4
Q Predictions Min                  136.389
V Predictions Mean               10498.7
V Predictions Std                13020.1
V Predictions Max                47733.1
V Predictions Min                  215.483
R Predictions Mean                 344.012
R Predictions Std                  715.408
R Predictions Max                 4430
R Predictions Min                  -11.9144
Log Pis Mean                        23.19
Log Pis Std                          6.58974
Log Pis Max                         41.8757
Log Pis Min                         -2.14439
Policy mu Mean                       0.497267
Policy mu Std                        9.65089
Policy mu Max                       45.5203
Policy mu Min                      -26.1226
Policy log std Mean                 -0.135349
Policy log std Std                   0.889931
Policy log std Max                   2
Policy log std Min                  -1.55322
_task0 Rewards Mean                  3.66503
_task0 Rewards Std                  19.3503
_task0 Rewards Max                 138.681
_task0 Rewards Min                  -0.867596
_task0 Returns Mean                549.754
_task0 Returns Std                 871.122
_task0 Returns Max                2189.75
_task0 Returns Min                -103.597
_task0 Actions Mean                  0.162725
_task0 Actions Std                   0.783392
_task0 Actions Max                   1
_task0 Actions Min                  -0.999986
Num Paths                          363
Exploration_task0 Rewards Mean     146.657
Exploration_task0 Rewards Std      526.394
Exploration_task0 Rewards Max     8053.29
Exploration_task0 Rewards Min       -9.95589
Exploration_task0 Returns Mean   22220.8
Exploration_task0 Returns Std    55078.5
Exploration_task0 Returns Max   407142
Exploration_task0 Returns Min    -1669.7
Exploration_task0 Actions Mean       0.214309
Exploration_task0 Actions Std        0.858515
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0               549.754
AverageReturn_all_train_tasks      546.09
AverageReturn_all_test_tasks       549.754
Number of train steps total       5000
Number of env steps total       251000
Number of rollouts total          1821
Train Time (s)                      96.3396
(Previous) Eval Time (s)            25.7369
Sample Time (s)                    105.777
Epoch Time (s)                     227.853
Total Train Time (s)              1147.69
Epoch                                4
------------------------------  ----------------
2019-06-27 00:51:59.595109 UTC | [dialturn] Iteration #4 | Epoch Duration: 227.62151432037354
2019-06-27 00:51:59.595312 UTC | [dialturn] Iteration #4 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000253365
Z variance train                     1.01572
KL Divergence                        0.00976638
KL Loss                              0.000976639
QF Loss                              7.28136e+06
VF Loss                         268161
RF Loss                          14525.3
Policy Loss                     -13180.7
Q Predictions Mean               12794.5
Q Predictions Std                15900.9
Q Predictions Max                57606.1
Q Predictions Min                  250.078
V Predictions Mean               13379.2
V Predictions Std                16516.1
V Predictions Max                61095.9
V Predictions Min                  288.332
R Predictions Mean                  49.749
R Predictions Std                  299.315
R Predictions Max                 3412.58
R Predictions Min                   -6.43062
Log Pis Mean                        16.9761
Log Pis Std                          7.82686
Log Pis Max                         40.8692
Log Pis Min                         -0.402799
Policy mu Mean                       0.940397
Policy mu Std                        7.3717
Policy mu Max                       44.9193
Policy mu Min                       -5.86435
Policy log std Mean                 -0.614343
Policy log std Std                   0.541998
Policy log std Max                   2
Policy log std Min                  -1.57351
_task0 Rewards Mean                  5.6337
_task0 Rewards Std                  27.9391
_task0 Rewards Max                 259.834
_task0 Rewards Min                  -0.794176
_task0 Returns Mean                845.055
_task0 Returns Std                1811.19
_task0 Returns Max                6248.37
_task0 Returns Min                 -97.8091
_task0 Actions Mean                  0.0687858
_task0 Actions Std                   0.796689
_task0 Actions Max                   1
_task0 Actions Min                  -0.999994
Num Paths                          363
Exploration_task0 Rewards Mean      43.5657
Exploration_task0 Rewards Std      236.122
Exploration_task0 Rewards Max     4337.06
Exploration_task0 Rewards Min       -9.82145
Exploration_task0 Returns Mean    6600.86
Exploration_task0 Returns Std    13326.5
Exploration_task0 Returns Max   136720
Exploration_task0 Returns Min    -1457.95
Exploration_task0 Actions Mean       0.140971
Exploration_task0 Actions Std        0.828054
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0               845.055
AverageReturn_all_train_tasks      502.322
AverageReturn_all_test_tasks       845.055
Number of train steps total       6000
Number of env steps total       301000
Number of rollouts total          2184
Train Time (s)                      97.8296
(Previous) Eval Time (s)            25.5037
Sample Time (s)                    106.31
Epoch Time (s)                     229.643
Total Train Time (s)              1377.16
Epoch                                5
------------------------------  ----------------
2019-06-27 00:55:49.070061 UTC | [dialturn] Iteration #5 | Epoch Duration: 229.47459173202515
2019-06-27 00:55:49.070256 UTC | [dialturn] Iteration #5 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00567727
Z variance train                     1.02115
KL Divergence                        0.0232305
KL Loss                              0.00232305
QF Loss                              8.41089e+06
VF Loss                          88640.7
RF Loss                         100300
Policy Loss                     -14712.5
Q Predictions Mean               14361.7
Q Predictions Std                17839.1
Q Predictions Max                68759.7
Q Predictions Min                  276.048
V Predictions Mean               14804
V Predictions Std                18346.5
V Predictions Max                72370.6
V Predictions Min                  257.117
R Predictions Mean                 159.282
R Predictions Std                  469.159
R Predictions Max                 3044.3
R Predictions Min                   -6.9621
Log Pis Mean                        16.0346
Log Pis Std                          7.58362
Log Pis Max                         45.6666
Log Pis Min                         -2.65894
Policy mu Mean                      -0.146576
Policy mu Std                        6.8463
Policy mu Max                       46.3275
Policy mu Min                      -29.5336
Policy log std Mean                 -0.599848
Policy log std Std                   0.493353
Policy log std Max                   2
Policy log std Min                  -1.56284
_task0 Rewards Mean                  9.61828
_task0 Rewards Std                  29.841
_task0 Rewards Max                 173.827
_task0 Rewards Min                  -0.863945
_task0 Returns Mean               1442.74
_task0 Returns Std                4114.36
_task0 Returns Max               16493.3
_task0 Returns Min                 -79.3801
_task0 Actions Mean                 -0.000944016
_task0 Actions Std                   0.788882
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean      96.4295
Exploration_task0 Rewards Std      505.952
Exploration_task0 Rewards Max     6846.34
Exploration_task0 Rewards Min       -9.1617
Exploration_task0 Returns Mean   14610.5
Exploration_task0 Returns Std    60388.9
Exploration_task0 Returns Max   647776
Exploration_task0 Returns Min    -1338.12
Exploration_task0 Actions Mean       0.111041
Exploration_task0 Actions Std        0.831937
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1442.74
AverageReturn_all_train_tasks      115.222
AverageReturn_all_test_tasks      1442.74
Number of train steps total       7000
Number of env steps total       351000
Number of rollouts total          2547
Train Time (s)                      97.4826
(Previous) Eval Time (s)            25.3339
Sample Time (s)                    105.465
Epoch Time (s)                     228.281
Total Train Time (s)              1605.39
Epoch                                6
------------------------------  ----------------
2019-06-27 00:59:37.299915 UTC | [dialturn] Iteration #6 | Epoch Duration: 228.22950172424316
2019-06-27 00:59:37.300158 UTC | [dialturn] Iteration #6 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00294588
Z variance train                     0.99038
KL Divergence                        0.0038824
KL Loss                              0.00038824
QF Loss                              5.38537e+06
VF Loss                          97026.8
RF Loss                         606018
Policy Loss                     -16343.6
Q Predictions Mean               15939.3
Q Predictions Std                20220.8
Q Predictions Max                79933.4
Q Predictions Min                  225.713
V Predictions Mean               16452.7
V Predictions Std                20875.7
V Predictions Max                84394.6
V Predictions Min                  368.257
R Predictions Mean                 267.282
R Predictions Std                  681.905
R Predictions Max                 3425.7
R Predictions Min                   -5.81617
Log Pis Mean                        15.8674
Log Pis Std                          7.74369
Log Pis Max                         40.6495
Log Pis Min                         -3.26117
Policy mu Mean                      -0.410095
Policy mu Std                        6.96004
Policy mu Max                       47.4303
Policy mu Min                      -33.6308
Policy log std Mean                 -0.600237
Policy log std Std                   0.507252
Policy log std Max                   2
Policy log std Min                  -1.57624
_task0 Rewards Mean                  4.49636
_task0 Rewards Std                  16.8662
_task0 Rewards Max                 115.716
_task0 Rewards Min                  -0.817203
_task0 Returns Mean                674.454
_task0 Returns Std                1594.38
_task0 Returns Max                5760.39
_task0 Returns Min                 -85.1724
_task0 Actions Mean                  0.0147856
_task0 Actions Std                   0.75308
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     301.733
Exploration_task0 Rewards Std      931.042
Exploration_task0 Rewards Max     7996.72
Exploration_task0 Rewards Min       -8.98835
Exploration_task0 Returns Mean   45717.1
Exploration_task0 Returns Std   127058
Exploration_task0 Returns Max   700760
Exploration_task0 Returns Min    -1224.83
Exploration_task0 Actions Mean      -0.0292894
Exploration_task0 Actions Std        0.821186
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0               674.454
AverageReturn_all_train_tasks    22543.8
AverageReturn_all_test_tasks       674.454
Number of train steps total       8000
Number of env steps total       401000
Number of rollouts total          2910
Train Time (s)                      97.8512
(Previous) Eval Time (s)            25.2806
Sample Time (s)                    105.556
Epoch Time (s)                     228.688
Total Train Time (s)              1834.17
Epoch                                7
------------------------------  ----------------
2019-06-27 01:03:26.082537 UTC | [dialturn] Iteration #7 | Epoch Duration: 228.78222155570984
2019-06-27 01:03:26.082726 UTC | [dialturn] Iteration #7 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00580321
Z variance train                     1.02159
KL Divergence                        0.0110155
KL Loss                              0.00110155
QF Loss                              1.56794e+07
VF Loss                         139604
RF Loss                          85664.6
Policy Loss                     -18630.6
Q Predictions Mean               18250.5
Q Predictions Std                23341.2
Q Predictions Max                91298.1
Q Predictions Min                  238.552
V Predictions Mean               18858.8
V Predictions Std                24022.2
V Predictions Max                95416.9
V Predictions Min                  418.462
R Predictions Mean                 327.118
R Predictions Std                 1009.35
R Predictions Max                 7042.74
R Predictions Min                  -10.2487
Log Pis Mean                        17.2198
Log Pis Std                          7.2063
Log Pis Max                         43.7415
Log Pis Min                         -2.82451
Policy mu Mean                      -0.714276
Policy mu Std                        5.39121
Policy mu Max                       34.8625
Policy mu Min                      -19.7754
Policy log std Mean                 -0.526098
Policy log std Std                   0.411069
Policy log std Max                   2
Policy log std Min                  -1.35261
_task0 Rewards Mean                 17.8066
_task0 Rewards Std                  36.5784
_task0 Rewards Max                 144.297
_task0 Rewards Min                  -0.782116
_task0 Returns Mean               2670.99
_task0 Returns Std                5147.47
_task0 Returns Max               15981.3
_task0 Returns Min                 -95.2849
_task0 Actions Mean                 -0.104312
_task0 Actions Std                   0.748081
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     450.528
Exploration_task0 Rewards Std     1251.39
Exploration_task0 Rewards Max     9738.2
Exploration_task0 Rewards Min       -8.81958
Exploration_task0 Returns Mean   68261.9
Exploration_task0 Returns Std   169585
Exploration_task0 Returns Max   823475
Exploration_task0 Returns Min    -1492.18
Exploration_task0 Actions Mean      -0.084623
Exploration_task0 Actions Std        0.828022
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2670.99
AverageReturn_all_train_tasks     8115.63
AverageReturn_all_test_tasks      2670.99
Number of train steps total       9000
Number of env steps total       451000
Number of rollouts total          3273
Train Time (s)                      97.2176
(Previous) Eval Time (s)            25.3737
Sample Time (s)                    105.921
Epoch Time (s)                     228.512
Total Train Time (s)              2062.74
Epoch                                8
------------------------------  ----------------
2019-06-27 01:07:14.658906 UTC | [dialturn] Iteration #8 | Epoch Duration: 228.57602429389954
2019-06-27 01:07:14.659141 UTC | [dialturn] Iteration #8 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00832934
Z variance train                     0.999186
KL Divergence                        0.00791651
KL Loss                              0.000791651
QF Loss                              1.12415e+07
VF Loss                          75031.6
RF Loss                          73983.5
Policy Loss                     -20522.1
Q Predictions Mean               20046.4
Q Predictions Std                25909.9
Q Predictions Max               104193
Q Predictions Min                  276.244
V Predictions Mean               20607
V Predictions Std                26576
V Predictions Max               108109
V Predictions Min                  439.567
R Predictions Mean                 513.231
R Predictions Std                 1045.15
R Predictions Max                 5856.93
R Predictions Min                  -16.35
Log Pis Mean                        18.1061
Log Pis Std                          7.3432
Log Pis Max                         48.5286
Log Pis Min                         -1.23681
Policy mu Mean                      -0.886191
Policy mu Std                        4.45284
Policy mu Max                       23.9108
Policy mu Min                      -18.1687
Policy log std Mean                 -0.567529
Policy log std Std                   0.345357
Policy log std Max                   1.9271
Policy log std Min                  -2.60684
_task0 Rewards Mean                 59.9637
_task0 Rewards Std                 126.613
_task0 Rewards Max                 518.952
_task0 Rewards Min                  -0.939883
_task0 Returns Mean               8994.56
_task0 Returns Std               18339
_task0 Returns Max               61284.4
_task0 Returns Min                -120.179
_task0 Actions Mean                 -0.242294
_task0 Actions Std                   0.779579
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     564.512
Exploration_task0 Rewards Std     1206.73
Exploration_task0 Rewards Max     7255.34
Exploration_task0 Rewards Min       -9.99518
Exploration_task0 Returns Mean   85532.2
Exploration_task0 Returns Std   169018
Exploration_task0 Returns Max   770466
Exploration_task0 Returns Min    -1261.22
Exploration_task0 Actions Mean      -0.181163
Exploration_task0 Actions Std        0.831616
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8994.56
AverageReturn_all_train_tasks    10809.1
AverageReturn_all_test_tasks      8994.56
Number of train steps total      10000
Number of env steps total       501000
Number of rollouts total          3636
Train Time (s)                      96.6751
(Previous) Eval Time (s)            25.4361
Sample Time (s)                    105.908
Epoch Time (s)                     228.019
Total Train Time (s)              2290.84
Epoch                                9
------------------------------  ----------------
2019-06-27 01:11:02.756960 UTC | [dialturn] Iteration #9 | Epoch Duration: 228.09763431549072
2019-06-27 01:11:02.757163 UTC | [dialturn] Iteration #9 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00192243
Z variance train                     0.995068
KL Divergence                        0.00380217
KL Loss                              0.000380217
QF Loss                              1.36893e+07
VF Loss                          99798.6
RF Loss                         157588
Policy Loss                     -22241.2
Q Predictions Mean               21863.4
Q Predictions Std                28402.7
Q Predictions Max               117943
Q Predictions Min                  329.426
V Predictions Mean               22308.9
V Predictions Std                28881.3
V Predictions Max               121160
V Predictions Min                  484.178
R Predictions Mean                 366.405
R Predictions Std                 1106.7
R Predictions Max                 7997.21
R Predictions Min                  -19.9196
Log Pis Mean                        20.049
Log Pis Std                          5.87111
Log Pis Max                         47.2828
Log Pis Min                          1.58099
Policy mu Mean                      -1.27052
Policy mu Std                        4.11965
Policy mu Max                       19.1355
Policy mu Min                      -24.3951
Policy log std Mean                 -0.731706
Policy log std Std                   0.353629
Policy log std Max                   1.56599
Policy log std Min                  -2.13147
_task0 Rewards Mean                 24.0273
_task0 Rewards Std                  66.3702
_task0 Rewards Max                 344.032
_task0 Rewards Min                  -0.863071
_task0 Returns Mean               3604.09
_task0 Returns Std                9399.86
_task0 Returns Max               39035.6
_task0 Returns Min                 -95.4654
_task0 Actions Mean                 -0.139221
_task0 Actions Std                   0.769007
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     221.996
Exploration_task0 Rewards Std      691.507
Exploration_task0 Rewards Max     6006.16
Exploration_task0 Rewards Min      -10.3638
Exploration_task0 Returns Mean   33635.7
Exploration_task0 Returns Std    96939.8
Exploration_task0 Returns Max   712002
Exploration_task0 Returns Min    -1413.25
Exploration_task0 Actions Mean      -0.156165
Exploration_task0 Actions Std        0.80749
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3604.09
AverageReturn_all_train_tasks      553.263
AverageReturn_all_test_tasks      3604.09
Number of train steps total      11000
Number of env steps total       551000
Number of rollouts total          3999
Train Time (s)                      96.3867
(Previous) Eval Time (s)            25.5136
Sample Time (s)                    106.395
Epoch Time (s)                     228.296
Total Train Time (s)              2519.22
Epoch                               10
------------------------------  ----------------
2019-06-27 01:14:51.143242 UTC | [dialturn] Iteration #10 | Epoch Duration: 228.38584280014038
2019-06-27 01:14:51.143439 UTC | [dialturn] Iteration #10 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00622651
Z variance train                     0.997385
KL Divergence                        0.00627086
KL Loss                              0.000627086
QF Loss                              3.86842e+07
VF Loss                         177372
RF Loss                         996766
Policy Loss                     -25914.3
Q Predictions Mean               25374.4
Q Predictions Std                33001
Q Predictions Max               129739
Q Predictions Min                  385.87
V Predictions Mean               26172.1
V Predictions Std                33685.1
V Predictions Max               134326
V Predictions Min                  587.183
R Predictions Mean                 573.989
R Predictions Std                 1607.98
R Predictions Max                11451.5
R Predictions Min                  -12.8345
Log Pis Mean                        20.8955
Log Pis Std                          5.51534
Log Pis Max                         42.1002
Log Pis Min                          0.423662
Policy mu Mean                      -1.10883
Policy mu Std                        4.75046
Policy mu Max                       23.977
Policy mu Min                      -27.239
Policy log std Mean                 -0.759917
Policy log std Std                   0.351146
Policy log std Max                   1.59284
Policy log std Min                  -2.04408
_task0 Rewards Mean                 35.8524
_task0 Rewards Std                  99.2244
_task0 Rewards Max                 556.386
_task0 Rewards Min                  -0.937999
_task0 Returns Mean               5377.86
_task0 Returns Std               13939.6
_task0 Returns Max               45338.9
_task0 Returns Min                -122.058
_task0 Actions Mean                 -0.185333
_task0 Actions Std                   0.773319
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     352.876
Exploration_task0 Rewards Std      844.861
Exploration_task0 Rewards Max     7012.57
Exploration_task0 Rewards Min       -9.4881
Exploration_task0 Returns Mean   53466
Exploration_task0 Returns Std   114942
Exploration_task0 Returns Max   773372
Exploration_task0 Returns Min    -1652.89
Exploration_task0 Actions Mean      -0.183594
Exploration_task0 Actions Std        0.826777
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5377.86
AverageReturn_all_train_tasks     4572.08
AverageReturn_all_test_tasks      5377.86
Number of train steps total      12000
Number of env steps total       601000
Number of rollouts total          4362
Train Time (s)                      97.9016
(Previous) Eval Time (s)            25.6024
Sample Time (s)                    105.952
Epoch Time (s)                     229.456
Total Train Time (s)              2748.53
Epoch                               11
------------------------------  ----------------
2019-06-27 01:18:40.457142 UTC | [dialturn] Iteration #11 | Epoch Duration: 229.31354308128357
2019-06-27 01:18:40.457346 UTC | [dialturn] Iteration #11 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00250361
Z variance train                     0.997453
KL Divergence                        0.000659324
KL Loss                              6.59324e-05
QF Loss                              3.72622e+07
VF Loss                         137290
RF Loss                          66185.6
Policy Loss                     -26954.5
Q Predictions Mean               26421.9
Q Predictions Std                34717.2
Q Predictions Max               140286
Q Predictions Min                  480.383
V Predictions Mean               26798.7
V Predictions Std                34993.7
V Predictions Max               143830
V Predictions Min                  732.774
R Predictions Mean                 405.161
R Predictions Std                  939.582
R Predictions Max                 4921.45
R Predictions Min                  -12.745
Log Pis Mean                        18.7946
Log Pis Std                          5.48163
Log Pis Max                         41.5401
Log Pis Min                          0.397425
Policy mu Mean                      -1.06623
Policy mu Std                        4.47541
Policy mu Max                       29.0973
Policy mu Min                      -28.9743
Policy log std Mean                 -0.70782
Policy log std Std                   0.400288
Policy log std Max                   2
Policy log std Min                  -2.13508
_task0 Rewards Mean                 32.8445
_task0 Rewards Std                  77.3563
_task0 Rewards Max                 461.235
_task0 Rewards Min                  -0.938002
_task0 Returns Mean               4926.68
_task0 Returns Std               10980.8
_task0 Returns Max               32743.9
_task0 Returns Min                -124.287
_task0 Actions Mean                 -0.119971
_task0 Actions Std                   0.743408
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     419.343
Exploration_task0 Rewards Std      947.067
Exploration_task0 Rewards Max     6484.33
Exploration_task0 Rewards Min      -11.8735
Exploration_task0 Returns Mean   63536.8
Exploration_task0 Returns Std   129539
Exploration_task0 Returns Max   802602
Exploration_task0 Returns Min    -1725.98
Exploration_task0 Actions Mean      -0.146177
Exploration_task0 Actions Std        0.808185
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4926.68
AverageReturn_all_train_tasks      542.094
AverageReturn_all_test_tasks      4926.68
Number of train steps total      13000
Number of env steps total       651000
Number of rollouts total          4725
Train Time (s)                      97.8711
(Previous) Eval Time (s)            25.459
Sample Time (s)                    106.073
Epoch Time (s)                     229.403
Total Train Time (s)              2977.51
Epoch                               12
------------------------------  ----------------
2019-06-27 01:22:29.434776 UTC | [dialturn] Iteration #12 | Epoch Duration: 228.97723865509033
2019-06-27 01:22:29.434979 UTC | [dialturn] Iteration #12 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00843038
Z variance train                     1.0016
KL Divergence                        0.00657732
KL Loss                              0.000657732
QF Loss                              2.98865e+07
VF Loss                         163878
RF Loss                         126215
Policy Loss                     -31243.3
Q Predictions Mean               30657.3
Q Predictions Std                38466.1
Q Predictions Max               149715
Q Predictions Min                  767.165
V Predictions Mean               31013.5
V Predictions Std                38667.8
V Predictions Max               152528
V Predictions Min                  583.655
R Predictions Mean                 399.586
R Predictions Std                  936.562
R Predictions Max                 4764.7
R Predictions Min                  -39.094
Log Pis Mean                        20.5471
Log Pis Std                          4.83087
Log Pis Max                         42.7671
Log Pis Min                          2.16832
Policy mu Mean                      -1.28892
Policy mu Std                        4.21345
Policy mu Max                       31.2035
Policy mu Min                      -25.5613
Policy log std Mean                 -0.683151
Policy log std Std                   0.27097
Policy log std Max                   2
Policy log std Min                  -1.6996
_task0 Rewards Mean                 49.1762
_task0 Rewards Std                  76.1481
_task0 Rewards Max                 215.973
_task0 Rewards Min                  -0.874246
_task0 Returns Mean               7376.44
_task0 Returns Std               11309.3
_task0 Returns Max               29573.9
_task0 Returns Min                -113.484
_task0 Actions Mean                 -0.164995
_task0 Actions Std                   0.828049
_task0 Actions Max                   0.999943
_task0 Actions Min                  -0.999994
Num Paths                          363
Exploration_task0 Rewards Mean     387.161
Exploration_task0 Rewards Std      784.499
Exploration_task0 Rewards Max     5278.86
Exploration_task0 Rewards Min      -10.0395
Exploration_task0 Returns Mean   58660.8
Exploration_task0 Returns Std   104753
Exploration_task0 Returns Max   330187
Exploration_task0 Returns Min    -1403.32
Exploration_task0 Actions Mean      -0.148791
Exploration_task0 Actions Std        0.838726
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7376.44
AverageReturn_all_train_tasks     3175.84
AverageReturn_all_test_tasks      7376.44
Number of train steps total      14000
Number of env steps total       701000
Number of rollouts total          5088
Train Time (s)                      96.4963
(Previous) Eval Time (s)            25.0318
Sample Time (s)                    105.156
Epoch Time (s)                     226.684
Total Train Time (s)              3204.78
Epoch                               13
------------------------------  ----------------
2019-06-27 01:26:16.709683 UTC | [dialturn] Iteration #13 | Epoch Duration: 227.27447390556335
2019-06-27 01:26:16.709879 UTC | [dialturn] Iteration #13 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00318201
Z variance train                     0.986115
KL Divergence                        0.00349763
KL Loss                              0.000349763
QF Loss                              4.19366e+07
VF Loss                         106120
RF Loss                         149291
Policy Loss                     -31264
Q Predictions Mean               30708.9
Q Predictions Std                39600.9
Q Predictions Max               157254
Q Predictions Min                 1053.9
V Predictions Mean               31298.5
V Predictions Std                40049.3
V Predictions Max               161282
V Predictions Min                 1243.62
R Predictions Mean                 334.803
R Predictions Std                  663.179
R Predictions Max                 3538.68
R Predictions Min                  -18.4193
Log Pis Mean                        19.7483
Log Pis Std                          4.70765
Log Pis Max                         41.9188
Log Pis Min                         -0.855934
Policy mu Mean                      -1.32982
Policy mu Std                        5.09722
Policy mu Max                       39.4706
Policy mu Min                      -44.1889
Policy log std Mean                 -0.621923
Policy log std Std                   0.305921
Policy log std Max                   2
Policy log std Min                  -1.74201
_task0 Rewards Mean                 49.7146
_task0 Rewards Std                  95.8413
_task0 Rewards Max                 343.626
_task0 Rewards Min                  -0.917872
_task0 Returns Mean               7457.19
_task0 Returns Std               14048.8
_task0 Returns Max               40058.3
_task0 Returns Min                -108.107
_task0 Actions Mean                 -0.206222
_task0 Actions Std                   0.795309
_task0 Actions Max                   0.999898
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     373.88
Exploration_task0 Rewards Std      732.682
Exploration_task0 Rewards Max     5745.36
Exploration_task0 Rewards Min       -9.38006
Exploration_task0 Returns Mean   56648.5
Exploration_task0 Returns Std   106575
Exploration_task0 Returns Max   462325
Exploration_task0 Returns Min    -1530.81
Exploration_task0 Actions Mean      -0.141734
Exploration_task0 Actions Std        0.828864
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7457.19
AverageReturn_all_train_tasks    10962.1
AverageReturn_all_test_tasks      7457.19
Number of train steps total      15000
Number of env steps total       751000
Number of rollouts total          5451
Train Time (s)                      96.9652
(Previous) Eval Time (s)            25.6205
Sample Time (s)                    106.327
Epoch Time (s)                     228.913
Total Train Time (s)              3433.42
Epoch                               14
------------------------------  ----------------
2019-06-27 01:30:05.354582 UTC | [dialturn] Iteration #14 | Epoch Duration: 228.6445415019989
2019-06-27 01:30:05.354784 UTC | [dialturn] Iteration #14 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00179843
Z variance train                     1.0027
KL Divergence                        0.00120296
KL Loss                              0.000120296
QF Loss                              2.81277e+07
VF Loss                          68301.3
RF Loss                          21768
Policy Loss                     -33307.1
Q Predictions Mean               32870.5
Q Predictions Std                41486
Q Predictions Max               161686
Q Predictions Min                 1286.36
V Predictions Mean               33345.3
V Predictions Std                41960.1
V Predictions Max               164679
V Predictions Min                 1436.43
R Predictions Mean                 385.545
R Predictions Std                  776.347
R Predictions Max                 5458.9
R Predictions Min                  -30.7129
Log Pis Mean                        18.6446
Log Pis Std                          5.18858
Log Pis Max                         52.063
Log Pis Min                          2.97435
Policy mu Mean                      -1.2194
Policy mu Std                        3.75668
Policy mu Max                       24.9158
Policy mu Min                      -28.1003
Policy log std Mean                 -0.70075
Policy log std Std                   0.213929
Policy log std Max                   2
Policy log std Min                  -2.45249
_task0 Rewards Mean                 11.148
_task0 Rewards Std                  26.0096
_task0 Rewards Max                 133.015
_task0 Rewards Min                  -0.809564
_task0 Returns Mean               1672.2
_task0 Returns Std                3573.49
_task0 Returns Max               12368.6
_task0 Returns Min                -102.794
_task0 Actions Mean                 -0.157488
_task0 Actions Std                   0.769586
_task0 Actions Max                   0.99987
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     545.492
Exploration_task0 Rewards Std     1135.94
Exploration_task0 Rewards Max     9082.28
Exploration_task0 Rewards Min      -10.0027
Exploration_task0 Returns Mean   82650.3
Exploration_task0 Returns Std   161023
Exploration_task0 Returns Max   837954
Exploration_task0 Returns Min    -1471.43
Exploration_task0 Actions Mean      -0.15378
Exploration_task0 Actions Std        0.813824
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1672.2
AverageReturn_all_train_tasks     4554.44
AverageReturn_all_test_tasks      1672.2
Number of train steps total      16000
Number of env steps total       801000
Number of rollouts total          5814
Train Time (s)                      96.5208
(Previous) Eval Time (s)            25.3509
Sample Time (s)                    106.788
Epoch Time (s)                     228.66
Total Train Time (s)              3662.42
Epoch                               15
------------------------------  ----------------
2019-06-27 01:33:54.350658 UTC | [dialturn] Iteration #15 | Epoch Duration: 228.99566960334778
2019-06-27 01:33:54.350849 UTC | [dialturn] Iteration #15 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00158333
Z variance train                     0.998525
KL Divergence                        0.000250669
KL Loss                              2.50669e-05
QF Loss                              3.49384e+07
VF Loss                         204641
RF Loss                          13142.2
Policy Loss                     -36879.4
Q Predictions Mean               36325.8
Q Predictions Std                45559.8
Q Predictions Max               166320
Q Predictions Min                 1573.06
V Predictions Mean               36634.8
V Predictions Std                45850.8
V Predictions Max               168628
V Predictions Min                 1672.5
R Predictions Mean                 484.625
R Predictions Std                  913.985
R Predictions Max                 3629
R Predictions Min                  -45.6031
Log Pis Mean                        19.7428
Log Pis Std                          4.79122
Log Pis Max                         45.4341
Log Pis Min                          4.29454
Policy mu Mean                      -1.34898
Policy mu Std                        4.13643
Policy mu Max                       28.2697
Policy mu Min                      -31.7635
Policy log std Mean                 -0.684732
Policy log std Std                   0.304432
Policy log std Max                   2
Policy log std Min                  -2.33967
_task0 Rewards Mean                 36.2939
_task0 Rewards Std                  74.9469
_task0 Rewards Max                 397.424
_task0 Rewards Min                  -0.854232
_task0 Returns Mean               5444.08
_task0 Returns Std               10920.9
_task0 Returns Max               43975.3
_task0 Returns Min                -112.057
_task0 Actions Mean                 -0.187563
_task0 Actions Std                   0.74057
_task0 Actions Max                   0.999942
_task0 Actions Min                  -0.999999
Num Paths                          363
Exploration_task0 Rewards Mean     391.515
Exploration_task0 Rewards Std      826.05
Exploration_task0 Rewards Max     6494.63
Exploration_task0 Rewards Min       -9.38007
Exploration_task0 Returns Mean   59320.5
Exploration_task0 Returns Std   117537
Exploration_task0 Returns Max   535111
Exploration_task0 Returns Min    -1187.12
Exploration_task0 Actions Mean      -0.198697
Exploration_task0 Actions Std        0.838121
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5444.08
AverageReturn_all_train_tasks    10227.2
AverageReturn_all_test_tasks      5444.08
Number of train steps total      17000
Number of env steps total       851000
Number of rollouts total          6177
Train Time (s)                      96.3248
(Previous) Eval Time (s)            25.6855
Sample Time (s)                    106.608
Epoch Time (s)                     228.618
Total Train Time (s)              3890.78
Epoch                               16
------------------------------  ----------------
2019-06-27 01:37:42.713480 UTC | [dialturn] Iteration #16 | Epoch Duration: 228.36247634887695
2019-06-27 01:37:42.713707 UTC | [dialturn] Iteration #16 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00657337
Z variance train                     0.998414
KL Divergence                        0.00372602
KL Loss                              0.000372602
QF Loss                              6.53697e+07
VF Loss                         105329
RF Loss                         304032
Policy Loss                     -37544.9
Q Predictions Mean               37117.7
Q Predictions Std                46877.4
Q Predictions Max               165978
Q Predictions Min                 1655.79
V Predictions Mean               37585.3
V Predictions Std                47356.9
V Predictions Max               169336
V Predictions Min                 1917.83
R Predictions Mean                 694.626
R Predictions Std                 1207.78
R Predictions Max                 5722.29
R Predictions Min                   -9.94616
Log Pis Mean                        18.6952
Log Pis Std                          4.89797
Log Pis Max                         39.679
Log Pis Min                         -1.03936
Policy mu Mean                      -1.14134
Policy mu Std                        5.38453
Policy mu Max                       49.432
Policy mu Min                      -44.0304
Policy log std Mean                 -0.67681
Policy log std Std                   0.316568
Policy log std Max                   2
Policy log std Min                  -1.68439
_task0 Rewards Mean                 18.0778
_task0 Rewards Std                  50.1612
_task0 Rewards Max                 197.179
_task0 Rewards Min                  -0.803171
_task0 Returns Mean               2711.67
_task0 Returns Std                7421.76
_task0 Returns Max               23444.9
_task0 Returns Min                 -89.3859
_task0 Actions Mean                 -0.149095
_task0 Actions Std                   0.795529
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     572.651
Exploration_task0 Rewards Std     1139.39
Exploration_task0 Rewards Max    13792.7
Exploration_task0 Rewards Min       -9.53186
Exploration_task0 Returns Mean   86765.3
Exploration_task0 Returns Std   159360
Exploration_task0 Returns Max   807933
Exploration_task0 Returns Min    -1400.38
Exploration_task0 Actions Mean      -0.177976
Exploration_task0 Actions Std        0.825291
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2711.67
AverageReturn_all_train_tasks      295.474
AverageReturn_all_test_tasks      2711.67
Number of train steps total      18000
Number of env steps total       901000
Number of rollouts total          6540
Train Time (s)                      97.4397
(Previous) Eval Time (s)            25.4285
Sample Time (s)                    106.617
Epoch Time (s)                     229.485
Total Train Time (s)              4120.35
Epoch                               17
------------------------------  ----------------
2019-06-27 01:41:32.288494 UTC | [dialturn] Iteration #17 | Epoch Duration: 229.57462620735168
2019-06-27 01:41:32.288715 UTC | [dialturn] Iteration #17 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00237972
Z variance train                     1.01385
KL Divergence                        0.00620791
KL Loss                              0.000620791
QF Loss                              1.08697e+08
VF Loss                              2.22663e+06
RF Loss                          20938
Policy Loss                     -37098.2
Q Predictions Mean               36723.7
Q Predictions Std                46744.9
Q Predictions Max               214122
Q Predictions Min                 2111.55
V Predictions Mean               38069.1
V Predictions Std                47489.3
V Predictions Max               248063
V Predictions Min                 2596.13
R Predictions Mean                 143.386
R Predictions Std                  364.572
R Predictions Max                 3527.24
R Predictions Min                  -16.8705
Log Pis Mean                        19.192
Log Pis Std                          6.32023
Log Pis Max                         46.4559
Log Pis Min                          0.764643
Policy mu Mean                      -0.682435
Policy mu Std                        4.81559
Policy mu Max                       42.0429
Policy mu Min                      -32.453
Policy log std Mean                 -0.952571
Policy log std Std                   0.684229
Policy log std Max                   2
Policy log std Min                  -4.0119
_task0 Rewards Mean                 10.4932
_task0 Rewards Std                  28.7581
_task0 Rewards Max                 156.216
_task0 Rewards Min                  -0.652253
_task0 Returns Mean               1573.98
_task0 Returns Std                4146.39
_task0 Returns Max               14790.5
_task0 Returns Min                 -84.3001
_task0 Actions Mean                 -0.0623084
_task0 Actions Std                   0.791611
_task0 Actions Max                   0.999999
_task0 Actions Min                  -0.999997
Num Paths                          363
Exploration_task0 Rewards Mean     110.736
Exploration_task0 Rewards Std      367.592
Exploration_task0 Rewards Max     5934.4
Exploration_task0 Rewards Min      -10.6158
Exploration_task0 Returns Mean   16778.1
Exploration_task0 Returns Std    45048.9
Exploration_task0 Returns Max   248454
Exploration_task0 Returns Min    -1425.69
Exploration_task0 Actions Mean      -0.137282
Exploration_task0 Actions Std        0.822167
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1573.98
AverageReturn_all_train_tasks     6146.31
AverageReturn_all_test_tasks      1573.98
Number of train steps total      19000
Number of env steps total       951000
Number of rollouts total          6903
Train Time (s)                      97.2398
(Previous) Eval Time (s)            25.5164
Sample Time (s)                    106.796
Epoch Time (s)                     229.552
Total Train Time (s)              4349.84
Epoch                               18
------------------------------  ----------------
2019-06-27 01:45:21.779600 UTC | [dialturn] Iteration #18 | Epoch Duration: 229.4907100200653
2019-06-27 01:45:21.779821 UTC | [dialturn] Iteration #18 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00241216
Z variance train                     1.0016
KL Divergence                        0.000415712
KL Loss                              4.15712e-05
QF Loss                              4.76952e+07
VF Loss                         142155
RF Loss                          20409.6
Policy Loss                     -39318.4
Q Predictions Mean               38680.9
Q Predictions Std                48283.1
Q Predictions Max               224291
Q Predictions Min                 2848.94
V Predictions Mean               39405.8
V Predictions Std                48733.7
V Predictions Max               228458
V Predictions Min                 3136.65
R Predictions Mean                 264.3
R Predictions Std                  487.039
R Predictions Max                 2014.27
R Predictions Min                  -38.2017
Log Pis Mean                        19.3399
Log Pis Std                          6.40782
Log Pis Max                         48.3444
Log Pis Min                          2.73108
Policy mu Mean                      -0.870136
Policy mu Std                        4.33021
Policy mu Max                       34.9271
Policy mu Min                      -25.1884
Policy log std Mean                 -0.870725
Policy log std Std                   0.801156
Policy log std Max                   2
Policy log std Min                  -3.9309
_task0 Rewards Mean                  2.36022
_task0 Rewards Std                  15.7432
_task0 Rewards Max                 167.3
_task0 Rewards Min                  -1.0487
_task0 Returns Mean                354.033
_task0 Returns Std                1015.67
_task0 Returns Max                4301.53
_task0 Returns Min                -117.742
_task0 Actions Mean                 -0.099461
_task0 Actions Std                   0.851767
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     251.298
Exploration_task0 Rewards Std      502.096
Exploration_task0 Rewards Max     2353.33
Exploration_task0 Rewards Min      -11.2724
Exploration_task0 Returns Mean   38075.4
Exploration_task0 Returns Std    72346.3
Exploration_task0 Returns Max   233174
Exploration_task0 Returns Min    -1473.12
Exploration_task0 Actions Mean      -0.0968489
Exploration_task0 Actions Std        0.839379
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0               354.033
AverageReturn_all_train_tasks      162.223
AverageReturn_all_test_tasks       354.033
Number of train steps total      20000
Number of env steps total            1.001e+06
Number of rollouts total          7266
Train Time (s)                      96.7507
(Previous) Eval Time (s)            25.4532
Sample Time (s)                    106.062
Epoch Time (s)                     228.266
Total Train Time (s)              4577.99
Epoch                               19
------------------------------  ----------------
2019-06-27 01:49:09.929409 UTC | [dialturn] Iteration #19 | Epoch Duration: 228.14937663078308
2019-06-27 01:49:09.929665 UTC | [dialturn] Iteration #19 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00194626
Z variance train                     0.998437
KL Divergence                        0.000936626
KL Loss                              9.36626e-05
QF Loss                              3.87586e+07
VF Loss                         229213
RF Loss                              1.09735e+06
Policy Loss                     -39948.7
Q Predictions Mean               39417.4
Q Predictions Std                49207.7
Q Predictions Max               230754
Q Predictions Min                 3246.37
V Predictions Mean               39834.6
V Predictions Std                49410.6
V Predictions Max               236189
V Predictions Min                 3411.29
R Predictions Mean                 453.427
R Predictions Std                  954.636
R Predictions Max                 4589.07
R Predictions Min                  -29.5204
Log Pis Mean                        20.6145
Log Pis Std                          7.54147
Log Pis Max                         46.4304
Log Pis Min                         -1.46264
Policy mu Mean                      -1.09667
Policy mu Std                        5.06407
Policy mu Max                       38.1855
Policy mu Min                      -33.2921
Policy log std Mean                 -0.944687
Policy log std Std                   0.785725
Policy log std Max                   2
Policy log std Min                  -3.8525
_task0 Rewards Mean                 20.4694
_task0 Rewards Std                  60.6698
_task0 Rewards Max                 609.626
_task0 Rewards Min                  -0.881963
_task0 Returns Mean               3070.41
_task0 Returns Std                5946.92
_task0 Returns Max               17494.9
_task0 Returns Min                -114.157
_task0 Actions Mean                  0.14671
_task0 Actions Std                   0.812042
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean      56.0749
Exploration_task0 Rewards Std      322.55
Exploration_task0 Rewards Max     8473.86
Exploration_task0 Rewards Min      -10.9525
Exploration_task0 Returns Mean    8496.2
Exploration_task0 Returns Std    31740.7
Exploration_task0 Returns Max   258581
Exploration_task0 Returns Min    -1460.88
Exploration_task0 Actions Mean      -0.0779359
Exploration_task0 Actions Std        0.856752
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3070.41
AverageReturn_all_train_tasks      440.802
AverageReturn_all_test_tasks      3070.41
Number of train steps total      21000
Number of env steps total            1.051e+06
Number of rollouts total          7629
Train Time (s)                      96.672
(Previous) Eval Time (s)            25.3354
Sample Time (s)                    105.836
Epoch Time (s)                     227.844
Total Train Time (s)              4805.93
Epoch                               20
------------------------------  ----------------
2019-06-27 01:52:57.876859 UTC | [dialturn] Iteration #20 | Epoch Duration: 227.94696164131165
2019-06-27 01:52:57.877105 UTC | [dialturn] Iteration #20 | Started Training: True
------------------------------  ----------------
Z mean train                         0.004607
Z variance train                     0.995706
KL Divergence                        0.00205598
KL Loss                              0.000205598
QF Loss                              2.92232e+07
VF Loss                         558822
RF Loss                         423641
Policy Loss                     -39492.2
Q Predictions Mean               38863.3
Q Predictions Std                48949.1
Q Predictions Max               231940
Q Predictions Min                 3353.78
V Predictions Mean               38941
V Predictions Std                49105.8
V Predictions Max               236674
V Predictions Min                 3387.26
R Predictions Mean                 103.07
R Predictions Std                  292.59
R Predictions Max                 1297.81
R Predictions Min                  -69.8014
Log Pis Mean                        24.168
Log Pis Std                          9.89937
Log Pis Max                         50.5047
Log Pis Min                         -4.62351
Policy mu Mean                       0.908675
Policy mu Std                       10.5042
Policy mu Max                      132.746
Policy mu Min                      -27.8232
Policy log std Mean                 -0.625827
Policy log std Std                   0.930627
Policy log std Max                   2
Policy log std Min                  -3.01094
_task0 Rewards Mean                 60.9661
_task0 Rewards Std                 109.792
_task0 Rewards Max                1083.11
_task0 Rewards Min                  -0.879924
_task0 Returns Mean               9144.92
_task0 Returns Std               13385.9
_task0 Returns Max               34904.5
_task0 Returns Min                -113.93
_task0 Actions Mean                 -0.119045
_task0 Actions Std                   0.8719
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     242.434
Exploration_task0 Rewards Std      649.326
Exploration_task0 Rewards Max    12872.7
Exploration_task0 Rewards Min      -11.3181
Exploration_task0 Returns Mean   36732.5
Exploration_task0 Returns Std    64577.7
Exploration_task0 Returns Max   276603
Exploration_task0 Returns Min    -1508.15
Exploration_task0 Actions Mean       0.173852
Exploration_task0 Actions Std        0.82708
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9144.92
AverageReturn_all_train_tasks     7153.71
AverageReturn_all_test_tasks      9144.92
Number of train steps total      22000
Number of env steps total            1.101e+06
Number of rollouts total          7992
Train Time (s)                      97.5302
(Previous) Eval Time (s)            25.4374
Sample Time (s)                    106.199
Epoch Time (s)                     229.167
Total Train Time (s)              5035.15
Epoch                               21
------------------------------  ----------------
2019-06-27 01:56:47.097968 UTC | [dialturn] Iteration #21 | Epoch Duration: 229.2206835746765
2019-06-27 01:56:47.098159 UTC | [dialturn] Iteration #21 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0017766
Z variance train                     1.00651
KL Divergence                        0.00106817
KL Loss                              0.000106817
QF Loss                              5.97175e+07
VF Loss                         238773
RF Loss                         588716
Policy Loss                     -39325.9
Q Predictions Mean               38927.6
Q Predictions Std                49271.5
Q Predictions Max               218487
Q Predictions Min                 3527.85
V Predictions Mean               39025.8
V Predictions Std                49452.7
V Predictions Max               218793
V Predictions Min                 3683.36
R Predictions Mean                 211.031
R Predictions Std                  364.27
R Predictions Max                 1718.22
R Predictions Min                  -18.6021
Log Pis Mean                        22.2511
Log Pis Std                         11.236
Log Pis Max                         49.414
Log Pis Min                         -2.22147
Policy mu Mean                      -2.02767
Policy mu Std                       10.1555
Policy mu Max                       48.6127
Policy mu Min                      -35.3725
Policy log std Mean                 -0.576696
Policy log std Std                   1.1117
Policy log std Max                   2
Policy log std Min                  -3.52798
_task0 Rewards Mean                 27.596
_task0 Rewards Std                  77.6278
_task0 Rewards Max                 574.124
_task0 Rewards Min                  -0.844278
_task0 Returns Mean               4139.4
_task0 Returns Std                5917.07
_task0 Returns Max               14661.9
_task0 Returns Min                -105.56
_task0 Actions Mean                  0.0267009
_task0 Actions Std                   0.849503
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     465.178
Exploration_task0 Rewards Std     1066.79
Exploration_task0 Rewards Max    13698.7
Exploration_task0 Rewards Min       -9.91531
Exploration_task0 Returns Mean   70481.5
Exploration_task0 Returns Std   118701
Exploration_task0 Returns Max   562299
Exploration_task0 Returns Min    -1325.89
Exploration_task0 Actions Mean      -0.0679242
Exploration_task0 Actions Std        0.865423
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4139.4
AverageReturn_all_train_tasks     3359.84
AverageReturn_all_test_tasks      4139.4
Number of train steps total      23000
Number of env steps total            1.151e+06
Number of rollouts total          8355
Train Time (s)                      97.4421
(Previous) Eval Time (s)            25.4901
Sample Time (s)                    106.819
Epoch Time (s)                     229.751
Total Train Time (s)              5264.84
Epoch                               22
------------------------------  ----------------
2019-06-27 02:00:36.788840 UTC | [dialturn] Iteration #22 | Epoch Duration: 229.690527677536
2019-06-27 02:00:36.789031 UTC | [dialturn] Iteration #22 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00271944
Z variance train                     1.00052
KL Divergence                        0.00100479
KL Loss                              0.000100479
QF Loss                              5.65556e+07
VF Loss                         143994
RF Loss                         353637
Policy Loss                     -42151.4
Q Predictions Mean               41585.6
Q Predictions Std                51129.2
Q Predictions Max               218793
Q Predictions Min                 3648.47
V Predictions Mean               42368.9
V Predictions Std                51612.1
V Predictions Max               219396
V Predictions Min                 3970.96
R Predictions Mean                 416.134
R Predictions Std                 1281.72
R Predictions Max                 9162.46
R Predictions Min                  -50.082
Log Pis Mean                        22.8961
Log Pis Std                         10.3072
Log Pis Max                         47.5175
Log Pis Min                         -1.33898
Policy mu Mean                      -1.58151
Policy mu Std                        9.92386
Policy mu Max                       64.924
Policy mu Min                      -46.929
Policy log std Mean                 -0.522051
Policy log std Std                   1.01823
Policy log std Max                   2
Policy log std Min                  -3.14801
_task0 Rewards Mean                 24.6231
_task0 Rewards Std                  69.8596
_task0 Rewards Max                 507.591
_task0 Rewards Min                  -0.853139
_task0 Returns Mean               3693.47
_task0 Returns Std                5775.83
_task0 Returns Max               16222.3
_task0 Returns Min                 -99.2876
_task0 Actions Mean                  0.139185
_task0 Actions Std                   0.793153
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     234.792
Exploration_task0 Rewards Std      777.427
Exploration_task0 Rewards Max     8417.98
Exploration_task0 Rewards Min      -10.1391
Exploration_task0 Returns Mean   35574.5
Exploration_task0 Returns Std    54529.5
Exploration_task0 Returns Max   175859
Exploration_task0 Returns Min    -1507.29
Exploration_task0 Actions Mean       0.0563056
Exploration_task0 Actions Std        0.847194
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3693.47
AverageReturn_all_train_tasks     2735.27
AverageReturn_all_test_tasks      3693.47
Number of train steps total      24000
Number of env steps total            1.201e+06
Number of rollouts total          8718
Train Time (s)                      97.58
(Previous) Eval Time (s)            25.4279
Sample Time (s)                    105.933
Epoch Time (s)                     228.941
Total Train Time (s)              5493.56
Epoch                               23
------------------------------  ----------------
2019-06-27 02:04:25.508547 UTC | [dialturn] Iteration #23 | Epoch Duration: 228.71936893463135
2019-06-27 02:04:25.508733 UTC | [dialturn] Iteration #23 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00233116
Z variance train                     1.00006
KL Divergence                        0.000685394
KL Loss                              6.85394e-05
QF Loss                              2.7123e+07
VF Loss                         152223
RF Loss                           5463.68
Policy Loss                     -41377
Q Predictions Mean               40789.6
Q Predictions Std                50955.3
Q Predictions Max               187843
Q Predictions Min                 3550.34
V Predictions Mean               41216.6
V Predictions Std                51253.7
V Predictions Max               186605
V Predictions Min                 3752.5
R Predictions Mean                 240.976
R Predictions Std                  851.902
R Predictions Max                 7350.94
R Predictions Min                 -133.162
Log Pis Mean                        22.0151
Log Pis Std                         10.6361
Log Pis Max                         50.1496
Log Pis Min                         -1.46621
Policy mu Mean                      -0.583082
Policy mu Std                       10.6869
Policy mu Max                       80.7169
Policy mu Min                      -56.2182
Policy log std Mean                 -0.486889
Policy log std Std                   0.851021
Policy log std Max                   2
Policy log std Min                  -2.66169
_task0 Rewards Mean                 26.7906
_task0 Rewards Std                  81.0773
_task0 Rewards Max                 697.161
_task0 Rewards Min                  -0.881962
_task0 Returns Mean               4018.59
_task0 Returns Std                5865.23
_task0 Returns Max               14207.9
_task0 Returns Min                -114.227
_task0 Actions Mean                 -0.0584372
_task0 Actions Std                   0.927303
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     227.876
Exploration_task0 Rewards Std      745.325
Exploration_task0 Rewards Max     8385.28
Exploration_task0 Rewards Min       -9.98537
Exploration_task0 Returns Mean   34526.7
Exploration_task0 Returns Std    53600.9
Exploration_task0 Returns Max   175204
Exploration_task0 Returns Min    -1304.55
Exploration_task0 Actions Mean       0.065216
Exploration_task0 Actions Std        0.862415
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4018.59
AverageReturn_all_train_tasks     2718.34
AverageReturn_all_test_tasks      4018.59
Number of train steps total      25000
Number of env steps total            1.251e+06
Number of rollouts total          9081
Train Time (s)                      97.2272
(Previous) Eval Time (s)            25.2054
Sample Time (s)                    106.313
Epoch Time (s)                     228.745
Total Train Time (s)              5722.39
Epoch                               24
------------------------------  ----------------
2019-06-27 02:08:14.343456 UTC | [dialturn] Iteration #24 | Epoch Duration: 228.83456254005432
2019-06-27 02:08:14.343641 UTC | [dialturn] Iteration #24 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00143935
Z variance train                     0.998085
KL Divergence                        0.000453571
KL Loss                              4.53571e-05
QF Loss                              7.88268e+07
VF Loss                         320606
RF Loss                          15708.7
Policy Loss                     -40905.8
Q Predictions Mean               40365.1
Q Predictions Std                51021.1
Q Predictions Max               230267
Q Predictions Min                 3643.94
V Predictions Mean               41383
V Predictions Std                51541.3
V Predictions Max               234514
V Predictions Min                 3923.27
R Predictions Mean                 242.797
R Predictions Std                  794.449
R Predictions Max                 6572.02
R Predictions Min                 -103.761
Log Pis Mean                        23.8299
Log Pis Std                          9.53748
Log Pis Max                         47.8428
Log Pis Min                         -4.02441
Policy mu Mean                      -0.790403
Policy mu Std                       10.0968
Policy mu Max                       81.8874
Policy mu Min                      -53.8378
Policy log std Mean                 -0.518876
Policy log std Std                   0.907784
Policy log std Max                   2
Policy log std Min                  -3.48695
_task0 Rewards Mean                 23.2025
_task0 Rewards Std                  61.8167
_task0 Rewards Max                 483.396
_task0 Rewards Min                  -0.881947
_task0 Returns Mean               3480.38
_task0 Returns Std                5887.86
_task0 Returns Max               16760.9
_task0 Returns Min                -114.224
_task0 Actions Mean                  0.0435716
_task0 Actions Std                   0.830271
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     210.34
Exploration_task0 Rewards Std      753.362
Exploration_task0 Rewards Max     8852.21
Exploration_task0 Rewards Min      -10.868
Exploration_task0 Returns Mean   31869.6
Exploration_task0 Returns Std    49184.1
Exploration_task0 Returns Max   205296
Exploration_task0 Returns Min    -1186.73
Exploration_task0 Actions Mean       0.118932
Exploration_task0 Actions Std        0.84429
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3480.38
AverageReturn_all_train_tasks     5459.46
AverageReturn_all_test_tasks      3480.38
Number of train steps total      26000
Number of env steps total            1.301e+06
Number of rollouts total          9444
Train Time (s)                      97.532
(Previous) Eval Time (s)            25.2935
Sample Time (s)                    105.861
Epoch Time (s)                     228.687
Total Train Time (s)              5951.18
Epoch                               25
------------------------------  ----------------
2019-06-27 02:12:03.134480 UTC | [dialturn] Iteration #25 | Epoch Duration: 228.79066252708435
2019-06-27 02:12:03.134695 UTC | [dialturn] Iteration #25 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00194635
Z variance train                     1.00227
KL Divergence                        0.000487458
KL Loss                              4.87458e-05
QF Loss                              7.24779e+07
VF Loss                         389244
RF Loss                           9911.37
Policy Loss                     -40378.7
Q Predictions Mean               40038.6
Q Predictions Std                50805.1
Q Predictions Max               211266
Q Predictions Min                 3886.83
V Predictions Mean               40676.8
V Predictions Std                51539.8
V Predictions Max               215796
V Predictions Min                 3775.33
R Predictions Mean                 231.388
R Predictions Std                  578.574
R Predictions Max                 5317.11
R Predictions Min                  -77.464
Log Pis Mean                        21.1966
Log Pis Std                         10.2148
Log Pis Max                         46.7604
Log Pis Min                         -3.25171
Policy mu Mean                      -0.155112
Policy mu Std                        9.63313
Policy mu Max                       64.0953
Policy mu Min                      -43.3512
Policy log std Mean                 -0.564714
Policy log std Std                   0.985582
Policy log std Max                   2
Policy log std Min                  -4.10489
_task0 Rewards Mean                 22.5175
_task0 Rewards Std                  59.7069
_task0 Rewards Max                 478.644
_task0 Rewards Min                  -0.880003
_task0 Returns Mean               3377.63
_task0 Returns Std                6034.43
_task0 Returns Max               16239.2
_task0 Returns Min                -112.714
_task0 Actions Mean                  0.0945964
_task0 Actions Std                   0.845304
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     185.191
Exploration_task0 Rewards Std      546.44
Exploration_task0 Rewards Max     8395.82
Exploration_task0 Rewards Min       -8.8228
Exploration_task0 Returns Mean   28059.2
Exploration_task0 Returns Std    52543
Exploration_task0 Returns Max   168198
Exploration_task0 Returns Min    -1549.33
Exploration_task0 Actions Mean       0.117125
Exploration_task0 Actions Std        0.796757
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3377.63
AverageReturn_all_train_tasks     2839.99
AverageReturn_all_test_tasks      3377.63
Number of train steps total      27000
Number of env steps total            1.351e+06
Number of rollouts total          9807
Train Time (s)                      97.2856
(Previous) Eval Time (s)            25.3961
Sample Time (s)                    106.181
Epoch Time (s)                     228.863
Total Train Time (s)              6180.3
Epoch                               26
------------------------------  ----------------
2019-06-27 02:15:52.253795 UTC | [dialturn] Iteration #26 | Epoch Duration: 229.11891627311707
2019-06-27 02:15:52.253999 UTC | [dialturn] Iteration #26 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00192833
Z variance train                     1.00204
KL Divergence                        0.000328416
KL Loss                              3.28416e-05
QF Loss                              4.41959e+07
VF Loss                          83552.8
RF Loss                          11450.7
Policy Loss                     -41522.3
Q Predictions Mean               41108.9
Q Predictions Std                51737.5
Q Predictions Max               218026
Q Predictions Min                 3453.4
V Predictions Mean               41562.2
V Predictions Std                52204.1
V Predictions Max               217423
V Predictions Min                 3644.95
R Predictions Mean                 161.49
R Predictions Std                  559.568
R Predictions Max                 6317.74
R Predictions Min                  -21.4241
Log Pis Mean                        21.9411
Log Pis Std                         10.5614
Log Pis Max                         47.3198
Log Pis Min                         -3.24508
Policy mu Mean                      -0.715149
Policy mu Std                       10.1728
Policy mu Max                       62.0757
Policy mu Min                      -39.2199
Policy log std Mean                 -0.445682
Policy log std Std                   1.0292
Policy log std Max                   2
Policy log std Min                  -4.42753
_task0 Rewards Mean                 19.4439
_task0 Rewards Std                  47.5258
_task0 Rewards Max                 392.881
_task0 Rewards Min                  -0.797904
_task0 Returns Mean               2916.58
_task0 Returns Std                5308.47
_task0 Returns Max               14817.6
_task0 Returns Min                -103.729
_task0 Actions Mean                  0.0885957
_task0 Actions Std                   0.765565
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     205.047
Exploration_task0 Rewards Std      582.735
Exploration_task0 Rewards Max    21842
Exploration_task0 Rewards Min      -10.3556
Exploration_task0 Returns Mean   31067.8
Exploration_task0 Returns Std    52340.9
Exploration_task0 Returns Max   318289
Exploration_task0 Returns Min    -1326.7
Exploration_task0 Actions Mean       0.0715246
Exploration_task0 Actions Std        0.80208
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2916.58
AverageReturn_all_train_tasks     5022.03
AverageReturn_all_test_tasks      2916.58
Number of train steps total      28000
Number of env steps total            1.401e+06
Number of rollouts total         10170
Train Time (s)                      96.4528
(Previous) Eval Time (s)            25.6505
Sample Time (s)                    106.243
Epoch Time (s)                     228.346
Total Train Time (s)              6408.17
Epoch                               27
------------------------------  ----------------
2019-06-27 02:19:40.124163 UTC | [dialturn] Iteration #27 | Epoch Duration: 227.86998319625854
2019-06-27 02:19:40.124402 UTC | [dialturn] Iteration #27 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00230668
Z variance train                     1.00014
KL Divergence                        0.000763772
KL Loss                              7.63772e-05
QF Loss                              5.44458e+07
VF Loss                         311584
RF Loss                          96854.3
Policy Loss                     -39645.3
Q Predictions Mean               39098.8
Q Predictions Std                50502.7
Q Predictions Max               220950
Q Predictions Min                 3082.45
V Predictions Mean               39170.3
V Predictions Std                50826.2
V Predictions Max               223946
V Predictions Min                 2985.61
R Predictions Mean                 212.439
R Predictions Std                  675.078
R Predictions Max                 8515.44
R Predictions Min                  -34.862
Log Pis Mean                        22.1819
Log Pis Std                         10.1232
Log Pis Max                         46.0154
Log Pis Min                         -3.11182
Policy mu Mean                      -0.902386
Policy mu Std                        9.69805
Policy mu Max                       59.4669
Policy mu Min                      -39.6489
Policy log std Mean                 -0.514726
Policy log std Std                   1.02043
Policy log std Max                   2
Policy log std Min                  -4.68175
_task0 Rewards Mean                 27.5143
_task0 Rewards Std                  65.629
_task0 Rewards Max                 477.889
_task0 Rewards Min                  -0.86366
_task0 Returns Mean               4127.14
_task0 Returns Std                6092.52
_task0 Returns Max               16622.2
_task0 Returns Min                -106.198
_task0 Actions Mean                  0.0382095
_task0 Actions Std                   0.775315
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     270.307
Exploration_task0 Rewards Std      811.774
Exploration_task0 Rewards Max    22555
Exploration_task0 Rewards Min       -9.0408
Exploration_task0 Returns Mean   40955.5
Exploration_task0 Returns Std    71407.2
Exploration_task0 Returns Max   308115
Exploration_task0 Returns Min    -1185.44
Exploration_task0 Actions Mean       0.00170399
Exploration_task0 Actions Std        0.842173
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4127.14
AverageReturn_all_train_tasks     1071.27
AverageReturn_all_test_tasks      4127.14
Number of train steps total      29000
Number of env steps total            1.451e+06
Number of rollouts total         10533
Train Time (s)                      96.9328
(Previous) Eval Time (s)            25.1727
Sample Time (s)                    105.808
Epoch Time (s)                     227.914
Total Train Time (s)              6636.4
Epoch                               28
------------------------------  ----------------
2019-06-27 02:23:28.356389 UTC | [dialturn] Iteration #28 | Epoch Duration: 228.23177313804626
2019-06-27 02:23:28.356674 UTC | [dialturn] Iteration #28 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00257353
Z variance train                     0.997104
KL Divergence                        0.000748594
KL Loss                              7.48594e-05
QF Loss                              1.30548e+08
VF Loss                              1.56906e+06
RF Loss                         137034
Policy Loss                     -41915.5
Q Predictions Mean               41690.6
Q Predictions Std                52358.6
Q Predictions Max               231983
Q Predictions Min                 3176.57
V Predictions Mean               42750.5
V Predictions Std                53358.6
V Predictions Max               238575
V Predictions Min                 3657.2
R Predictions Mean                 286.837
R Predictions Std                  966.081
R Predictions Max                 9709.62
R Predictions Min                  -31.7575
Log Pis Mean                        24.2511
Log Pis Std                         10.3998
Log Pis Max                         48.0322
Log Pis Min                         -3.30613
Policy mu Mean                      -1.57332
Policy mu Std                       11.6024
Policy mu Max                       51.8569
Policy mu Min                      -47.7157
Policy log std Mean                 -0.572798
Policy log std Std                   1.25732
Policy log std Max                   2
Policy log std Min                  -5.11977
_task0 Rewards Mean                 21.0689
_task0 Rewards Std                  58.7628
_task0 Rewards Max                 514.507
_task0 Rewards Min                  -0.835545
_task0 Returns Mean               3160.34
_task0 Returns Std                6166.8
_task0 Returns Max               18331
_task0 Returns Min                -109.056
_task0 Actions Mean                  0.00761298
_task0 Actions Std                   0.77048
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     283.546
Exploration_task0 Rewards Std      875.822
Exploration_task0 Rewards Max    13966.5
Exploration_task0 Rewards Min       -8.85033
Exploration_task0 Returns Mean   42961.5
Exploration_task0 Returns Std    74521
Exploration_task0 Returns Max   292801
Exploration_task0 Returns Min    -1346.3
Exploration_task0 Actions Mean      -0.0243222
Exploration_task0 Actions Std        0.830074
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3160.34
AverageReturn_all_train_tasks     3904.53
AverageReturn_all_test_tasks      3160.34
Number of train steps total      30000
Number of env steps total            1.501e+06
Number of rollouts total         10896
Train Time (s)                      97.7478
(Previous) Eval Time (s)            25.4893
Sample Time (s)                    106.259
Epoch Time (s)                     229.496
Total Train Time (s)              6865.67
Epoch                               29
------------------------------  ----------------
2019-06-27 02:27:17.628153 UTC | [dialturn] Iteration #29 | Epoch Duration: 229.27125024795532
2019-06-27 02:27:17.628366 UTC | [dialturn] Iteration #29 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0032387
Z variance train                     0.998591
KL Divergence                        0.00118237
KL Loss                              0.000118237
QF Loss                              7.55446e+07
VF Loss                         173376
RF Loss                          35593.9
Policy Loss                     -42211.3
Q Predictions Mean               41730.7
Q Predictions Std                52316
Q Predictions Max               223242
Q Predictions Min                 3009.22
V Predictions Mean               42115.7
V Predictions Std                52625
V Predictions Max               221957
V Predictions Min                 3110.31
R Predictions Mean                 227.058
R Predictions Std                  703.655
R Predictions Max                 7488.67
R Predictions Min                  -11.3373
Log Pis Mean                        22.488
Log Pis Std                         10.6772
Log Pis Max                         46.5211
Log Pis Min                         -1.96729
Policy mu Mean                      -1.53714
Policy mu Std                       11.77
Policy mu Max                       61.4671
Policy mu Min                      -49.1852
Policy log std Mean                 -0.602675
Policy log std Std                   1.3007
Policy log std Max                   2
Policy log std Min                  -5.02175
_task0 Rewards Mean                 18.8693
_task0 Rewards Std                  64.7711
_task0 Rewards Max                 699.002
_task0 Rewards Min                  -0.756727
_task0 Returns Mean               2830.4
_task0 Returns Std                6324.82
_task0 Returns Max               22449.4
_task0 Returns Min                 -90.5637
_task0 Actions Mean                 -0.0505496
_task0 Actions Std                   0.703074
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     296.388
Exploration_task0 Rewards Std      982.313
Exploration_task0 Rewards Max    20894.8
Exploration_task0 Rewards Min       -9.20067
Exploration_task0 Returns Mean   44907.3
Exploration_task0 Returns Std    87125.2
Exploration_task0 Returns Max   361985
Exploration_task0 Returns Min    -1191
Exploration_task0 Actions Mean      -0.022207
Exploration_task0 Actions Std        0.810329
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2830.4
AverageReturn_all_train_tasks     4012.13
AverageReturn_all_test_tasks      2830.4
Number of train steps total      31000
Number of env steps total            1.551e+06
Number of rollouts total         11259
Train Time (s)                      97.3486
(Previous) Eval Time (s)            25.2634
Sample Time (s)                    106.023
Epoch Time (s)                     228.635
Total Train Time (s)              7094.51
Epoch                               30
------------------------------  ----------------
2019-06-27 02:31:06.478564 UTC | [dialturn] Iteration #30 | Epoch Duration: 228.8499915599823
2019-06-27 02:31:06.478765 UTC | [dialturn] Iteration #30 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00320561
Z variance train                     1.00083
KL Divergence                        0.000700188
KL Loss                              7.00188e-05
QF Loss                              6.96979e+07
VF Loss                         334325
RF Loss                          21136.8
Policy Loss                     -41818.6
Q Predictions Mean               41225.4
Q Predictions Std                52368.1
Q Predictions Max               217005
Q Predictions Min                 2898.88
V Predictions Mean               42182.8
V Predictions Std                53091
V Predictions Max               218244
V Predictions Min                 3021.47
R Predictions Mean                 280.326
R Predictions Std                  928.83
R Predictions Max                12877.1
R Predictions Min                  -41.6137
Log Pis Mean                        22.6907
Log Pis Std                          9.879
Log Pis Max                         46.7384
Log Pis Min                         -3.31226
Policy mu Mean                      -1.2636
Policy mu Std                       10.6443
Policy mu Max                       69.7156
Policy mu Min                      -45.9822
Policy log std Mean                 -0.684199
Policy log std Std                   1.28562
Policy log std Max                   2
Policy log std Min                  -4.99651
_task0 Rewards Mean                 26.1858
_task0 Rewards Std                  94.9198
_task0 Rewards Max                1619.81
_task0 Rewards Min                  -0.792112
_task0 Returns Mean               3927.88
_task0 Returns Std                8143.83
_task0 Returns Max               32734
_task0 Returns Min                -107.351
_task0 Actions Mean                 -0.0668421
_task0 Actions Std                   0.797383
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     277.704
Exploration_task0 Rewards Std     1091.77
Exploration_task0 Rewards Max    21382.9
Exploration_task0 Rewards Min       -9.76776
Exploration_task0 Returns Mean   42076.3
Exploration_task0 Returns Std    88457.5
Exploration_task0 Returns Max   372980
Exploration_task0 Returns Min    -1278.17
Exploration_task0 Actions Mean      -0.0354849
Exploration_task0 Actions Std        0.817535
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3927.88
AverageReturn_all_train_tasks     3881.48
AverageReturn_all_test_tasks      3927.88
Number of train steps total      32000
Number of env steps total            1.601e+06
Number of rollouts total         11622
Train Time (s)                      97.948
(Previous) Eval Time (s)            25.4773
Sample Time (s)                    106.516
Epoch Time (s)                     229.941
Total Train Time (s)              7324.44
Epoch                               31
------------------------------  ----------------
2019-06-27 02:34:56.406516 UTC | [dialturn] Iteration #31 | Epoch Duration: 229.92757153511047
2019-06-27 02:34:56.406713 UTC | [dialturn] Iteration #31 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00431908
Z variance train                     1.0002
KL Divergence                        0.00233108
KL Loss                              0.000233108
QF Loss                              6.06557e+07
VF Loss                         263899
RF Loss                           7329.02
Policy Loss                     -41626.6
Q Predictions Mean               41193.5
Q Predictions Std                51710.9
Q Predictions Max               178775
Q Predictions Min                 2916.44
V Predictions Mean               41501.5
V Predictions Std                51796.7
V Predictions Max               180672
V Predictions Min                 3197.28
R Predictions Mean                 310.655
R Predictions Std                  871.221
R Predictions Max                13758.1
R Predictions Min                  -36.8881
Log Pis Mean                        21.5241
Log Pis Std                          9.1375
Log Pis Max                         46.4005
Log Pis Min                         -3.32126
Policy mu Mean                      -1.84353
Policy mu Std                       10.3521
Policy mu Max                       68.8276
Policy mu Min                      -45.5264
Policy log std Mean                 -0.634534
Policy log std Std                   1.26605
Policy log std Max                   2
Policy log std Min                  -4.68783
_task0 Rewards Mean                 19.3258
_task0 Rewards Std                  46.709
_task0 Rewards Max                 396.021
_task0 Rewards Min                  -0.73902
_task0 Returns Mean               2898.87
_task0 Returns Std                5109.64
_task0 Returns Max               14253.3
_task0 Returns Min                 -88.677
_task0 Actions Mean                  0.00444797
_task0 Actions Std                   0.799055
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     215.355
Exploration_task0 Rewards Std      737.023
Exploration_task0 Rewards Max    21308
Exploration_task0 Rewards Min      -10.3554
Exploration_task0 Returns Mean   32629.5
Exploration_task0 Returns Std    64763.1
Exploration_task0 Returns Max   361614
Exploration_task0 Returns Min    -1373.97
Exploration_task0 Actions Mean      -0.0368736
Exploration_task0 Actions Std        0.803946
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2898.87
AverageReturn_all_train_tasks     3563.87
AverageReturn_all_test_tasks      2898.87
Number of train steps total      33000
Number of env steps total            1.651e+06
Number of rollouts total         11985
Train Time (s)                      97.9502
(Previous) Eval Time (s)            25.4623
Sample Time (s)                    106.527
Epoch Time (s)                     229.939
Total Train Time (s)              7554.57
Epoch                               32
------------------------------  ----------------
2019-06-27 02:38:46.536532 UTC | [dialturn] Iteration #32 | Epoch Duration: 230.129656791687
2019-06-27 02:38:46.536741 UTC | [dialturn] Iteration #32 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00120936
Z variance train                     1.00212
KL Divergence                        0.00026286
KL Loss                              2.62861e-05
QF Loss                              7.84622e+07
VF Loss                         178317
RF Loss                          31929.1
Policy Loss                     -42364.9
Q Predictions Mean               41890.7
Q Predictions Std                52626.7
Q Predictions Max               231002
Q Predictions Min                 3085.68
V Predictions Mean               42287.6
V Predictions Std                53016.6
V Predictions Max               234105
V Predictions Min                 3114.29
R Predictions Mean                 288.434
R Predictions Std                 1032.06
R Predictions Max                10251.3
R Predictions Min                  -25.8677
Log Pis Mean                        22.6349
Log Pis Std                         10.0656
Log Pis Max                         50.5014
Log Pis Min                         -3.57776
Policy mu Mean                      -1.20145
Policy mu Std                        9.12973
Policy mu Max                       74.2031
Policy mu Min                      -43.3204
Policy log std Mean                 -0.71242
Policy log std Std                   1.14312
Policy log std Max                   2
Policy log std Min                  -4.93279
_task0 Rewards Mean                 27.8355
_task0 Rewards Std                  71.5118
_task0 Rewards Max                 763.758
_task0 Rewards Min                  -0.874827
_task0 Returns Mean               4175.33
_task0 Returns Std                8346.64
_task0 Returns Max               34595.5
_task0 Returns Min                -112.527
_task0 Actions Mean                 -0.0615574
_task0 Actions Std                   0.807826
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     288.998
Exploration_task0 Rewards Std      933.386
Exploration_task0 Rewards Max    21223.9
Exploration_task0 Rewards Min      -11.4976
Exploration_task0 Returns Mean   43787.5
Exploration_task0 Returns Std    78524.2
Exploration_task0 Returns Max   340136
Exploration_task0 Returns Min    -1244.79
Exploration_task0 Actions Mean      -0.0399988
Exploration_task0 Actions Std        0.825635
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4175.33
AverageReturn_all_train_tasks     3541.33
AverageReturn_all_test_tasks      4175.33
Number of train steps total      34000
Number of env steps total            1.701e+06
Number of rollouts total         12348
Train Time (s)                      97.2449
(Previous) Eval Time (s)            25.6513
Sample Time (s)                    106.869
Epoch Time (s)                     229.766
Total Train Time (s)              7784.43
Epoch                               33
------------------------------  ----------------
2019-06-27 02:42:36.397388 UTC | [dialturn] Iteration #33 | Epoch Duration: 229.86039805412292
2019-06-27 02:42:36.397573 UTC | [dialturn] Iteration #33 | Started Training: True
------------------------------  ----------------
Z mean train                         0.001355
Z variance train                     0.999549
KL Divergence                        0.000187453
KL Loss                              1.87453e-05
QF Loss                              3.5203e+07
VF Loss                         297074
RF Loss                          19238.7
Policy Loss                     -43067.2
Q Predictions Mean               42511.7
Q Predictions Std                53064.8
Q Predictions Max               206045
Q Predictions Min                 2679.66
V Predictions Mean               42748.3
V Predictions Std                53226
V Predictions Max               207031
V Predictions Min                 3151.3
R Predictions Mean                 284.949
R Predictions Std                  939.178
R Predictions Max                12057.9
R Predictions Min                  -31.1436
Log Pis Mean                        22.2255
Log Pis Std                         10.6052
Log Pis Max                         48.7301
Log Pis Min                         -1.67555
Policy mu Mean                      -1.64182
Policy mu Std                       10.3436
Policy mu Max                       69.982
Policy mu Min                      -46.3163
Policy log std Mean                 -0.609234
Policy log std Std                   1.23754
Policy log std Max                   2
Policy log std Min                  -4.94179
_task0 Rewards Mean                 34.8107
_task0 Rewards Std                 132.482
_task0 Rewards Max                2133.71
_task0 Rewards Min                  -0.69783
_task0 Returns Mean               5221.6
_task0 Returns Std                9931.97
_task0 Returns Max               34607.1
_task0 Returns Min                 -94.5065
_task0 Actions Mean                 -0.0340803
_task0 Actions Std                   0.803437
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     308.894
Exploration_task0 Rewards Std      971.763
Exploration_task0 Rewards Max    20551.6
Exploration_task0 Rewards Min       -9.41031
Exploration_task0 Returns Mean   46802.1
Exploration_task0 Returns Std    86467.3
Exploration_task0 Returns Max   369129
Exploration_task0 Returns Min    -1382.59
Exploration_task0 Actions Mean      -0.00782495
Exploration_task0 Actions Std        0.824398
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5221.6
AverageReturn_all_train_tasks     2929.6
AverageReturn_all_test_tasks      5221.6
Number of train steps total      35000
Number of env steps total            1.751e+06
Number of rollouts total         12711
Train Time (s)                      97.1324
(Previous) Eval Time (s)            25.7448
Sample Time (s)                    106.703
Epoch Time (s)                     229.581
Total Train Time (s)              8013.74
Epoch                               34
------------------------------  ----------------
2019-06-27 02:46:25.708555 UTC | [dialturn] Iteration #34 | Epoch Duration: 229.31082677841187
2019-06-27 02:46:25.708747 UTC | [dialturn] Iteration #34 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00276428
Z variance train                     0.999004
KL Divergence                        0.000574762
KL Loss                              5.74762e-05
QF Loss                              5.40686e+07
VF Loss                         226578
RF Loss                           5563.35
Policy Loss                     -42311.8
Q Predictions Mean               41715
Q Predictions Std                52811.6
Q Predictions Max               192617
Q Predictions Min                 2218.71
V Predictions Mean               42138.8
V Predictions Std                53036.1
V Predictions Max               195098
V Predictions Min                 3042.52
R Predictions Mean                 212.654
R Predictions Std                  658.446
R Predictions Max                10775.9
R Predictions Min                  -22.4881
Log Pis Mean                        22.5284
Log Pis Std                         10.4712
Log Pis Max                         49.8823
Log Pis Min                         -1.43592
Policy mu Mean                      -1.09134
Policy mu Std                       10.5972
Policy mu Max                       72.21
Policy mu Min                      -49.548
Policy log std Mean                 -0.629952
Policy log std Std                   1.16144
Policy log std Max                   2
Policy log std Min                  -5.11443
_task0 Rewards Mean                 30.5837
_task0 Rewards Std                  91.0309
_task0 Rewards Max                 970.852
_task0 Rewards Min                  -0.907986
_task0 Returns Mean               4587.56
_task0 Returns Std                8818.37
_task0 Returns Max               29771.6
_task0 Returns Min                -105.939
_task0 Actions Mean                 -0.027247
_task0 Actions Std                   0.834524
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     398.057
Exploration_task0 Rewards Std     1377.19
Exploration_task0 Rewards Max    21246.3
Exploration_task0 Rewards Min       -9.78447
Exploration_task0 Returns Mean   60311.7
Exploration_task0 Returns Std   106668
Exploration_task0 Returns Max   377127
Exploration_task0 Returns Min    -1228.23
Exploration_task0 Actions Mean      -0.0446928
Exploration_task0 Actions Std        0.858328
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4587.56
AverageReturn_all_train_tasks     3223.12
AverageReturn_all_test_tasks      4587.56
Number of train steps total      36000
Number of env steps total            1.801e+06
Number of rollouts total         13074
Train Time (s)                      97.7423
(Previous) Eval Time (s)            25.4736
Sample Time (s)                    106.444
Epoch Time (s)                     229.66
Total Train Time (s)              8243.73
Epoch                               35
------------------------------  ----------------
2019-06-27 02:50:15.709994 UTC | [dialturn] Iteration #35 | Epoch Duration: 230.00108981132507
2019-06-27 02:50:15.710200 UTC | [dialturn] Iteration #35 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00138776
Z variance train                     0.999392
KL Divergence                        0.000384002
KL Loss                              3.84002e-05
QF Loss                              6.10664e+07
VF Loss                         135501
RF Loss                          17672.1
Policy Loss                     -42984.5
Q Predictions Mean               42381.3
Q Predictions Std                53170.1
Q Predictions Max               211438
Q Predictions Min                 2434.48
V Predictions Mean               42822.8
V Predictions Std                53612.9
V Predictions Max               214220
V Predictions Min                 2980.86
R Predictions Mean                 298.612
R Predictions Std                  855.48
R Predictions Max                12909.5
R Predictions Min                  -10.2721
Log Pis Mean                        22.2894
Log Pis Std                         10.0519
Log Pis Max                         49.8382
Log Pis Min                          0.411881
Policy mu Mean                      -1.77081
Policy mu Std                       12.1198
Policy mu Max                       71.1872
Policy mu Min                      -57.8231
Policy log std Mean                 -0.563803
Policy log std Std                   1.15967
Policy log std Max                   2
Policy log std Min                  -4.92477
_task0 Rewards Mean                 51.8611
_task0 Rewards Std                 114.198
_task0 Rewards Max                 909.88
_task0 Rewards Min                  -0.668122
_task0 Returns Mean               7779.17
_task0 Returns Std               11194
_task0 Returns Max               26689
_task0 Returns Min                 -71.7684
_task0 Actions Mean                  0.0542481
_task0 Actions Std                   0.840629
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     274.594
Exploration_task0 Rewards Std      779.44
Exploration_task0 Rewards Max    21273
Exploration_task0 Rewards Min       -9.37873
Exploration_task0 Returns Mean   41605.1
Exploration_task0 Returns Std    74441.2
Exploration_task0 Returns Max   403066
Exploration_task0 Returns Min    -1192.6
Exploration_task0 Actions Mean      -0.0111138
Exploration_task0 Actions Std        0.820844
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7779.17
AverageReturn_all_train_tasks     9190.59
AverageReturn_all_test_tasks      7779.17
Number of train steps total      37000
Number of env steps total            1.851e+06
Number of rollouts total         13437
Train Time (s)                      98.3811
(Previous) Eval Time (s)            25.8129
Sample Time (s)                    106.632
Epoch Time (s)                     230.826
Total Train Time (s)              8474.4
Epoch                               36
------------------------------  ----------------
2019-06-27 02:54:06.376456 UTC | [dialturn] Iteration #36 | Epoch Duration: 230.6660931110382
2019-06-27 02:54:06.376693 UTC | [dialturn] Iteration #36 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00226211
Z variance train                     1.0013
KL Divergence                        0.000528906
KL Loss                              5.28906e-05
QF Loss                              3.96358e+07
VF Loss                         116013
RF Loss                          88136.2
Policy Loss                     -41091.3
Q Predictions Mean               40522.9
Q Predictions Std                52445.9
Q Predictions Max               243594
Q Predictions Min                 1651.15
V Predictions Mean               41005
V Predictions Std                52849.1
V Predictions Max               245542
V Predictions Min                 2450.02
R Predictions Mean                 217.817
R Predictions Std                  644.808
R Predictions Max                12142
R Predictions Min                  -21.8304
Log Pis Mean                        22.2836
Log Pis Std                         10.3113
Log Pis Max                         49.4122
Log Pis Min                          0.0730083
Policy mu Mean                      -1.62518
Policy mu Std                       12.4188
Policy mu Max                       82.8585
Policy mu Min                      -56.9595
Policy log std Mean                 -0.541447
Policy log std Std                   1.14438
Policy log std Max                   2
Policy log std Min                  -4.94816
_task0 Rewards Mean                 50.443
_task0 Rewards Std                 129.058
_task0 Rewards Max                1333.88
_task0 Rewards Min                  -0.904
_task0 Returns Mean               7566.45
_task0 Returns Std               12208.1
_task0 Returns Max               37109.4
_task0 Returns Min                 -87.2594
_task0 Actions Mean                  0.0575333
_task0 Actions Std                   0.812194
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     292.205
Exploration_task0 Rewards Std      762.378
Exploration_task0 Rewards Max    19930.3
Exploration_task0 Rewards Min       -9.39836
Exploration_task0 Returns Mean   44273.5
Exploration_task0 Returns Std    77546.1
Exploration_task0 Returns Max   344333
Exploration_task0 Returns Min    -1236.99
Exploration_task0 Actions Mean       0.078233
Exploration_task0 Actions Std        0.811741
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7566.45
AverageReturn_all_train_tasks     3512.37
AverageReturn_all_test_tasks      7566.45
Number of train steps total      38000
Number of env steps total            1.901e+06
Number of rollouts total         13800
Train Time (s)                      97.8097
(Previous) Eval Time (s)            25.6512
Sample Time (s)                    106.839
Epoch Time (s)                     230.3
Total Train Time (s)              8704.42
Epoch                               37
------------------------------  ----------------
2019-06-27 02:57:56.396401 UTC | [dialturn] Iteration #37 | Epoch Duration: 230.01949310302734
2019-06-27 02:57:56.396607 UTC | [dialturn] Iteration #37 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00287884
Z variance train                     1.00026
KL Divergence                        0.000718248
KL Loss                              7.18248e-05
QF Loss                              4.31059e+07
VF Loss                         130251
RF Loss                         264609
Policy Loss                     -44640.4
Q Predictions Mean               44075
Q Predictions Std                54953.7
Q Predictions Max               229380
Q Predictions Min                 1698.64
V Predictions Mean               44473.6
V Predictions Std                55333.6
V Predictions Max               232475
V Predictions Min                 2614.42
R Predictions Mean                 325.432
R Predictions Std                  878.902
R Predictions Max                10190.9
R Predictions Min                   -9.5794
Log Pis Mean                        24.0257
Log Pis Std                         11.1482
Log Pis Max                         51.3241
Log Pis Min                         -6.82474
Policy mu Mean                      -2.03714
Policy mu Std                       13.3799
Policy mu Max                       74.7057
Policy mu Min                      -61.8582
Policy log std Mean                 -0.441335
Policy log std Std                   1.0928
Policy log std Max                   2
Policy log std Min                  -5.07078
_task0 Rewards Mean                 38.337
_task0 Rewards Std                  95.5074
_task0 Rewards Max                 833.948
_task0 Rewards Min                  -0.776287
_task0 Returns Mean               5750.56
_task0 Returns Std               11120.1
_task0 Returns Max               33590.7
_task0 Returns Min                -100.621
_task0 Actions Mean                  0.169903
_task0 Actions Std                   0.827731
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     277.361
Exploration_task0 Rewards Std      823.601
Exploration_task0 Rewards Max    19196.2
Exploration_task0 Rewards Min       -8.80636
Exploration_task0 Returns Mean   42024.4
Exploration_task0 Returns Std    79912
Exploration_task0 Returns Max   418074
Exploration_task0 Returns Min    -1175.42
Exploration_task0 Actions Mean       0.212317
Exploration_task0 Actions Std        0.814535
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5750.56
AverageReturn_all_train_tasks    13233.1
AverageReturn_all_test_tasks      5750.56
Number of train steps total      39000
Number of env steps total            1.951e+06
Number of rollouts total         14163
Train Time (s)                      97.2941
(Previous) Eval Time (s)            25.3693
Sample Time (s)                    106.369
Epoch Time (s)                     229.032
Total Train Time (s)              8933.69
Epoch                               38
------------------------------  ----------------
2019-06-27 03:01:45.676840 UTC | [dialturn] Iteration #38 | Epoch Duration: 229.28001308441162
2019-06-27 03:01:45.677029 UTC | [dialturn] Iteration #38 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000903108
Z variance train                     0.999618
KL Divergence                        0.000107716
KL Loss                              1.07716e-05
QF Loss                              3.41229e+07
VF Loss                              1.07781e+06
RF Loss                              1.17136e+06
Policy Loss                     -43435.5
Q Predictions Mean               42775.3
Q Predictions Std                54253.2
Q Predictions Max               245112
Q Predictions Min                 1693.78
V Predictions Mean               42704.2
V Predictions Std                54204.3
V Predictions Max               243634
V Predictions Min                 1813.1
R Predictions Mean                 690.195
R Predictions Std                 1867.78
R Predictions Max                13495.9
R Predictions Min                  -11.1439
Log Pis Mean                        22.5714
Log Pis Std                         10.6306
Log Pis Max                         48.4786
Log Pis Min                         -1.81772
Policy mu Mean                      -1.55437
Policy mu Std                       14.1816
Policy mu Max                       83.6518
Policy mu Min                      -68.1472
Policy log std Mean                 -0.519431
Policy log std Std                   1.18124
Policy log std Max                   2
Policy log std Min                  -4.76559
_task0 Rewards Mean                 30.9264
_task0 Rewards Std                  88.663
_task0 Rewards Max                1060.04
_task0 Rewards Min                  -0.833012
_task0 Returns Mean               4638.96
_task0 Returns Std                8744.33
_task0 Returns Max               31194.1
_task0 Returns Min                -103.382
_task0 Actions Mean                  0.104463
_task0 Actions Std                   0.789067
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     338.873
Exploration_task0 Rewards Std      933.888
Exploration_task0 Rewards Max    21831.1
Exploration_task0 Rewards Min       -9.38001
Exploration_task0 Returns Mean   51344.4
Exploration_task0 Returns Std   100768
Exploration_task0 Returns Max   423139
Exploration_task0 Returns Min    -1500.04
Exploration_task0 Actions Mean       0.164779
Exploration_task0 Actions Std        0.822942
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4638.96
AverageReturn_all_train_tasks     6029.15
AverageReturn_all_test_tasks      4638.96
Number of train steps total      40000
Number of env steps total            2.001e+06
Number of rollouts total         14526
Train Time (s)                      97.9276
(Previous) Eval Time (s)            25.6156
Sample Time (s)                    107.267
Epoch Time (s)                     230.81
Total Train Time (s)              9164.64
Epoch                               39
------------------------------  ----------------
2019-06-27 03:05:36.628596 UTC | [dialturn] Iteration #39 | Epoch Duration: 230.95141196250916
2019-06-27 03:05:36.628797 UTC | [dialturn] Iteration #39 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00406502
Z variance train                     1.00001
KL Divergence                        0.00178388
KL Loss                              0.000178388
QF Loss                              6.87127e+07
VF Loss                         536044
RF Loss                          20984.7
Policy Loss                     -42649.5
Q Predictions Mean               41991
Q Predictions Std                53936
Q Predictions Max               215196
Q Predictions Min                 1543.53
V Predictions Mean               43217.9
V Predictions Std                54906.1
V Predictions Max               217380
V Predictions Min                 2218.47
R Predictions Mean                 372.854
R Predictions Std                 1094.35
R Predictions Max                12444
R Predictions Min                   -9.21713
Log Pis Mean                        22.2884
Log Pis Std                         11.5972
Log Pis Max                         52.3668
Log Pis Min                         -2.88562
Policy mu Mean                      -1.22355
Policy mu Std                       13.887
Policy mu Max                       83.7146
Policy mu Min                      -69.5975
Policy log std Mean                 -0.594954
Policy log std Std                   1.18139
Policy log std Max                   2
Policy log std Min                  -5.3428
_task0 Rewards Mean                 68.8543
_task0 Rewards Std                 145.672
_task0 Rewards Max                1494.48
_task0 Rewards Min                  -0.621795
_task0 Returns Mean              10328.1
_task0 Returns Std               14786
_task0 Returns Max               37811.4
_task0 Returns Min                 -82.4638
_task0 Actions Mean                 -0.0489888
_task0 Actions Std                   0.845127
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     371.06
Exploration_task0 Rewards Std     1102.94
Exploration_task0 Rewards Max    22701
Exploration_task0 Rewards Min      -10.5055
Exploration_task0 Returns Mean   56221.3
Exploration_task0 Returns Std   104478
Exploration_task0 Returns Max   383927
Exploration_task0 Returns Min    -1422.01
Exploration_task0 Actions Mean      -0.0180406
Exploration_task0 Actions Std        0.808258
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10328.1
AverageReturn_all_train_tasks     2991.22
AverageReturn_all_test_tasks     10328.1
Number of train steps total      41000
Number of env steps total            2.051e+06
Number of rollouts total         14889
Train Time (s)                      99.1233
(Previous) Eval Time (s)            25.7551
Sample Time (s)                    107.246
Epoch Time (s)                     232.124
Total Train Time (s)              9396.55
Epoch                               40
------------------------------  ----------------
2019-06-27 03:09:28.538660 UTC | [dialturn] Iteration #40 | Epoch Duration: 231.9097077846527
2019-06-27 03:09:28.538848 UTC | [dialturn] Iteration #40 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00342164
Z variance train                     1.00236
KL Divergence                        0.00139822
KL Loss                              0.000139822
QF Loss                              4.64842e+07
VF Loss                          95460
RF Loss                         104203
Policy Loss                     -43362.3
Q Predictions Mean               42838
Q Predictions Std                54101.8
Q Predictions Max               248152
Q Predictions Min                 1182.59
V Predictions Mean               43352.9
V Predictions Std                54530.9
V Predictions Max               252281
V Predictions Min                 1542.89
R Predictions Mean                 528.572
R Predictions Std                 1409.19
R Predictions Max                13019.3
R Predictions Min                  -11.0986
Log Pis Mean                        22.8598
Log Pis Std                         12.2867
Log Pis Max                         52.0827
Log Pis Min                         -0.240134
Policy mu Mean                      -2.36459
Policy mu Std                       15.8494
Policy mu Max                       84.5278
Policy mu Min                      -66.9629
Policy log std Mean                 -0.587631
Policy log std Std                   1.25952
Policy log std Max                   2
Policy log std Min                  -5.25354
_task0 Rewards Mean                 38.5171
_task0 Rewards Std                  91.9067
_task0 Rewards Max                1006.71
_task0 Rewards Min                  -0.937999
_task0 Returns Mean               5777.56
_task0 Returns Std               10453.5
_task0 Returns Max               37253.4
_task0 Returns Min                -113.933
_task0 Actions Mean                  0.0454871
_task0 Actions Std                   0.824698
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     245.035
Exploration_task0 Rewards Std      744.452
Exploration_task0 Rewards Max    15678.4
Exploration_task0 Rewards Min      -11.1085
Exploration_task0 Returns Mean   37126.6
Exploration_task0 Returns Std    79892.1
Exploration_task0 Returns Max   380142
Exploration_task0 Returns Min    -1266.1
Exploration_task0 Actions Mean       0.0799845
Exploration_task0 Actions Std        0.828475
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5777.56
AverageReturn_all_train_tasks     3520.85
AverageReturn_all_test_tasks      5777.56
Number of train steps total      42000
Number of env steps total            2.101e+06
Number of rollouts total         15252
Train Time (s)                      98.0637
(Previous) Eval Time (s)            25.5395
Sample Time (s)                    106.612
Epoch Time (s)                     230.216
Total Train Time (s)              9626.75
Epoch                               41
------------------------------  ----------------
2019-06-27 03:13:18.741750 UTC | [dialturn] Iteration #41 | Epoch Duration: 230.2027406692505
2019-06-27 03:13:18.741952 UTC | [dialturn] Iteration #41 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00161856
Z variance train                     0.999377
KL Divergence                        0.000293825
KL Loss                              2.93825e-05
QF Loss                              6.66493e+07
VF Loss                         146392
RF Loss                          13664.6
Policy Loss                     -43431.5
Q Predictions Mean               42709.7
Q Predictions Std                54542.4
Q Predictions Max               203840
Q Predictions Min                  762.233
V Predictions Mean               43220.8
V Predictions Std                55000.1
V Predictions Max               204979
V Predictions Min                 1169.32
R Predictions Mean                 400.672
R Predictions Std                 1006.98
R Predictions Max                14856.3
R Predictions Min                  -22.9378
Log Pis Mean                        22.3188
Log Pis Std                         11.7867
Log Pis Max                         51.5162
Log Pis Min                         -0.878109
Policy mu Mean                      -2.54949
Policy mu Std                       14.7772
Policy mu Max                       82.5597
Policy mu Min                      -73.2644
Policy log std Mean                 -0.671251
Policy log std Std                   1.28126
Policy log std Max                   2
Policy log std Min                  -4.77835
_task0 Rewards Mean                 19.8251
_task0 Rewards Std                  54.005
_task0 Rewards Max                 527.545
_task0 Rewards Min                  -0.851127
_task0 Returns Mean               2973.76
_task0 Returns Std                6230.51
_task0 Returns Max               21353.4
_task0 Returns Min                -101.226
_task0 Actions Mean                  0.128126
_task0 Actions Std                   0.793983
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     360.413
Exploration_task0 Rewards Std      942.162
Exploration_task0 Rewards Max    16294.2
Exploration_task0 Rewards Min       -9.39873
Exploration_task0 Returns Mean   54608
Exploration_task0 Returns Std   107124
Exploration_task0 Returns Max   486087
Exploration_task0 Returns Min    -1363.1
Exploration_task0 Actions Mean      -0.00558442
Exploration_task0 Actions Std        0.814469
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2973.76
AverageReturn_all_train_tasks     6609.59
AverageReturn_all_test_tasks      2973.76
Number of train steps total      43000
Number of env steps total            2.151e+06
Number of rollouts total         15615
Train Time (s)                      98.7974
(Previous) Eval Time (s)            25.5253
Sample Time (s)                    107.056
Epoch Time (s)                     231.379
Total Train Time (s)              9858.16
Epoch                               42
------------------------------  ----------------
2019-06-27 03:17:10.156394 UTC | [dialturn] Iteration #42 | Epoch Duration: 231.4142849445343
2019-06-27 03:17:10.156596 UTC | [dialturn] Iteration #42 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00147135
Z variance train                     0.99974
KL Divergence                        0.000332899
KL Loss                              3.32899e-05
QF Loss                              6.20872e+07
VF Loss                         547990
RF Loss                           6004.38
Policy Loss                     -45588.3
Q Predictions Mean               44888.6
Q Predictions Std                56067.3
Q Predictions Max               215856
Q Predictions Min                  660.477
V Predictions Mean               45141.6
V Predictions Std                56422.1
V Predictions Max               218422
V Predictions Min                  837.181
R Predictions Mean                 328.049
R Predictions Std                  941.842
R Predictions Max                13878.3
R Predictions Min                  -39.7887
Log Pis Mean                        22.129
Log Pis Std                         12.0796
Log Pis Max                         51.0641
Log Pis Min                         -1.70172
Policy mu Mean                      -1.84564
Policy mu Std                       15.6862
Policy mu Max                       90.8186
Policy mu Min                      -61.3971
Policy log std Mean                 -0.509888
Policy log std Std                   1.24653
Policy log std Max                   2
Policy log std Min                  -4.09108
_task0 Rewards Mean                  7.74413
_task0 Rewards Std                  31.1571
_task0 Rewards Max                 287.908
_task0 Rewards Min                  -0.911337
_task0 Returns Mean               1161.62
_task0 Returns Std                1842.29
_task0 Returns Max                5316.95
_task0 Returns Min                -118.165
_task0 Actions Mean                  0.126168
_task0 Actions Std                   0.797309
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     341.974
Exploration_task0 Rewards Std      953.983
Exploration_task0 Rewards Max    16037.8
Exploration_task0 Rewards Min      -10.5018
Exploration_task0 Returns Mean   51814.2
Exploration_task0 Returns Std    98834
Exploration_task0 Returns Max   398285
Exploration_task0 Returns Min    -1434.54
Exploration_task0 Actions Mean       0.0510476
Exploration_task0 Actions Std        0.815299
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1161.62
AverageReturn_all_train_tasks    10102.5
AverageReturn_all_test_tasks      1161.62
Number of train steps total      44000
Number of env steps total            2.201e+06
Number of rollouts total         15978
Train Time (s)                      98.4496
(Previous) Eval Time (s)            25.5593
Sample Time (s)                    106.662
Epoch Time (s)                     230.671
Total Train Time (s)             10088.7
Epoch                               43
------------------------------  ----------------
2019-06-27 03:21:00.659617 UTC | [dialturn] Iteration #43 | Epoch Duration: 230.50284218788147
2019-06-27 03:21:00.659820 UTC | [dialturn] Iteration #43 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00246956
Z variance train                     1.00169
KL Divergence                        0.000535946
KL Loss                              5.35946e-05
QF Loss                              6.35356e+07
VF Loss                         409143
RF Loss                          33436.1
Policy Loss                     -44192.5
Q Predictions Mean               43629.2
Q Predictions Std                55260
Q Predictions Max               238144
Q Predictions Min                  380.514
V Predictions Mean               44607.9
V Predictions Std                56116
V Predictions Max               242599
V Predictions Min                  646.719
R Predictions Mean                 431.402
R Predictions Std                 1112.84
R Predictions Max                11245.3
R Predictions Min                  -30.3833
Log Pis Mean                        22.4121
Log Pis Std                         12.3777
Log Pis Max                         52.2462
Log Pis Min                         -3.20553
Policy mu Mean                      -3.59662
Policy mu Std                       17.9702
Policy mu Max                      105.333
Policy mu Min                      -74.0103
Policy log std Mean                 -0.524982
Policy log std Std                   1.28316
Policy log std Max                   2
Policy log std Min                  -4.29735
_task0 Rewards Mean                 39.3706
_task0 Rewards Std                 113.477
_task0 Rewards Max                1498.23
_task0 Rewards Min                  -1.10113
_task0 Returns Mean               5905.59
_task0 Returns Std               10664
_task0 Returns Max               31973.6
_task0 Returns Min                -121.149
_task0 Actions Mean                  0.0837137
_task0 Actions Std                   0.808338
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     433.76
Exploration_task0 Rewards Std     1170.84
Exploration_task0 Rewards Max    17278.9
Exploration_task0 Rewards Min      -10.2609
Exploration_task0 Returns Mean   65721.2
Exploration_task0 Returns Std   114567
Exploration_task0 Returns Max   464876
Exploration_task0 Returns Min    -1350.92
Exploration_task0 Actions Mean       0.022595
Exploration_task0 Actions Std        0.815528
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5905.59
AverageReturn_all_train_tasks     9617.39
AverageReturn_all_test_tasks      5905.59
Number of train steps total      45000
Number of env steps total            2.251e+06
Number of rollouts total         16341
Train Time (s)                      98.8755
(Previous) Eval Time (s)            25.3896
Sample Time (s)                    106.125
Epoch Time (s)                     230.39
Total Train Time (s)             10319.4
Epoch                               44
------------------------------  ----------------
2019-06-27 03:24:51.401632 UTC | [dialturn] Iteration #44 | Epoch Duration: 230.74165749549866
2019-06-27 03:24:51.401852 UTC | [dialturn] Iteration #44 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00252575
Z variance train                     1.00003
KL Divergence                        0.000694598
KL Loss                              6.94598e-05
QF Loss                              4.1094e+07
VF Loss                         108099
RF Loss                          31064.5
Policy Loss                     -43479.7
Q Predictions Mean               42864
Q Predictions Std                54517.3
Q Predictions Max               206354
Q Predictions Min                  364.543
V Predictions Mean               43441.8
V Predictions Std                55016.9
V Predictions Max               208065
V Predictions Min                  382.741
R Predictions Mean                 354.234
R Predictions Std                  895.379
R Predictions Max                10513.2
R Predictions Min                  -79.1088
Log Pis Mean                        22.3186
Log Pis Std                         12.7002
Log Pis Max                         51.0566
Log Pis Min                         -2.42303
Policy mu Mean                      -4.52509
Policy mu Std                       17.9749
Policy mu Max                      101.536
Policy mu Min                      -79.3658
Policy log std Mean                 -0.532961
Policy log std Std                   1.2824
Policy log std Max                   2
Policy log std Min                  -4.39882
_task0 Rewards Mean                 34.8691
_task0 Rewards Std                 116.243
_task0 Rewards Max                1611.09
_task0 Rewards Min                  -0.890213
_task0 Returns Mean               5230.37
_task0 Returns Std               11588.6
_task0 Returns Max               39429.7
_task0 Returns Min                -108.609
_task0 Actions Mean                  0.139136
_task0 Actions Std                   0.809068
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     378.061
Exploration_task0 Rewards Std     1049.82
Exploration_task0 Rewards Max    22995.7
Exploration_task0 Rewards Min      -10.3741
Exploration_task0 Returns Mean   57281.9
Exploration_task0 Returns Std   104056
Exploration_task0 Returns Max   425138
Exploration_task0 Returns Min    -1216.13
Exploration_task0 Actions Mean       0.00921516
Exploration_task0 Actions Std        0.8443
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5230.37
AverageReturn_all_train_tasks     4448.07
AverageReturn_all_test_tasks      5230.37
Number of train steps total      46000
Number of env steps total            2.301e+06
Number of rollouts total         16704
Train Time (s)                      99.1946
(Previous) Eval Time (s)            25.7402
Sample Time (s)                    106.494
Epoch Time (s)                     231.428
Total Train Time (s)             10550.8
Epoch                               45
------------------------------  ----------------
2019-06-27 03:28:42.839414 UTC | [dialturn] Iteration #45 | Epoch Duration: 231.43735456466675
2019-06-27 03:28:42.839638 UTC | [dialturn] Iteration #45 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00103545
Z variance train                     1.00479
KL Divergence                        0.000886954
KL Loss                              8.86954e-05
QF Loss                              6.56954e+07
VF Loss                         762996
RF Loss                          99756.7
Policy Loss                     -44332.4
Q Predictions Mean               44014.6
Q Predictions Std                55549.3
Q Predictions Max               216516
Q Predictions Min                  323.524
V Predictions Mean               44907.2
V Predictions Std                56337.6
V Predictions Max               220540
V Predictions Min                  280.393
R Predictions Mean                 504.475
R Predictions Std                 1279.18
R Predictions Max                13187.9
R Predictions Min                  -32.5471
Log Pis Mean                        22.7608
Log Pis Std                         13.0024
Log Pis Max                         50.5651
Log Pis Min                         -1.89334
Policy mu Mean                      -3.35433
Policy mu Std                       20.2973
Policy mu Max                      108.196
Policy mu Min                      -93.3647
Policy log std Mean                 -0.458948
Policy log std Std                   1.29312
Policy log std Max                   2
Policy log std Min                  -4.39741
_task0 Rewards Mean                 28.5959
_task0 Rewards Std                  83.5668
_task0 Rewards Max                 675.077
_task0 Rewards Min                  -0.863952
_task0 Returns Mean               4289.39
_task0 Returns Std                8617.88
_task0 Returns Max               25144.3
_task0 Returns Min                -103.022
_task0 Actions Mean                  0.129077
_task0 Actions Std                   0.831537
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     423.923
Exploration_task0 Rewards Std     1163.76
Exploration_task0 Rewards Max    22810.4
Exploration_task0 Rewards Min       -9.40045
Exploration_task0 Returns Mean   64230.8
Exploration_task0 Returns Std   125795
Exploration_task0 Returns Max        1.33602e+06
Exploration_task0 Returns Min    -1459.5
Exploration_task0 Actions Mean       0.0559349
Exploration_task0 Actions Std        0.848766
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4289.39
AverageReturn_all_train_tasks      608.874
AverageReturn_all_test_tasks      4289.39
Number of train steps total      47000
Number of env steps total            2.351e+06
Number of rollouts total         17067
Train Time (s)                     100.39
(Previous) Eval Time (s)            25.7478
Sample Time (s)                    107.362
Epoch Time (s)                     233.5
Total Train Time (s)             10784.3
Epoch                               46
------------------------------  ----------------
2019-06-27 03:32:36.283651 UTC | [dialturn] Iteration #46 | Epoch Duration: 233.44380807876587
2019-06-27 03:32:36.283883 UTC | [dialturn] Iteration #46 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00154999
Z variance train                     0.99853
KL Divergence                        0.000392706
KL Loss                              3.92706e-05
QF Loss                              3.64904e+07
VF Loss                         584894
RF Loss                          55099.1
Policy Loss                     -46087.8
Q Predictions Mean               45613.8
Q Predictions Std                57092.4
Q Predictions Max               246019
Q Predictions Min                  292.845
V Predictions Mean               45577.4
V Predictions Std                57066.2
V Predictions Max               248121
V Predictions Min                  296.221
R Predictions Mean                 593.156
R Predictions Std                 1279.74
R Predictions Max                 8605.07
R Predictions Min                  -11.6377
Log Pis Mean                        23.095
Log Pis Std                         13.0393
Log Pis Max                         51.5985
Log Pis Min                         -1.69704
Policy mu Mean                      -4.73686
Policy mu Std                       20.499
Policy mu Max                      102.99
Policy mu Min                     -114.38
Policy log std Mean                 -0.470441
Policy log std Std                   1.29522
Policy log std Max                   2
Policy log std Min                  -4.47758
_task0 Rewards Mean                 40.8658
_task0 Rewards Std                 109.091
_task0 Rewards Max                 975.141
_task0 Rewards Min                  -0.938006
_task0 Returns Mean               6129.87
_task0 Returns Std               10971.5
_task0 Returns Max               31521.6
_task0 Returns Min                -116.717
_task0 Actions Mean                  0.0569084
_task0 Actions Std                   0.842428
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     506.201
Exploration_task0 Rewards Std     1170.37
Exploration_task0 Rewards Max    17530.1
Exploration_task0 Rewards Min      -12.5823
Exploration_task0 Returns Mean   76697.2
Exploration_task0 Returns Std   128548
Exploration_task0 Returns Max   756546
Exploration_task0 Returns Min    -1474.96
Exploration_task0 Actions Mean       0.0166251
Exploration_task0 Actions Std        0.853146
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6129.87
AverageReturn_all_train_tasks     6069.75
AverageReturn_all_test_tasks      6129.87
Number of train steps total      48000
Number of env steps total            2.401e+06
Number of rollouts total         17430
Train Time (s)                      98.1353
(Previous) Eval Time (s)            25.6901
Sample Time (s)                    106.015
Epoch Time (s)                     229.841
Total Train Time (s)             11014.1
Epoch                               47
------------------------------  ----------------
2019-06-27 03:36:26.098381 UTC | [dialturn] Iteration #47 | Epoch Duration: 229.8142910003662
2019-06-27 03:36:26.098574 UTC | [dialturn] Iteration #47 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00112294
Z variance train                     1.00101
KL Divergence                        0.000109073
KL Loss                              1.09073e-05
QF Loss                              8.41237e+07
VF Loss                         144915
RF Loss                          26398.3
Policy Loss                     -44908.2
Q Predictions Mean               44522.9
Q Predictions Std                55659.4
Q Predictions Max               212032
Q Predictions Min                  281.447
V Predictions Mean               45031.7
V Predictions Std                56225.1
V Predictions Max               213030
V Predictions Min                  261.117
R Predictions Mean                 461.424
R Predictions Std                 1242.06
R Predictions Max                15915.3
R Predictions Min                  -25.934
Log Pis Mean                        23.0065
Log Pis Std                         12.2445
Log Pis Max                         49.3838
Log Pis Min                         -2.32347
Policy mu Mean                      -4.71849
Policy mu Std                       21.6804
Policy mu Max                      116.697
Policy mu Min                      -90.4349
Policy log std Mean                 -0.388079
Policy log std Std                   1.31903
Policy log std Max                   2
Policy log std Min                  -4.36004
_task0 Rewards Mean                 49.4998
_task0 Rewards Std                 137.808
_task0 Rewards Max                1382.25
_task0 Rewards Min                  -0.844655
_task0 Returns Mean               7424.98
_task0 Returns Std               13056.5
_task0 Returns Max               36632.3
_task0 Returns Min                -104.118
_task0 Actions Mean                  0.0335823
_task0 Actions Std                   0.824721
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     419.932
Exploration_task0 Rewards Std     1052.11
Exploration_task0 Rewards Max    20144.6
Exploration_task0 Rewards Min       -9.31622
Exploration_task0 Returns Mean   63626
Exploration_task0 Returns Std   112048
Exploration_task0 Returns Max   435891
Exploration_task0 Returns Min    -1518.6
Exploration_task0 Actions Mean       0.0615963
Exploration_task0 Actions Std        0.840762
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7424.98
AverageReturn_all_train_tasks     7631.58
AverageReturn_all_test_tasks      7424.98
Number of train steps total      49000
Number of env steps total            2.451e+06
Number of rollouts total         17793
Train Time (s)                      98.6051
(Previous) Eval Time (s)            25.6622
Sample Time (s)                    106.139
Epoch Time (s)                     230.406
Total Train Time (s)             11244.5
Epoch                               48
------------------------------  ----------------
2019-06-27 03:40:16.521759 UTC | [dialturn] Iteration #48 | Epoch Duration: 230.42303037643433
2019-06-27 03:40:16.521970 UTC | [dialturn] Iteration #48 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00196947
Z variance train                     0.998425
KL Divergence                        0.000737674
KL Loss                              7.37674e-05
QF Loss                              8.62355e+07
VF Loss                         477902
RF Loss                           9939.89
Policy Loss                     -44949.2
Q Predictions Mean               44406.3
Q Predictions Std                55440.3
Q Predictions Max               250001
Q Predictions Min                  328.75
V Predictions Mean               45499.3
V Predictions Std                56230.1
V Predictions Max               254204
V Predictions Min                  712.319
R Predictions Mean                 427.007
R Predictions Std                 1226.28
R Predictions Max                13309.9
R Predictions Min                  -33.0826
Log Pis Mean                        23.1761
Log Pis Std                         13.3352
Log Pis Max                         51.6214
Log Pis Min                         -5.85697
Policy mu Mean                      -3.32295
Policy mu Std                       22.4025
Policy mu Max                      152.22
Policy mu Min                     -106.416
Policy log std Mean                 -0.361833
Policy log std Std                   1.28563
Policy log std Max                   2
Policy log std Min                  -4.33811
_task0 Rewards Mean                 36.5586
_task0 Rewards Std                  86.4984
_task0 Rewards Max                 645.528
_task0 Rewards Min                  -0.767602
_task0 Returns Mean               5483.79
_task0 Returns Std                9281.89
_task0 Returns Max               29320
_task0 Returns Min                 -99.5275
_task0 Actions Mean                  0.0426456
_task0 Actions Std                   0.847071
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     339.317
Exploration_task0 Rewards Std      986.134
Exploration_task0 Rewards Max    17685.3
Exploration_task0 Rewards Min      -10.6035
Exploration_task0 Returns Mean   51411.7
Exploration_task0 Returns Std    97818.9
Exploration_task0 Returns Max   463785
Exploration_task0 Returns Min    -1587.31
Exploration_task0 Actions Mean       0.0250436
Exploration_task0 Actions Std        0.850719
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5483.79
AverageReturn_all_train_tasks     6660.18
AverageReturn_all_test_tasks      5483.79
Number of train steps total      50000
Number of env steps total            2.501e+06
Number of rollouts total         18156
Train Time (s)                      98.597
(Previous) Eval Time (s)            25.6776
Sample Time (s)                    106.425
Epoch Time (s)                     230.7
Total Train Time (s)             11475.2
Epoch                               49
------------------------------  ----------------
2019-06-27 03:44:07.186444 UTC | [dialturn] Iteration #49 | Epoch Duration: 230.66426753997803
2019-06-27 03:44:07.186676 UTC | [dialturn] Iteration #49 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00236468
Z variance train                     0.995873
KL Divergence                        0.00151435
KL Loss                              0.000151435
QF Loss                              7.59663e+07
VF Loss                         349053
RF Loss                          10415.8
Policy Loss                     -44455.4
Q Predictions Mean               43954.9
Q Predictions Std                55126.6
Q Predictions Max               231682
Q Predictions Min                  103.318
V Predictions Mean               44794.2
V Predictions Std                55955.3
V Predictions Max               236922
V Predictions Min                  272.676
R Predictions Mean                 480.598
R Predictions Std                 1158.55
R Predictions Max                10310.6
R Predictions Min                  -61.4958
Log Pis Mean                        23.5415
Log Pis Std                         12.5878
Log Pis Max                         53.1941
Log Pis Min                         -3.08381
Policy mu Mean                      -4.94738
Policy mu Std                       21.2251
Policy mu Max                       93.9995
Policy mu Min                      -90.035
Policy log std Mean                 -0.371084
Policy log std Std                   1.27228
Policy log std Max                   2
Policy log std Min                  -4.59545
_task0 Rewards Mean                 44.2321
_task0 Rewards Std                 124.995
_task0 Rewards Max                1264.29
_task0 Rewards Min                  -0.857204
_task0 Returns Mean               6634.81
_task0 Returns Std               11520.5
_task0 Returns Max               38424.5
_task0 Returns Min                 -98.7594
_task0 Actions Mean                  0.0368403
_task0 Actions Std                   0.793467
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     429.26
Exploration_task0 Rewards Std     1079.04
Exploration_task0 Rewards Max    19589.8
Exploration_task0 Rewards Min      -10.0422
Exploration_task0 Returns Mean   65039.4
Exploration_task0 Returns Std   108918
Exploration_task0 Returns Max   398133
Exploration_task0 Returns Min    -1355.56
Exploration_task0 Actions Mean       0.0507666
Exploration_task0 Actions Std        0.844905
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6634.81
AverageReturn_all_train_tasks     2737.09
AverageReturn_all_test_tasks      6634.81
Number of train steps total      51000
Number of env steps total            2.551e+06
Number of rollouts total         18519
Train Time (s)                      98.79
(Previous) Eval Time (s)            25.6408
Sample Time (s)                    106.799
Epoch Time (s)                     231.229
Total Train Time (s)             11706.4
Epoch                               50
------------------------------  ----------------
2019-06-27 03:47:58.372284 UTC | [dialturn] Iteration #50 | Epoch Duration: 231.1853687763214
2019-06-27 03:47:58.372490 UTC | [dialturn] Iteration #50 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000915728
Z variance train                     1.00131
KL Divergence                        0.0001372
KL Loss                              1.372e-05
QF Loss                              1.10277e+08
VF Loss                         264525
RF Loss                           9537.12
Policy Loss                     -45863.7
Q Predictions Mean               45430.3
Q Predictions Std                55851.1
Q Predictions Max               241941
Q Predictions Min                  122.75
V Predictions Mean               45515.1
V Predictions Std                56054.5
V Predictions Max               244698
V Predictions Min                  275.491
R Predictions Mean                 495.302
R Predictions Std                 1116.12
R Predictions Max                 9963.29
R Predictions Min                  -16.5329
Log Pis Mean                        22.7348
Log Pis Std                         13.1259
Log Pis Max                         52.2857
Log Pis Min                         -1.53838
Policy mu Mean                      -5.79528
Policy mu Std                       22.335
Policy mu Max                      144.914
Policy mu Min                     -157.639
Policy log std Mean                 -0.305922
Policy log std Std                   1.27948
Policy log std Max                   2
Policy log std Min                  -4.53479
_task0 Rewards Mean                 46.2091
_task0 Rewards Std                  95.4668
_task0 Rewards Max                 725.168
_task0 Rewards Min                  -0.796621
_task0 Returns Mean               6931.37
_task0 Returns Std               11701
_task0 Returns Max               36819
_task0 Returns Min                 -93.9097
_task0 Actions Mean                  0.0222886
_task0 Actions Std                   0.84003
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     467.879
Exploration_task0 Rewards Std     1257.5
Exploration_task0 Rewards Max    22830.9
Exploration_task0 Rewards Min       -9.01248
Exploration_task0 Returns Mean   70890.8
Exploration_task0 Returns Std   121169
Exploration_task0 Returns Max   420563
Exploration_task0 Returns Min    -1188.4
Exploration_task0 Actions Mean       0.0513265
Exploration_task0 Actions Std        0.847474
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6931.37
AverageReturn_all_train_tasks     4252.68
AverageReturn_all_test_tasks      6931.37
Number of train steps total      52000
Number of env steps total            2.601e+06
Number of rollouts total         18882
Train Time (s)                      99.4583
(Previous) Eval Time (s)            25.5956
Sample Time (s)                    106.725
Epoch Time (s)                     231.779
Total Train Time (s)             11938.3
Epoch                               51
------------------------------  ----------------
2019-06-27 03:51:50.336955 UTC | [dialturn] Iteration #51 | Epoch Duration: 231.96425008773804
2019-06-27 03:51:50.337162 UTC | [dialturn] Iteration #51 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00147872
Z variance train                     1.00004
KL Divergence                        0.000201528
KL Loss                              2.01528e-05
QF Loss                              9.88984e+07
VF Loss                         165305
RF Loss                           8678.05
Policy Loss                     -43431.9
Q Predictions Mean               43019.4
Q Predictions Std                53338.1
Q Predictions Max               234040
Q Predictions Min                    6.57667
V Predictions Mean               43484.4
V Predictions Std                53825.4
V Predictions Max               237021
V Predictions Min                  275.877
R Predictions Mean                 492.597
R Predictions Std                 1246.25
R Predictions Max                11896.8
R Predictions Min                  -27.8888
Log Pis Mean                        22.8195
Log Pis Std                         12.8913
Log Pis Max                         52.453
Log Pis Min                         -2.21968
Policy mu Mean                      -4.70081
Policy mu Std                       20.4373
Policy mu Max                      133.157
Policy mu Min                     -146.981
Policy log std Mean                 -0.258351
Policy log std Std                   1.23852
Policy log std Max                   2
Policy log std Min                  -4.45314
_task0 Rewards Mean                 55.6918
_task0 Rewards Std                 114.302
_task0 Rewards Max                 705.919
_task0 Rewards Min                  -0.918477
_task0 Returns Mean               8353.77
_task0 Returns Std               11896.3
_task0 Returns Max               28873.6
_task0 Returns Min                -104.544
_task0 Actions Mean                 -0.0649607
_task0 Actions Std                   0.835342
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     407.636
Exploration_task0 Rewards Std     1122.52
Exploration_task0 Rewards Max    16652.7
Exploration_task0 Rewards Min      -10.3721
Exploration_task0 Returns Mean   61763
Exploration_task0 Returns Std   109029
Exploration_task0 Returns Max   401894
Exploration_task0 Returns Min    -1220.94
Exploration_task0 Actions Mean       0.00111071
Exploration_task0 Actions Std        0.842024
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8353.77
AverageReturn_all_train_tasks     4412.1
AverageReturn_all_test_tasks      8353.77
Number of train steps total      53000
Number of env steps total            2.651e+06
Number of rollouts total         19245
Train Time (s)                      99.9105
(Previous) Eval Time (s)            25.7791
Sample Time (s)                    107.628
Epoch Time (s)                     233.317
Total Train Time (s)             12171.4
Epoch                               52
------------------------------  ----------------
2019-06-27 03:55:43.418682 UTC | [dialturn] Iteration #52 | Epoch Duration: 233.08129811286926
2019-06-27 03:55:43.418920 UTC | [dialturn] Iteration #52 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00196549
Z variance train                     0.998166
KL Divergence                        0.000543721
KL Loss                              5.43721e-05
QF Loss                              7.8826e+07
VF Loss                         229026
RF Loss                          19516.6
Policy Loss                     -43056.6
Q Predictions Mean               42558.6
Q Predictions Std                54128.2
Q Predictions Max               240396
Q Predictions Min                   84.5063
V Predictions Mean               43410.1
V Predictions Std                54703.3
V Predictions Max               244664
V Predictions Min                  471.441
R Predictions Mean                 538.319
R Predictions Std                 1155.88
R Predictions Max                 9331.81
R Predictions Min                 -293.183
Log Pis Mean                        22.8569
Log Pis Std                         12.685
Log Pis Max                         49.6236
Log Pis Min                         -2.26428
Policy mu Mean                      -3.31439
Policy mu Std                       18.9536
Policy mu Max                      149.832
Policy mu Min                     -143.956
Policy log std Mean                 -0.321339
Policy log std Std                   1.24876
Policy log std Max                   2
Policy log std Min                  -4.53407
_task0 Rewards Mean                 40.0281
_task0 Rewards Std                  99.54
_task0 Rewards Max                 729.778
_task0 Rewards Min                  -0.827619
_task0 Returns Mean               6004.22
_task0 Returns Std               11077.6
_task0 Returns Max               28983.7
_task0 Returns Min                -103.657
_task0 Actions Mean                  0.0747506
_task0 Actions Std                   0.839503
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     431.254
Exploration_task0 Rewards Std      997.909
Exploration_task0 Rewards Max    13395.4
Exploration_task0 Rewards Min       -9.51854
Exploration_task0 Returns Mean   65341.5
Exploration_task0 Returns Std   111979
Exploration_task0 Returns Max   399660
Exploration_task0 Returns Min    -1357.29
Exploration_task0 Actions Mean       0.112593
Exploration_task0 Actions Std        0.839119
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6004.22
AverageReturn_all_train_tasks     4703.79
AverageReturn_all_test_tasks      6004.22
Number of train steps total      54000
Number of env steps total            2.701e+06
Number of rollouts total         19608
Train Time (s)                      98.8259
(Previous) Eval Time (s)            25.5416
Sample Time (s)                    106.798
Epoch Time (s)                     231.166
Total Train Time (s)             12402.5
Epoch                               53
------------------------------  ----------------
2019-06-27 03:59:34.557891 UTC | [dialturn] Iteration #53 | Epoch Duration: 231.1387813091278
2019-06-27 03:59:34.558103 UTC | [dialturn] Iteration #53 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000624771
Z variance train                     1.00237
KL Divergence                        0.000133461
KL Loss                              1.33461e-05
QF Loss                              4.88433e+07
VF Loss                         569178
RF Loss                          11302.1
Policy Loss                     -43266.2
Q Predictions Mean               42837.1
Q Predictions Std                53262.3
Q Predictions Max               249039
Q Predictions Min                   32.3791
V Predictions Mean               43717.6
V Predictions Std                54158.9
V Predictions Max               252354
V Predictions Min                  300.473
R Predictions Mean                 486.57
R Predictions Std                 1152.18
R Predictions Max                 9556.94
R Predictions Min                  -25.6522
Log Pis Mean                        23.0383
Log Pis Std                         12.4118
Log Pis Max                         51.6138
Log Pis Min                         -6.31506
Policy mu Mean                      -3.87197
Policy mu Std                       18.6221
Policy mu Max                      176.327
Policy mu Min                     -168.494
Policy log std Mean                 -0.226954
Policy log std Std                   1.21182
Policy log std Max                   2
Policy log std Min                  -4.82233
_task0 Rewards Mean                 22.6808
_task0 Rewards Std                  68.4498
_task0 Rewards Max                 850.874
_task0 Rewards Min                  -0.885445
_task0 Returns Mean               3402.12
_task0 Returns Std                6211.74
_task0 Returns Max               24011.5
_task0 Returns Min                -105.817
_task0 Actions Mean                  0.221649
_task0 Actions Std                   0.793692
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     355.564
Exploration_task0 Rewards Std     1004.65
Exploration_task0 Rewards Max    11936.9
Exploration_task0 Rewards Min      -10.467
Exploration_task0 Returns Mean   53873.3
Exploration_task0 Returns Std   102334
Exploration_task0 Returns Max   371522
Exploration_task0 Returns Min    -1432.8
Exploration_task0 Actions Mean       0.0971372
Exploration_task0 Actions Std        0.831005
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3402.12
AverageReturn_all_train_tasks     7211.43
AverageReturn_all_test_tasks      3402.12
Number of train steps total      55000
Number of env steps total            2.751e+06
Number of rollouts total         19971
Train Time (s)                      98.2233
(Previous) Eval Time (s)            25.5132
Sample Time (s)                    106.408
Epoch Time (s)                     230.145
Total Train Time (s)             12632.7
Epoch                               54
------------------------------  ----------------
2019-06-27 04:03:24.723235 UTC | [dialturn] Iteration #54 | Epoch Duration: 230.16492795944214
2019-06-27 04:03:24.723426 UTC | [dialturn] Iteration #54 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000841362
Z variance train                     0.998846
KL Divergence                        0.000175422
KL Loss                              1.75422e-05
QF Loss                              5.40142e+07
VF Loss                         351942
RF Loss                           5526.48
Policy Loss                     -42968.6
Q Predictions Mean               42476.1
Q Predictions Std                52727.8
Q Predictions Max               227640
Q Predictions Min                   27.4269
V Predictions Mean               42674.3
V Predictions Std                52822.3
V Predictions Max               230361
V Predictions Min                  313.824
R Predictions Mean                 425
R Predictions Std                  992.393
R Predictions Max                 8303.9
R Predictions Min                  -13.0214
Log Pis Mean                        23.7016
Log Pis Std                         12.3229
Log Pis Max                         52.1044
Log Pis Min                         -1.02513
Policy mu Mean                      -2.58566
Policy mu Std                       17.6587
Policy mu Max                      188.629
Policy mu Min                     -177.671
Policy log std Mean                 -0.271691
Policy log std Std                   1.17597
Policy log std Max                   2
Policy log std Min                  -5.05045
_task0 Rewards Mean                 50.1701
_task0 Rewards Std                 135.011
_task0 Rewards Max                1490.88
_task0 Rewards Min                  -0.785506
_task0 Returns Mean               7525.51
_task0 Returns Std               13055.7
_task0 Returns Max               38978.1
_task0 Returns Min                -102.284
_task0 Actions Mean                  0.128895
_task0 Actions Std                   0.798247
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     391.337
Exploration_task0 Rewards Std     1021.74
Exploration_task0 Rewards Max    20154.7
Exploration_task0 Rewards Min      -10.8447
Exploration_task0 Returns Mean   59293.5
Exploration_task0 Returns Std    99233.9
Exploration_task0 Returns Max   402088
Exploration_task0 Returns Min    -1471.72
Exploration_task0 Actions Mean       0.115438
Exploration_task0 Actions Std        0.828431
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7525.51
AverageReturn_all_train_tasks     3775.22
AverageReturn_all_test_tasks      7525.51
Number of train steps total      56000
Number of env steps total            2.801e+06
Number of rollouts total         20334
Train Time (s)                     100.362
(Previous) Eval Time (s)            25.5321
Sample Time (s)                    106.997
Epoch Time (s)                     232.892
Total Train Time (s)             12865.4
Epoch                               55
------------------------------  ----------------
2019-06-27 04:07:17.442223 UTC | [dialturn] Iteration #55 | Epoch Duration: 232.71859669685364
2019-06-27 04:07:17.442413 UTC | [dialturn] Iteration #55 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00263192
Z variance train                     0.999953
KL Divergence                        0.000525243
KL Loss                              5.25243e-05
QF Loss                              5.21067e+07
VF Loss                         107258
RF Loss                           7200.59
Policy Loss                     -44451.6
Q Predictions Mean               43906.3
Q Predictions Std                53639.7
Q Predictions Max               218905
Q Predictions Min                  108.612
V Predictions Mean               44600.4
V Predictions Std                54226.3
V Predictions Max               220181
V Predictions Min                  298.874
R Predictions Mean                 433.817
R Predictions Std                  988.48
R Predictions Max                 8812.81
R Predictions Min                  -26.4133
Log Pis Mean                        23.8067
Log Pis Std                         12.4318
Log Pis Max                         52.793
Log Pis Min                         -7.33858
Policy mu Mean                      -3.47608
Policy mu Std                       17.0088
Policy mu Max                      123.925
Policy mu Min                     -108.388
Policy log std Mean                 -0.24547
Policy log std Std                   1.18941
Policy log std Max                   2
Policy log std Min                  -4.99295
_task0 Rewards Mean                 38.4075
_task0 Rewards Std                 111.156
_task0 Rewards Max                1415.83
_task0 Rewards Min                  -0.819075
_task0 Returns Mean               5761.13
_task0 Returns Std               10680.2
_task0 Returns Max               32832
_task0 Returns Min                -103.865
_task0 Actions Mean                  0.0868705
_task0 Actions Std                   0.806457
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     536.897
Exploration_task0 Rewards Std     1117.59
Exploration_task0 Rewards Max    16198.3
Exploration_task0 Rewards Min       -9.39842
Exploration_task0 Returns Mean   81348.1
Exploration_task0 Returns Std   125985
Exploration_task0 Returns Max   381786
Exploration_task0 Returns Min    -1299.05
Exploration_task0 Actions Mean       0.0538643
Exploration_task0 Actions Std        0.860156
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5761.13
AverageReturn_all_train_tasks     8736.49
AverageReturn_all_test_tasks      5761.13
Number of train steps total      57000
Number of env steps total            2.851e+06
Number of rollouts total         20697
Train Time (s)                      99.1882
(Previous) Eval Time (s)            25.3577
Sample Time (s)                    106.597
Epoch Time (s)                     231.142
Total Train Time (s)             13096.8
Epoch                               56
------------------------------  ----------------
2019-06-27 04:11:08.858532 UTC | [dialturn] Iteration #56 | Epoch Duration: 231.41596031188965
2019-06-27 04:11:08.858722 UTC | [dialturn] Iteration #56 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00154909
Z variance train                     1.00089
KL Divergence                        0.000221908
KL Loss                              2.21908e-05
QF Loss                              4.8386e+07
VF Loss                         799674
RF Loss                          12215.2
Policy Loss                     -42770.5
Q Predictions Mean               42213.3
Q Predictions Std                52102.6
Q Predictions Max               218056
Q Predictions Min                   99.1497
V Predictions Mean               42178.2
V Predictions Std                52134.3
V Predictions Max               217566
V Predictions Min                  302.095
R Predictions Mean                 358.516
R Predictions Std                  903.905
R Predictions Max                13987.9
R Predictions Min                  -37.281
Log Pis Mean                        22.2578
Log Pis Std                         12.5074
Log Pis Max                         50.924
Log Pis Min                         -3.41477
Policy mu Mean                      -2.95682
Policy mu Std                       15.7168
Policy mu Max                      118.403
Policy mu Min                     -102.693
Policy log std Mean                 -0.292447
Policy log std Std                   1.15861
Policy log std Max                   2
Policy log std Min                  -4.85626
_task0 Rewards Mean                 59.6537
_task0 Rewards Std                 121.445
_task0 Rewards Max                1469.29
_task0 Rewards Min                  -0.789634
_task0 Returns Mean               8948.05
_task0 Returns Std               13803.9
_task0 Returns Max               33900.6
_task0 Returns Min                 -99.4566
_task0 Actions Mean                 -0.05904
_task0 Actions Std                   0.843244
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     456.386
Exploration_task0 Rewards Std     1087.17
Exploration_task0 Rewards Max    17677
Exploration_task0 Rewards Min      -13.1303
Exploration_task0 Returns Mean   69149.4
Exploration_task0 Returns Std   115702
Exploration_task0 Returns Max   361391
Exploration_task0 Returns Min    -1390.15
Exploration_task0 Actions Mean       0.0781985
Exploration_task0 Actions Std        0.827641
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8948.05
AverageReturn_all_train_tasks     4457.34
AverageReturn_all_test_tasks      8948.05
Number of train steps total      58000
Number of env steps total            2.901e+06
Number of rollouts total         21060
Train Time (s)                     100.532
(Previous) Eval Time (s)            25.6298
Sample Time (s)                    107.091
Epoch Time (s)                     233.253
Total Train Time (s)             13330
Epoch                               57
------------------------------  ----------------
2019-06-27 04:15:02.027179 UTC | [dialturn] Iteration #57 | Epoch Duration: 233.16830325126648
2019-06-27 04:15:02.027377 UTC | [dialturn] Iteration #57 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00175311
Z variance train                     0.998996
KL Divergence                        0.000822295
KL Loss                              8.22295e-05
QF Loss                              4.70861e+07
VF Loss                         187551
RF Loss                          11023.8
Policy Loss                     -43083.4
Q Predictions Mean               42513.1
Q Predictions Std                51734.3
Q Predictions Max               225678
Q Predictions Min                  158.63
V Predictions Mean               42755.2
V Predictions Std                52182.5
V Predictions Max               224976
V Predictions Min                  345.298
R Predictions Mean                 436.182
R Predictions Std                  991.968
R Predictions Max                10118
R Predictions Min                  -35.9248
Log Pis Mean                        23.6531
Log Pis Std                         12.8972
Log Pis Max                         51.4865
Log Pis Min                         -6.3556
Policy mu Mean                      -4.07276
Policy mu Std                       17.9549
Policy mu Max                      116.713
Policy mu Min                      -79.4864
Policy log std Mean                 -0.216959
Policy log std Std                   1.21952
Policy log std Max                   2
Policy log std Min                  -5.14223
_task0 Rewards Mean                 46.1192
_task0 Rewards Std                  93.7694
_task0 Rewards Max                 671.412
_task0 Rewards Min                  -1.11752
_task0 Returns Mean               6917.87
_task0 Returns Std               11895.6
_task0 Returns Max               35441
_task0 Returns Min                -104.297
_task0 Actions Mean                  0.0689342
_task0 Actions Std                   0.878149
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     419.142
Exploration_task0 Rewards Std     1109.62
Exploration_task0 Rewards Max    22760.2
Exploration_task0 Rewards Min      -10.2162
Exploration_task0 Returns Mean   63506.4
Exploration_task0 Returns Std   111489
Exploration_task0 Returns Max   529649
Exploration_task0 Returns Min    -1291.57
Exploration_task0 Actions Mean       0.100127
Exploration_task0 Actions Std        0.85067
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6917.87
AverageReturn_all_train_tasks     6199.88
AverageReturn_all_test_tasks      6917.87
Number of train steps total      59000
Number of env steps total            2.951e+06
Number of rollouts total         21423
Train Time (s)                     100.023
(Previous) Eval Time (s)            25.5434
Sample Time (s)                    107.112
Epoch Time (s)                     232.678
Total Train Time (s)             13562.8
Epoch                               58
------------------------------  ----------------
2019-06-27 04:18:54.835596 UTC | [dialturn] Iteration #58 | Epoch Duration: 232.80805778503418
2019-06-27 04:18:54.835807 UTC | [dialturn] Iteration #58 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00311531
Z variance train                     1.00088
KL Divergence                        0.00118773
KL Loss                              0.000118773
QF Loss                              2.64137e+07
VF Loss                         222837
RF Loss                          25261.6
Policy Loss                     -41100
Q Predictions Mean               40655.4
Q Predictions Std                50348.6
Q Predictions Max               220878
Q Predictions Min                 1043.57
V Predictions Mean               41446.7
V Predictions Std                50924
V Predictions Max               221964
V Predictions Min                 1571.83
R Predictions Mean                 472.684
R Predictions Std                 1015.25
R Predictions Max                11214.5
R Predictions Min                  -24.4972
Log Pis Mean                        22.0379
Log Pis Std                         12.5955
Log Pis Max                         50.0938
Log Pis Min                         -3.82324
Policy mu Mean                      -2.28824
Policy mu Std                       15.759
Policy mu Max                      118.507
Policy mu Min                      -84.4947
Policy log std Mean                 -0.314409
Policy log std Std                   1.19788
Policy log std Max                   2
Policy log std Min                  -5.01365
_task0 Rewards Mean                 49.1397
_task0 Rewards Std                 100.927
_task0 Rewards Max                 756.373
_task0 Rewards Min                  -0.962564
_task0 Returns Mean               7370.95
_task0 Returns Std               11565.3
_task0 Returns Max               30883.2
_task0 Returns Min                -115.798
_task0 Actions Mean                 -0.00778194
_task0 Actions Std                   0.805396
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     412.502
Exploration_task0 Rewards Std      945.533
Exploration_task0 Rewards Max    18136
Exploration_task0 Rewards Min       -9.27196
Exploration_task0 Returns Mean   62500.3
Exploration_task0 Returns Std   106486
Exploration_task0 Returns Max   405129
Exploration_task0 Returns Min    -1239.12
Exploration_task0 Actions Mean       0.0462963
Exploration_task0 Actions Std        0.803308
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7370.95
AverageReturn_all_train_tasks     2866.5
AverageReturn_all_test_tasks      7370.95
Number of train steps total      60000
Number of env steps total            3.001e+06
Number of rollouts total         21786
Train Time (s)                     100.388
(Previous) Eval Time (s)            25.6717
Sample Time (s)                    107.676
Epoch Time (s)                     233.735
Total Train Time (s)             13796.6
Epoch                               59
------------------------------  ----------------
2019-06-27 04:22:48.646590 UTC | [dialturn] Iteration #59 | Epoch Duration: 233.81055974960327
2019-06-27 04:22:48.646787 UTC | [dialturn] Iteration #59 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00225036
Z variance train                     0.999128
KL Divergence                        0.000536412
KL Loss                              5.36412e-05
QF Loss                              2.18037e+07
VF Loss                         156453
RF Loss                          22252
Policy Loss                     -40081.7
Q Predictions Mean               39553.9
Q Predictions Std                49274.6
Q Predictions Max               217041
Q Predictions Min                 2389.76
V Predictions Mean               39780.6
V Predictions Std                49656.3
V Predictions Max               217824
V Predictions Min                 2668.24
R Predictions Mean                 495.439
R Predictions Std                  902.12
R Predictions Max                 7718.12
R Predictions Min                  -12.3985
Log Pis Mean                        22.5773
Log Pis Std                         13.0331
Log Pis Max                         52.1283
Log Pis Min                         -4.71415
Policy mu Mean                      -2.13921
Policy mu Std                       15.8315
Policy mu Max                      107.669
Policy mu Min                      -81.0915
Policy log std Mean                 -0.229609
Policy log std Std                   1.15494
Policy log std Max                   2
Policy log std Min                  -4.82088
_task0 Rewards Mean                 17.1061
_task0 Rewards Std                  79.9245
_task0 Rewards Max                 952.108
_task0 Rewards Min                  -0.788971
_task0 Returns Mean               2565.92
_task0 Returns Std                7830.09
_task0 Returns Max               28106.5
_task0 Returns Min                -100.379
_task0 Actions Mean                 -0.283939
_task0 Actions Std                   0.798095
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     409.528
Exploration_task0 Rewards Std      844.654
Exploration_task0 Rewards Max    18600.2
Exploration_task0 Rewards Min      -11.5353
Exploration_task0 Returns Mean   62049.7
Exploration_task0 Returns Std    98853.1
Exploration_task0 Returns Max   449224
Exploration_task0 Returns Min    -1216.84
Exploration_task0 Actions Mean      -0.0305255
Exploration_task0 Actions Std        0.826176
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              2565.92
AverageReturn_all_train_tasks      134.536
AverageReturn_all_test_tasks      2565.92
Number of train steps total      61000
Number of env steps total            3.051e+06
Number of rollouts total         22149
Train Time (s)                     100.776
(Previous) Eval Time (s)            25.7455
Sample Time (s)                    106.598
Epoch Time (s)                     233.119
Total Train Time (s)             14029.6
Epoch                               60
------------------------------  ----------------
2019-06-27 04:26:41.592635 UTC | [dialturn] Iteration #60 | Epoch Duration: 232.94568490982056
2019-06-27 04:26:41.592844 UTC | [dialturn] Iteration #60 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00158799
Z variance train                     1.00105
KL Divergence                        0.000358384
KL Loss                              3.58384e-05
QF Loss                              4.61113e+07
VF Loss                          86552.9
RF Loss                         564034
Policy Loss                     -42663.2
Q Predictions Mean               42200.2
Q Predictions Std                52603.9
Q Predictions Max               251729
Q Predictions Min                  866.187
V Predictions Mean               42564.3
V Predictions Std                53139.1
V Predictions Max               251185
V Predictions Min                 1381.28
R Predictions Mean                 400.6
R Predictions Std                 1221.17
R Predictions Max                10930.9
R Predictions Min                  -14.4556
Log Pis Mean                        22.5391
Log Pis Std                         12.7797
Log Pis Max                         51.1078
Log Pis Min                         -1.71526
Policy mu Mean                      -4.34199
Policy mu Std                       15.8579
Policy mu Max                       99.9299
Policy mu Min                      -87.0476
Policy log std Mean                 -0.297091
Policy log std Std                   1.2461
Policy log std Max                   2
Policy log std Min                  -4.72031
_task0 Rewards Mean                 64.3331
_task0 Rewards Std                 151.908
_task0 Rewards Max                1600.5
_task0 Rewards Min                  -0.882015
_task0 Returns Mean               9649.96
_task0 Returns Std               14519.3
_task0 Returns Max               40698.1
_task0 Returns Min                 -96.654
_task0 Actions Mean                 -0.0866081
_task0 Actions Std                   0.865856
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     252.94
Exploration_task0 Rewards Std      932.214
Exploration_task0 Rewards Max    20950.7
Exploration_task0 Rewards Min      -13.451
Exploration_task0 Returns Mean   38324.3
Exploration_task0 Returns Std    94907.7
Exploration_task0 Returns Max   396880
Exploration_task0 Returns Min    -1076.24
Exploration_task0 Actions Mean      -0.137398
Exploration_task0 Actions Std        0.82159
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9649.96
AverageReturn_all_train_tasks     4556.16
AverageReturn_all_test_tasks      9649.96
Number of train steps total      62000
Number of env steps total            3.101e+06
Number of rollouts total         22512
Train Time (s)                      99.4061
(Previous) Eval Time (s)            25.5709
Sample Time (s)                    107.077
Epoch Time (s)                     232.054
Total Train Time (s)             14261.7
Epoch                               61
------------------------------  ----------------
2019-06-27 04:30:33.744201 UTC | [dialturn] Iteration #61 | Epoch Duration: 232.15118956565857
2019-06-27 04:30:33.744428 UTC | [dialturn] Iteration #61 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00183113
Z variance train                     1.00173
KL Divergence                        0.000577904
KL Loss                              5.77904e-05
QF Loss                              8.27865e+07
VF Loss                         106114
RF Loss                          51171.5
Policy Loss                     -42929.5
Q Predictions Mean               42488.7
Q Predictions Std                52354.3
Q Predictions Max               245996
Q Predictions Min                 2679.43
V Predictions Mean               42955.9
V Predictions Std                52855
V Predictions Max               248565
V Predictions Min                 2713.22
R Predictions Mean                 586.939
R Predictions Std                 1239.8
R Predictions Max                16237.4
R Predictions Min                  -12.9717
Log Pis Mean                        22.2399
Log Pis Std                         13.1035
Log Pis Max                         50.2067
Log Pis Min                         -3.87835
Policy mu Mean                      -3.33508
Policy mu Std                       17.7756
Policy mu Max                      102.584
Policy mu Min                      -90.5018
Policy log std Mean                 -0.154179
Policy log std Std                   1.24089
Policy log std Max                   2
Policy log std Min                  -4.84302
_task0 Rewards Mean                 35.2332
_task0 Rewards Std                  84.5088
_task0 Rewards Max                 644.078
_task0 Rewards Min                  -0.886326
_task0 Returns Mean               5284.97
_task0 Returns Std                8873.55
_task0 Returns Max               22705.3
_task0 Returns Min                -104.489
_task0 Actions Mean                 -0.0460661
_task0 Actions Std                   0.776224
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     586.885
Exploration_task0 Rewards Std     1253.28
Exploration_task0 Rewards Max    16355
Exploration_task0 Rewards Min       -8.92255
Exploration_task0 Returns Mean   88922
Exploration_task0 Returns Std   136560
Exploration_task0 Returns Max   460370
Exploration_task0 Returns Min    -1231.62
Exploration_task0 Actions Mean      -0.0348246
Exploration_task0 Actions Std        0.832042
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5284.97
AverageReturn_all_train_tasks     7168.37
AverageReturn_all_test_tasks      5284.97
Number of train steps total      63000
Number of env steps total            3.151e+06
Number of rollouts total         22875
Train Time (s)                      98.987
(Previous) Eval Time (s)            25.6666
Sample Time (s)                    107.445
Epoch Time (s)                     232.099
Total Train Time (s)             14494
Epoch                               62
------------------------------  ----------------
2019-06-27 04:34:25.999508 UTC | [dialturn] Iteration #62 | Epoch Duration: 232.25486946105957
2019-06-27 04:34:25.999693 UTC | [dialturn] Iteration #62 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000901134
Z variance train                     0.995334
KL Divergence                        0.00022426
KL Loss                              2.2426e-05
QF Loss                              6.32729e+07
VF Loss                         262014
RF Loss                          23990.9
Policy Loss                     -42210.4
Q Predictions Mean               41879.4
Q Predictions Std                52259.1
Q Predictions Max               244786
Q Predictions Min                 1847.45
V Predictions Mean               42482.9
V Predictions Std                52947.5
V Predictions Max               248357
V Predictions Min                 2224.31
R Predictions Mean                 574.568
R Predictions Std                 1082.45
R Predictions Max                 7562.33
R Predictions Min                  -12.6611
Log Pis Mean                        22.8928
Log Pis Std                         13.179
Log Pis Max                         51.8704
Log Pis Min                         -1.69177
Policy mu Mean                      -2.9086
Policy mu Std                       18.613
Policy mu Max                      123.687
Policy mu Min                      -77.1466
Policy log std Mean                 -0.263582
Policy log std Std                   1.2106
Policy log std Max                   2
Policy log std Min                  -5.07347
_task0 Rewards Mean                 66.6754
_task0 Rewards Std                 167.196
_task0 Rewards Max                2022.79
_task0 Rewards Min                  -0.823036
_task0 Returns Mean              10001.3
_task0 Returns Std               14506.3
_task0 Returns Max               40262.1
_task0 Returns Min                 -99.905
_task0 Actions Mean                 -0.0156695
_task0 Actions Std                   0.809555
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     544.982
Exploration_task0 Rewards Std      993.023
Exploration_task0 Rewards Max    11020
Exploration_task0 Rewards Min      -10.293
Exploration_task0 Returns Mean   82573
Exploration_task0 Returns Std   126070
Exploration_task0 Returns Max   493289
Exploration_task0 Returns Min    -1148.06
Exploration_task0 Actions Mean      -0.0365435
Exploration_task0 Actions Std        0.875227
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10001.3
AverageReturn_all_train_tasks    11976.1
AverageReturn_all_test_tasks     10001.3
Number of train steps total      64000
Number of env steps total            3.201e+06
Number of rollouts total         23238
Train Time (s)                      98.3478
(Previous) Eval Time (s)            25.8214
Sample Time (s)                    107.702
Epoch Time (s)                     231.871
Total Train Time (s)             14725.7
Epoch                               63
------------------------------  ----------------
2019-06-27 04:38:17.766687 UTC | [dialturn] Iteration #63 | Epoch Duration: 231.76682877540588
2019-06-27 04:38:17.766903 UTC | [dialturn] Iteration #63 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0012591
Z variance train                     0.999252
KL Divergence                        0.00015686
KL Loss                              1.5686e-05
QF Loss                              5.39928e+07
VF Loss                         134228
RF Loss                          68378.6
Policy Loss                     -43704.1
Q Predictions Mean               43367.2
Q Predictions Std                52768.5
Q Predictions Max               245996
Q Predictions Min                  975.865
V Predictions Mean               43934.3
V Predictions Std                53232.4
V Predictions Max               248975
V Predictions Min                 1599.29
R Predictions Mean                 694.786
R Predictions Std                 1386.13
R Predictions Max                12900.1
R Predictions Min                  -13.5894
Log Pis Mean                        22.6355
Log Pis Std                         13.2334
Log Pis Max                         50.7785
Log Pis Min                         -1.55057
Policy mu Mean                      -3.34965
Policy mu Std                       19.1345
Policy mu Max                      104.344
Policy mu Min                      -82.3691
Policy log std Mean                 -0.23
Policy log std Std                   1.27246
Policy log std Max                   2
Policy log std Min                  -4.75879
_task0 Rewards Mean                 48.8142
_task0 Rewards Std                  94.6287
_task0 Rewards Max                 825.482
_task0 Rewards Min                  -0.898693
_task0 Returns Mean               7322.13
_task0 Returns Std               11080.9
_task0 Returns Max               30741.1
_task0 Returns Min                -111.635
_task0 Actions Mean                 -0.0392656
_task0 Actions Std                   0.816457
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     567.841
Exploration_task0 Rewards Std     1208.07
Exploration_task0 Rewards Max    18610.9
Exploration_task0 Rewards Min       -9.38162
Exploration_task0 Returns Mean   86036.5
Exploration_task0 Returns Std   135288
Exploration_task0 Returns Max   571410
Exploration_task0 Returns Min    -1263.56
Exploration_task0 Actions Mean      -0.00962445
Exploration_task0 Actions Std        0.832546
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7322.13
AverageReturn_all_train_tasks     9326.88
AverageReturn_all_test_tasks      7322.13
Number of train steps total      65000
Number of env steps total            3.251e+06
Number of rollouts total         23601
Train Time (s)                      98.3401
(Previous) Eval Time (s)            25.7154
Sample Time (s)                    107.353
Epoch Time (s)                     231.408
Total Train Time (s)             14956.9
Epoch                               64
------------------------------  ----------------
2019-06-27 04:42:08.994210 UTC | [dialturn] Iteration #64 | Epoch Duration: 231.22710800170898
2019-06-27 04:42:08.994434 UTC | [dialturn] Iteration #64 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00125348
Z variance train                     1.0027
KL Divergence                        0.000430767
KL Loss                              4.30767e-05
QF Loss                              4.37631e+07
VF Loss                         261679
RF Loss                           3186.35
Policy Loss                     -44325.4
Q Predictions Mean               43750.7
Q Predictions Std                54190
Q Predictions Max               241329
Q Predictions Min                 1368.55
V Predictions Mean               44062.5
V Predictions Std                54468.9
V Predictions Max               244466
V Predictions Min                 1783.01
R Predictions Mean                 569.244
R Predictions Std                 1117.91
R Predictions Max                15996.2
R Predictions Min                  -20.0425
Log Pis Mean                        22.6796
Log Pis Std                         13.2933
Log Pis Max                         50.9755
Log Pis Min                         -4.10016
Policy mu Mean                      -3.71524
Policy mu Std                       17.7713
Policy mu Max                       99.402
Policy mu Min                      -87.2316
Policy log std Mean                 -0.330916
Policy log std Std                   1.27228
Policy log std Max                   2
Policy log std Min                  -5.12096
_task0 Rewards Mean                 45.4869
_task0 Rewards Std                  91.4514
_task0 Rewards Max                 745.331
_task0 Rewards Min                  -1.00722
_task0 Returns Mean               6823.03
_task0 Returns Std               11565.4
_task0 Returns Max               30747.9
_task0 Returns Min                -113.531
_task0 Actions Mean                 -0.0187671
_task0 Actions Std                   0.811589
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     576.428
Exploration_task0 Rewards Std     1008.53
Exploration_task0 Rewards Max     8399.53
Exploration_task0 Rewards Min       -9.65334
Exploration_task0 Returns Mean   87337.6
Exploration_task0 Returns Std   131383
Exploration_task0 Returns Max   391025
Exploration_task0 Returns Min    -1609.48
Exploration_task0 Actions Mean      -0.08789
Exploration_task0 Actions Std        0.83828
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6823.03
AverageReturn_all_train_tasks    11952.9
AverageReturn_all_test_tasks      6823.03
Number of train steps total      66000
Number of env steps total            3.301e+06
Number of rollouts total         23964
Train Time (s)                      98.737
(Previous) Eval Time (s)            25.5331
Sample Time (s)                    106.786
Epoch Time (s)                     231.056
Total Train Time (s)             15188.2
Epoch                               65
------------------------------  ----------------
2019-06-27 04:46:00.206421 UTC | [dialturn] Iteration #65 | Epoch Duration: 231.2117953300476
2019-06-27 04:46:00.206622 UTC | [dialturn] Iteration #65 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000523057
Z variance train                     0.998691
KL Divergence                        4.18718e-05
KL Loss                              4.18718e-06
QF Loss                              4.28126e+07
VF Loss                         108348
RF Loss                          28437.5
Policy Loss                     -44029.1
Q Predictions Mean               43494.3
Q Predictions Std                54404.7
Q Predictions Max               238392
Q Predictions Min                  907.495
V Predictions Mean               44146.1
V Predictions Std                54791.5
V Predictions Max               241798
V Predictions Min                 1604.07
R Predictions Mean                 571.611
R Predictions Std                 1320.36
R Predictions Max                15578.6
R Predictions Min                 -107.02
Log Pis Mean                        22.1822
Log Pis Std                         13.4923
Log Pis Max                         51.2187
Log Pis Min                         -8.62689
Policy mu Mean                      -3.82355
Policy mu Std                       16.5523
Policy mu Max                       81.0942
Policy mu Min                     -106.726
Policy log std Mean                 -0.267259
Policy log std Std                   1.25422
Policy log std Max                   2
Policy log std Min                  -4.72663
_task0 Rewards Mean                 64.5598
_task0 Rewards Std                 123.352
_task0 Rewards Max                1685.5
_task0 Rewards Min                  -0.770531
_task0 Returns Mean               9683.97
_task0 Returns Std               13758.1
_task0 Returns Max               36123.4
_task0 Returns Min                 -97.9958
_task0 Actions Mean                 -0.0208232
_task0 Actions Std                   0.776119
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     537.681
Exploration_task0 Rewards Std     1084.74
Exploration_task0 Rewards Max    19120.5
Exploration_task0 Rewards Min       -9.38239
Exploration_task0 Returns Mean   81466.8
Exploration_task0 Returns Std   124064
Exploration_task0 Returns Max   445753
Exploration_task0 Returns Min    -1286.64
Exploration_task0 Actions Mean      -0.0330899
Exploration_task0 Actions Std        0.818355
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9683.97
AverageReturn_all_train_tasks     5374.68
AverageReturn_all_test_tasks      9683.97
Number of train steps total      67000
Number of env steps total            3.351e+06
Number of rollouts total         24327
Train Time (s)                      98.6769
(Previous) Eval Time (s)            25.6873
Sample Time (s)                    106.792
Epoch Time (s)                     231.156
Total Train Time (s)             15419.1
Epoch                               66
------------------------------  ----------------
2019-06-27 04:49:51.185064 UTC | [dialturn] Iteration #66 | Epoch Duration: 230.97822880744934
2019-06-27 04:49:51.185279 UTC | [dialturn] Iteration #66 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000356534
Z variance train                     0.99814
KL Divergence                        7.08978e-05
KL Loss                              7.08978e-06
QF Loss                              4.80265e+07
VF Loss                          81683.1
RF Loss                           5329.23
Policy Loss                     -44053.4
Q Predictions Mean               43498.9
Q Predictions Std                53900.5
Q Predictions Max               243381
Q Predictions Min                 1442.97
V Predictions Mean               44065.6
V Predictions Std                54528.5
V Predictions Max               246348
V Predictions Min                 2028.08
R Predictions Mean                 442.951
R Predictions Std                  896.644
R Predictions Max                13856.4
R Predictions Min                  -24.0719
Log Pis Mean                        21.6373
Log Pis Std                         13.5361
Log Pis Max                         49.9838
Log Pis Min                         -5.39578
Policy mu Mean                      -3.71113
Policy mu Std                       18.2272
Policy mu Max                       85.3057
Policy mu Min                     -115.127
Policy log std Mean                 -0.184514
Policy log std Std                   1.25826
Policy log std Max                   2
Policy log std Min                  -4.70455
_task0 Rewards Mean                 36.6304
_task0 Rewards Std                  79.5803
_task0 Rewards Max                 740.007
_task0 Rewards Min                  -0.847289
_task0 Returns Mean               5494.56
_task0 Returns Std                9352.01
_task0 Returns Max               25069.9
_task0 Returns Min                -107.913
_task0 Actions Mean                 -0.0282413
_task0 Actions Std                   0.858553
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     474.739
Exploration_task0 Rewards Std      988.262
Exploration_task0 Rewards Max    14187.9
Exploration_task0 Rewards Min      -10.2893
Exploration_task0 Returns Mean   71930.2
Exploration_task0 Returns Std   113886
Exploration_task0 Returns Max   483488
Exploration_task0 Returns Min    -1196.32
Exploration_task0 Actions Mean       0.0300381
Exploration_task0 Actions Std        0.828524
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5494.56
AverageReturn_all_train_tasks     3404.35
AverageReturn_all_test_tasks      5494.56
Number of train steps total      68000
Number of env steps total            3.401e+06
Number of rollouts total         24690
Train Time (s)                      99.8304
(Previous) Eval Time (s)            25.5084
Sample Time (s)                    106.65
Epoch Time (s)                     231.988
Total Train Time (s)             15651.1
Epoch                               67
------------------------------  ----------------
2019-06-27 04:53:43.144442 UTC | [dialturn] Iteration #67 | Epoch Duration: 231.9589819908142
2019-06-27 04:53:43.144640 UTC | [dialturn] Iteration #67 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00157322
Z variance train                     1.00176
KL Divergence                        0.000226761
KL Loss                              2.26761e-05
QF Loss                              6.25352e+07
VF Loss                              1.01558e+06
RF Loss                           4534.69
Policy Loss                     -46180.3
Q Predictions Mean               45856.7
Q Predictions Std                56998.5
Q Predictions Max               242238
Q Predictions Min                 1541.37
V Predictions Mean               46891.6
V Predictions Std                57919.8
V Predictions Max               246657
V Predictions Min                 2162.73
R Predictions Mean                 470.326
R Predictions Std                  854.42
R Predictions Max                 6352.29
R Predictions Min                  -13.0405
Log Pis Mean                        22.6391
Log Pis Std                         13.047
Log Pis Max                         49.4365
Log Pis Min                         -4.09449
Policy mu Mean                      -3.21118
Policy mu Std                       18.5708
Policy mu Max                       93.2813
Policy mu Min                      -98.5504
Policy log std Mean                 -0.232614
Policy log std Std                   1.28825
Policy log std Max                   2
Policy log std Min                  -4.50774
_task0 Rewards Mean                 49.6384
_task0 Rewards Std                  86.6965
_task0 Rewards Max                 542.384
_task0 Rewards Min                  -0.938002
_task0 Returns Mean               7445.76
_task0 Returns Std               12007.5
_task0 Returns Max               32329.3
_task0 Returns Min                -117.472
_task0 Actions Mean                 -0.137218
_task0 Actions Std                   0.806874
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     437.52
Exploration_task0 Rewards Std      800.381
Exploration_task0 Rewards Max    22374.4
Exploration_task0 Rewards Min       -9.74548
Exploration_task0 Returns Mean   66290.9
Exploration_task0 Returns Std   102228
Exploration_task0 Returns Max   403171
Exploration_task0 Returns Min    -1418.75
Exploration_task0 Actions Mean      -0.0651057
Exploration_task0 Actions Std        0.819262
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7445.76
AverageReturn_all_train_tasks     7055.88
AverageReturn_all_test_tasks      7445.76
Number of train steps total      69000
Number of env steps total            3.451e+06
Number of rollouts total         25053
Train Time (s)                     100.279
(Previous) Eval Time (s)            25.4776
Sample Time (s)                    107.049
Epoch Time (s)                     232.806
Total Train Time (s)             15884.2
Epoch                               68
------------------------------  ----------------
2019-06-27 04:57:36.258081 UTC | [dialturn] Iteration #68 | Epoch Duration: 233.11327838897705
2019-06-27 04:57:36.258281 UTC | [dialturn] Iteration #68 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00128563
Z variance train                     0.998493
KL Divergence                        0.000240441
KL Loss                              2.40441e-05
QF Loss                              8.01281e+07
VF Loss                         139910
RF Loss                           5188.98
Policy Loss                     -43676.5
Q Predictions Mean               43340.2
Q Predictions Std                54813.7
Q Predictions Max               241530
Q Predictions Min                 2891.43
V Predictions Mean               43736.6
V Predictions Std                55312.3
V Predictions Max               244734
V Predictions Min                 2809
R Predictions Mean                 450.839
R Predictions Std                  883.553
R Predictions Max                 9308.65
R Predictions Min                  -23.0185
Log Pis Mean                        21.6705
Log Pis Std                         13.5361
Log Pis Max                         51.6617
Log Pis Min                         -1.66072
Policy mu Mean                      -4.03628
Policy mu Std                       16.8426
Policy mu Max                       77.3703
Policy mu Min                      -95.1394
Policy log std Mean                 -0.20047
Policy log std Std                   1.20356
Policy log std Max                   2
Policy log std Min                  -3.93638
_task0 Rewards Mean                 52.3012
_task0 Rewards Std                 112.539
_task0 Rewards Max                1005.26
_task0 Rewards Min                  -0.854577
_task0 Returns Mean               7845.18
_task0 Returns Std               12487.1
_task0 Returns Max               36086.6
_task0 Returns Min                -105.378
_task0 Actions Mean                  0.0207713
_task0 Actions Std                   0.788467
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     524.275
Exploration_task0 Rewards Std     1171.31
Exploration_task0 Rewards Max    19509
Exploration_task0 Rewards Min      -10.2201
Exploration_task0 Returns Mean   79435.6
Exploration_task0 Returns Std   124896
Exploration_task0 Returns Max   429997
Exploration_task0 Returns Min    -1547.91
Exploration_task0 Actions Mean      -0.00856564
Exploration_task0 Actions Std        0.826125
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7845.18
AverageReturn_all_train_tasks     7109.09
AverageReturn_all_test_tasks      7845.18
Number of train steps total      70000
Number of env steps total            3.501e+06
Number of rollouts total         25416
Train Time (s)                      99.4555
(Previous) Eval Time (s)            25.7837
Sample Time (s)                    107.716
Epoch Time (s)                     232.955
Total Train Time (s)             16117.2
Epoch                               69
------------------------------  ----------------
2019-06-27 05:01:29.263327 UTC | [dialturn] Iteration #69 | Epoch Duration: 233.00488448143005
2019-06-27 05:01:29.263515 UTC | [dialturn] Iteration #69 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000854287
Z variance train                     0.998295
KL Divergence                        0.000201187
KL Loss                              2.01187e-05
QF Loss                              6.16074e+07
VF Loss                         147783
RF Loss                          44397.6
Policy Loss                     -44777
Q Predictions Mean               44356.4
Q Predictions Std                54962.6
Q Predictions Max               238892
Q Predictions Min                 2069.29
V Predictions Mean               44730.6
V Predictions Std                55251.9
V Predictions Max               242156
V Predictions Min                 2372.21
R Predictions Mean                 579.98
R Predictions Std                 1311.53
R Predictions Max                11949.4
R Predictions Min                  -12.1526
Log Pis Mean                        21.2821
Log Pis Std                         13.3733
Log Pis Max                         50.9248
Log Pis Min                         -3.40019
Policy mu Mean                      -4.69788
Policy mu Std                       18.0718
Policy mu Max                       84.2303
Policy mu Min                      -93.7972
Policy log std Mean                 -0.19575
Policy log std Std                   1.24372
Policy log std Max                   2
Policy log std Min                  -4.14351
_task0 Rewards Mean                 63.6215
_task0 Rewards Std                 149.721
_task0 Rewards Max                1768.85
_task0 Rewards Min                  -0.880703
_task0 Returns Mean               9543.22
_task0 Returns Std               14309.8
_task0 Returns Max               39613.9
_task0 Returns Min                -103.07
_task0 Actions Mean                 -0.0283845
_task0 Actions Std                   0.837241
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     455.825
Exploration_task0 Rewards Std      940.77
Exploration_task0 Rewards Max    16985.8
Exploration_task0 Rewards Min       -9.96037
Exploration_task0 Returns Mean   69064.4
Exploration_task0 Returns Std   109897
Exploration_task0 Returns Max   456914
Exploration_task0 Returns Min    -1289.29
Exploration_task0 Actions Mean      -0.0715513
Exploration_task0 Actions Std        0.828337
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9543.22
AverageReturn_all_train_tasks     9414.88
AverageReturn_all_test_tasks      9543.22
Number of train steps total      71000
Number of env steps total            3.551e+06
Number of rollouts total         25779
Train Time (s)                      99.6589
(Previous) Eval Time (s)            25.8319
Sample Time (s)                    107.291
Epoch Time (s)                     232.782
Total Train Time (s)             16349.9
Epoch                               70
------------------------------  ----------------
2019-06-27 05:05:21.926938 UTC | [dialturn] Iteration #70 | Epoch Duration: 232.66321182250977
2019-06-27 05:05:21.927133 UTC | [dialturn] Iteration #70 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00150531
Z variance train                     1.00005
KL Divergence                        0.000447498
KL Loss                              4.47498e-05
QF Loss                              3.95832e+07
VF Loss                         404045
RF Loss                          21729.2
Policy Loss                     -45162.4
Q Predictions Mean               44834.2
Q Predictions Std                56237.5
Q Predictions Max               229698
Q Predictions Min                 1370.42
V Predictions Mean               45524.4
V Predictions Std                56939.6
V Predictions Max               235310
V Predictions Min                 2239.79
R Predictions Mean                 499.035
R Predictions Std                 1073.34
R Predictions Max                13117.6
R Predictions Min                  -11.1587
Log Pis Mean                        21.0053
Log Pis Std                         13.4543
Log Pis Max                         50.8231
Log Pis Min                         -4.47446
Policy mu Mean                      -3.50175
Policy mu Std                       16.0344
Policy mu Max                       87.0927
Policy mu Min                      -87.4801
Policy log std Mean                 -0.232265
Policy log std Std                   1.20591
Policy log std Max                   2
Policy log std Min                  -3.63125
_task0 Rewards Mean                 45.9818
_task0 Rewards Std                  95.2376
_task0 Rewards Max                 827.096
_task0 Rewards Min                  -0.826647
_task0 Returns Mean               6897.27
_task0 Returns Std               11439.8
_task0 Returns Max               35680.2
_task0 Returns Min                -108.214
_task0 Actions Mean                 -0.121548
_task0 Actions Std                   0.783623
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     498.529
Exploration_task0 Rewards Std     1059.48
Exploration_task0 Rewards Max    22052.5
Exploration_task0 Rewards Min      -10.6746
Exploration_task0 Returns Mean   75534.7
Exploration_task0 Returns Std   119807
Exploration_task0 Returns Max   426482
Exploration_task0 Returns Min    -1457.11
Exploration_task0 Actions Mean      -0.121144
Exploration_task0 Actions Std        0.825346
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6897.27
AverageReturn_all_train_tasks     7641.62
AverageReturn_all_test_tasks      6897.27
Number of train steps total      72000
Number of env steps total            3.601e+06
Number of rollouts total         26142
Train Time (s)                      98.8514
(Previous) Eval Time (s)            25.7121
Sample Time (s)                    107.389
Epoch Time (s)                     231.952
Total Train Time (s)             16581.9
Epoch                               71
------------------------------  ----------------
2019-06-27 05:09:13.940874 UTC | [dialturn] Iteration #71 | Epoch Duration: 232.01358246803284
2019-06-27 05:09:13.941072 UTC | [dialturn] Iteration #71 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00149751
Z variance train                     0.996347
KL Divergence                        0.000692513
KL Loss                              6.92513e-05
QF Loss                              4.23056e+07
VF Loss                         196127
RF Loss                          12221.3
Policy Loss                     -44808.8
Q Predictions Mean               44482.3
Q Predictions Std                55721.3
Q Predictions Max               230932
Q Predictions Min                 3090.38
V Predictions Mean               44536.8
V Predictions Std                55957.1
V Predictions Max               233501
V Predictions Min                 2809.68
R Predictions Mean                 521.904
R Predictions Std                 1109.81
R Predictions Max                10847.9
R Predictions Min                 -130.938
Log Pis Mean                        21.9221
Log Pis Std                         13.5381
Log Pis Max                         52.3355
Log Pis Min                         -4.41695
Policy mu Mean                      -4.75152
Policy mu Std                       16.7194
Policy mu Max                       81.1502
Policy mu Min                      -84.9452
Policy log std Mean                 -0.17713
Policy log std Std                   1.21796
Policy log std Max                   2
Policy log std Min                  -4.03499
_task0 Rewards Mean                 39.0318
_task0 Rewards Std                  94.4808
_task0 Rewards Max                 785.002
_task0 Rewards Min                  -0.796397
_task0 Returns Mean               5854.78
_task0 Returns Std                9372.74
_task0 Returns Max               26950.9
_task0 Returns Min                -103.256
_task0 Actions Mean                  0.189109
_task0 Actions Std                   0.827066
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     499.815
Exploration_task0 Rewards Std     1241.22
Exploration_task0 Rewards Max    22311.1
Exploration_task0 Rewards Min      -10.128
Exploration_task0 Returns Mean   75729.6
Exploration_task0 Returns Std   129173
Exploration_task0 Returns Max   443140
Exploration_task0 Returns Min    -1444.04
Exploration_task0 Actions Mean       0.0284654
Exploration_task0 Actions Std        0.863415
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5854.78
AverageReturn_all_train_tasks     2731.38
AverageReturn_all_test_tasks      5854.78
Number of train steps total      73000
Number of env steps total            3.651e+06
Number of rollouts total         26505
Train Time (s)                      98.6555
(Previous) Eval Time (s)            25.772
Sample Time (s)                    107.039
Epoch Time (s)                     231.466
Total Train Time (s)             16813.1
Epoch                               72
------------------------------  ----------------
2019-06-27 05:13:05.130778 UTC | [dialturn] Iteration #72 | Epoch Duration: 231.18954157829285
2019-06-27 05:13:05.130999 UTC | [dialturn] Iteration #72 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000984178
Z variance train                     1.00055
KL Divergence                        5.84769e-05
KL Loss                              5.84769e-06
QF Loss                              4.10084e+07
VF Loss                         888210
RF Loss                           2297.8
Policy Loss                     -44579.4
Q Predictions Mean               44308.6
Q Predictions Std                56336.3
Q Predictions Max               235136
Q Predictions Min                 2430.58
V Predictions Mean               45353.2
V Predictions Std                57038.5
V Predictions Max               239531
V Predictions Min                 3087.17
R Predictions Mean                 379.366
R Predictions Std                  710.941
R Predictions Max                 5710.99
R Predictions Min                  -38.9604
Log Pis Mean                        21.055
Log Pis Std                         13.3116
Log Pis Max                         50.3009
Log Pis Min                         -6.67682
Policy mu Mean                      -3.26601
Policy mu Std                       18.5541
Policy mu Max                       90.191
Policy mu Min                      -99.174
Policy log std Mean                 -0.213423
Policy log std Std                   1.26699
Policy log std Max                   2
Policy log std Min                  -4.17638
_task0 Rewards Mean                 47.579
_task0 Rewards Std                  90.433
_task0 Rewards Max                 840.017
_task0 Rewards Min                  -0.826481
_task0 Returns Mean               7136.85
_task0 Returns Std               11302
_task0 Returns Max               29999.4
_task0 Returns Min                -110.374
_task0 Actions Mean                  0.0210831
_task0 Actions Std                   0.815839
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     410.475
Exploration_task0 Rewards Std      823.095
Exploration_task0 Rewards Max    14182
Exploration_task0 Rewards Min       -9.93329
Exploration_task0 Returns Mean   62193.2
Exploration_task0 Returns Std   103616
Exploration_task0 Returns Max   376684
Exploration_task0 Returns Min    -1474.71
Exploration_task0 Actions Mean       0.0689169
Exploration_task0 Actions Std        0.835976
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7136.85
AverageReturn_all_train_tasks    10261.4
AverageReturn_all_test_tasks      7136.85
Number of train steps total      74000
Number of env steps total            3.701e+06
Number of rollouts total         26868
Train Time (s)                      99.5489
(Previous) Eval Time (s)            25.4937
Sample Time (s)                    106.939
Epoch Time (s)                     231.982
Total Train Time (s)             17045.4
Epoch                               73
------------------------------  ----------------
2019-06-27 05:16:57.423666 UTC | [dialturn] Iteration #73 | Epoch Duration: 232.29245519638062
2019-06-27 05:16:57.423886 UTC | [dialturn] Iteration #73 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000905827
Z variance train                     0.999538
KL Divergence                        6.75929e-05
KL Loss                              6.75929e-06
QF Loss                              7.30744e+07
VF Loss                         454190
RF Loss                          11679
Policy Loss                     -46508.5
Q Predictions Mean               46255
Q Predictions Std                57530.1
Q Predictions Max               223769
Q Predictions Min                 1220.05
V Predictions Mean               46951.9
V Predictions Std                58173.4
V Predictions Max               228009
V Predictions Min                 3003.49
R Predictions Mean                 488.122
R Predictions Std                 1115.16
R Predictions Max                10259.4
R Predictions Min                  -23.1715
Log Pis Mean                        21.4512
Log Pis Std                         13.339
Log Pis Max                         49.3628
Log Pis Min                         -2.28186
Policy mu Mean                      -4.46301
Policy mu Std                       17.1045
Policy mu Max                       81.1462
Policy mu Min                      -75.6971
Policy log std Mean                 -0.197076
Policy log std Std                   1.25587
Policy log std Max                   2
Policy log std Min                  -4.35575
_task0 Rewards Mean                 37.1422
_task0 Rewards Std                  74.4647
_task0 Rewards Max                 531.308
_task0 Rewards Min                  -1.00953
_task0 Returns Mean               5571.33
_task0 Returns Std                9522.43
_task0 Returns Max               32240
_task0 Returns Min                -115.641
_task0 Actions Mean                  0.184612
_task0 Actions Std                   0.804131
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     492.474
Exploration_task0 Rewards Std      999.928
Exploration_task0 Rewards Max    17893.2
Exploration_task0 Rewards Min       -9.36914
Exploration_task0 Returns Mean   74617.2
Exploration_task0 Returns Std   120491
Exploration_task0 Returns Max   450206
Exploration_task0 Returns Min    -1514.94
Exploration_task0 Actions Mean       0.061707
Exploration_task0 Actions Std        0.839379
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5571.33
AverageReturn_all_train_tasks     7542.27
AverageReturn_all_test_tasks      5571.33
Number of train steps total      75000
Number of env steps total            3.751e+06
Number of rollouts total         27231
Train Time (s)                     100.697
(Previous) Eval Time (s)            25.8029
Sample Time (s)                    107.748
Epoch Time (s)                     234.248
Total Train Time (s)             17279.6
Epoch                               74
------------------------------  ----------------
2019-06-27 05:20:51.656344 UTC | [dialturn] Iteration #74 | Epoch Duration: 234.23226118087769
2019-06-27 05:20:51.656536 UTC | [dialturn] Iteration #74 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00119232
Z variance train                     0.99883
KL Divergence                        0.000152681
KL Loss                              1.52681e-05
QF Loss                              4.57024e+07
VF Loss                         125094
RF Loss                           3481.61
Policy Loss                     -43780.8
Q Predictions Mean               43443.6
Q Predictions Std                56314.8
Q Predictions Max               232047
Q Predictions Min                 2750.68
V Predictions Mean               43936.7
V Predictions Std                56697.1
V Predictions Max               235106
V Predictions Min                 3063.11
R Predictions Mean                 294.809
R Predictions Std                  601.151
R Predictions Max                 4004.24
R Predictions Min                 -112.744
Log Pis Mean                        21.9295
Log Pis Std                         13.7697
Log Pis Max                         50.2137
Log Pis Min                         -3.8653
Policy mu Mean                      -2.83553
Policy mu Std                       16.4004
Policy mu Max                       92.0006
Policy mu Min                      -77.043
Policy log std Mean                 -0.301909
Policy log std Std                   1.16886
Policy log std Max                   2
Policy log std Min                  -4.01927
_task0 Rewards Mean                 39.8612
_task0 Rewards Std                  71.9149
_task0 Rewards Max                 663.202
_task0 Rewards Min                  -0.908828
_task0 Returns Mean               5979.18
_task0 Returns Std                9599.87
_task0 Returns Max               30035.6
_task0 Returns Min                -119.324
_task0 Actions Mean                  0.108735
_task0 Actions Std                   0.825252
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     464.895
Exploration_task0 Rewards Std      996.701
Exploration_task0 Rewards Max    20547.6
Exploration_task0 Rewards Min      -10.5503
Exploration_task0 Returns Mean   70438.7
Exploration_task0 Returns Std   116668
Exploration_task0 Returns Max   579211
Exploration_task0 Returns Min    -1344.14
Exploration_task0 Actions Mean       0.0683015
Exploration_task0 Actions Std        0.835481
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5979.18
AverageReturn_all_train_tasks     4535.53
AverageReturn_all_test_tasks      5979.18
Number of train steps total      76000
Number of env steps total            3.801e+06
Number of rollouts total         27594
Train Time (s)                      99.6424
(Previous) Eval Time (s)            25.7858
Sample Time (s)                    107.965
Epoch Time (s)                     233.393
Total Train Time (s)             17513
Epoch                               75
------------------------------  ----------------
2019-06-27 05:24:45.105861 UTC | [dialturn] Iteration #75 | Epoch Duration: 233.44910335540771
2019-06-27 05:24:45.106053 UTC | [dialturn] Iteration #75 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00084208
Z variance train                     0.999728
KL Divergence                        9.31658e-05
KL Loss                              9.31658e-06
QF Loss                              4.41782e+07
VF Loss                         168079
RF Loss                           2383.81
Policy Loss                     -46272.3
Q Predictions Mean               45940.8
Q Predictions Std                58198.4
Q Predictions Max               223316
Q Predictions Min                 2415.29
V Predictions Mean               46199.2
V Predictions Std                58392.8
V Predictions Max               225945
V Predictions Min                 2868.89
R Predictions Mean                 433.509
R Predictions Std                  844.372
R Predictions Max                 6603.52
R Predictions Min                  -15.1193
Log Pis Mean                        21.4723
Log Pis Std                         13.8745
Log Pis Max                         55.2872
Log Pis Min                         -4.73013
Policy mu Mean                      -4.34896
Policy mu Std                       16.8445
Policy mu Max                      107.273
Policy mu Min                      -69.7907
Policy log std Mean                 -0.191813
Policy log std Std                   1.19851
Policy log std Max                   2
Policy log std Min                  -4.14648
_task0 Rewards Mean                 64.7525
_task0 Rewards Std                 113.408
_task0 Rewards Max                 782.885
_task0 Rewards Min                  -0.912085
_task0 Returns Mean               9712.87
_task0 Returns Std               14903.7
_task0 Returns Max               37481
_task0 Returns Min                -103.234
_task0 Actions Mean                  0.0761874
_task0 Actions Std                   0.816118
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     488.124
Exploration_task0 Rewards Std      891.938
Exploration_task0 Rewards Max    13014.4
Exploration_task0 Rewards Min      -11.1141
Exploration_task0 Returns Mean   73958.2
Exploration_task0 Returns Std   121265
Exploration_task0 Returns Max   532819
Exploration_task0 Returns Min    -1280.92
Exploration_task0 Actions Mean       0.0341228
Exploration_task0 Actions Std        0.836788
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9712.87
AverageReturn_all_train_tasks     4807.57
AverageReturn_all_test_tasks      9712.87
Number of train steps total      77000
Number of env steps total            3.851e+06
Number of rollouts total         27957
Train Time (s)                      99.2291
(Previous) Eval Time (s)            25.8403
Sample Time (s)                    106.931
Epoch Time (s)                     232
Total Train Time (s)             17745.1
Epoch                               76
------------------------------  ----------------
2019-06-27 05:28:37.154925 UTC | [dialturn] Iteration #76 | Epoch Duration: 232.04872250556946
2019-06-27 05:28:37.155138 UTC | [dialturn] Iteration #76 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000300445
Z variance train                     1.00041
KL Divergence                        1.647e-05
KL Loss                              1.647e-06
QF Loss                              4.955e+07
VF Loss                         737455
RF Loss                           3347.46
Policy Loss                     -46412.4
Q Predictions Mean               45960.9
Q Predictions Std                58006
Q Predictions Max               227225
Q Predictions Min                 2402.22
V Predictions Mean               46816.6
V Predictions Std                59001.7
V Predictions Max               232602
V Predictions Min                 2617.76
R Predictions Mean                 377.69
R Predictions Std                  770.607
R Predictions Max                 8284.1
R Predictions Min                   -9.77419
Log Pis Mean                        21.2747
Log Pis Std                         13.7759
Log Pis Max                         52.0458
Log Pis Min                         -4.00048
Policy mu Mean                      -3.27936
Policy mu Std                       16.0677
Policy mu Max                      104.801
Policy mu Min                      -72.0225
Policy log std Mean                 -0.217153
Policy log std Std                   1.18536
Policy log std Max                   2
Policy log std Min                  -3.79989
_task0 Rewards Mean                 63.1064
_task0 Rewards Std                 111.97
_task0 Rewards Max                 780.002
_task0 Rewards Min                  -0.89949
_task0 Returns Mean               9465.96
_task0 Returns Std               14841.8
_task0 Returns Max               38959
_task0 Returns Min                -114.738
_task0 Actions Mean                 -0.166459
_task0 Actions Std                   0.81278
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     492.848
Exploration_task0 Rewards Std     1022.03
Exploration_task0 Rewards Max    12033.2
Exploration_task0 Rewards Min      -11.1102
Exploration_task0 Returns Mean   74673.9
Exploration_task0 Returns Std   123041
Exploration_task0 Returns Max   460875
Exploration_task0 Returns Min    -1492.54
Exploration_task0 Actions Mean       0.0736338
Exploration_task0 Actions Std        0.84088
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9465.96
AverageReturn_all_train_tasks    10771.1
AverageReturn_all_test_tasks      9465.96
Number of train steps total      78000
Number of env steps total            3.901e+06
Number of rollouts total         28320
Train Time (s)                      99.5959
(Previous) Eval Time (s)            25.8872
Sample Time (s)                    107.61
Epoch Time (s)                     233.093
Total Train Time (s)             17978.1
Epoch                               77
------------------------------  ----------------
2019-06-27 05:32:30.203007 UTC | [dialturn] Iteration #77 | Epoch Duration: 233.0476894378662
2019-06-27 05:32:30.203214 UTC | [dialturn] Iteration #77 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00184749
Z variance train                     0.99966
KL Divergence                        0.000454572
KL Loss                              4.54572e-05
QF Loss                              5.73792e+07
VF Loss                         220182
RF Loss                          12975
Policy Loss                     -45666.8
Q Predictions Mean               45180.9
Q Predictions Std                57794.1
Q Predictions Max               225014
Q Predictions Min                 2664.49
V Predictions Mean               45818.2
V Predictions Std                58342.7
V Predictions Max               227306
V Predictions Min                 2573.66
R Predictions Mean                 536.746
R Predictions Std                 1142.5
R Predictions Max                13325.2
R Predictions Min                  -16.0599
Log Pis Mean                        21.5099
Log Pis Std                         13.5565
Log Pis Max                         52.5986
Log Pis Min                         -5.25682
Policy mu Mean                      -5.13327
Policy mu Std                       17.0174
Policy mu Max                      214.85
Policy mu Min                      -74.6489
Policy log std Mean                 -0.213545
Policy log std Std                   1.1954
Policy log std Max                   2
Policy log std Min                  -4.06722
_task0 Rewards Mean                 30.5664
_task0 Rewards Std                  51.2586
_task0 Rewards Max                 266.74
_task0 Rewards Min                  -0.795587
_task0 Returns Mean               4584.96
_task0 Returns Std                7471.09
_task0 Returns Max               23117.9
_task0 Returns Min                -103.555
_task0 Actions Mean                  0.219589
_task0 Actions Std                   0.853065
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     563.949
Exploration_task0 Rewards Std     1191.74
Exploration_task0 Rewards Max    21267.7
Exploration_task0 Rewards Min      -11.0889
Exploration_task0 Returns Mean   85446.9
Exploration_task0 Returns Std   135526
Exploration_task0 Returns Max   542014
Exploration_task0 Returns Min    -1499.47
Exploration_task0 Actions Mean       0.0679584
Exploration_task0 Actions Std        0.838958
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              4584.96
AverageReturn_all_train_tasks     5487.23
AverageReturn_all_test_tasks      4584.96
Number of train steps total      79000
Number of env steps total            3.951e+06
Number of rollouts total         28683
Train Time (s)                     100.304
(Previous) Eval Time (s)            25.8406
Sample Time (s)                    107.173
Epoch Time (s)                     233.318
Total Train Time (s)             18211.5
Epoch                               78
------------------------------  ----------------
2019-06-27 05:36:23.599191 UTC | [dialturn] Iteration #78 | Epoch Duration: 233.3958055973053
2019-06-27 05:36:23.599406 UTC | [dialturn] Iteration #78 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000574316
Z variance train                     0.999851
KL Divergence                        4.22863e-05
KL Loss                              4.22863e-06
QF Loss                              1.17855e+08
VF Loss                         151980
RF Loss                           7089.63
Policy Loss                     -45607.1
Q Predictions Mean               45629
Q Predictions Std                58714.4
Q Predictions Max               219307
Q Predictions Min                 1959.95
V Predictions Mean               45679.8
V Predictions Std                58698.1
V Predictions Max               220818
V Predictions Min                 2598.83
R Predictions Mean                 458.357
R Predictions Std                  896.374
R Predictions Max                 9552.63
R Predictions Min                   -9.54043
Log Pis Mean                        21.3917
Log Pis Std                         13.6725
Log Pis Max                         50.1538
Log Pis Min                         -3.58573
Policy mu Mean                      -4.17277
Policy mu Std                       16.4697
Policy mu Max                      137.906
Policy mu Min                      -75.0999
Policy log std Mean                 -0.14859
Policy log std Std                   1.12662
Policy log std Max                   2
Policy log std Min                  -3.44106
_task0 Rewards Mean                 39.8591
_task0 Rewards Std                  74.4676
_task0 Rewards Max                 416.591
_task0 Rewards Min                  -1.03738
_task0 Returns Mean               5978.86
_task0 Returns Std               10570.7
_task0 Returns Max               33795
_task0 Returns Min                -116.98
_task0 Actions Mean                  0.0527992
_task0 Actions Std                   0.865562
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     461.898
Exploration_task0 Rewards Std      873.42
Exploration_task0 Rewards Max    15659.6
Exploration_task0 Rewards Min      -10.9484
Exploration_task0 Returns Mean   69984.5
Exploration_task0 Returns Std   110637
Exploration_task0 Returns Max   516581
Exploration_task0 Returns Min    -1346.98
Exploration_task0 Actions Mean       0.103867
Exploration_task0 Actions Std        0.838011
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5978.86
AverageReturn_all_train_tasks    11439
AverageReturn_all_test_tasks      5978.86
Number of train steps total      80000
Number of env steps total            4.001e+06
Number of rollouts total         29046
Train Time (s)                     100.205
(Previous) Eval Time (s)            25.9171
Sample Time (s)                    107.711
Epoch Time (s)                     233.834
Total Train Time (s)             18445.3
Epoch                               79
------------------------------  ----------------
2019-06-27 05:40:17.352543 UTC | [dialturn] Iteration #79 | Epoch Duration: 233.75294017791748
2019-06-27 05:40:17.352733 UTC | [dialturn] Iteration #79 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000812296
Z variance train                     1.00031
KL Divergence                        0.00013046
KL Loss                              1.3046e-05
QF Loss                              6.29953e+07
VF Loss                         915054
RF Loss                           5870.83
Policy Loss                     -45468.4
Q Predictions Mean               45207.6
Q Predictions Std                58302.8
Q Predictions Max               219253
Q Predictions Min                 2159.22
V Predictions Mean               44818.2
V Predictions Std                58085.3
V Predictions Max               219718
V Predictions Min                 1410.91
R Predictions Mean                 676.859
R Predictions Std                 1160.04
R Predictions Max                 8231.51
R Predictions Min                  -18.6967
Log Pis Mean                        20.5501
Log Pis Std                         12.9402
Log Pis Max                         50.4466
Log Pis Min                         -7.87091
Policy mu Mean                      -4.6901
Policy mu Std                       15.8607
Policy mu Max                      175.492
Policy mu Min                      -73.938
Policy log std Mean                 -0.154231
Policy log std Std                   1.09594
Policy log std Max                   2
Policy log std Min                  -3.21671
_task0 Rewards Mean                 42.0874
_task0 Rewards Std                  70.5189
_task0 Rewards Max                 353.393
_task0 Rewards Min                  -0.882816
_task0 Returns Mean               6313.11
_task0 Returns Std               10146.1
_task0 Returns Max               29797
_task0 Returns Min                -111.09
_task0 Actions Mean                  0.214809
_task0 Actions Std                   0.838132
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     579.019
Exploration_task0 Rewards Std     1129.49
Exploration_task0 Rewards Max    16492.7
Exploration_task0 Rewards Min      -10.3274
Exploration_task0 Returns Mean   87730.2
Exploration_task0 Returns Std   138721
Exploration_task0 Returns Max   549880
Exploration_task0 Returns Min    -1497.14
Exploration_task0 Actions Mean       0.167966
Exploration_task0 Actions Std        0.852838
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6313.11
AverageReturn_all_train_tasks     2214.54
AverageReturn_all_test_tasks      6313.11
Number of train steps total      81000
Number of env steps total            4.051e+06
Number of rollouts total         29409
Train Time (s)                      99.2721
(Previous) Eval Time (s)            25.8348
Sample Time (s)                    107.37
Epoch Time (s)                     232.477
Total Train Time (s)             18677.9
Epoch                               80
------------------------------  ----------------
2019-06-27 05:44:09.971484 UTC | [dialturn] Iteration #80 | Epoch Duration: 232.61859679222107
2019-06-27 05:44:09.971678 UTC | [dialturn] Iteration #80 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00148402
Z variance train                     1.00239
KL Divergence                        0.000379688
KL Loss                              3.79688e-05
QF Loss                              8.12922e+07
VF Loss                         613251
RF Loss                           4056.12
Policy Loss                     -45676.8
Q Predictions Mean               45490.4
Q Predictions Std                57983.8
Q Predictions Max               208206
Q Predictions Min                 2469.07
V Predictions Mean               45220.3
V Predictions Std                57733.1
V Predictions Max               203638
V Predictions Min                 2068.37
R Predictions Mean                 534.086
R Predictions Std                  990.53
R Predictions Max                 8194.9
R Predictions Min                 -386.476
Log Pis Mean                        20.6893
Log Pis Std                         12.9541
Log Pis Max                         47.6097
Log Pis Min                         -2.52565
Policy mu Mean                      -4.23487
Policy mu Std                       17.4696
Policy mu Max                      144.174
Policy mu Min                      -74.1813
Policy log std Mean                 -0.148861
Policy log std Std                   1.14857
Policy log std Max                   2
Policy log std Min                  -3.05022
_task0 Rewards Mean                 73.7572
_task0 Rewards Std                 157.734
_task0 Rewards Max                1443.9
_task0 Rewards Min                  -0.832312
_task0 Returns Mean              11063.6
_task0 Returns Std               16738.9
_task0 Returns Max               44638.4
_task0 Returns Min                 -98.6453
_task0 Actions Mean                 -0.0435185
_task0 Actions Std                   0.792907
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     618.11
Exploration_task0 Rewards Std     1176.23
Exploration_task0 Rewards Max    18982.1
Exploration_task0 Rewards Min      -10.9141
Exploration_task0 Returns Mean   93653.1
Exploration_task0 Returns Std   148252
Exploration_task0 Returns Max   503003
Exploration_task0 Returns Min    -1209.85
Exploration_task0 Actions Mean       0.104077
Exploration_task0 Actions Std        0.843954
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             11063.6
AverageReturn_all_train_tasks     6008.6
AverageReturn_all_test_tasks     11063.6
Number of train steps total      82000
Number of env steps total            4.101e+06
Number of rollouts total         29772
Train Time (s)                     100.605
(Previous) Eval Time (s)            25.9754
Sample Time (s)                    107.4
Epoch Time (s)                     233.98
Total Train Time (s)             18911.7
Epoch                               81
------------------------------  ----------------
2019-06-27 05:48:03.829320 UTC | [dialturn] Iteration #81 | Epoch Duration: 233.85747838020325
2019-06-27 05:48:03.829532 UTC | [dialturn] Iteration #81 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00195753
Z variance train                     1.00177
KL Divergence                        0.000634218
KL Loss                              6.34218e-05
QF Loss                              9.76247e+07
VF Loss                         243105
RF Loss                           4007.21
Policy Loss                     -46191
Q Predictions Mean               45952.5
Q Predictions Std                58887.8
Q Predictions Max               208100
Q Predictions Min                 2216.06
V Predictions Mean               46180.5
V Predictions Std                59105
V Predictions Max               209606
V Predictions Min                 2110.44
R Predictions Mean                 502.599
R Predictions Std                  973.497
R Predictions Max                 9477.51
R Predictions Min                  -52.0419
Log Pis Mean                        20.6701
Log Pis Std                         12.9937
Log Pis Max                         49.3515
Log Pis Min                         -5.297
Policy mu Mean                      -4.98846
Policy mu Std                       17.0009
Policy mu Max                      106.761
Policy mu Min                      -69.8573
Policy log std Mean                 -0.15383
Policy log std Std                   1.12159
Policy log std Max                   2
Policy log std Min                  -2.9239
_task0 Rewards Mean                 58.9229
_task0 Rewards Std                 103.369
_task0 Rewards Max                 664.899
_task0 Rewards Min                  -0.882941
_task0 Returns Mean               8838.43
_task0 Returns Std               12939
_task0 Returns Max               32931
_task0 Returns Min                -106.768
_task0 Actions Mean                  0.0266546
_task0 Actions Std                   0.84382
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     522.911
Exploration_task0 Rewards Std     1373.09
Exploration_task0 Rewards Max    22800.6
Exploration_task0 Rewards Min       -9.11741
Exploration_task0 Returns Mean   79229
Exploration_task0 Returns Std   139809
Exploration_task0 Returns Max   516066
Exploration_task0 Returns Min    -1519.55
Exploration_task0 Actions Mean       0.00186173
Exploration_task0 Actions Std        0.850623
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8838.43
AverageReturn_all_train_tasks     4801.65
AverageReturn_all_test_tasks      8838.43
Number of train steps total      83000
Number of env steps total            4.151e+06
Number of rollouts total         30135
Train Time (s)                     100.693
(Previous) Eval Time (s)            25.851
Sample Time (s)                    107.734
Epoch Time (s)                     234.278
Total Train Time (s)             19145.8
Epoch                               82
------------------------------  ----------------
2019-06-27 05:51:57.888598 UTC | [dialturn] Iteration #82 | Epoch Duration: 234.05885243415833
2019-06-27 05:51:57.888807 UTC | [dialturn] Iteration #82 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000806672
Z variance train                     1.00015
KL Divergence                        6.75035e-05
KL Loss                              6.75035e-06
QF Loss                              5.85622e+07
VF Loss                         241581
RF Loss                          21636
Policy Loss                     -46432.4
Q Predictions Mean               46212.1
Q Predictions Std                59339.2
Q Predictions Max               204298
Q Predictions Min                 2091.55
V Predictions Mean               46453.3
V Predictions Std                59621.5
V Predictions Max               205597
V Predictions Min                 1899.27
R Predictions Mean                 572.59
R Predictions Std                 1164.28
R Predictions Max                10756.4
R Predictions Min                 -171.9
Log Pis Mean                        20.7913
Log Pis Std                         13.1301
Log Pis Max                         50.7612
Log Pis Min                         -4.63359
Policy mu Mean                      -3.04363
Policy mu Std                       16.7797
Policy mu Max                       97.1082
Policy mu Min                      -64.5082
Policy log std Mean                 -0.253934
Policy log std Std                   1.11509
Policy log std Max                   2
Policy log std Min                  -3.65043
_task0 Rewards Mean                 56.6185
_task0 Rewards Std                 119.527
_task0 Rewards Max                 952.489
_task0 Rewards Min                  -0.939838
_task0 Returns Mean               8492.77
_task0 Returns Std               13226
_task0 Returns Max               37653.4
_task0 Returns Min                -119.287
_task0 Actions Mean                  0.084973
_task0 Actions Std                   0.860488
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     610.758
Exploration_task0 Rewards Std     1304.43
Exploration_task0 Rewards Max    22963.4
Exploration_task0 Rewards Min       -9.31063
Exploration_task0 Returns Mean   92539.1
Exploration_task0 Returns Std   145283
Exploration_task0 Returns Max   550257
Exploration_task0 Returns Min    -1473.58
Exploration_task0 Actions Mean       0.0674046
Exploration_task0 Actions Std        0.839883
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8492.77
AverageReturn_all_train_tasks    10792.9
AverageReturn_all_test_tasks      8492.77
Number of train steps total      84000
Number of env steps total            4.201e+06
Number of rollouts total         30498
Train Time (s)                      99.6131
(Previous) Eval Time (s)            25.6307
Sample Time (s)                    107.978
Epoch Time (s)                     233.222
Total Train Time (s)             19378.8
Epoch                               83
------------------------------  ----------------
2019-06-27 05:55:50.937564 UTC | [dialturn] Iteration #83 | Epoch Duration: 233.04857659339905
2019-06-27 05:55:50.937783 UTC | [dialturn] Iteration #83 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000982465
Z variance train                     1.00007
KL Divergence                        9.5982e-05
KL Loss                              9.5982e-06
QF Loss                              7.37613e+07
VF Loss                         299087
RF Loss                          18273.5
Policy Loss                     -44526.9
Q Predictions Mean               44142.2
Q Predictions Std                58247.4
Q Predictions Max               203906
Q Predictions Min                 1825.56
V Predictions Mean               44570.1
V Predictions Std                58604.1
V Predictions Max               204206
V Predictions Min                 1901.64
R Predictions Mean                 613.903
R Predictions Std                 1524.3
R Predictions Max                14985.7
R Predictions Min                  -14.8747
Log Pis Mean                        19.3558
Log Pis Std                         13.5525
Log Pis Max                         50.5692
Log Pis Min                         -7.57671
Policy mu Mean                      -4.6729
Policy mu Std                       15.7034
Policy mu Max                      119.564
Policy mu Min                      -72.6754
Policy log std Mean                 -0.282059
Policy log std Std                   1.12487
Policy log std Max                   2
Policy log std Min                  -3.78719
_task0 Rewards Mean                 54.1137
_task0 Rewards Std                  90.1175
_task0 Rewards Max                 677.84
_task0 Rewards Min                  -0.921395
_task0 Returns Mean               8117.06
_task0 Returns Std               11660.2
_task0 Returns Max               29371.5
_task0 Returns Min                -101.403
_task0 Actions Mean                  0.0238613
_task0 Actions Std                   0.828224
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     507.288
Exploration_task0 Rewards Std     1419.03
Exploration_task0 Rewards Max    22807.6
Exploration_task0 Rewards Min      -10.2607
Exploration_task0 Returns Mean   76861.8
Exploration_task0 Returns Std   143491
Exploration_task0 Returns Max   516595
Exploration_task0 Returns Min    -1523.54
Exploration_task0 Actions Mean       0.0755077
Exploration_task0 Actions Std        0.863302
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8117.06
AverageReturn_all_train_tasks     6876.14
AverageReturn_all_test_tasks      8117.06
Number of train steps total      85000
Number of env steps total            4.251e+06
Number of rollouts total         30861
Train Time (s)                      98.888
(Previous) Eval Time (s)            25.456
Sample Time (s)                    107.258
Epoch Time (s)                     231.602
Total Train Time (s)             19610.5
Epoch                               84
------------------------------  ----------------
2019-06-27 05:59:42.612315 UTC | [dialturn] Iteration #84 | Epoch Duration: 231.67436337471008
2019-06-27 05:59:42.612499 UTC | [dialturn] Iteration #84 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000517791
Z variance train                     1.0013
KL Divergence                        0.000109018
KL Loss                              1.09018e-05
QF Loss                              5.36302e+07
VF Loss                         423542
RF Loss                          13754.3
Policy Loss                     -45082
Q Predictions Mean               44774.2
Q Predictions Std                59285.5
Q Predictions Max               203283
Q Predictions Min                 1752.32
V Predictions Mean               44938.3
V Predictions Std                59423.7
V Predictions Max               205029
V Predictions Min                 1755.04
R Predictions Mean                 502.312
R Predictions Std                 1205.89
R Predictions Max                15336.3
R Predictions Min                 -121.448
Log Pis Mean                        19.8335
Log Pis Std                         13.8049
Log Pis Max                         50.0289
Log Pis Min                         -4.26431
Policy mu Mean                      -4.27444
Policy mu Std                       16.1816
Policy mu Max                      162.936
Policy mu Min                      -98.3203
Policy log std Mean                 -0.258395
Policy log std Std                   1.13196
Policy log std Max                   2
Policy log std Min                  -3.74897
_task0 Rewards Mean                 41.4607
_task0 Rewards Std                 149.769
_task0 Rewards Max                2303.05
_task0 Rewards Min                  -1.03565
_task0 Returns Mean               6219.11
_task0 Returns Std               14692.8
_task0 Returns Max               49825.4
_task0 Returns Min                -120.501
_task0 Actions Mean                  0.0702706
_task0 Actions Std                   0.823611
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     465.293
Exploration_task0 Rewards Std     1033.79
Exploration_task0 Rewards Max    15746.9
Exploration_task0 Rewards Min      -11.2588
Exploration_task0 Returns Mean   70499
Exploration_task0 Returns Std   120215
Exploration_task0 Returns Max   478190
Exploration_task0 Returns Min    -1424.4
Exploration_task0 Actions Mean       0.0103408
Exploration_task0 Actions Std        0.859509
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6219.11
AverageReturn_all_train_tasks    11301.2
AverageReturn_all_test_tasks      6219.11
Number of train steps total      86000
Number of env steps total            4.301e+06
Number of rollouts total         31224
Train Time (s)                      99.5745
(Previous) Eval Time (s)            25.5267
Sample Time (s)                    107.03
Epoch Time (s)                     232.131
Total Train Time (s)             19842.6
Epoch                               85
------------------------------  ----------------
2019-06-27 06:03:34.749033 UTC | [dialturn] Iteration #85 | Epoch Duration: 232.1363821029663
2019-06-27 06:03:34.749265 UTC | [dialturn] Iteration #85 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00112449
Z variance train                     1.00167
KL Divergence                        0.000320904
KL Loss                              3.20904e-05
QF Loss                              7.01229e+07
VF Loss                         582058
RF Loss                           5186.77
Policy Loss                     -47843
Q Predictions Mean               47407.4
Q Predictions Std                60258.8
Q Predictions Max               200176
Q Predictions Min                 1765.66
V Predictions Mean               48115.1
V Predictions Std                60976.3
V Predictions Max               202692
V Predictions Min                 1837.9
R Predictions Mean                 464.481
R Predictions Std                 1024.7
R Predictions Max                11764.1
R Predictions Min                  -13.7562
Log Pis Mean                        20.9109
Log Pis Std                         14.198
Log Pis Max                         53.0631
Log Pis Min                         -5.33249
Policy mu Mean                      -3.64084
Policy mu Std                       15.8487
Policy mu Max                      133.159
Policy mu Min                     -114.238
Policy log std Mean                 -0.276859
Policy log std Std                   1.10484
Policy log std Max                   2
Policy log std Min                  -4.1713
_task0 Rewards Mean                 52.9439
_task0 Rewards Std                 133.16
_task0 Rewards Max                1627.45
_task0 Rewards Min                  -0.939838
_task0 Returns Mean               7941.58
_task0 Returns Std               13606.7
_task0 Returns Max               41426.5
_task0 Returns Min                -118.796
_task0 Actions Mean                 -0.0572341
_task0 Actions Std                   0.825853
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     406.29
Exploration_task0 Rewards Std     1014.27
Exploration_task0 Rewards Max    19815.1
Exploration_task0 Rewards Min      -10.7154
Exploration_task0 Returns Mean   61559.1
Exploration_task0 Returns Std   116800
Exploration_task0 Returns Max   558141
Exploration_task0 Returns Min    -1525.9
Exploration_task0 Actions Mean       0.0225102
Exploration_task0 Actions Std        0.859416
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7941.58
AverageReturn_all_train_tasks     3882.22
AverageReturn_all_test_tasks      7941.58
Number of train steps total      87000
Number of env steps total            4.351e+06
Number of rollouts total         31587
Train Time (s)                      99.2869
(Previous) Eval Time (s)            25.5306
Sample Time (s)                    107.251
Epoch Time (s)                     232.068
Total Train Time (s)             20074.9
Epoch                               86
------------------------------  ----------------
2019-06-27 06:07:27.003664 UTC | [dialturn] Iteration #86 | Epoch Duration: 232.25415539741516
2019-06-27 06:07:27.003885 UTC | [dialturn] Iteration #86 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00029765
Z variance train                     1.00288
KL Divergence                        8.97221e-05
KL Loss                              8.97221e-06
QF Loss                              6.31361e+07
VF Loss                         548534
RF Loss                           2660.7
Policy Loss                     -45806.8
Q Predictions Mean               45373.8
Q Predictions Std                60008.2
Q Predictions Max               192746
Q Predictions Min                 1767.39
V Predictions Mean               46008.7
V Predictions Std                60656.9
V Predictions Max               195178
V Predictions Min                 1669.28
R Predictions Mean                 347.413
R Predictions Std                  964.298
R Predictions Max                11642.7
R Predictions Min                  -55.5875
Log Pis Mean                        20.3394
Log Pis Std                         13.5613
Log Pis Max                         55.5796
Log Pis Min                         -4.9292
Policy mu Mean                      -2.82618
Policy mu Std                       14.1013
Policy mu Max                      150.36
Policy mu Min                     -152.283
Policy log std Mean                 -0.311424
Policy log std Std                   1.03578
Policy log std Max                   2
Policy log std Min                  -4.49349
_task0 Rewards Mean                 24.4356
_task0 Rewards Std                  44.9117
_task0 Rewards Max                 263.034
_task0 Rewards Min                  -0.971783
_task0 Returns Mean               3665.34
_task0 Returns Std                6115.95
_task0 Returns Max               16326.8
_task0 Returns Min                -108.384
_task0 Actions Mean                  0.118654
_task0 Actions Std                   0.806389
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     401.923
Exploration_task0 Rewards Std     1036.2
Exploration_task0 Rewards Max    15050.3
Exploration_task0 Rewards Min      -11.3499
Exploration_task0 Returns Mean   60897.5
Exploration_task0 Returns Std   123865
Exploration_task0 Returns Max   505422
Exploration_task0 Returns Min    -1299.07
Exploration_task0 Actions Mean       0.0267893
Exploration_task0 Actions Std        0.848056
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              3665.34
AverageReturn_all_train_tasks    12316.6
AverageReturn_all_test_tasks      3665.34
Number of train steps total      88000
Number of env steps total            4.401e+06
Number of rollouts total         31950
Train Time (s)                      97.7978
(Previous) Eval Time (s)            25.7154
Sample Time (s)                    107.301
Epoch Time (s)                     230.814
Total Train Time (s)             20305.6
Epoch                               87
------------------------------  ----------------
2019-06-27 06:11:17.682715 UTC | [dialturn] Iteration #87 | Epoch Duration: 230.6785728931427
2019-06-27 06:11:17.682908 UTC | [dialturn] Iteration #87 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00071253
Z variance train                     0.997807
KL Divergence                        0.000215661
KL Loss                              2.15661e-05
QF Loss                              6.76487e+07
VF Loss                         451276
RF Loss                         117555
Policy Loss                     -45189.5
Q Predictions Mean               44980.5
Q Predictions Std                60025.5
Q Predictions Max               200565
Q Predictions Min                 1550.15
V Predictions Mean               45436.6
V Predictions Std                60423.8
V Predictions Max               205147
V Predictions Min                 1512.66
R Predictions Mean                 316.881
R Predictions Std                 1275.41
R Predictions Max                15422.6
R Predictions Min                  -66.2033
Log Pis Mean                        20.6569
Log Pis Std                         13.8896
Log Pis Max                         53.2577
Log Pis Min                         -4.09662
Policy mu Mean                      -2.45397
Policy mu Std                       13.349
Policy mu Max                      220.961
Policy mu Min                     -183.731
Policy log std Mean                 -0.400418
Policy log std Std                   0.982643
Policy log std Max                   2
Policy log std Min                  -3.91048
_task0 Rewards Mean                 41.4544
_task0 Rewards Std                  93.3682
_task0 Rewards Max                 402.109
_task0 Rewards Min                  -0.885856
_task0 Returns Mean               6218.16
_task0 Returns Std               12726.3
_task0 Returns Max               40596.2
_task0 Returns Min                -111.461
_task0 Actions Mean                  0.0827493
_task0 Actions Std                   0.76695
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     369.904
Exploration_task0 Rewards Std     1016.93
Exploration_task0 Rewards Max    20790.3
Exploration_task0 Rewards Min      -11.2899
Exploration_task0 Returns Mean   56046.1
Exploration_task0 Returns Std   116354
Exploration_task0 Returns Max   709535
Exploration_task0 Returns Min    -1307.56
Exploration_task0 Actions Mean       0.0350328
Exploration_task0 Actions Std        0.829066
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6218.16
AverageReturn_all_train_tasks     6992.44
AverageReturn_all_test_tasks      6218.16
Number of train steps total      89000
Number of env steps total            4.451e+06
Number of rollouts total         32313
Train Time (s)                      97.7129
(Previous) Eval Time (s)            25.5787
Sample Time (s)                    107.127
Epoch Time (s)                     230.419
Total Train Time (s)             20535.8
Epoch                               88
------------------------------  ----------------
2019-06-27 06:15:07.909165 UTC | [dialturn] Iteration #88 | Epoch Duration: 230.22606778144836
2019-06-27 06:15:07.909432 UTC | [dialturn] Iteration #88 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000242522
Z variance train                     0.996892
KL Divergence                        0.000197349
KL Loss                              1.97349e-05
QF Loss                              6.99388e+07
VF Loss                              1.56489e+06
RF Loss                           4693.94
Policy Loss                     -45124.2
Q Predictions Mean               44868.5
Q Predictions Std                59999.2
Q Predictions Max               207469
Q Predictions Min                 1732.49
V Predictions Mean               45822.5
V Predictions Std                61062.8
V Predictions Max               211744
V Predictions Min                 1651.59
R Predictions Mean                 300.258
R Predictions Std                  872.544
R Predictions Max                14254.3
R Predictions Min                  -64.7814
Log Pis Mean                        19.7608
Log Pis Std                         13.6379
Log Pis Max                         55.4211
Log Pis Min                         -4.35156
Policy mu Mean                      -2.7822
Policy mu Std                       14.4877
Policy mu Max                      198.838
Policy mu Min                     -124.99
Policy log std Mean                 -0.331222
Policy log std Std                   1.02215
Policy log std Max                   2
Policy log std Min                  -3.96084
_task0 Rewards Mean                  9.21129
_task0 Rewards Std                  40.2487
_task0 Rewards Max                 454.935
_task0 Rewards Min                  -1.19999
_task0 Returns Mean               1381.69
_task0 Returns Std                5194.81
_task0 Returns Max               22446.4
_task0 Returns Min                -112.432
_task0 Actions Mean                 -0.11112
_task0 Actions Std                   0.845857
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     310.175
Exploration_task0 Rewards Std      875.78
Exploration_task0 Rewards Max    17245.2
Exploration_task0 Rewards Min      -11.3031
Exploration_task0 Returns Mean   46996.3
Exploration_task0 Returns Std   103498
Exploration_task0 Returns Max   545406
Exploration_task0 Returns Min    -1601.43
Exploration_task0 Actions Mean       0.06539
Exploration_task0 Actions Std        0.848899
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              1381.69
AverageReturn_all_train_tasks     1751.64
AverageReturn_all_test_tasks      1381.69
Number of train steps total      90000
Number of env steps total            4.501e+06
Number of rollouts total         32676
Train Time (s)                      98.3253
(Previous) Eval Time (s)            25.3847
Sample Time (s)                    106.604
Epoch Time (s)                     230.314
Total Train Time (s)             20766.4
Epoch                               89
------------------------------  ----------------
2019-06-27 06:18:58.539538 UTC | [dialturn] Iteration #89 | Epoch Duration: 230.62990951538086
2019-06-27 06:18:58.539739 UTC | [dialturn] Iteration #89 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000881033
Z variance train                     1.00058
KL Divergence                        8.57649e-05
KL Loss                              8.57649e-06
QF Loss                              7.61359e+07
VF Loss                         577852
RF Loss                           4078.55
Policy Loss                     -45062
Q Predictions Mean               44919.6
Q Predictions Std                60479.7
Q Predictions Max               207889
Q Predictions Min                 1771.34
V Predictions Mean               45252.5
V Predictions Std                60817.3
V Predictions Max               207976
V Predictions Min                 1538.8
R Predictions Mean                 307.922
R Predictions Std                  798.219
R Predictions Max                 9617.05
R Predictions Min                  -26.9269
Log Pis Mean                        20.9722
Log Pis Std                         13.7229
Log Pis Max                         54.3105
Log Pis Min                         -3.60171
Policy mu Mean                      -3.06372
Policy mu Std                       14.8616
Policy mu Max                      161.904
Policy mu Min                     -115.241
Policy log std Mean                 -0.290684
Policy log std Std                   1.04423
Policy log std Max                   2
Policy log std Min                  -3.76872
_task0 Rewards Mean                 57.5046
_task0 Rewards Std                 106.406
_task0 Rewards Max                 946.687
_task0 Rewards Min                  -0.900706
_task0 Returns Mean               8625.69
_task0 Returns Std               12842.6
_task0 Returns Max               41140.9
_task0 Returns Min                -109.716
_task0 Actions Mean                 -0.0716227
_task0 Actions Std                   0.859241
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     346.683
Exploration_task0 Rewards Std      934.968
Exploration_task0 Rewards Max    20713.8
Exploration_task0 Rewards Min      -10.3444
Exploration_task0 Returns Mean   52527.8
Exploration_task0 Returns Std   107190
Exploration_task0 Returns Max   539235
Exploration_task0 Returns Min    -1464.37
Exploration_task0 Actions Mean      -0.100165
Exploration_task0 Actions Std        0.853734
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8625.69
AverageReturn_all_train_tasks    10206.7
AverageReturn_all_test_tasks      8625.69
Number of train steps total      91000
Number of env steps total            4.551e+06
Number of rollouts total         33039
Train Time (s)                      98.8976
(Previous) Eval Time (s)            25.6989
Sample Time (s)                    107.026
Epoch Time (s)                     231.622
Total Train Time (s)             20997.8
Epoch                               90
------------------------------  ----------------
2019-06-27 06:22:49.957729 UTC | [dialturn] Iteration #90 | Epoch Duration: 231.41782212257385
2019-06-27 06:22:49.957978 UTC | [dialturn] Iteration #90 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00148001
Z variance train                     0.995927
KL Divergence                        0.000583033
KL Loss                              5.83033e-05
QF Loss                              6.98731e+07
VF Loss                         519190
RF Loss                          30324.2
Policy Loss                     -45287.5
Q Predictions Mean               44851.9
Q Predictions Std                59778.9
Q Predictions Max               198709
Q Predictions Min                 1737.71
V Predictions Mean               45092.6
V Predictions Std                60049.8
V Predictions Max               202849
V Predictions Min                 1573.71
R Predictions Mean                 640.903
R Predictions Std                 1428.49
R Predictions Max                16201.9
R Predictions Min                  -18.3073
Log Pis Mean                        20.8909
Log Pis Std                         13.3556
Log Pis Max                         49.4079
Log Pis Min                         -4.12847
Policy mu Mean                      -1.6799
Policy mu Std                       15.9584
Policy mu Max                      156.417
Policy mu Min                      -83.2665
Policy log std Mean                 -0.357068
Policy log std Std                   1.02719
Policy log std Max                   2
Policy log std Min                  -3.09013
_task0 Rewards Mean                 39.9175
_task0 Rewards Std                  79.446
_task0 Rewards Max                 704.032
_task0 Rewards Min                  -0.983221
_task0 Returns Mean               5987.63
_task0 Returns Std                9826.58
_task0 Returns Max               35115.1
_task0 Returns Min                -117.729
_task0 Actions Mean                 -0.0848021
_task0 Actions Std                   0.822481
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     513.073
Exploration_task0 Rewards Std     1215.13
Exploration_task0 Rewards Max    19668.6
Exploration_task0 Rewards Min      -10.3554
Exploration_task0 Returns Mean   77738.3
Exploration_task0 Returns Std   132687
Exploration_task0 Returns Max   537670
Exploration_task0 Returns Min    -1626.97
Exploration_task0 Actions Mean      -0.0256403
Exploration_task0 Actions Std        0.868207
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5987.63
AverageReturn_all_train_tasks     3660.71
AverageReturn_all_test_tasks      5987.63
Number of train steps total      92000
Number of env steps total            4.601e+06
Number of rollouts total         33402
Train Time (s)                     103.786
(Previous) Eval Time (s)            25.4929
Sample Time (s)                    106.859
Epoch Time (s)                     236.138
Total Train Time (s)             21233.9
Epoch                               91
------------------------------  ----------------
2019-06-27 06:26:46.049554 UTC | [dialturn] Iteration #91 | Epoch Duration: 236.09135222434998
2019-06-27 06:26:46.049741 UTC | [dialturn] Iteration #91 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00070427
Z variance train                     0.999884
KL Divergence                        5.00214e-05
KL Loss                              5.00214e-06
QF Loss                              1.20391e+08
VF Loss                         403745
RF Loss                          81905
Policy Loss                     -45459
Q Predictions Mean               45028
Q Predictions Std                59497.4
Q Predictions Max               200962
Q Predictions Min                 1663.58
V Predictions Mean               45519.3
V Predictions Std                59990.8
V Predictions Max               201084
V Predictions Min                 1536.48
R Predictions Mean                 574.061
R Predictions Std                 1375.23
R Predictions Max                12255.4
R Predictions Min                  -32.5643
Log Pis Mean                        21.1511
Log Pis Std                         13.943
Log Pis Max                         52.9127
Log Pis Min                         -4.24872
Policy mu Mean                      -2.2105
Policy mu Std                       17.9823
Policy mu Max                      112.488
Policy mu Min                      -97.3678
Policy log std Mean                 -0.249237
Policy log std Std                   1.07668
Policy log std Max                   2
Policy log std Min                  -3.08115
_task0 Rewards Mean                 35.5512
_task0 Rewards Std                  74.1189
_task0 Rewards Max                 630.067
_task0 Rewards Min                  -0.938002
_task0 Returns Mean               5332.68
_task0 Returns Std                8898.32
_task0 Returns Max               26012.8
_task0 Returns Min                -112.898
_task0 Actions Mean                 -0.0168363
_task0 Actions Std                   0.851646
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     615.898
Exploration_task0 Rewards Std     1460.3
Exploration_task0 Rewards Max    21835.5
Exploration_task0 Rewards Min      -11.8581
Exploration_task0 Returns Mean   93318
Exploration_task0 Returns Std   147531
Exploration_task0 Returns Max   524221
Exploration_task0 Returns Min    -1519.15
Exploration_task0 Actions Mean      -0.0683819
Exploration_task0 Actions Std        0.862678
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5332.68
AverageReturn_all_train_tasks     9908.49
AverageReturn_all_test_tasks      5332.68
Number of train steps total      93000
Number of env steps total            4.651e+06
Number of rollouts total         33765
Train Time (s)                      99.6602
(Previous) Eval Time (s)            25.445
Sample Time (s)                    107.316
Epoch Time (s)                     232.421
Total Train Time (s)             21466.5
Epoch                               92
------------------------------  ----------------
2019-06-27 06:30:38.620857 UTC | [dialturn] Iteration #92 | Epoch Duration: 232.5709412097931
2019-06-27 06:30:38.621050 UTC | [dialturn] Iteration #92 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000761859
Z variance train                     1.00016
KL Divergence                        8.02788e-05
KL Loss                              8.02788e-06
QF Loss                              6.73258e+07
VF Loss                         417676
RF Loss                          10977.4
Policy Loss                     -48948.9
Q Predictions Mean               48602.6
Q Predictions Std                61486.4
Q Predictions Max               198464
Q Predictions Min                 1781.57
V Predictions Mean               49070
V Predictions Std                61937
V Predictions Max               199230
V Predictions Min                 1633.02
R Predictions Mean                 643.039
R Predictions Std                 1415.44
R Predictions Max                13806.5
R Predictions Min                 -100.293
Log Pis Mean                        21.6638
Log Pis Std                         14.0094
Log Pis Max                         52.5046
Log Pis Min                         -6.50149
Policy mu Mean                      -2.78823
Policy mu Std                       17.95
Policy mu Max                      131.773
Policy mu Min                      -81.5682
Policy log std Mean                 -0.246489
Policy log std Std                   1.10677
Policy log std Max                   2
Policy log std Min                  -2.89927
_task0 Rewards Mean                 54.4832
_task0 Rewards Std                 153.016
_task0 Rewards Max                1706.78
_task0 Rewards Min                  -1.01007
_task0 Returns Mean               8172.48
_task0 Returns Std               14602.1
_task0 Returns Max               45561.2
_task0 Returns Min                -120.649
_task0 Actions Mean                 -0.101887
_task0 Actions Std                   0.828682
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     668.242
Exploration_task0 Rewards Std     1499.95
Exploration_task0 Rewards Max    18680.3
Exploration_task0 Rewards Min      -10.376
Exploration_task0 Returns Mean  101249
Exploration_task0 Returns Std   161512
Exploration_task0 Returns Max   565910
Exploration_task0 Returns Min    -1386.09
Exploration_task0 Actions Mean      -0.0575749
Exploration_task0 Actions Std        0.867603
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8172.48
AverageReturn_all_train_tasks     6333.33
AverageReturn_all_test_tasks      8172.48
Number of train steps total      94000
Number of env steps total            4.701e+06
Number of rollouts total         34128
Train Time (s)                      99.8655
(Previous) Eval Time (s)            25.5932
Sample Time (s)                    106.989
Epoch Time (s)                     232.447
Total Train Time (s)             21698.9
Epoch                               93
------------------------------  ----------------
2019-06-27 06:34:31.032708 UTC | [dialturn] Iteration #93 | Epoch Duration: 232.41149711608887
2019-06-27 06:34:31.032944 UTC | [dialturn] Iteration #93 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000651416
Z variance train                     1.00011
KL Divergence                        6.49681e-05
KL Loss                              6.49681e-06
QF Loss                              6.63524e+07
VF Loss                         423973
RF Loss                           7794.37
Policy Loss                     -46787.7
Q Predictions Mean               46484.8
Q Predictions Std                60633
Q Predictions Max               184045
Q Predictions Min                 1702.38
V Predictions Mean               46926.1
V Predictions Std                61052.1
V Predictions Max               189527
V Predictions Min                 1715.96
R Predictions Mean                 575.436
R Predictions Std                 1311.27
R Predictions Max                11243.9
R Predictions Min                  -14.184
Log Pis Mean                        20.6155
Log Pis Std                         13.8613
Log Pis Max                         54.3166
Log Pis Min                         -3.09336
Policy mu Mean                      -2.01836
Policy mu Std                       14.2565
Policy mu Max                      123.836
Policy mu Min                      -72.632
Policy log std Mean                 -0.360826
Policy log std Std                   0.996096
Policy log std Max                   2
Policy log std Min                  -2.9922
_task0 Rewards Mean                 59.253
_task0 Rewards Std                 131.697
_task0 Rewards Max                1062.79
_task0 Rewards Min                  -0.912653
_task0 Returns Mean               8887.94
_task0 Returns Std               14210
_task0 Returns Max               38326.3
_task0 Returns Min                -117.577
_task0 Actions Mean                  0.00492906
_task0 Actions Std                   0.86923
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     575.103
Exploration_task0 Rewards Std     1316.19
Exploration_task0 Rewards Max    16080.4
Exploration_task0 Rewards Min      -10.3739
Exploration_task0 Returns Mean   87136.8
Exploration_task0 Returns Std   140851
Exploration_task0 Returns Max   526192
Exploration_task0 Returns Min    -1703.72
Exploration_task0 Actions Mean      -0.0610884
Exploration_task0 Actions Std        0.897519
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8887.94
AverageReturn_all_train_tasks     3523.66
AverageReturn_all_test_tasks      8887.94
Number of train steps total      95000
Number of env steps total            4.751e+06
Number of rollouts total         34491
Train Time (s)                      99.8158
(Previous) Eval Time (s)            25.5558
Sample Time (s)                    107.235
Epoch Time (s)                     232.607
Total Train Time (s)             21931.7
Epoch                               94
------------------------------  ----------------
2019-06-27 06:38:23.840525 UTC | [dialturn] Iteration #94 | Epoch Duration: 232.80737495422363
2019-06-27 06:38:23.840734 UTC | [dialturn] Iteration #94 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000628673
Z variance train                     1.00029
KL Divergence                        2.81243e-05
KL Loss                              2.81243e-06
QF Loss                              7.28566e+07
VF Loss                         360460
RF Loss                           4218.72
Policy Loss                     -47673.8
Q Predictions Mean               47376.6
Q Predictions Std                61172.2
Q Predictions Max               197180
Q Predictions Min                 1843.97
V Predictions Mean               47550.4
V Predictions Std                61265.9
V Predictions Max               196571
V Predictions Min                 1746.24
R Predictions Mean                 429.475
R Predictions Std                  811.731
R Predictions Max                 9041.89
R Predictions Min                  -17.2274
Log Pis Mean                        21.3493
Log Pis Std                         13.6853
Log Pis Max                         52.5643
Log Pis Min                         -4.55209
Policy mu Mean                      -3.77346
Policy mu Std                       16.1158
Policy mu Max                      144.535
Policy mu Min                      -80.9213
Policy log std Mean                 -0.275354
Policy log std Std                   1.11238
Policy log std Max                   2
Policy log std Min                  -3.00237
_task0 Rewards Mean                 68.9478
_task0 Rewards Std                 148.719
_task0 Rewards Max                1619.81
_task0 Rewards Min                  -1.12862
_task0 Returns Mean              10342.2
_task0 Returns Std               16688.2
_task0 Returns Max               51477.8
_task0 Returns Min                -118.43
_task0 Actions Mean                 -0.131851
_task0 Actions Std                   0.891592
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     558.949
Exploration_task0 Rewards Std     1285.46
Exploration_task0 Rewards Max    18817.5
Exploration_task0 Rewards Min       -9.80569
Exploration_task0 Returns Mean   84689.2
Exploration_task0 Returns Std   133944
Exploration_task0 Returns Max   561889
Exploration_task0 Returns Min    -1595.02
Exploration_task0 Actions Mean      -0.0493673
Exploration_task0 Actions Std        0.90019
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10342.2
AverageReturn_all_train_tasks     5506.7
AverageReturn_all_test_tasks     10342.2
Number of train steps total      96000
Number of env steps total            4.801e+06
Number of rollouts total         34854
Train Time (s)                      98.9102
(Previous) Eval Time (s)            25.7552
Sample Time (s)                    106.873
Epoch Time (s)                     231.538
Total Train Time (s)             22163.1
Epoch                               95
------------------------------  ----------------
2019-06-27 06:42:15.202430 UTC | [dialturn] Iteration #95 | Epoch Duration: 231.36148166656494
2019-06-27 06:42:15.202676 UTC | [dialturn] Iteration #95 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00140348
Z variance train                     1.00178
KL Divergence                        0.000362214
KL Loss                              3.62214e-05
QF Loss                              4.56116e+07
VF Loss                         499456
RF Loss                          68691.3
Policy Loss                     -48605.6
Q Predictions Mean               48110.6
Q Predictions Std                61848.9
Q Predictions Max               196729
Q Predictions Min                 1838.96
V Predictions Mean               48376.4
V Predictions Std                62117.7
V Predictions Max               197959
V Predictions Min                 1769.48
R Predictions Mean                 610.949
R Predictions Std                 1608.48
R Predictions Max                17906.8
R Predictions Min                  -10.9876
Log Pis Mean                        21.4084
Log Pis Std                         13.1529
Log Pis Max                         55.0757
Log Pis Min                         -3.65765
Policy mu Mean                      -2.4188
Policy mu Std                       13.5538
Policy mu Max                      145.421
Policy mu Min                      -76.3543
Policy log std Mean                 -0.401075
Policy log std Std                   1.03289
Policy log std Max                   2
Policy log std Min                  -4.92749
_task0 Rewards Mean                 50.1568
_task0 Rewards Std                 111.836
_task0 Rewards Max                1049.01
_task0 Rewards Min                  -0.852285
_task0 Returns Mean               7523.53
_task0 Returns Std               12186.5
_task0 Returns Max               33820.9
_task0 Returns Min                -113.778
_task0 Actions Mean                  0.0392117
_task0 Actions Std                   0.887647
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     621.501
Exploration_task0 Rewards Std     1386.44
Exploration_task0 Rewards Max    23004.7
Exploration_task0 Rewards Min      -10.374
Exploration_task0 Returns Mean   94166.9
Exploration_task0 Returns Std   153912
Exploration_task0 Returns Max   807491
Exploration_task0 Returns Min    -1273.31
Exploration_task0 Actions Mean       0.0091568
Exploration_task0 Actions Std        0.888017
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              7523.53
AverageReturn_all_train_tasks     2150.6
AverageReturn_all_test_tasks      7523.53
Number of train steps total      97000
Number of env steps total            4.851e+06
Number of rollouts total         35217
Train Time (s)                      99.9714
(Previous) Eval Time (s)            25.577
Sample Time (s)                    106.757
Epoch Time (s)                     232.306
Total Train Time (s)             22395.6
Epoch                               96
------------------------------  ----------------
2019-06-27 06:46:07.735894 UTC | [dialturn] Iteration #96 | Epoch Duration: 232.53300619125366
2019-06-27 06:46:07.736129 UTC | [dialturn] Iteration #96 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00143168
Z variance train                     0.999462
KL Divergence                        0.000321302
KL Loss                              3.21302e-05
QF Loss                              8.34982e+07
VF Loss                         388695
RF Loss                          68080.2
Policy Loss                     -47954.3
Q Predictions Mean               47396.7
Q Predictions Std                61742.7
Q Predictions Max               187093
Q Predictions Min                 1681.73
V Predictions Mean               47993.4
V Predictions Std                62495.8
V Predictions Max               188804
V Predictions Min                 1636.93
R Predictions Mean                 758.401
R Predictions Std                 1883.66
R Predictions Max                16824.2
R Predictions Min                  -15.9013
Log Pis Mean                        21.1552
Log Pis Std                         13.0468
Log Pis Max                         56.2183
Log Pis Min                         -5.72148
Policy mu Mean                      -2.76009
Policy mu Std                       14.0089
Policy mu Max                       97.2572
Policy mu Min                      -83.579
Policy log std Mean                 -0.401588
Policy log std Std                   1.01992
Policy log std Max                   2
Policy log std Min                  -4.33469
_task0 Rewards Mean                 67.3007
_task0 Rewards Std                 152.642
_task0 Rewards Max                1540.18
_task0 Rewards Min                  -1.03751
_task0 Returns Mean              10095.1
_task0 Returns Std               16606.9
_task0 Returns Max               47076.4
_task0 Returns Min                -121.003
_task0 Actions Mean                  0.0168595
_task0 Actions Std                   0.851545
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     599.569
Exploration_task0 Rewards Std     1387.77
Exploration_task0 Rewards Max    22652.6
Exploration_task0 Rewards Min      -11.3619
Exploration_task0 Returns Mean   90843.9
Exploration_task0 Returns Std   151291
Exploration_task0 Returns Max   616604
Exploration_task0 Returns Min    -1392.69
Exploration_task0 Actions Mean      -0.0106501
Exploration_task0 Actions Std        0.881273
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10095.1
AverageReturn_all_train_tasks    18146.9
AverageReturn_all_test_tasks     10095.1
Number of train steps total      98000
Number of env steps total            4.901e+06
Number of rollouts total         35580
Train Time (s)                      99.7016
(Previous) Eval Time (s)            25.803
Sample Time (s)                    107.054
Epoch Time (s)                     232.558
Total Train Time (s)             22628.1
Epoch                               97
------------------------------  ----------------
2019-06-27 06:50:00.255048 UTC | [dialturn] Iteration #97 | Epoch Duration: 232.5186619758606
2019-06-27 06:50:00.255327 UTC | [dialturn] Iteration #97 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00235918
Z variance train                     1.00103
KL Divergence                        0.000628985
KL Loss                              6.28985e-05
QF Loss                              1.05178e+08
VF Loss                         394501
RF Loss                          12372.7
Policy Loss                     -47389.3
Q Predictions Mean               46957.9
Q Predictions Std                62381
Q Predictions Max               195166
Q Predictions Min                 1720.17
V Predictions Mean               47367.3
V Predictions Std                62804.3
V Predictions Max               196292
V Predictions Min                 1732.74
R Predictions Mean                 596.094
R Predictions Std                 1253.59
R Predictions Max                16790
R Predictions Min                  -99.4894
Log Pis Mean                        20.46
Log Pis Std                         13.3531
Log Pis Max                         55.8866
Log Pis Min                         -3.70923
Policy mu Mean                      -1.69571
Policy mu Std                       11.9898
Policy mu Max                      113.644
Policy mu Min                      -71.2142
Policy log std Mean                 -0.60554
Policy log std Std                   0.977667
Policy log std Max                   2
Policy log std Min                  -6.65436
_task0 Rewards Mean                 60.6083
_task0 Rewards Std                 153.36
_task0 Rewards Max                2007.21
_task0 Rewards Min                  -0.846047
_task0 Returns Mean               9091.24
_task0 Returns Std               14792.8
_task0 Returns Max               48225.5
_task0 Returns Min                -111.672
_task0 Actions Mean                 -0.0259114
_task0 Actions Std                   0.860999
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     734.249
Exploration_task0 Rewards Std     1697.58
Exploration_task0 Rewards Max    22325.4
Exploration_task0 Rewards Min      -11.3467
Exploration_task0 Returns Mean  111250
Exploration_task0 Returns Std   186319
Exploration_task0 Returns Max   669161
Exploration_task0 Returns Min    -1615.68
Exploration_task0 Actions Mean      -0.0287863
Exploration_task0 Actions Std        0.873554
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9091.24
AverageReturn_all_train_tasks     6775
AverageReturn_all_test_tasks      9091.24
Number of train steps total      99000
Number of env steps total            4.951e+06
Number of rollouts total         35943
Train Time (s)                      98.9361
(Previous) Eval Time (s)            25.762
Sample Time (s)                    107.126
Epoch Time (s)                     231.824
Total Train Time (s)             22859.8
Epoch                               98
------------------------------  ----------------
2019-06-27 06:53:51.905876 UTC | [dialturn] Iteration #98 | Epoch Duration: 231.65034532546997
2019-06-27 06:53:51.906072 UTC | [dialturn] Iteration #98 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0014047
Z variance train                     0.999454
KL Divergence                        0.000249912
KL Loss                              2.49912e-05
QF Loss                              9.70902e+07
VF Loss                         855027
RF Loss                          12320.3
Policy Loss                     -50251.4
Q Predictions Mean               49945.1
Q Predictions Std                63645.1
Q Predictions Max               194882
Q Predictions Min                 1756.21
V Predictions Mean               50774.8
V Predictions Std                64451
V Predictions Max               197304
V Predictions Min                 1752.09
R Predictions Mean                 650.193
R Predictions Std                 1554.44
R Predictions Max                15443.9
R Predictions Min                  -62.6947
Log Pis Mean                        21.4006
Log Pis Std                         12.9134
Log Pis Max                         55.671
Log Pis Min                         -3.78879
Policy mu Mean                      -1.13169
Policy mu Std                       13.0497
Policy mu Max                       96.7131
Policy mu Min                      -64.9527
Policy log std Mean                 -0.52062
Policy log std Std                   1.04977
Policy log std Max                   2
Policy log std Min                  -6.84446
_task0 Rewards Mean                 56.2995
_task0 Rewards Std                 128.875
_task0 Rewards Max                1174.38
_task0 Rewards Min                  -1.13588
_task0 Returns Mean               8444.92
_task0 Returns Std               13343
_task0 Returns Max               40072.7
_task0 Returns Min                -125.989
_task0 Actions Mean                 -0.133362
_task0 Actions Std                   0.809225
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     613.022
Exploration_task0 Rewards Std     1336.39
Exploration_task0 Rewards Max    18777.1
Exploration_task0 Rewards Min      -11.2235
Exploration_task0 Returns Mean   92882.1
Exploration_task0 Returns Std   144588
Exploration_task0 Returns Max   593015
Exploration_task0 Returns Min    -1549.49
Exploration_task0 Actions Mean      -0.0112792
Exploration_task0 Actions Std        0.878433
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8444.92
AverageReturn_all_train_tasks     4470.73
AverageReturn_all_test_tasks      8444.92
Number of train steps total     100000
Number of env steps total            5.001e+06
Number of rollouts total         36306
Train Time (s)                      99.8791
(Previous) Eval Time (s)            25.5867
Sample Time (s)                    106.431
Epoch Time (s)                     231.897
Total Train Time (s)             23091.9
Epoch                               99
------------------------------  ----------------
2019-06-27 06:57:44.004079 UTC | [dialturn] Iteration #99 | Epoch Duration: 232.09785175323486
2019-06-27 06:57:44.004280 UTC | [dialturn] Iteration #99 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000949713
Z variance train                     0.999895
KL Divergence                        0.000107459
KL Loss                              1.07459e-05
QF Loss                              1.55804e+08
VF Loss                         373208
RF Loss                           8838.05
Policy Loss                     -50093.6
Q Predictions Mean               49677.1
Q Predictions Std                64426.4
Q Predictions Max               195903
Q Predictions Min                 1819.17
V Predictions Mean               50032.7
V Predictions Std                64748.3
V Predictions Max               196697
V Predictions Min                 1652.16
R Predictions Mean                 534.447
R Predictions Std                 1161.83
R Predictions Max                12007.6
R Predictions Min                  -86.936
Log Pis Mean                        21.5474
Log Pis Std                         13.1716
Log Pis Max                         55.0751
Log Pis Min                         -3.63795
Policy mu Mean                      -2.12219
Policy mu Std                       13.1627
Policy mu Max                      101.232
Policy mu Min                      -81.9636
Policy log std Mean                 -0.509655
Policy log std Std                   1.00602
Policy log std Max                   2
Policy log std Min                  -5.16386
_task0 Rewards Mean                 45.6676
_task0 Rewards Std                 115.052
_task0 Rewards Max                1465.69
_task0 Rewards Min                  -0.857829
_task0 Returns Mean               6850.14
_task0 Returns Std               12800.1
_task0 Returns Max               47869.8
_task0 Returns Min                -108.689
_task0 Actions Mean                  0.0107701
_task0 Actions Std                   0.870362
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     599.27
Exploration_task0 Rewards Std     1323.89
Exploration_task0 Rewards Max    17429.2
Exploration_task0 Rewards Min      -11.3539
Exploration_task0 Returns Mean   90798.6
Exploration_task0 Returns Std   146159
Exploration_task0 Returns Max   573892
Exploration_task0 Returns Min    -1351.67
Exploration_task0 Actions Mean      -0.101947
Exploration_task0 Actions Std        0.863639
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6850.14
AverageReturn_all_train_tasks    12500.4
AverageReturn_all_test_tasks      6850.14
Number of train steps total     101000
Number of env steps total            5.051e+06
Number of rollouts total         36669
Train Time (s)                     100.884
(Previous) Eval Time (s)            25.7864
Sample Time (s)                    105.871
Epoch Time (s)                     232.541
Total Train Time (s)             23324.1
Epoch                              100
------------------------------  ----------------
2019-06-27 07:01:36.238178 UTC | [dialturn] Iteration #100 | Epoch Duration: 232.23374390602112
2019-06-27 07:01:36.238375 UTC | [dialturn] Iteration #100 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000690406
Z variance train                     1.00031
KL Divergence                        6.21283e-05
KL Loss                              6.21283e-06
QF Loss                              6.31553e+07
VF Loss                         678049
RF Loss                           7121.76
Policy Loss                     -51054.1
Q Predictions Mean               50558.4
Q Predictions Std                65148.9
Q Predictions Max               194413
Q Predictions Min                 1734.03
V Predictions Mean               51381.8
V Predictions Std                66083.3
V Predictions Max               197322
V Predictions Min                 1588.84
R Predictions Mean                 611.846
R Predictions Std                 1340
R Predictions Max                10333.8
R Predictions Min                 -244.912
Log Pis Mean                        22.2427
Log Pis Std                         13.2213
Log Pis Max                         55.2384
Log Pis Min                         -3.4215
Policy mu Mean                      -1.93508
Policy mu Std                       12.9008
Policy mu Max                      100.269
Policy mu Min                      -85.5427
Policy log std Mean                 -0.457533
Policy log std Std                   1.01969
Policy log std Max                   2
Policy log std Min                  -5.45897
_task0 Rewards Mean                 36.1927
_task0 Rewards Std                  75.6438
_task0 Rewards Max                 465.091
_task0 Rewards Min                  -1.06881
_task0 Returns Mean               5428.9
_task0 Returns Std                9020
_task0 Returns Max               24258.2
_task0 Returns Min                -123.852
_task0 Actions Mean                  0.0447582
_task0 Actions Std                   0.853862
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     575.56
Exploration_task0 Rewards Std     1556.97
Exploration_task0 Rewards Max    21638.3
Exploration_task0 Rewards Min      -11.0811
Exploration_task0 Returns Mean   87206
Exploration_task0 Returns Std   163499
Exploration_task0 Returns Max   672935
Exploration_task0 Returns Min    -1543.57
Exploration_task0 Actions Mean      -0.082514
Exploration_task0 Actions Std        0.863214
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5428.9
AverageReturn_all_train_tasks    12718.3
AverageReturn_all_test_tasks      5428.9
Number of train steps total     102000
Number of env steps total            5.101e+06
Number of rollouts total         37032
Train Time (s)                      99.2291
(Previous) Eval Time (s)            25.4776
Sample Time (s)                    106.783
Epoch Time (s)                     231.49
Total Train Time (s)             23555.5
Epoch                              101
------------------------------  ----------------
2019-06-27 07:05:27.629467 UTC | [dialturn] Iteration #101 | Epoch Duration: 231.39093899726868
2019-06-27 07:05:27.629677 UTC | [dialturn] Iteration #101 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0017076
Z variance train                     0.998994
KL Divergence                        0.000374694
KL Loss                              3.74694e-05
QF Loss                              6.34827e+07
VF Loss                         477002
RF Loss                          14935.6
Policy Loss                     -52037
Q Predictions Mean               51435.9
Q Predictions Std                65384
Q Predictions Max               195588
Q Predictions Min                 1720.11
V Predictions Mean               52094.4
V Predictions Std                65977.8
V Predictions Max               197898
V Predictions Min                 1696.47
R Predictions Mean                 538.451
R Predictions Std                 1450.93
R Predictions Max                17794.6
R Predictions Min                 -301.176
Log Pis Mean                        21.748
Log Pis Std                         13.184
Log Pis Max                         55.4841
Log Pis Min                         -1.93593
Policy mu Mean                      -2.32546
Policy mu Std                       13.4383
Policy mu Max                      115.452
Policy mu Min                      -83.7435
Policy log std Mean                 -0.4611
Policy log std Std                   1.03323
Policy log std Max                   2
Policy log std Min                  -5.36474
_task0 Rewards Mean                 62.8104
_task0 Rewards Std                 126.458
_task0 Rewards Max                1128.67
_task0 Rewards Min                  -0.940823
_task0 Returns Mean               9421.57
_task0 Returns Std               14459.6
_task0 Returns Max               46122.9
_task0 Returns Min                -110.481
_task0 Actions Mean                 -0.105862
_task0 Actions Std                   0.872113
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     737.337
Exploration_task0 Rewards Std     1768.42
Exploration_task0 Rewards Max    21661.7
Exploration_task0 Rewards Min      -11.058
Exploration_task0 Returns Mean  111718
Exploration_task0 Returns Std   186234
Exploration_task0 Returns Max   580041
Exploration_task0 Returns Min    -1368.77
Exploration_task0 Actions Mean      -0.110354
Exploration_task0 Actions Std        0.875926
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9421.57
AverageReturn_all_train_tasks    10070.4
AverageReturn_all_test_tasks      9421.57
Number of train steps total     103000
Number of env steps total            5.151e+06
Number of rollouts total         37395
Train Time (s)                     100.19
(Previous) Eval Time (s)            25.3775
Sample Time (s)                    106.964
Epoch Time (s)                     232.532
Total Train Time (s)             23788.4
Epoch                              102
------------------------------  ----------------
2019-06-27 07:09:20.523673 UTC | [dialturn] Iteration #102 | Epoch Duration: 232.89381313323975
2019-06-27 07:09:20.523889 UTC | [dialturn] Iteration #102 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000573432
Z variance train                     0.999456
KL Divergence                        6.14046e-05
KL Loss                              6.14046e-06
QF Loss                              1.16686e+08
VF Loss                         390520
RF Loss                           9659.41
Policy Loss                     -50844.7
Q Predictions Mean               50440.2
Q Predictions Std                65511.1
Q Predictions Max               196654
Q Predictions Min                 1624.09
V Predictions Mean               50783
V Predictions Std                65804.5
V Predictions Max               198703
V Predictions Min                 1659.27
R Predictions Mean                 626.154
R Predictions Std                 1482.78
R Predictions Max                13282.2
R Predictions Min                  -87.5989
Log Pis Mean                        22.0023
Log Pis Std                         13.6911
Log Pis Max                         55.8091
Log Pis Min                         -3.87277
Policy mu Mean                      -2.18102
Policy mu Std                       14.115
Policy mu Max                       98.0513
Policy mu Min                      -70.8117
Policy log std Mean                 -0.358932
Policy log std Std                   1.09386
Policy log std Max                   2
Policy log std Min                  -4.90356
_task0 Rewards Mean                 56.9063
_task0 Rewards Std                 137.453
_task0 Rewards Max                1082.27
_task0 Rewards Min                  -1.07971
_task0 Returns Mean               8535.94
_task0 Returns Std               15079.4
_task0 Returns Max               39927
_task0 Returns Min                -124.496
_task0 Actions Mean                  0.0593817
_task0 Actions Std                   0.884442
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     549.615
Exploration_task0 Rewards Std     1206.76
Exploration_task0 Rewards Max    22169.3
Exploration_task0 Rewards Min      -10.6305
Exploration_task0 Returns Mean   83275.1
Exploration_task0 Returns Std   132083
Exploration_task0 Returns Max   539514
Exploration_task0 Returns Min    -1671.96
Exploration_task0 Actions Mean      -0.0752413
Exploration_task0 Actions Std        0.880453
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8535.94
AverageReturn_all_train_tasks     9686.76
AverageReturn_all_test_tasks      8535.94
Number of train steps total     104000
Number of env steps total            5.201e+06
Number of rollouts total         37758
Train Time (s)                     101.005
(Previous) Eval Time (s)            25.7378
Sample Time (s)                    107.003
Epoch Time (s)                     233.746
Total Train Time (s)             24022.2
Epoch                              103
------------------------------  ----------------
2019-06-27 07:13:14.340480 UTC | [dialturn] Iteration #103 | Epoch Duration: 233.81641578674316
2019-06-27 07:13:14.340677 UTC | [dialturn] Iteration #103 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000848272
Z variance train                     1.00041
KL Divergence                        6.98419e-05
KL Loss                              6.98419e-06
QF Loss                              1.32677e+08
VF Loss                              1.16795e+06
RF Loss                          32331
Policy Loss                     -50135.8
Q Predictions Mean               49888.9
Q Predictions Std                65583.7
Q Predictions Max               204468
Q Predictions Min                 1629.18
V Predictions Mean               50722.3
V Predictions Std                66519.3
V Predictions Max               204880
V Predictions Min                 1580.67
R Predictions Mean                 571.236
R Predictions Std                 1285.86
R Predictions Max                13858.3
R Predictions Min                 -143.538
Log Pis Mean                        21.2971
Log Pis Std                         13.1801
Log Pis Max                         58.5239
Log Pis Min                         -5.12104
Policy mu Mean                      -1.59841
Policy mu Std                       12.191
Policy mu Max                       88.7227
Policy mu Min                      -71.8141
Policy log std Mean                 -0.465643
Policy log std Std                   1.01322
Policy log std Max                   2
Policy log std Min                  -4.64097
_task0 Rewards Mean                 81.4311
_task0 Rewards Std                 179.17
_task0 Rewards Max                1877.34
_task0 Rewards Min                  -0.835404
_task0 Returns Mean              12214.7
_task0 Returns Std               18846.4
_task0 Returns Max               50781.8
_task0 Returns Min                 -95.0902
_task0 Actions Mean                  0.00373423
_task0 Actions Std                   0.838609
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     543.552
Exploration_task0 Rewards Std     1355.96
Exploration_task0 Rewards Max    22426.7
Exploration_task0 Rewards Min      -11.2183
Exploration_task0 Returns Mean   82356.4
Exploration_task0 Returns Std   143242
Exploration_task0 Returns Max   555094
Exploration_task0 Returns Min    -1495.35
Exploration_task0 Actions Mean       0.0286978
Exploration_task0 Actions Std        0.886948
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             12214.7
AverageReturn_all_train_tasks    10283
AverageReturn_all_test_tasks     12214.7
Number of train steps total     105000
Number of env steps total            5.251e+06
Number of rollouts total         38121
Train Time (s)                     100.428
(Previous) Eval Time (s)            25.8073
Sample Time (s)                    107.701
Epoch Time (s)                     233.937
Total Train Time (s)             24256
Epoch                              104
------------------------------  ----------------
2019-06-27 07:17:08.157397 UTC | [dialturn] Iteration #104 | Epoch Duration: 233.816499710083
2019-06-27 07:17:08.157628 UTC | [dialturn] Iteration #104 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000764746
Z variance train                     0.998066
KL Divergence                        0.000119426
KL Loss                              1.19426e-05
QF Loss                              7.08325e+07
VF Loss                              1.21141e+06
RF Loss                          32171.3
Policy Loss                     -51353.5
Q Predictions Mean               51049.2
Q Predictions Std                66280.9
Q Predictions Max               200816
Q Predictions Min                 1679.12
V Predictions Mean               50737.6
V Predictions Std                66006.7
V Predictions Max               201678
V Predictions Min                 1454.35
R Predictions Mean                 657.911
R Predictions Std                 1359.7
R Predictions Max                19841
R Predictions Min                  -21.6881
Log Pis Mean                        20.8137
Log Pis Std                         13.0659
Log Pis Max                         51.2499
Log Pis Min                         -7.53733
Policy mu Mean                      -1.11249
Policy mu Std                       12.1471
Policy mu Max                      112.263
Policy mu Min                      -89.285
Policy log std Mean                 -0.480263
Policy log std Std                   1.01913
Policy log std Max                   2
Policy log std Min                  -4.54794
_task0 Rewards Mean                 78.4084
_task0 Rewards Std                 171.475
_task0 Rewards Max                1236.53
_task0 Rewards Min                  -1.04118
_task0 Returns Mean              11761.3
_task0 Returns Std               18132
_task0 Returns Max               47257.8
_task0 Returns Min                -122.228
_task0 Actions Mean                 -0.167289
_task0 Actions Std                   0.87588
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     622.989
Exploration_task0 Rewards Std     1549.35
Exploration_task0 Rewards Max    23091.1
Exploration_task0 Rewards Min      -11.2855
Exploration_task0 Returns Mean   94392.3
Exploration_task0 Returns Std   161121
Exploration_task0 Returns Max   551546
Exploration_task0 Returns Min    -1416.76
Exploration_task0 Actions Mean      -0.0217985
Exploration_task0 Actions Std        0.87979
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             11761.3
AverageReturn_all_train_tasks    11658.6
AverageReturn_all_test_tasks     11761.3
Number of train steps total     106000
Number of env steps total            5.301e+06
Number of rollouts total         38484
Train Time (s)                     100.989
(Previous) Eval Time (s)            25.6857
Sample Time (s)                    106.482
Epoch Time (s)                     233.158
Total Train Time (s)             24489.1
Epoch                              105
------------------------------  ----------------
2019-06-27 07:21:01.206950 UTC | [dialturn] Iteration #105 | Epoch Duration: 233.0491292476654
2019-06-27 07:21:01.207191 UTC | [dialturn] Iteration #105 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000968594
Z variance train                     1.00101
KL Divergence                        0.00013834
KL Loss                              1.3834e-05
QF Loss                              5.99148e+07
VF Loss                         550666
RF Loss                           7384.45
Policy Loss                     -48833.7
Q Predictions Mean               48564.6
Q Predictions Std                65502.7
Q Predictions Max               200772
Q Predictions Min                 1719.2
V Predictions Mean               48488.8
V Predictions Std                65574.7
V Predictions Max               204354
V Predictions Min                 1525.78
R Predictions Mean                 654.495
R Predictions Std                 1499.84
R Predictions Max                17369.1
R Predictions Min                  -33.22
Log Pis Mean                        20.7408
Log Pis Std                         13.5183
Log Pis Max                         54.0197
Log Pis Min                         -4.71422
Policy mu Mean                      -1.37048
Policy mu Std                       12.434
Policy mu Max                      107.55
Policy mu Min                      -85.0329
Policy log std Mean                 -0.459366
Policy log std Std                   1.05657
Policy log std Max                   2
Policy log std Min                  -4.78519
_task0 Rewards Mean                 63.863
_task0 Rewards Std                 149.912
_task0 Rewards Max                1642.37
_task0 Rewards Min                  -1.03562
_task0 Returns Mean               9579.45
_task0 Returns Std               17083.4
_task0 Returns Max               55905.7
_task0 Returns Min                -120.978
_task0 Actions Mean                 -0.183919
_task0 Actions Std                   0.846252
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     649.613
Exploration_task0 Rewards Std     1513.54
Exploration_task0 Rewards Max    21734.7
Exploration_task0 Rewards Min      -10.8322
Exploration_task0 Returns Mean   98426.2
Exploration_task0 Returns Std   158492
Exploration_task0 Returns Max   544558
Exploration_task0 Returns Min    -1622.15
Exploration_task0 Actions Mean      -0.0854225
Exploration_task0 Actions Std        0.87353
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9579.45
AverageReturn_all_train_tasks     6454.16
AverageReturn_all_test_tasks      9579.45
Number of train steps total     107000
Number of env steps total            5.351e+06
Number of rollouts total         38847
Train Time (s)                     101.586
(Previous) Eval Time (s)            25.5759
Sample Time (s)                    106.466
Epoch Time (s)                     233.628
Total Train Time (s)             24722.5
Epoch                              106
------------------------------  ----------------
2019-06-27 07:24:54.693731 UTC | [dialturn] Iteration #106 | Epoch Duration: 233.48637580871582
2019-06-27 07:24:54.693932 UTC | [dialturn] Iteration #106 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000529947
Z variance train                     0.999419
KL Divergence                        5.19113e-05
KL Loss                              5.19113e-06
QF Loss                              6.30398e+07
VF Loss                         486862
RF Loss                           7532.32
Policy Loss                     -52739.2
Q Predictions Mean               52222.4
Q Predictions Std                67801.9
Q Predictions Max               203823
Q Predictions Min                 1604.76
V Predictions Mean               52615.7
V Predictions Std                68341.7
V Predictions Max               209410
V Predictions Min                 1430.83
R Predictions Mean                 555.375
R Predictions Std                 1383.78
R Predictions Max                13912.7
R Predictions Min                  -83.0871
Log Pis Mean                        20.2982
Log Pis Std                         13.3026
Log Pis Max                         55.4939
Log Pis Min                         -5.45688
Policy mu Mean                      -1.27828
Policy mu Std                       13.0114
Policy mu Max                      109.929
Policy mu Min                      -89.4197
Policy log std Mean                 -0.476797
Policy log std Std                   1.03344
Policy log std Max                   2
Policy log std Min                  -5.11675
_task0 Rewards Mean                 38.3671
_task0 Rewards Std                  79.4863
_task0 Rewards Max                 597.013
_task0 Rewards Min                  -0.90471
_task0 Returns Mean               5755.07
_task0 Returns Std               10267.8
_task0 Returns Max               33789.8
_task0 Returns Min                -116.968
_task0 Actions Mean                 -0.174953
_task0 Actions Std                   0.838215
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     458.77
Exploration_task0 Rewards Std     1288.4
Exploration_task0 Rewards Max    22493.2
Exploration_task0 Rewards Min      -11.3443
Exploration_task0 Returns Mean   69510.6
Exploration_task0 Returns Std   136835
Exploration_task0 Returns Max   593149
Exploration_task0 Returns Min    -1678.12
Exploration_task0 Actions Mean      -0.133241
Exploration_task0 Actions Std        0.866031
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              5755.07
AverageReturn_all_train_tasks     9786.76
AverageReturn_all_test_tasks      5755.07
Number of train steps total     108000
Number of env steps total            5.401e+06
Number of rollouts total         39210
Train Time (s)                     101.932
(Previous) Eval Time (s)            25.4332
Sample Time (s)                    106.655
Epoch Time (s)                     234.02
Total Train Time (s)             24956.6
Epoch                              107
------------------------------  ----------------
2019-06-27 07:28:48.755979 UTC | [dialturn] Iteration #107 | Epoch Duration: 234.0618815422058
2019-06-27 07:28:48.756190 UTC | [dialturn] Iteration #107 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000572104
Z variance train                     0.998713
KL Divergence                        7.5601e-05
KL Loss                              7.5601e-06
QF Loss                              8.87447e+07
VF Loss                         566963
RF Loss                           8059.25
Policy Loss                     -51705.2
Q Predictions Mean               51167.2
Q Predictions Std                67654.1
Q Predictions Max               205576
Q Predictions Min                  958.036
V Predictions Mean               51773.2
V Predictions Std                68316
V Predictions Max               209943
V Predictions Min                 1432.42
R Predictions Mean                 546.95
R Predictions Std                 1179.21
R Predictions Max                10762.1
R Predictions Min                  -75.6339
Log Pis Mean                        20.3205
Log Pis Std                         13.1814
Log Pis Max                         53.1541
Log Pis Min                         -4.85759
Policy mu Mean                      -1.43753
Policy mu Std                       13.9989
Policy mu Max                      132.752
Policy mu Min                     -114.436
Policy log std Mean                 -0.425131
Policy log std Std                   0.979278
Policy log std Max                   2
Policy log std Min                  -5.08827
_task0 Rewards Mean                 65.8461
_task0 Rewards Std                 150.812
_task0 Rewards Max                1172.03
_task0 Rewards Min                  -0.888569
_task0 Returns Mean               9876.92
_task0 Returns Std               16616
_task0 Returns Max               41100
_task0 Returns Min                -104.127
_task0 Actions Mean                 -0.0498964
_task0 Actions Std                   0.864698
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     535.594
Exploration_task0 Rewards Std     1166.49
Exploration_task0 Rewards Max    20344.1
Exploration_task0 Rewards Min      -13.0018
Exploration_task0 Returns Mean   81150.6
Exploration_task0 Returns Std   136016
Exploration_task0 Returns Max   594815
Exploration_task0 Returns Min    -1327.44
Exploration_task0 Actions Mean      -0.142553
Exploration_task0 Actions Std        0.862946
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9876.92
AverageReturn_all_train_tasks     7236
AverageReturn_all_test_tasks      9876.92
Number of train steps total     109000
Number of env steps total            5.451e+06
Number of rollouts total         39573
Train Time (s)                     101.067
(Previous) Eval Time (s)            25.4737
Sample Time (s)                    106.103
Epoch Time (s)                     232.643
Total Train Time (s)             25189.5
Epoch                              108
------------------------------  ----------------
2019-06-27 07:32:41.613831 UTC | [dialturn] Iteration #108 | Epoch Duration: 232.85747933387756
2019-06-27 07:32:41.614061 UTC | [dialturn] Iteration #108 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00064796
Z variance train                     1.00015
KL Divergence                        5.95277e-05
KL Loss                              5.95277e-06
QF Loss                              1.09936e+08
VF Loss                              1.04791e+06
RF Loss                          14670.7
Policy Loss                     -53738.6
Q Predictions Mean               53385.8
Q Predictions Std                68618.1
Q Predictions Max               206898
Q Predictions Min                 1350.81
V Predictions Mean               54268.6
V Predictions Std                69508.8
V Predictions Max               212823
V Predictions Min                 1410.86
R Predictions Mean                 638.765
R Predictions Std                 1494.49
R Predictions Max                11501.1
R Predictions Min                 -111.856
Log Pis Mean                        21.7565
Log Pis Std                         13.9574
Log Pis Max                         52.5961
Log Pis Min                         -3.64398
Policy mu Mean                      -1.79992
Policy mu Std                       15.8949
Policy mu Max                      144.97
Policy mu Min                     -125.646
Policy log std Mean                 -0.366991
Policy log std Std                   0.978834
Policy log std Max                   2
Policy log std Min                  -5.07931
_task0 Rewards Mean                 55.3923
_task0 Rewards Std                 154.052
_task0 Rewards Max                1559.88
_task0 Rewards Min                  -0.8931
_task0 Returns Mean               8308.84
_task0 Returns Std               17291.8
_task0 Returns Max               54156.6
_task0 Returns Min                -113.676
_task0 Actions Mean                 -0.189012
_task0 Actions Std                   0.854664
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     524.491
Exploration_task0 Rewards Std     1234.74
Exploration_task0 Rewards Max    21986.7
Exploration_task0 Rewards Min      -11.2159
Exploration_task0 Returns Mean   79468.3
Exploration_task0 Returns Std   142497
Exploration_task0 Returns Max   587520
Exploration_task0 Returns Min    -1618.8
Exploration_task0 Actions Mean      -0.0934164
Exploration_task0 Actions Std        0.879474
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8308.84
AverageReturn_all_train_tasks     5498.9
AverageReturn_all_test_tasks      8308.84
Number of train steps total     110000
Number of env steps total            5.501e+06
Number of rollouts total         39936
Train Time (s)                     101.649
(Previous) Eval Time (s)            25.6868
Sample Time (s)                    107.057
Epoch Time (s)                     234.393
Total Train Time (s)             25423.7
Epoch                              109
------------------------------  ----------------
2019-06-27 07:36:35.887095 UTC | [dialturn] Iteration #109 | Epoch Duration: 234.272864818573
2019-06-27 07:36:35.887287 UTC | [dialturn] Iteration #109 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00109131
Z variance train                     1.00082
KL Divergence                        0.000149703
KL Loss                              1.49703e-05
QF Loss                              6.62725e+07
VF Loss                         634440
RF Loss                           5718.53
Policy Loss                     -54643.4
Q Predictions Mean               54028.1
Q Predictions Std                69093.6
Q Predictions Max               206396
Q Predictions Min                 1442.69
V Predictions Mean               54361.2
V Predictions Std                69582.3
V Predictions Max               211228
V Predictions Min                 1277.56
R Predictions Mean                 516.411
R Predictions Std                 1158.13
R Predictions Max                 9336.17
R Predictions Min                  -71.2437
Log Pis Mean                        20.849
Log Pis Std                         13.5171
Log Pis Max                         51.7875
Log Pis Min                         -4.31451
Policy mu Mean                      -1.62678
Policy mu Std                       14.6864
Policy mu Max                      157.883
Policy mu Min                     -136.328
Policy log std Mean                 -0.428645
Policy log std Std                   0.972607
Policy log std Max                   2
Policy log std Min                  -5.3253
_task0 Rewards Mean                 67.4949
_task0 Rewards Std                 157.206
_task0 Rewards Max                1977.34
_task0 Rewards Min                  -0.885046
_task0 Returns Mean              10124.2
_task0 Returns Std               18044
_task0 Returns Max               57598.5
_task0 Returns Min                -112.805
_task0 Actions Mean                 -0.178665
_task0 Actions Std                   0.836916
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     720.609
Exploration_task0 Rewards Std     1619.97
Exploration_task0 Rewards Max    21864.4
Exploration_task0 Rewards Min      -10.5561
Exploration_task0 Returns Mean  109183
Exploration_task0 Returns Std   179595
Exploration_task0 Returns Max   598742
Exploration_task0 Returns Min    -1361.13
Exploration_task0 Actions Mean      -0.110171
Exploration_task0 Actions Std        0.863354
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10124.2
AverageReturn_all_train_tasks     1996.09
AverageReturn_all_test_tasks     10124.2
Number of train steps total     111000
Number of env steps total            5.551e+06
Number of rollouts total         40299
Train Time (s)                     102.339
(Previous) Eval Time (s)            25.5649
Sample Time (s)                    106.99
Epoch Time (s)                     234.895
Total Train Time (s)             25658.6
Epoch                              110
------------------------------  ----------------
2019-06-27 07:40:30.788952 UTC | [dialturn] Iteration #110 | Epoch Duration: 234.9015085697174
2019-06-27 07:40:30.789161 UTC | [dialturn] Iteration #110 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00162049
Z variance train                     1.00151
KL Divergence                        0.000373626
KL Loss                              3.73626e-05
QF Loss                              1.62007e+08
VF Loss                         660673
RF Loss                           3332.1
Policy Loss                     -52163.6
Q Predictions Mean               51914.6
Q Predictions Std                69455.7
Q Predictions Max               208190
Q Predictions Min                 1345.8
V Predictions Mean               52405.6
V Predictions Std                70071.7
V Predictions Max               214062
V Predictions Min                 1337.05
R Predictions Mean                 435.953
R Predictions Std                 1077.69
R Predictions Max                14498.8
R Predictions Min                  -95.864
Log Pis Mean                        19.9421
Log Pis Std                         13.2741
Log Pis Max                         52.2863
Log Pis Min                         -4.39641
Policy mu Mean                      -1.46564
Policy mu Std                       15.4624
Policy mu Max                      154.711
Policy mu Min                     -128.46
Policy log std Mean                 -0.362037
Policy log std Std                   0.974587
Policy log std Max                   2
Policy log std Min                  -5.07019
_task0 Rewards Mean                 55.7703
_task0 Rewards Std                 169.07
_task0 Rewards Max                1913.76
_task0 Rewards Min                  -1.0218
_task0 Returns Mean               8365.54
_task0 Returns Std               18978.5
_task0 Returns Max               58741.8
_task0 Returns Min                -116.908
_task0 Actions Mean                 -0.217012
_task0 Actions Std                   0.808653
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     497.211
Exploration_task0 Rewards Std     1249.11
Exploration_task0 Rewards Max    22791
Exploration_task0 Rewards Min      -10.3557
Exploration_task0 Returns Mean   75335
Exploration_task0 Returns Std   141437
Exploration_task0 Returns Max   579961
Exploration_task0 Returns Min    -1553.55
Exploration_task0 Actions Mean      -0.0877032
Exploration_task0 Actions Std        0.865878
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8365.54
AverageReturn_all_train_tasks     4073.34
AverageReturn_all_test_tasks      8365.54
Number of train steps total     112000
Number of env steps total            5.601e+06
Number of rollouts total         40662
Train Time (s)                     101.325
(Previous) Eval Time (s)            25.5702
Sample Time (s)                    106.759
Epoch Time (s)                     233.654
Total Train Time (s)             25892.3
Epoch                              111
------------------------------  ----------------
2019-06-27 07:44:24.514791 UTC | [dialturn] Iteration #111 | Epoch Duration: 233.72545862197876
2019-06-27 07:44:24.515023 UTC | [dialturn] Iteration #111 | Started Training: True
------------------------------  ----------------
Z mean train                         0.001594
Z variance train                     0.99915
KL Divergence                        0.000277416
KL Loss                              2.77416e-05
QF Loss                              8.35563e+07
VF Loss                         792328
RF Loss                           5022.4
Policy Loss                     -53829.8
Q Predictions Mean               53321.7
Q Predictions Std                70636.9
Q Predictions Max               211306
Q Predictions Min                 1413.69
V Predictions Mean               53524
V Predictions Std                70820
V Predictions Max               215936
V Predictions Min                 1351.3
R Predictions Mean                 430.884
R Predictions Std                 1136.95
R Predictions Max                12135.4
R Predictions Min                 -115.118
Log Pis Mean                        19.688
Log Pis Std                         12.461
Log Pis Max                         48.6332
Log Pis Min                         -3.21131
Policy mu Mean                      -1.7943
Policy mu Std                       14.5027
Policy mu Max                      130.225
Policy mu Min                     -110.644
Policy log std Mean                 -0.363402
Policy log std Std                   0.971667
Policy log std Max                   2
Policy log std Min                  -4.62949
_task0 Rewards Mean                 41.3317
_task0 Rewards Std                 112.922
_task0 Rewards Max                1057.62
_task0 Rewards Min                  -0.931532
_task0 Returns Mean               6199.75
_task0 Returns Std               12618.1
_task0 Returns Max               36468.5
_task0 Returns Min                -110.752
_task0 Actions Mean                 -0.186226
_task0 Actions Std                   0.843912
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     392.214
Exploration_task0 Rewards Std     1159.01
Exploration_task0 Rewards Max    22539.2
Exploration_task0 Rewards Min      -10.3568
Exploration_task0 Returns Mean   59426.3
Exploration_task0 Returns Std   130900
Exploration_task0 Returns Max   586980
Exploration_task0 Returns Min    -1412.05
Exploration_task0 Actions Mean      -0.207109
Exploration_task0 Actions Std        0.831343
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              6199.75
AverageReturn_all_train_tasks     9568.07
AverageReturn_all_test_tasks      6199.75
Number of train steps total     113000
Number of env steps total            5.651e+06
Number of rollouts total         41025
Train Time (s)                     100.103
(Previous) Eval Time (s)            25.64
Sample Time (s)                    106.553
Epoch Time (s)                     232.296
Total Train Time (s)             26124.5
Epoch                              112
------------------------------  ----------------
2019-06-27 07:48:16.708416 UTC | [dialturn] Iteration #112 | Epoch Duration: 232.19321060180664
2019-06-27 07:48:16.708640 UTC | [dialturn] Iteration #112 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00113931
Z variance train                     1.00188
KL Divergence                        0.000301009
KL Loss                              3.01009e-05
QF Loss                              1.09028e+08
VF Loss                         594918
RF Loss                           7158.8
Policy Loss                     -55395
Q Predictions Mean               54771.5
Q Predictions Std                70830.3
Q Predictions Max               211812
Q Predictions Min                 1327.71
V Predictions Mean               55293.8
V Predictions Std                71329.1
V Predictions Max               217266
V Predictions Min                 1367.47
R Predictions Mean                 617.607
R Predictions Std                 1372.97
R Predictions Max                12405.9
R Predictions Min                  -39.9608
Log Pis Mean                        20.7179
Log Pis Std                         12.3082
Log Pis Max                         55.806
Log Pis Min                        -10.3601
Policy mu Mean                      -1.67888
Policy mu Std                       15.8978
Policy mu Max                      176.639
Policy mu Min                     -124.656
Policy log std Mean                 -0.347451
Policy log std Std                   1.00257
Policy log std Max                   2
Policy log std Min                  -4.8761
_task0 Rewards Mean                 63.608
_task0 Rewards Std                 160
_task0 Rewards Max                1579.24
_task0 Rewards Min                  -0.927537
_task0 Returns Mean               9541.2
_task0 Returns Std               17795
_task0 Returns Max               55467.1
_task0 Returns Min                -109.312
_task0 Actions Mean                 -0.124085
_task0 Actions Std                   0.842216
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     669.079
Exploration_task0 Rewards Std     1504.23
Exploration_task0 Rewards Max    21465.8
Exploration_task0 Rewards Min       -9.39945
Exploration_task0 Returns Mean  101376
Exploration_task0 Returns Std   167554
Exploration_task0 Returns Max   609989
Exploration_task0 Returns Min    -1739.07
Exploration_task0 Actions Mean      -0.164796
Exploration_task0 Actions Std        0.843828
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9541.2
AverageReturn_all_train_tasks    11974.1
AverageReturn_all_test_tasks      9541.2
Number of train steps total     114000
Number of env steps total            5.701e+06
Number of rollouts total         41388
Train Time (s)                     100.303
(Previous) Eval Time (s)            25.5354
Sample Time (s)                    106.042
Epoch Time (s)                     231.88
Total Train Time (s)             26356.4
Epoch                              113
------------------------------  ----------------
2019-06-27 07:52:08.622221 UTC | [dialturn] Iteration #113 | Epoch Duration: 231.9133698940277
2019-06-27 07:52:08.622417 UTC | [dialturn] Iteration #113 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000740774
Z variance train                     0.999735
KL Divergence                        8.21451e-05
KL Loss                              8.21451e-06
QF Loss                              1.03025e+08
VF Loss                         648922
RF Loss                           9849.38
Policy Loss                     -53428.2
Q Predictions Mean               53048.7
Q Predictions Std                69819.7
Q Predictions Max               212538
Q Predictions Min                 1445.89
V Predictions Mean               53722
V Predictions Std                70464.5
V Predictions Max               218657
V Predictions Min                 1447.13
R Predictions Mean                 537.844
R Predictions Std                 1210.17
R Predictions Max                14077.3
R Predictions Min                 -169.301
Log Pis Mean                        21.1955
Log Pis Std                         12.6192
Log Pis Max                         51.5501
Log Pis Min                         -5.64031
Policy mu Mean                      -1.296
Policy mu Std                       15.1002
Policy mu Max                      144.345
Policy mu Min                     -110.598
Policy log std Mean                 -0.432575
Policy log std Std                   1.00021
Policy log std Max                   2
Policy log std Min                  -5.1225
_task0 Rewards Mean                 99.931
_task0 Rewards Std                 230.107
_task0 Rewards Max                2159.05
_task0 Rewards Min                  -1.03557
_task0 Returns Mean              14989.7
_task0 Returns Std               23422.1
_task0 Returns Max               61035.1
_task0 Returns Min                -121.918
_task0 Actions Mean                 -0.0903872
_task0 Actions Std                   0.827498
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     654.817
Exploration_task0 Rewards Std     1732.75
Exploration_task0 Rewards Max    22684.3
Exploration_task0 Rewards Min      -11.2195
Exploration_task0 Returns Mean   99214.6
Exploration_task0 Returns Std   173256
Exploration_task0 Returns Max   574974
Exploration_task0 Returns Min    -1430.77
Exploration_task0 Actions Mean      -0.172475
Exploration_task0 Actions Std        0.840055
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             14989.7
AverageReturn_all_train_tasks     3203.9
AverageReturn_all_test_tasks     14989.7
Number of train steps total     115000
Number of env steps total            5.751e+06
Number of rollouts total         41751
Train Time (s)                     101.923
(Previous) Eval Time (s)            25.5674
Sample Time (s)                    106.013
Epoch Time (s)                     233.503
Total Train Time (s)             26590.1
Epoch                              114
------------------------------  ----------------
2019-06-27 07:56:02.285634 UTC | [dialturn] Iteration #114 | Epoch Duration: 233.66305303573608
2019-06-27 07:56:02.285888 UTC | [dialturn] Iteration #114 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00048413
Z variance train                     0.999762
KL Divergence                        2.73328e-05
KL Loss                              2.73328e-06
QF Loss                              8.35039e+07
VF Loss                         507743
RF Loss                          40285.3
Policy Loss                     -54126.3
Q Predictions Mean               53533.2
Q Predictions Std                70643.9
Q Predictions Max               215583
Q Predictions Min                 1357.47
V Predictions Mean               54264
V Predictions Std                71291.2
V Predictions Max               219954
V Predictions Min                 1492.14
R Predictions Mean                 501.898
R Predictions Std                 1235.07
R Predictions Max                16971
R Predictions Min                  -46.944
Log Pis Mean                        21.4899
Log Pis Std                         12.5349
Log Pis Max                         49.9484
Log Pis Min                         -1.89192
Policy mu Mean                      -1.38256
Policy mu Std                       17.4298
Policy mu Max                      185.511
Policy mu Min                     -124.063
Policy log std Mean                 -0.368288
Policy log std Std                   1.02981
Policy log std Max                   2
Policy log std Min                  -4.88244
_task0 Rewards Mean                 86.179
_task0 Rewards Std                 190.481
_task0 Rewards Max                2270.74
_task0 Rewards Min                  -1.20175
_task0 Returns Mean              12926.9
_task0 Returns Std               19436.5
_task0 Returns Max               61714.6
_task0 Returns Min                -117.66
_task0 Actions Mean                 -0.120989
_task0 Actions Std                   0.80343
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     654.757
Exploration_task0 Rewards Std     1423.22
Exploration_task0 Rewards Max    22591.5
Exploration_task0 Rewards Min      -10.5465
Exploration_task0 Returns Mean   99205.6
Exploration_task0 Returns Std   160857
Exploration_task0 Returns Max   785847
Exploration_task0 Returns Min    -1233.94
Exploration_task0 Actions Mean      -0.0940741
Exploration_task0 Actions Std        0.851804
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             12926.9
AverageReturn_all_train_tasks     9185.11
AverageReturn_all_test_tasks     12926.9
Number of train steps total     116000
Number of env steps total            5.801e+06
Number of rollouts total         42114
Train Time (s)                     101.048
(Previous) Eval Time (s)            25.726
Sample Time (s)                    107.061
Epoch Time (s)                     233.836
Total Train Time (s)             26823.7
Epoch                              115
------------------------------  ----------------
2019-06-27 07:59:55.870420 UTC | [dialturn] Iteration #115 | Epoch Duration: 233.584317445755
2019-06-27 07:59:55.870642 UTC | [dialturn] Iteration #115 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00226271
Z variance train                     1.00165
KL Divergence                        0.000677363
KL Loss                              6.77363e-05
QF Loss                              9.369e+07
VF Loss                              1.45084e+06
RF Loss                          12835.1
Policy Loss                     -54545.7
Q Predictions Mean               53846.8
Q Predictions Std                70629.1
Q Predictions Max               215136
Q Predictions Min                 1494.53
V Predictions Mean               53906.9
V Predictions Std                70649.8
V Predictions Max               219770
V Predictions Min                 1515.41
R Predictions Mean                 489.006
R Predictions Std                 1393.59
R Predictions Max                19646.6
R Predictions Min                 -102.43
Log Pis Mean                        20.9365
Log Pis Std                         12.5027
Log Pis Max                         53.0773
Log Pis Min                         -2.69186
Policy mu Mean                      -0.749972
Policy mu Std                       15.1807
Policy mu Max                      154.911
Policy mu Min                      -98.8638
Policy log std Mean                 -0.405086
Policy log std Std                   1.05053
Policy log std Max                   2
Policy log std Min                  -4.89047
_task0 Rewards Mean                 64.275
_task0 Rewards Std                 145.805
_task0 Rewards Max                1155.8
_task0 Rewards Min                  -0.925793
_task0 Returns Mean               9641.25
_task0 Returns Std               16959.3
_task0 Returns Max               46972.8
_task0 Returns Min                -110.915
_task0 Actions Mean                 -0.124249
_task0 Actions Std                   0.819502
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     631.647
Exploration_task0 Rewards Std     1704.93
Exploration_task0 Rewards Max    23032.2
Exploration_task0 Rewards Min      -12.005
Exploration_task0 Returns Mean   95704.1
Exploration_task0 Returns Std   171736
Exploration_task0 Returns Max   582686
Exploration_task0 Returns Min    -1592.87
Exploration_task0 Actions Mean      -0.114321
Exploration_task0 Actions Std        0.834678
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9641.25
AverageReturn_all_train_tasks    16976.4
AverageReturn_all_test_tasks      9641.25
Number of train steps total     117000
Number of env steps total            5.851e+06
Number of rollouts total         42477
Train Time (s)                     101.355
(Previous) Eval Time (s)            25.4731
Sample Time (s)                    106.751
Epoch Time (s)                     233.579
Total Train Time (s)             27057.5
Epoch                              116
------------------------------  ----------------
2019-06-27 08:03:49.706219 UTC | [dialturn] Iteration #116 | Epoch Duration: 233.8354091644287
2019-06-27 08:03:49.706464 UTC | [dialturn] Iteration #116 | Started Training: True
------------------------------  ----------------
Z mean train                         0.0014726
Z variance train                     0.999258
KL Divergence                        0.000376932
KL Loss                              3.76932e-05
QF Loss                              1.18345e+08
VF Loss                         546233
RF Loss                          34480
Policy Loss                     -56079.6
Q Predictions Mean               55429.2
Q Predictions Std                72042.5
Q Predictions Max               216488
Q Predictions Min                 1571.63
V Predictions Mean               56283.1
V Predictions Std                72876.9
V Predictions Max               221807
V Predictions Min                 1709.82
R Predictions Mean                 801.799
R Predictions Std                 1975.63
R Predictions Max                18892.4
R Predictions Min                  -50.2571
Log Pis Mean                        21.793
Log Pis Std                         12.742
Log Pis Max                         53.216
Log Pis Min                         -5.48792
Policy mu Mean                      -0.764916
Policy mu Std                       15.7153
Policy mu Max                      144.711
Policy mu Min                      -98.4956
Policy log std Mean                 -0.387598
Policy log std Std                   1.02055
Policy log std Max                   2
Policy log std Min                  -4.87562
_task0 Rewards Mean                111.634
_task0 Rewards Std                 241.443
_task0 Rewards Max                2111.3
_task0 Rewards Min                  -0.931837
_task0 Returns Mean              16745
_task0 Returns Std               23489.3
_task0 Returns Max               57867.6
_task0 Returns Min                -107.419
_task0 Actions Mean                 -0.0463366
_task0 Actions Std                   0.798964
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     550.158
Exploration_task0 Rewards Std     1366.5
Exploration_task0 Rewards Max    22294.7
Exploration_task0 Rewards Min      -10.0252
Exploration_task0 Returns Mean   83357.3
Exploration_task0 Returns Std   146047
Exploration_task0 Returns Max   559163
Exploration_task0 Returns Min    -1656.16
Exploration_task0 Actions Mean      -0.0791388
Exploration_task0 Actions Std        0.873117
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             16745
AverageReturn_all_train_tasks     7945.16
AverageReturn_all_test_tasks     16745
Number of train steps total     118000
Number of env steps total            5.901e+06
Number of rollouts total         42840
Train Time (s)                     100.717
(Previous) Eval Time (s)            25.7282
Sample Time (s)                    107.658
Epoch Time (s)                     234.103
Total Train Time (s)             27291.6
Epoch                              117
------------------------------  ----------------
2019-06-27 08:07:43.796275 UTC | [dialturn] Iteration #117 | Epoch Duration: 234.08955764770508
2019-06-27 08:07:43.796504 UTC | [dialturn] Iteration #117 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000689811
Z variance train                     0.997638
KL Divergence                        0.000218582
KL Loss                              2.18582e-05
QF Loss                              1.18296e+08
VF Loss                         585227
RF Loss                          11087.7
Policy Loss                     -57828.1
Q Predictions Mean               57051
Q Predictions Std                73649.9
Q Predictions Max               218148
Q Predictions Min                 1788.74
V Predictions Mean               57628.6
V Predictions Std                74439.5
V Predictions Max               223580
V Predictions Min                 1598.32
R Predictions Mean                 686.814
R Predictions Std                 1553.87
R Predictions Max                17065.5
R Predictions Min                  -13.8768
Log Pis Mean                        20.9973
Log Pis Std                         12.3486
Log Pis Max                         50.4476
Log Pis Min                         -2.3968
Policy mu Mean                      -0.205556
Policy mu Std                       14.3152
Policy mu Max                      152.578
Policy mu Min                     -102.016
Policy log std Mean                 -0.494988
Policy log std Std                   1.08439
Policy log std Max                   2
Policy log std Min                  -5.35473
_task0 Rewards Mean                 53.3425
_task0 Rewards Std                 161.648
_task0 Rewards Max                1481.52
_task0 Rewards Min                  -0.785433
_task0 Returns Mean               8001.38
_task0 Returns Std               16934.2
_task0 Returns Max               55216.9
_task0 Returns Min                 -93.257
_task0 Actions Mean                  0.00332974
_task0 Actions Std                   0.82981
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     630.469
Exploration_task0 Rewards Std     1735.05
Exploration_task0 Rewards Max    22257.1
Exploration_task0 Rewards Min      -10.1621
Exploration_task0 Returns Mean   95525.7
Exploration_task0 Returns Std   174004
Exploration_task0 Returns Max   588729
Exploration_task0 Returns Min    -1162.92
Exploration_task0 Actions Mean      -0.0290171
Exploration_task0 Actions Std        0.852873
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8001.38
AverageReturn_all_train_tasks     8223.34
AverageReturn_all_test_tasks      8001.38
Number of train steps total     119000
Number of env steps total            5.951e+06
Number of rollouts total         43203
Train Time (s)                     100.905
(Previous) Eval Time (s)            25.7133
Sample Time (s)                    106.843
Epoch Time (s)                     233.461
Total Train Time (s)             27524.6
Epoch                              118
------------------------------  ----------------
2019-06-27 08:11:36.783976 UTC | [dialturn] Iteration #118 | Epoch Duration: 232.98725485801697
2019-06-27 08:11:36.784190 UTC | [dialturn] Iteration #118 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00108571
Z variance train                     1.00178
KL Divergence                        0.000169355
KL Loss                              1.69355e-05
QF Loss                              7.06353e+07
VF Loss                              2.0171e+06
RF Loss                          14933
Policy Loss                     -57398.7
Q Predictions Mean               56732.1
Q Predictions Std                73386.6
Q Predictions Max               220954
Q Predictions Min                 1891.72
V Predictions Mean               58203.6
V Predictions Std                74991.7
V Predictions Max               223711
V Predictions Min                 1917.5
R Predictions Mean                 757.023
R Predictions Std                 1752.99
R Predictions Max                18721.5
R Predictions Min                  -10.825
Log Pis Mean                        21.4366
Log Pis Std                         12.969
Log Pis Max                         54.9496
Log Pis Min                         -5.07822
Policy mu Mean                       0.206462
Policy mu Std                       14.4024
Policy mu Max                      151.623
Policy mu Min                      -91.9586
Policy log std Mean                 -0.414795
Policy log std Std                   1.04505
Policy log std Max                   2
Policy log std Min                  -4.17206
_task0 Rewards Mean                 74.6514
_task0 Rewards Std                 178.818
_task0 Rewards Max                2200.83
_task0 Rewards Min                  -0.851318
_task0 Returns Mean              11197.7
_task0 Returns Std               17572.5
_task0 Returns Max               48824.2
_task0 Returns Min                -110.399
_task0 Actions Mean                 -0.0517443
_task0 Actions Std                   0.822906
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     730.548
Exploration_task0 Rewards Std     1764.33
Exploration_task0 Rewards Max    22912.5
Exploration_task0 Rewards Min      -11.0557
Exploration_task0 Returns Mean  110689
Exploration_task0 Returns Std   183506
Exploration_task0 Returns Max   891951
Exploration_task0 Returns Min    -1135.01
Exploration_task0 Actions Mean      -0.0757276
Exploration_task0 Actions Std        0.833462
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             11197.7
AverageReturn_all_train_tasks     8822.47
AverageReturn_all_test_tasks     11197.7
Number of train steps total     120000
Number of env steps total            6.001e+06
Number of rollouts total         43566
Train Time (s)                      99.5959
(Previous) Eval Time (s)            25.2382
Sample Time (s)                    105.08
Epoch Time (s)                     229.914
Total Train Time (s)             27754.8
Epoch                              119
------------------------------  ----------------
2019-06-27 08:15:26.999567 UTC | [dialturn] Iteration #119 | Epoch Duration: 230.21521711349487
2019-06-27 08:15:26.999800 UTC | [dialturn] Iteration #119 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000832656
Z variance train                     0.999845
KL Divergence                        9.38375e-05
KL Loss                              9.38375e-06
QF Loss                              1.56311e+08
VF Loss                              1.21379e+06
RF Loss                           6829.89
Policy Loss                     -56825.3
Q Predictions Mean               56204.9
Q Predictions Std                73638.4
Q Predictions Max               224050
Q Predictions Min                 2003.4
V Predictions Mean               56353.3
V Predictions Std                73648.5
V Predictions Max               227294
V Predictions Min                 1974.26
R Predictions Mean                 568.204
R Predictions Std                 1229.35
R Predictions Max                 9840.21
R Predictions Min                  -61.8407
Log Pis Mean                        20.6495
Log Pis Std                         12.2124
Log Pis Max                         54.6766
Log Pis Min                         -3.4852
Policy mu Mean                       0.490576
Policy mu Std                       13.7907
Policy mu Max                      164
Policy mu Min                     -109.745
Policy log std Mean                 -0.511414
Policy log std Std                   1.0477
Policy log std Max                   2
Policy log std Min                  -5.42643
_task0 Rewards Mean                100.857
_task0 Rewards Std                 208.699
_task0 Rewards Max                2091.39
_task0 Rewards Min                  -0.864345
_task0 Returns Mean              15128.6
_task0 Returns Std               21441.8
_task0 Returns Max               52586.6
_task0 Returns Min                -102.674
_task0 Actions Mean                 -0.0387525
_task0 Actions Std                   0.792047
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     620.372
Exploration_task0 Rewards Std     1425.22
Exploration_task0 Rewards Max    21243.7
Exploration_task0 Rewards Min       -9.86636
Exploration_task0 Returns Mean   93995.8
Exploration_task0 Returns Std   159036
Exploration_task0 Returns Max   711871
Exploration_task0 Returns Min    -1380.46
Exploration_task0 Actions Mean      -0.0434196
Exploration_task0 Actions Std        0.829213
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             15128.6
AverageReturn_all_train_tasks     4434.39
AverageReturn_all_test_tasks     15128.6
Number of train steps total     121000
Number of env steps total            6.051e+06
Number of rollouts total         43929
Train Time (s)                     100.509
(Previous) Eval Time (s)            25.5375
Sample Time (s)                    107.151
Epoch Time (s)                     233.198
Total Train Time (s)             27988.1
Epoch                              120
------------------------------  ----------------
2019-06-27 08:19:20.336888 UTC | [dialturn] Iteration #120 | Epoch Duration: 233.3369071483612
2019-06-27 08:19:20.337112 UTC | [dialturn] Iteration #120 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00204281
Z variance train                     1.00169
KL Divergence                        0.000499504
KL Loss                              4.99504e-05
QF Loss                              9.37719e+07
VF Loss                         533136
RF Loss                          43887.7
Policy Loss                     -57024.4
Q Predictions Mean               56503
Q Predictions Std                73279.1
Q Predictions Max               224501
Q Predictions Min                 2039.34
V Predictions Mean               57138.9
V Predictions Std                73955
V Predictions Max               228448
V Predictions Min                 2002.34
R Predictions Mean                 829.463
R Predictions Std                 1848.98
R Predictions Max                15036.4
R Predictions Min                   -9.92274
Log Pis Mean                        21.2924
Log Pis Std                         12.1659
Log Pis Max                         52.0268
Log Pis Min                         -4.33557
Policy mu Mean                      -0.386352
Policy mu Std                       15.3716
Policy mu Max                      156.582
Policy mu Min                     -121.323
Policy log std Mean                 -0.467738
Policy log std Std                   1.13748
Policy log std Max                   2
Policy log std Min                  -5.72692
_task0 Rewards Mean                 62.1606
_task0 Rewards Std                 153.399
_task0 Rewards Max                1583.61
_task0 Rewards Min                  -1.01621
_task0 Returns Mean               9324.09
_task0 Returns Std               14927.2
_task0 Returns Max               46043.8
_task0 Returns Min                 -87.2172
_task0 Actions Mean                  0.0103853
_task0 Actions Std                   0.850577
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     855.001
Exploration_task0 Rewards Std     2031.56
Exploration_task0 Rewards Max    22824.4
Exploration_task0 Rewards Min       -9.21938
Exploration_task0 Returns Mean  129546
Exploration_task0 Returns Std   208556
Exploration_task0 Returns Max   982646
Exploration_task0 Returns Min    -1251.78
Exploration_task0 Actions Mean      -0.0692366
Exploration_task0 Actions Std        0.820963
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              9324.09
AverageReturn_all_train_tasks     9622.63
AverageReturn_all_test_tasks      9324.09
Number of train steps total     122000
Number of env steps total            6.101e+06
Number of rollouts total         44292
Train Time (s)                     101.57
(Previous) Eval Time (s)            25.6751
Sample Time (s)                    107.324
Epoch Time (s)                     234.569
Total Train Time (s)             28222.9
Epoch                              121
------------------------------  ----------------
2019-06-27 08:23:15.122592 UTC | [dialturn] Iteration #121 | Epoch Duration: 234.7853090763092
2019-06-27 08:23:15.122804 UTC | [dialturn] Iteration #121 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000733807
Z variance train                     0.999231
KL Divergence                        5.19193e-05
KL Loss                              5.19193e-06
QF Loss                              1.18455e+08
VF Loss                         573414
RF Loss                          16667.3
Policy Loss                     -56397.3
Q Predictions Mean               55998.6
Q Predictions Std                73739.2
Q Predictions Max               226724
Q Predictions Min                 2083.47
V Predictions Mean               56278.1
V Predictions Std                74043.1
V Predictions Max               229474
V Predictions Min                 2227.29
R Predictions Mean                 866.385
R Predictions Std                 1820.75
R Predictions Max                18589.1
R Predictions Min                  -10.8297
Log Pis Mean                        20.7563
Log Pis Std                         11.9907
Log Pis Max                         55.9184
Log Pis Min                         -4.31381
Policy mu Mean                      -0.368905
Policy mu Std                       15.2415
Policy mu Max                      149.28
Policy mu Min                     -108.564
Policy log std Mean                 -0.444869
Policy log std Std                   1.122
Policy log std Max                   2
Policy log std Min                  -6.62057
_task0 Rewards Mean                 93.1581
_task0 Rewards Std                 224.29
_task0 Rewards Max                2194.71
_task0 Rewards Min                  -0.797924
_task0 Returns Mean              13973.7
_task0 Returns Std               21837.4
_task0 Returns Max               61193.6
_task0 Returns Min                 -93.0602
_task0 Actions Mean                 -0.0451839
_task0 Actions Std                   0.82059
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     755.458
Exploration_task0 Rewards Std     1803.74
Exploration_task0 Rewards Max    22858.1
Exploration_task0 Rewards Min       -9.35272
Exploration_task0 Returns Mean  114463
Exploration_task0 Returns Std   183184
Exploration_task0 Returns Max   633477
Exploration_task0 Returns Min    -1524.27
Exploration_task0 Actions Mean       0.0140886
Exploration_task0 Actions Std        0.842911
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             13973.7
AverageReturn_all_train_tasks     2919.49
AverageReturn_all_test_tasks     13973.7
Number of train steps total     123000
Number of env steps total            6.151e+06
Number of rollouts total         44655
Train Time (s)                     100.936
(Previous) Eval Time (s)            25.8898
Sample Time (s)                    107.302
Epoch Time (s)                     234.127
Total Train Time (s)             28456.9
Epoch                              122
------------------------------  ----------------
2019-06-27 08:27:09.068323 UTC | [dialturn] Iteration #122 | Epoch Duration: 233.94534540176392
2019-06-27 08:27:09.068538 UTC | [dialturn] Iteration #122 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00159383
Z variance train                     0.998484
KL Divergence                        0.000326338
KL Loss                              3.26338e-05
QF Loss                              6.29314e+07
VF Loss                              2.29207e+06
RF Loss                          49210.6
Policy Loss                     -60182.1
Q Predictions Mean               59187.3
Q Predictions Std                76674.3
Q Predictions Max               230207
Q Predictions Min                 2109.32
V Predictions Mean               59250.3
V Predictions Std                76758.2
V Predictions Max               229822
V Predictions Min                 2110.87
R Predictions Mean                 836.235
R Predictions Std                 2073.07
R Predictions Max                19748.8
R Predictions Min                  -95.0209
Log Pis Mean                        20.8421
Log Pis Std                         12.0643
Log Pis Max                         51.8809
Log Pis Min                         -3.24923
Policy mu Mean                      -0.409204
Policy mu Std                       15.2872
Policy mu Max                      141.834
Policy mu Min                     -108.839
Policy log std Mean                 -0.499957
Policy log std Std                   1.14362
Policy log std Max                   2
Policy log std Min                  -4.72731
_task0 Rewards Mean                 98.7085
_task0 Rewards Std                 219.648
_task0 Rewards Max                2227.89
_task0 Rewards Min                  -0.866402
_task0 Returns Mean              14806.3
_task0 Returns Std               21286.1
_task0 Returns Max               51446.8
_task0 Returns Min                 -96.4544
_task0 Actions Mean                  0.0227053
_task0 Actions Std                   0.827308
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     862.099
Exploration_task0 Rewards Std     1852.37
Exploration_task0 Rewards Max    20277.4
Exploration_task0 Rewards Min       -9.46802
Exploration_task0 Returns Mean  130621
Exploration_task0 Returns Std   199611
Exploration_task0 Returns Max   632720
Exploration_task0 Returns Min    -1227.14
Exploration_task0 Actions Mean      -0.0166056
Exploration_task0 Actions Std        0.836346
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             14806.3
AverageReturn_all_train_tasks    10087.3
AverageReturn_all_test_tasks     14806.3
Number of train steps total     124000
Number of env steps total            6.201e+06
Number of rollouts total         45018
Train Time (s)                     101.208
(Previous) Eval Time (s)            25.7066
Sample Time (s)                    107.387
Epoch Time (s)                     234.301
Total Train Time (s)             28691.3
Epoch                              123
------------------------------  ----------------
2019-06-27 08:31:03.488942 UTC | [dialturn] Iteration #123 | Epoch Duration: 234.42018032073975
2019-06-27 08:31:03.489141 UTC | [dialturn] Iteration #123 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000608663
Z variance train                     1.00036
KL Divergence                        3.63385e-05
KL Loss                              3.63385e-06
QF Loss                              6.41282e+07
VF Loss                         956175
RF Loss                          18189.7
Policy Loss                     -62350.4
Q Predictions Mean               61517.6
Q Predictions Std                77656.8
Q Predictions Max               233843
Q Predictions Min                 2054.76
V Predictions Mean               61873.5
V Predictions Std                78025.9
V Predictions Max               232814
V Predictions Min                 2176.21
R Predictions Mean                 659.218
R Predictions Std                 1765
R Predictions Max                18267.4
R Predictions Min                 -219.276
Log Pis Mean                        21.5712
Log Pis Std                         12.0488
Log Pis Max                         51.1356
Log Pis Min                         -2.66859
Policy mu Mean                      -0.322255
Policy mu Std                       14.4892
Policy mu Max                      131.386
Policy mu Min                     -119.189
Policy log std Mean                 -0.438898
Policy log std Std                   1.1271
Policy log std Max                   2
Policy log std Min                  -7.34578
_task0 Rewards Mean                 93.1692
_task0 Rewards Std                 216.235
_task0 Rewards Max                2304.55
_task0 Rewards Min                  -0.89933
_task0 Returns Mean              13975.4
_task0 Returns Std               19967.9
_task0 Returns Max               51053.7
_task0 Returns Min                -102.473
_task0 Actions Mean                  0.0369733
_task0 Actions Std                   0.85693
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     776.971
Exploration_task0 Rewards Std     1721.12
Exploration_task0 Rewards Max    21694.9
Exploration_task0 Rewards Min      -11.0535
Exploration_task0 Returns Mean  117723
Exploration_task0 Returns Std   187194
Exploration_task0 Returns Max   773687
Exploration_task0 Returns Min    -1237.79
Exploration_task0 Actions Mean      -0.0105378
Exploration_task0 Actions Std        0.84642
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             13975.4
AverageReturn_all_train_tasks    11640
AverageReturn_all_test_tasks     13975.4
Number of train steps total     125000
Number of env steps total            6.251e+06
Number of rollouts total         45381
Train Time (s)                     100.641
(Previous) Eval Time (s)            25.8238
Sample Time (s)                    107.181
Epoch Time (s)                     233.646
Total Train Time (s)             28924.6
Epoch                              124
------------------------------  ----------------
2019-06-27 08:34:56.858309 UTC | [dialturn] Iteration #124 | Epoch Duration: 233.3689534664154
2019-06-27 08:34:56.858501 UTC | [dialturn] Iteration #124 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000484047
Z variance train                     0.999713
KL Divergence                        3.74321e-05
KL Loss                              3.74321e-06
QF Loss                              1.53423e+08
VF Loss                              2.26938e+06
RF Loss                          18519.4
Policy Loss                     -61400.6
Q Predictions Mean               60876.8
Q Predictions Std                78908.3
Q Predictions Max               237952
Q Predictions Min                 2255.12
V Predictions Mean               60482.7
V Predictions Std                78523
V Predictions Max               233185
V Predictions Min                 2280.24
R Predictions Mean                 827.557
R Predictions Std                 2037.76
R Predictions Max                18371.8
R Predictions Min                 -116.386
Log Pis Mean                        21.172
Log Pis Std                         11.8343
Log Pis Max                         53.8879
Log Pis Min                         -2.89632
Policy mu Mean                      -0.244876
Policy mu Std                       14.106
Policy mu Max                      114.709
Policy mu Min                      -95.8088
Policy log std Mean                 -0.494339
Policy log std Std                   1.10796
Policy log std Max                   2
Policy log std Min                  -7.90913
_task0 Rewards Mean                 58.6592
_task0 Rewards Std                 154.133
_task0 Rewards Max                2006.17
_task0 Rewards Min                  -0.784394
_task0 Returns Mean               8798.88
_task0 Returns Std               15277.1
_task0 Returns Max               45321.9
_task0 Returns Min                 -89.1417
_task0 Actions Mean                 -0.0484919
_task0 Actions Std                   0.839764
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     669.03
Exploration_task0 Rewards Std     1707.53
Exploration_task0 Rewards Max    22264.2
Exploration_task0 Rewards Min      -10.346
Exploration_task0 Returns Mean  101368
Exploration_task0 Returns Std   177473
Exploration_task0 Returns Max   822913
Exploration_task0 Returns Min    -1220.78
Exploration_task0 Actions Mean      -0.0177799
Exploration_task0 Actions Std        0.856526
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0              8798.88
AverageReturn_all_train_tasks     7406.51
AverageReturn_all_test_tasks      8798.88
Number of train steps total     126000
Number of env steps total            6.301e+06
Number of rollouts total         45744
Train Time (s)                     101.739
(Previous) Eval Time (s)            25.5449
Sample Time (s)                    107.183
Epoch Time (s)                     234.467
Total Train Time (s)             29159.3
Epoch                              125
------------------------------  ----------------
2019-06-27 08:38:51.534419 UTC | [dialturn] Iteration #125 | Epoch Duration: 234.67573428153992
2019-06-27 08:38:51.534621 UTC | [dialturn] Iteration #125 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00172205
Z variance train                     1.00372
KL Divergence                        0.000551955
KL Loss                              5.51955e-05
QF Loss                              8.19481e+07
VF Loss                         616803
RF Loss                          13482.3
Policy Loss                     -61312.3
Q Predictions Mean               60812.6
Q Predictions Std                79240.2
Q Predictions Max               239296
Q Predictions Min                 2237.23
V Predictions Mean               61107.8
V Predictions Std                79582.3
V Predictions Max               237749
V Predictions Min                 2340
R Predictions Mean                 648.358
R Predictions Std                 1694.41
R Predictions Max                17951.5
R Predictions Min                 -149.851
Log Pis Mean                        21.6715
Log Pis Std                         11.3602
Log Pis Max                         53.132
Log Pis Min                         -1.86479
Policy mu Mean                      -0.150766
Policy mu Std                       13.109
Policy mu Max                      104.071
Policy mu Min                      -98.6704
Policy log std Mean                 -0.500988
Policy log std Std                   1.07056
Policy log std Max                   2
Policy log std Min                  -7.89198
_task0 Rewards Mean                 86.0067
_task0 Rewards Std                 193.566
_task0 Rewards Max                1628.59
_task0 Rewards Min                  -1.07842
_task0 Returns Mean              12901
_task0 Returns Std               21060.5
_task0 Returns Max               54498.8
_task0 Returns Min                -103.257
_task0 Actions Mean                 -0.00190273
_task0 Actions Std                   0.839042
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     878.252
Exploration_task0 Rewards Std     2043.87
Exploration_task0 Rewards Max    22388
Exploration_task0 Rewards Min      -10.3554
Exploration_task0 Returns Mean  133068
Exploration_task0 Returns Std   211436
Exploration_task0 Returns Max   866888
Exploration_task0 Returns Min    -1241.41
Exploration_task0 Actions Mean       0.012094
Exploration_task0 Actions Std        0.853918
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             12901
AverageReturn_all_train_tasks    11357.1
AverageReturn_all_test_tasks     12901
Number of train steps total     127000
Number of env steps total            6.351e+06
Number of rollouts total         46107
Train Time (s)                     102.383
(Previous) Eval Time (s)            25.7526
Sample Time (s)                    107.431
Epoch Time (s)                     235.566
Total Train Time (s)             29394.8
Epoch                              126
------------------------------  ----------------
2019-06-27 08:42:46.995348 UTC | [dialturn] Iteration #126 | Epoch Duration: 235.46057081222534
2019-06-27 08:42:46.995557 UTC | [dialturn] Iteration #126 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000953775
Z variance train                     0.997673
KL Divergence                        0.000231809
KL Loss                              2.31809e-05
QF Loss                              9.44418e+07
VF Loss                         751842
RF Loss                          63738.8
Policy Loss                     -62830.9
Q Predictions Mean               62181.9
Q Predictions Std                79507.5
Q Predictions Max               243114
Q Predictions Min                 2152.69
V Predictions Mean               63013.4
V Predictions Std                80297.8
V Predictions Max               241553
V Predictions Min                 2442.01
R Predictions Mean                 777.308
R Predictions Std                 1990.06
R Predictions Max                16694.6
R Predictions Min                 -107.458
Log Pis Mean                        20.8677
Log Pis Std                         11.1772
Log Pis Max                         54.5066
Log Pis Min                         -1.15748
Policy mu Mean                      -0.123563
Policy mu Std                       12.8463
Policy mu Max                      105.812
Policy mu Min                     -102.505
Policy log std Mean                 -0.568037
Policy log std Std                   1.07839
Policy log std Max                   2
Policy log std Min                  -8.21489
_task0 Rewards Mean                 77.0184
_task0 Rewards Std                 183.939
_task0 Rewards Max                1745.65
_task0 Rewards Min                  -0.782821
_task0 Returns Mean              11552.8
_task0 Returns Std               17872.9
_task0 Returns Max               48951.9
_task0 Returns Min                 -78.2261
_task0 Actions Mean                 -0.0987085
_task0 Actions Std                   0.816204
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     758.104
Exploration_task0 Rewards Std     2015.32
Exploration_task0 Rewards Max    22743.9
Exploration_task0 Rewards Min      -11.667
Exploration_task0 Returns Mean  114864
Exploration_task0 Returns Std   194262
Exploration_task0 Returns Max   789098
Exploration_task0 Returns Min    -1638.91
Exploration_task0 Actions Mean       0.0389794
Exploration_task0 Actions Std        0.862488
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             11552.8
AverageReturn_all_train_tasks    25869.4
AverageReturn_all_test_tasks     11552.8
Number of train steps total     128000
Number of env steps total            6.401e+06
Number of rollouts total         46470
Train Time (s)                     102.383
(Previous) Eval Time (s)            25.6457
Sample Time (s)                    107.825
Epoch Time (s)                     235.854
Total Train Time (s)             29630.7
Epoch                              127
------------------------------  ----------------
2019-06-27 08:46:42.957519 UTC | [dialturn] Iteration #127 | Epoch Duration: 235.96180200576782
2019-06-27 08:46:42.957718 UTC | [dialturn] Iteration #127 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000316604
Z variance train                     0.999959
KL Divergence                        1.12821e-05
KL Loss                              1.12821e-06
QF Loss                              2.12995e+08
VF Loss                         955344
RF Loss                          25710.5
Policy Loss                     -62889.2
Q Predictions Mean               62471.2
Q Predictions Std                81602.1
Q Predictions Max               246801
Q Predictions Min                 2123.73
V Predictions Mean               63330.9
V Predictions Std                82441.5
V Predictions Max               245021
V Predictions Min                 2493.87
R Predictions Mean                 820.456
R Predictions Std                 1609.2
R Predictions Max                13411.8
R Predictions Min                  -37.1803
Log Pis Mean                        20.9789
Log Pis Std                         12.1075
Log Pis Max                         54.8916
Log Pis Min                         -3.62947
Policy mu Mean                       0.269574
Policy mu Std                       12.6563
Policy mu Max                      135.004
Policy mu Min                     -113.724
Policy log std Mean                 -0.641368
Policy log std Std                   0.993718
Policy log std Max                   2
Policy log std Min                  -6.59183
_task0 Rewards Mean                 93.8717
_task0 Rewards Std                 216.428
_task0 Rewards Max                2108.2
_task0 Rewards Min                  -0.833949
_task0 Returns Mean              14080.8
_task0 Returns Std               24338.1
_task0 Returns Max               64362.1
_task0 Returns Min                -102.824
_task0 Actions Mean                  0.0119514
_task0 Actions Std                   0.809491
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     879.393
Exploration_task0 Rewards Std     2029.22
Exploration_task0 Rewards Max    22657.6
Exploration_task0 Rewards Min      -10.3559
Exploration_task0 Returns Mean  133241
Exploration_task0 Returns Std   235368
Exploration_task0 Returns Max        1.30691e+06
Exploration_task0 Returns Min    -1216.8
Exploration_task0 Actions Mean       0.0253003
Exploration_task0 Actions Std        0.848107
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             14080.8
AverageReturn_all_train_tasks     6583.63
AverageReturn_all_test_tasks     14080.8
Number of train steps total     129000
Number of env steps total            6.451e+06
Number of rollouts total         46833
Train Time (s)                     101.037
(Previous) Eval Time (s)            25.7523
Sample Time (s)                    106.872
Epoch Time (s)                     233.661
Total Train Time (s)             29864.5
Epoch                              128
------------------------------  ----------------
2019-06-27 08:50:36.698499 UTC | [dialturn] Iteration #128 | Epoch Duration: 233.74061679840088
2019-06-27 08:50:36.698724 UTC | [dialturn] Iteration #128 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000983559
Z variance train                     1.00064
KL Divergence                        9.96001e-05
KL Loss                              9.96001e-06
QF Loss                              1.25303e+08
VF Loss                         704676
RF Loss                         232460
Policy Loss                     -65706.5
Q Predictions Mean               65122.9
Q Predictions Std                82450.4
Q Predictions Max               251839
Q Predictions Min                 2294.53
V Predictions Mean               65858.5
V Predictions Std                83304.6
V Predictions Max               249343
V Predictions Min                 2468.97
R Predictions Mean                 928.973
R Predictions Std                 2133.46
R Predictions Max                15598
R Predictions Min                  -50.3636
Log Pis Mean                        20.6173
Log Pis Std                         11.4562
Log Pis Max                         53.4808
Log Pis Min                         -2.21564
Policy mu Mean                       0.0561561
Policy mu Std                       12.8739
Policy mu Max                      101.256
Policy mu Min                      -84.6728
Policy log std Mean                 -0.598414
Policy log std Std                   1.0549
Policy log std Max                   2
Policy log std Min                  -6.63129
_task0 Rewards Mean                150.745
_task0 Rewards Std                 331.575
_task0 Rewards Max                1522.65
_task0 Rewards Min                  -0.688679
_task0 Returns Mean              22611.7
_task0 Returns Std               46172.7
_task0 Returns Max              152237
_task0 Returns Min                 -72.0745
_task0 Actions Mean                 -0.119772
_task0 Actions Std                   0.807796
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     865.181
Exploration_task0 Rewards Std     2232.64
Exploration_task0 Rewards Max    22504.6
Exploration_task0 Rewards Min       -9.38002
Exploration_task0 Returns Mean  131088
Exploration_task0 Returns Std   258626
Exploration_task0 Returns Max        1.59489e+06
Exploration_task0 Returns Min    -1228.71
Exploration_task0 Actions Mean      -0.0389102
Exploration_task0 Actions Std        0.820684
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             22611.7
AverageReturn_all_train_tasks    23091.4
AverageReturn_all_test_tasks     22611.7
Number of train steps total     130000
Number of env steps total            6.501e+06
Number of rollouts total         47196
Train Time (s)                     100.302
(Previous) Eval Time (s)            25.8302
Sample Time (s)                    107.716
Epoch Time (s)                     233.848
Total Train Time (s)             30098.2
Epoch                              129
------------------------------  ----------------
2019-06-27 08:54:30.470510 UTC | [dialturn] Iteration #129 | Epoch Duration: 233.77162289619446
2019-06-27 08:54:30.470726 UTC | [dialturn] Iteration #129 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00117098
Z variance train                     0.999449
KL Divergence                        0.000113591
KL Loss                              1.13591e-05
QF Loss                              9.49771e+07
VF Loss                              1.22109e+06
RF Loss                         114714
Policy Loss                     -62197.4
Q Predictions Mean               61310.7
Q Predictions Std                81615.9
Q Predictions Max               254224
Q Predictions Min                 2242.83
V Predictions Mean               61719.4
V Predictions Std                81995.5
V Predictions Max               251152
V Predictions Min                 2531.11
R Predictions Mean                1217.4
R Predictions Std                 2661.95
R Predictions Max                16664.4
R Predictions Min                 -210.102
Log Pis Mean                        19.4182
Log Pis Std                         11.2318
Log Pis Max                         53.7271
Log Pis Min                         -2.27822
Policy mu Mean                      -0.0207677
Policy mu Std                       13.2392
Policy mu Max                      162.377
Policy mu Min                     -117.257
Policy log std Mean                 -0.655725
Policy log std Std                   1.04503
Policy log std Max                   2
Policy log std Min                  -6.0506
_task0 Rewards Mean                227.189
_task0 Rewards Std                 387.931
_task0 Rewards Max                1840.54
_task0 Rewards Min                  -0.614982
_task0 Returns Mean              34078.4
_task0 Returns Std               53090
_task0 Returns Max              140573
_task0 Returns Min                 -77.1775
_task0 Actions Mean                 -0.048812
_task0 Actions Std                   0.770694
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1402.49
Exploration_task0 Rewards Std     3207.31
Exploration_task0 Rewards Max    23088.3
Exploration_task0 Rewards Min       -9.38274
Exploration_task0 Returns Mean  212498
Exploration_task0 Returns Std   434096
Exploration_task0 Returns Max        2.1982e+06
Exploration_task0 Returns Min    -1466.09
Exploration_task0 Actions Mean      -0.0763712
Exploration_task0 Actions Std        0.847512
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             34078.4
AverageReturn_all_train_tasks    21290.6
AverageReturn_all_test_tasks     34078.4
Number of train steps total     131000
Number of env steps total            6.551e+06
Number of rollouts total         47559
Train Time (s)                     101.998
(Previous) Eval Time (s)            25.7524
Sample Time (s)                    107.133
Epoch Time (s)                     234.884
Total Train Time (s)             30333.1
Epoch                              130
------------------------------  ----------------
2019-06-27 08:58:25.358848 UTC | [dialturn] Iteration #130 | Epoch Duration: 234.88796615600586
2019-06-27 08:58:25.359041 UTC | [dialturn] Iteration #130 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00102871
Z variance train                     1.0002
KL Divergence                        0.000205761
KL Loss                              2.05761e-05
QF Loss                              1.98382e+08
VF Loss                         524639
RF Loss                         201436
Policy Loss                     -67630.8
Q Predictions Mean               66936.1
Q Predictions Std                86545.6
Q Predictions Max               260521
Q Predictions Min                 2363.97
V Predictions Mean               67511.4
V Predictions Std                87238.5
V Predictions Max               256235
V Predictions Min                 2487.28
R Predictions Mean                1682.31
R Predictions Std                 3702.22
R Predictions Max                18206.3
R Predictions Min                  -44.121
Log Pis Mean                        20.7815
Log Pis Std                         11.5477
Log Pis Max                         50.0816
Log Pis Min                         -4.66575
Policy mu Mean                      -0.047918
Policy mu Std                       12.1923
Policy mu Max                      160.039
Policy mu Min                     -112.096
Policy log std Mean                 -0.62988
Policy log std Std                   1.08186
Policy log std Max                   2
Policy log std Min                  -6.06941
_task0 Rewards Mean                 86.0912
_task0 Rewards Std                 226.544
_task0 Rewards Max                2008.19
_task0 Rewards Min                  -0.804521
_task0 Returns Mean              12913.7
_task0 Returns Std               30321.2
_task0 Returns Max              116022
_task0 Returns Min                 -95.5317
_task0 Actions Mean                 -0.16168
_task0 Actions Std                   0.807594
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1494.01
Exploration_task0 Rewards Std     3286.18
Exploration_task0 Rewards Max    23128.4
Exploration_task0 Rewards Min      -12.5134
Exploration_task0 Returns Mean  226365
Exploration_task0 Returns Std   445183
Exploration_task0 Returns Max        2.32898e+06
Exploration_task0 Returns Min    -1142.2
Exploration_task0 Actions Mean      -0.0645864
Exploration_task0 Actions Std        0.825111
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             12913.7
AverageReturn_all_train_tasks    12276.7
AverageReturn_all_test_tasks     12913.7
Number of train steps total     132000
Number of env steps total            6.601e+06
Number of rollouts total         47922
Train Time (s)                     100.681
(Previous) Eval Time (s)            25.7549
Sample Time (s)                    106.724
Epoch Time (s)                     233.159
Total Train Time (s)             30565.7
Epoch                              131
------------------------------  ----------------
2019-06-27 09:02:17.963570 UTC | [dialturn] Iteration #131 | Epoch Duration: 232.60436844825745
2019-06-27 09:02:17.963791 UTC | [dialturn] Iteration #131 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000633943
Z variance train                     0.99911
KL Divergence                        5.57896e-05
KL Loss                              5.57896e-06
QF Loss                              5.88004e+07
VF Loss                              1.68196e+06
RF Loss                          58985.5
Policy Loss                     -69896.7
Q Predictions Mean               68941.8
Q Predictions Std                89514.6
Q Predictions Max               268830
Q Predictions Min                 2450.23
V Predictions Mean               69146.5
V Predictions Std                89963.1
V Predictions Max               262945
V Predictions Min                 2496.61
R Predictions Mean                1559.48
R Predictions Std                 3025.87
R Predictions Max                19693.5
R Predictions Min                   -9.53621
Log Pis Mean                        20.045
Log Pis Std                         11.5821
Log Pis Max                         53.6313
Log Pis Min                         -2.98524
Policy mu Mean                       0.217804
Policy mu Std                       11.6928
Policy mu Max                      136.064
Policy mu Min                     -102.552
Policy log std Mean                 -0.691089
Policy log std Std                   1.07177
Policy log std Max                   2
Policy log std Min                  -7.00037
_task0 Rewards Mean                227.87
_task0 Rewards Std                 446.651
_task0 Rewards Max                1985.95
_task0 Rewards Min                  -1.03748
_task0 Returns Mean              34180.5
_task0 Returns Std               62475
_task0 Returns Max              198114
_task0 Returns Min                -116.776
_task0 Actions Mean                 -0.0916416
_task0 Actions Std                   0.808371
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1170.01
Exploration_task0 Rewards Std     3002.11
Exploration_task0 Rewards Max    22444.8
Exploration_task0 Rewards Min      -10.3556
Exploration_task0 Returns Mean  177275
Exploration_task0 Returns Std   405832
Exploration_task0 Returns Max        1.76437e+06
Exploration_task0 Returns Min    -1304.18
Exploration_task0 Actions Mean      -0.086264
Exploration_task0 Actions Std        0.83557
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             34180.5
AverageReturn_all_train_tasks     7010.44
AverageReturn_all_test_tasks     34180.5
Number of train steps total     133000
Number of env steps total            6.651e+06
Number of rollouts total         48285
Train Time (s)                      98.5944
(Previous) Eval Time (s)            25.1983
Sample Time (s)                    105.395
Epoch Time (s)                     229.188
Total Train Time (s)             30794.8
Epoch                              132
------------------------------  ----------------
2019-06-27 09:06:07.020511 UTC | [dialturn] Iteration #132 | Epoch Duration: 229.05655550956726
2019-06-27 09:06:07.020745 UTC | [dialturn] Iteration #132 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000548827
Z variance train                     1.0007
KL Divergence                        2.94668e-05
KL Loss                              2.94668e-06
QF Loss                              1.7901e+08
VF Loss                              1.80607e+06
RF Loss                          67048.2
Policy Loss                     -70576.6
Q Predictions Mean               69547.7
Q Predictions Std                91734.3
Q Predictions Max               273014
Q Predictions Min                 2424.57
V Predictions Mean               69840.6
V Predictions Std                92166.8
V Predictions Max               269539
V Predictions Min                 2635.78
R Predictions Mean                1325.86
R Predictions Std                 2793.32
R Predictions Max                16834
R Predictions Min                 -106.353
Log Pis Mean                        19.7312
Log Pis Std                         11.4612
Log Pis Max                         52.3259
Log Pis Min                         -6.14274
Policy mu Mean                      -0.202595
Policy mu Std                       11.4118
Policy mu Max                      118.466
Policy mu Min                      -92.0674
Policy log std Mean                 -0.685808
Policy log std Std                   1.09108
Policy log std Max                   2
Policy log std Min                  -6.75807
_task0 Rewards Mean                 71.7659
_task0 Rewards Std                 168.234
_task0 Rewards Max                 976.104
_task0 Rewards Min                  -0.693785
_task0 Returns Mean              10764.9
_task0 Returns Std               24150.2
_task0 Returns Max               99172
_task0 Returns Min                 -81.3892
_task0 Actions Mean                 -0.117755
_task0 Actions Std                   0.818164
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1569.94
Exploration_task0 Rewards Std     3475.03
Exploration_task0 Rewards Max    22383.2
Exploration_task0 Rewards Min      -10.3171
Exploration_task0 Returns Mean  237870
Exploration_task0 Returns Std   483358
Exploration_task0 Returns Max        2.01238e+06
Exploration_task0 Returns Min    -1571.03
Exploration_task0 Actions Mean      -0.0877878
Exploration_task0 Actions Std        0.845103
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             10764.9
AverageReturn_all_train_tasks    45460.9
AverageReturn_all_test_tasks     10764.9
Number of train steps total     134000
Number of env steps total            6.701e+06
Number of rollouts total         48648
Train Time (s)                      99.0605
(Previous) Eval Time (s)            25.0657
Sample Time (s)                    104.871
Epoch Time (s)                     228.997
Total Train Time (s)             31024.5
Epoch                              133
------------------------------  ----------------
2019-06-27 09:09:56.746556 UTC | [dialturn] Iteration #133 | Epoch Duration: 229.72563910484314
2019-06-27 09:09:56.746785 UTC | [dialturn] Iteration #133 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000920131
Z variance train                     0.999501
KL Divergence                        9.80248e-05
KL Loss                              9.80248e-06
QF Loss                              1.91728e+08
VF Loss                              1.05943e+06
RF Loss                          71965.1
Policy Loss                     -76110.2
Q Predictions Mean               75606.8
Q Predictions Std                95473.2
Q Predictions Max               284225
Q Predictions Min                 2478.09
V Predictions Mean               75793.5
V Predictions Std                95680.9
V Predictions Max               279157
V Predictions Min                 2622.33
R Predictions Mean                1214.99
R Predictions Std                 2650.91
R Predictions Max                19845.9
R Predictions Min                  -25.3663
Log Pis Mean                        20.7384
Log Pis Std                         12.1129
Log Pis Max                         53.1274
Log Pis Min                         -0.806658
Policy mu Mean                      -0.0176889
Policy mu Std                       10.8998
Policy mu Max                      136.259
Policy mu Min                      -81.3035
Policy log std Mean                 -0.704596
Policy log std Std                   1.09068
Policy log std Max                   2
Policy log std Min                  -6.26145
_task0 Rewards Mean                266.082
_task0 Rewards Std                 551.886
_task0 Rewards Max                2216.18
_task0 Rewards Min                  -0.774699
_task0 Returns Mean              39912.3
_task0 Returns Std               78313.8
_task0 Returns Max              251647
_task0 Returns Min                -100.354
_task0 Actions Mean                  0.0816821
_task0 Actions Std                   0.78582
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1055.1
Exploration_task0 Rewards Std     2435.11
Exploration_task0 Rewards Max    21764.7
Exploration_task0 Rewards Min       -9.04564
Exploration_task0 Returns Mean  159864
Exploration_task0 Returns Std   345496
Exploration_task0 Returns Max        2.0161e+06
Exploration_task0 Returns Min    -1242.75
Exploration_task0 Actions Mean      -0.0473716
Exploration_task0 Actions Std        0.837443
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             39912.3
AverageReturn_all_train_tasks     2546.54
AverageReturn_all_test_tasks     39912.3
Number of train steps total     135000
Number of env steps total            6.751e+06
Number of rollouts total         49011
Train Time (s)                      98.9575
(Previous) Eval Time (s)            25.7932
Sample Time (s)                    105.887
Epoch Time (s)                     230.638
Total Train Time (s)             31254.6
Epoch                              134
------------------------------  ----------------
2019-06-27 09:13:46.854626 UTC | [dialturn] Iteration #134 | Epoch Duration: 230.10767698287964
2019-06-27 09:13:46.854854 UTC | [dialturn] Iteration #134 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000894613
Z variance train                     1.00209
KL Divergence                        0.000160286
KL Loss                              1.60286e-05
QF Loss                              1.73681e+08
VF Loss                         941206
RF Loss                          95933.3
Policy Loss                     -75362.1
Q Predictions Mean               74321.8
Q Predictions Std                97735.7
Q Predictions Max               292811
Q Predictions Min                 2457.48
V Predictions Mean               75101.2
V Predictions Std                98520.4
V Predictions Max               289430
V Predictions Min                 2674.27
R Predictions Mean                1221.86
R Predictions Std                 2646.15
R Predictions Max                21943
R Predictions Min                  -44.2113
Log Pis Mean                        21.2822
Log Pis Std                         12.03
Log Pis Max                         54.4637
Log Pis Min                         -4.70406
Policy mu Mean                       0.0855789
Policy mu Std                       10.5036
Policy mu Max                      122.082
Policy mu Min                      -86.1159
Policy log std Mean                 -0.769297
Policy log std Std                   1.09832
Policy log std Max                   2
Policy log std Min                  -6.44609
_task0 Rewards Mean                160.223
_task0 Rewards Std                 345.177
_task0 Rewards Max                2257.81
_task0 Rewards Min                  -0.73878
_task0 Returns Mean              24033.5
_task0 Returns Std               49000.3
_task0 Returns Max              167631
_task0 Returns Min                 -66.5801
_task0 Actions Mean                  0.02254
_task0 Actions Std                   0.841868
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1016.91
Exploration_task0 Rewards Std     2353.26
Exploration_task0 Rewards Max    22835.7
Exploration_task0 Rewards Min       -9.27781
Exploration_task0 Returns Mean  154078
Exploration_task0 Returns Std   327194
Exploration_task0 Returns Max        2.02505e+06
Exploration_task0 Returns Min    -1141.26
Exploration_task0 Actions Mean      -0.0442941
Exploration_task0 Actions Std        0.859302
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             24033.5
AverageReturn_all_train_tasks    47881.9
AverageReturn_all_test_tasks     24033.5
Number of train steps total     136000
Number of env steps total            6.801e+06
Number of rollouts total         49374
Train Time (s)                      98.1825
(Previous) Eval Time (s)            25.2619
Sample Time (s)                    105.07
Epoch Time (s)                     228.515
Total Train Time (s)             31482.9
Epoch                              135
------------------------------  ----------------
2019-06-27 09:17:35.126442 UTC | [dialturn] Iteration #135 | Epoch Duration: 228.27140355110168
2019-06-27 09:17:35.126665 UTC | [dialturn] Iteration #135 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00104979
Z variance train                     0.999271
KL Divergence                        0.000115186
KL Loss                              1.15186e-05
QF Loss                              1.58867e+08
VF Loss                              3.0911e+06
RF Loss                          92747.5
Policy Loss                     -80540.4
Q Predictions Mean               79727.8
Q Predictions Std               102257
Q Predictions Max               302201
Q Predictions Min                 2569.09
V Predictions Mean               79521.1
V Predictions Std               102146
V Predictions Max               298367
V Predictions Min                 2754.1
R Predictions Mean                1496.48
R Predictions Std                 3079.14
R Predictions Max                19917.1
R Predictions Min                  -55.2687
Log Pis Mean                        22.1617
Log Pis Std                         11.1104
Log Pis Max                         54.1891
Log Pis Min                         -1.59547
Policy mu Mean                      -0.0680008
Policy mu Std                       10.3377
Policy mu Max                      111.741
Policy mu Min                      -96.3054
Policy log std Mean                 -0.794366
Policy log std Std                   1.14454
Policy log std Max                   2
Policy log std Min                  -7.20545
_task0 Rewards Mean                216.372
_task0 Rewards Std                 404.97
_task0 Rewards Max                2061.05
_task0 Rewards Min                  -0.843671
_task0 Returns Mean              32455.8
_task0 Returns Std               57522.8
_task0 Returns Max              179272
_task0 Returns Min                 -99.4489
_task0 Actions Mean                  0.0866583
_task0 Actions Std                   0.837256
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1897.31
Exploration_task0 Rewards Std     4221.99
Exploration_task0 Rewards Max    23137.8
Exploration_task0 Rewards Min       -9.0791
Exploration_task0 Returns Mean  287471
Exploration_task0 Returns Std   600939
Exploration_task0 Returns Max        2.66276e+06
Exploration_task0 Returns Min    -1272.9
Exploration_task0 Actions Mean       0.00856943
Exploration_task0 Actions Std        0.843116
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             32455.8
AverageReturn_all_train_tasks    10790.6
AverageReturn_all_test_tasks     32455.8
Number of train steps total     137000
Number of env steps total            6.851e+06
Number of rollouts total         49737
Train Time (s)                     101.844
(Previous) Eval Time (s)            25.0171
Sample Time (s)                    106.225
Epoch Time (s)                     233.086
Total Train Time (s)             31716.8
Epoch                              136
------------------------------  ----------------
2019-06-27 09:21:29.033698 UTC | [dialturn] Iteration #136 | Epoch Duration: 233.90686702728271
2019-06-27 09:21:29.033902 UTC | [dialturn] Iteration #136 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000679713
Z variance train                     0.99965
KL Divergence                        5.30752e-05
KL Loss                              5.30752e-06
QF Loss                              1.69495e+08
VF Loss                              1.05302e+06
RF Loss                         163708
Policy Loss                     -78720.7
Q Predictions Mean               77617.5
Q Predictions Std               103644
Q Predictions Max               313608
Q Predictions Min                 2622.33
V Predictions Mean               78792.1
V Predictions Std               104959
V Predictions Max               310768
V Predictions Min                 2812.13
R Predictions Mean                2059.09
R Predictions Std                 4316.25
R Predictions Max                20021.8
R Predictions Min                   -8.83965
Log Pis Mean                        21.1557
Log Pis Std                         10.9716
Log Pis Max                         53.4346
Log Pis Min                         -6.18885
Policy mu Mean                      -0.228295
Policy mu Std                        8.03889
Policy mu Max                       92.8793
Policy mu Min                      -90.2298
Policy log std Mean                 -0.922049
Policy log std Std                   0.968185
Policy log std Max                   2
Policy log std Min                  -8.82417
_task0 Rewards Mean                183.577
_task0 Rewards Std                 396.473
_task0 Rewards Max                1398.28
_task0 Rewards Min                  -0.734971
_task0 Returns Mean              27536.6
_task0 Returns Std               57257.3
_task0 Returns Max              170247
_task0 Returns Min                 -72.3285
_task0 Actions Mean                 -0.137464
_task0 Actions Std                   0.782976
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1340.47
Exploration_task0 Rewards Std     2910.5
Exploration_task0 Rewards Max    22040.4
Exploration_task0 Rewards Min       -8.76395
Exploration_task0 Returns Mean  203102
Exploration_task0 Returns Std   407269
Exploration_task0 Returns Max        2.68899e+06
Exploration_task0 Returns Min    -1561.64
Exploration_task0 Actions Mean      -0.00340513
Exploration_task0 Actions Std        0.819841
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             27536.6
AverageReturn_all_train_tasks     6782.34
AverageReturn_all_test_tasks     27536.6
Number of train steps total     138000
Number of env steps total            6.901e+06
Number of rollouts total         50100
Train Time (s)                      99.2296
(Previous) Eval Time (s)            25.8367
Sample Time (s)                    107.433
Epoch Time (s)                     232.5
Total Train Time (s)             31949.1
Epoch                              137
------------------------------  ----------------
2019-06-27 09:25:21.338526 UTC | [dialturn] Iteration #137 | Epoch Duration: 232.30440616607666
2019-06-27 09:25:21.338745 UTC | [dialturn] Iteration #137 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00116159
Z variance train                     1.0006
KL Divergence                        0.000180395
KL Loss                              1.80395e-05
QF Loss                              2.76574e+08
VF Loss                              1.34355e+06
RF Loss                          62029.7
Policy Loss                     -83681.9
Q Predictions Mean               83030.8
Q Predictions Std               110600
Q Predictions Max               327815
Q Predictions Min                 2827.04
V Predictions Mean               83318.8
V Predictions Std               110920
V Predictions Max               322587
V Predictions Min                 3012.09
R Predictions Mean                1328.21
R Predictions Std                 3305.79
R Predictions Max                16972
R Predictions Min                 -369.017
Log Pis Mean                        20.6191
Log Pis Std                         10.7934
Log Pis Max                         54.414
Log Pis Min                         -4.28795
Policy mu Mean                      -0.787204
Policy mu Std                        8.30459
Policy mu Max                       86.8812
Policy mu Min                      -92.2526
Policy log std Mean                 -0.921885
Policy log std Std                   1.01052
Policy log std Max                   2
Policy log std Min                  -7.71972
_task0 Rewards Mean                 86.6772
_task0 Rewards Std                 154.429
_task0 Rewards Max                 713.733
_task0 Rewards Min                  -0.59645
_task0 Returns Mean              13001.6
_task0 Returns Std               22156.9
_task0 Returns Max               69922.1
_task0 Returns Min                 -82.0801
_task0 Actions Mean                 -0.0133067
_task0 Actions Std                   0.757456
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1794.59
Exploration_task0 Rewards Std     4255.91
Exploration_task0 Rewards Max    22771.8
Exploration_task0 Rewards Min       -9.38002
Exploration_task0 Returns Mean  271908
Exploration_task0 Returns Std   604995
Exploration_task0 Returns Max        2.53958e+06
Exploration_task0 Returns Min    -1190.04
Exploration_task0 Actions Mean      -0.0699451
Exploration_task0 Actions Std        0.806264
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             13001.6
AverageReturn_all_train_tasks    55880.5
AverageReturn_all_test_tasks     13001.6
Number of train steps total     139000
Number of env steps total            6.951e+06
Number of rollouts total         50463
Train Time (s)                     100.579
(Previous) Eval Time (s)            25.6401
Sample Time (s)                    107.456
Epoch Time (s)                     233.675
Total Train Time (s)             32182.7
Epoch                              138
------------------------------  ----------------
2019-06-27 09:29:14.930731 UTC | [dialturn] Iteration #138 | Epoch Duration: 233.5918252468109
2019-06-27 09:29:14.930937 UTC | [dialturn] Iteration #138 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000723816
Z variance train                     0.99989
KL Divergence                        6.06518e-05
KL Loss                              6.06518e-06
QF Loss                              1.90536e+08
VF Loss                              1.04193e+06
RF Loss                         188958
Policy Loss                     -83655.1
Q Predictions Mean               82568.2
Q Predictions Std               111005
Q Predictions Max               340003
Q Predictions Min                 2719.11
V Predictions Mean               83715.4
V Predictions Std               112214
V Predictions Max               336134
V Predictions Min                 2864.46
R Predictions Mean                1418.7
R Predictions Std                 3404.12
R Predictions Max                18941.6
R Predictions Min                  -95.9038
Log Pis Mean                        20.9217
Log Pis Std                         11.1187
Log Pis Max                         52.8932
Log Pis Min                         -4.07763
Policy mu Mean                      -0.601538
Policy mu Std                        8.58999
Policy mu Max                       83.9472
Policy mu Min                      -90.0595
Policy log std Mean                 -0.827406
Policy log std Std                   0.987548
Policy log std Max                   2
Policy log std Min                  -6.09587
_task0 Rewards Mean                100.627
_task0 Rewards Std                 224.94
_task0 Rewards Max                1161.84
_task0 Rewards Min                  -0.845964
_task0 Returns Mean              15094.1
_task0 Returns Std               31858.2
_task0 Returns Max              111506
_task0 Returns Min                 -99.9883
_task0 Actions Mean                 -0.0311677
_task0 Actions Std                   0.826428
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean     989.397
Exploration_task0 Rewards Std     2543.59
Exploration_task0 Rewards Max    22393.4
Exploration_task0 Rewards Min      -10.3569
Exploration_task0 Returns Mean  149909
Exploration_task0 Returns Std   351846
Exploration_task0 Returns Max        2.10599e+06
Exploration_task0 Returns Min    -1206.39
Exploration_task0 Actions Mean      -0.0258139
Exploration_task0 Actions Std        0.820526
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             15094.1
AverageReturn_all_train_tasks    48631.1
AverageReturn_all_test_tasks     15094.1
Number of train steps total     140000
Number of env steps total            7.001e+06
Number of rollouts total         50826
Train Time (s)                     101.958
(Previous) Eval Time (s)            25.5551
Sample Time (s)                    107.204
Epoch Time (s)                     234.717
Total Train Time (s)             32417.6
Epoch                              139
------------------------------  ----------------
2019-06-27 09:33:09.885764 UTC | [dialturn] Iteration #139 | Epoch Duration: 234.95466995239258
2019-06-27 09:33:09.885974 UTC | [dialturn] Iteration #139 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000963878
Z variance train                     1.00031
KL Divergence                        7.3826e-05
KL Loss                              7.3826e-06
QF Loss                              5.01757e+08
VF Loss                              1.09284e+06
RF Loss                         110027
Policy Loss                     -88200.1
Q Predictions Mean               86816.2
Q Predictions Std               116733
Q Predictions Max               353129
Q Predictions Min                 2703.46
V Predictions Mean               88504.1
V Predictions Std               118546
V Predictions Max               350617
V Predictions Min                 3003.44
R Predictions Mean                1289.3
R Predictions Std                 3194.27
R Predictions Max                20856.3
R Predictions Min                  -84.1025
Log Pis Mean                        20.3992
Log Pis Std                         10.8072
Log Pis Max                         54.0416
Log Pis Min                         -2.79416
Policy mu Mean                      -0.424702
Policy mu Std                        7.56685
Policy mu Max                       66.467
Policy mu Min                      -85.3981
Policy log std Mean                 -0.9546
Policy log std Std                   1.01956
Policy log std Max                   2
Policy log std Min                  -8.06831
_task0 Rewards Mean                 77.6987
_task0 Rewards Std                 177.916
_task0 Rewards Max                 858.38
_task0 Rewards Min                  -0.934288
_task0 Returns Mean              11654.8
_task0 Returns Std               25504.2
_task0 Returns Max               79676.6
_task0 Returns Min                -123.027
_task0 Actions Mean                 -0.145996
_task0 Actions Std                   0.760584
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1614.63
Exploration_task0 Rewards Std     3864.89
Exploration_task0 Rewards Max    22964.7
Exploration_task0 Rewards Min      -10.3867
Exploration_task0 Returns Mean  244640
Exploration_task0 Returns Std   541868
Exploration_task0 Returns Max        2.51595e+06
Exploration_task0 Returns Min    -1245.03
Exploration_task0 Actions Mean      -0.089701
Exploration_task0 Actions Std        0.805745
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             11654.8
AverageReturn_all_train_tasks    35760.4
AverageReturn_all_test_tasks     11654.8
Number of train steps total     141000
Number of env steps total            7.051e+06
Number of rollouts total         51189
Train Time (s)                     101.514
(Previous) Eval Time (s)            25.7914
Sample Time (s)                    107.091
Epoch Time (s)                     234.397
Total Train Time (s)             32652.1
Epoch                              140
------------------------------  ----------------
2019-06-27 09:37:04.309672 UTC | [dialturn] Iteration #140 | Epoch Duration: 234.42353057861328
2019-06-27 09:37:04.309878 UTC | [dialturn] Iteration #140 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000872753
Z variance train                     0.999746
KL Divergence                        8.59821e-05
KL Loss                              8.59821e-06
QF Loss                              1.97966e+08
VF Loss                              1.12072e+06
RF Loss                          79881.3
Policy Loss                     -91889.5
Q Predictions Mean               90509.9
Q Predictions Std               121354
Q Predictions Max               364733
Q Predictions Min                 2720.78
V Predictions Mean               91741.4
V Predictions Std               122545
V Predictions Max               361478
V Predictions Min                 3022.92
R Predictions Mean                1524.34
R Predictions Std                 3770.23
R Predictions Max                21048.6
R Predictions Min                  -42.9418
Log Pis Mean                        20.7625
Log Pis Std                         10.4154
Log Pis Max                         54.9858
Log Pis Min                         -4.1696
Policy mu Mean                      -0.243993
Policy mu Std                        7.32528
Policy mu Max                       52.4549
Policy mu Min                      -81.2455
Policy log std Mean                 -0.924532
Policy log std Std                   0.995373
Policy log std Max                   2
Policy log std Min                  -7.09816
_task0 Rewards Mean                260.798
_task0 Rewards Std                 392.117
_task0 Rewards Max                1430.9
_task0 Rewards Min                  -0.636084
_task0 Returns Mean              39119.7
_task0 Returns Std               55760.2
_task0 Returns Max              151244
_task0 Returns Min                 -88.6676
_task0 Actions Mean                 -0.0833619
_task0 Actions Std                   0.762688
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1415.01
Exploration_task0 Rewards Std     3083
Exploration_task0 Rewards Max    20922.4
Exploration_task0 Rewards Min       -9.35501
Exploration_task0 Returns Mean  214396
Exploration_task0 Returns Std   433526
Exploration_task0 Returns Max        2.0408e+06
Exploration_task0 Returns Min    -1235.7
Exploration_task0 Actions Mean      -0.0635746
Exploration_task0 Actions Std        0.811507
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             39119.7
AverageReturn_all_train_tasks     1429.42
AverageReturn_all_test_tasks     39119.7
Number of train steps total     142000
Number of env steps total            7.101e+06
Number of rollouts total         51552
Train Time (s)                     100.595
(Previous) Eval Time (s)            25.8169
Sample Time (s)                    107.252
Epoch Time (s)                     233.663
Total Train Time (s)             32885.7
Epoch                              141
------------------------------  ----------------
2019-06-27 09:40:57.951376 UTC | [dialturn] Iteration #141 | Epoch Duration: 233.64132690429688
2019-06-27 09:40:57.951600 UTC | [dialturn] Iteration #141 | Started Training: True
------------------------------  ----------------
Z mean train                         0.000943326
Z variance train                     0.999245
KL Divergence                        9.3254e-05
KL Loss                              9.3254e-06
QF Loss                              2.64203e+08
VF Loss                              2.29133e+06
RF Loss                          35429
Policy Loss                     -96263
Q Predictions Mean               94583.4
Q Predictions Std               128845
Q Predictions Max               378145
Q Predictions Min                 2671.96
V Predictions Mean               96465.8
V Predictions Std               130921
V Predictions Max               376485
V Predictions Min                 3046.33
R Predictions Mean                 903.887
R Predictions Std                 2212.29
R Predictions Max                21096.5
R Predictions Min                  -68.4798
Log Pis Mean                        20.5229
Log Pis Std                         10.2877
Log Pis Max                         52.9178
Log Pis Min                         -1.82463
Policy mu Mean                      -0.234895
Policy mu Std                        7.38994
Policy mu Max                       46.5444
Policy mu Min                      -81.2401
Policy log std Mean                 -0.907996
Policy log std Std                   1.04065
Policy log std Max                   2
Policy log std Min                  -5.86858
_task0 Rewards Mean                124.352
_task0 Rewards Std                 256.662
_task0 Rewards Max                 854.511
_task0 Rewards Min                  -0.73976
_task0 Returns Mean              18652.8
_task0 Returns Std               36985.8
_task0 Returns Max               93741.4
_task0 Returns Min                 -82.3363
_task0 Actions Mean                 -0.143255
_task0 Actions Std                   0.763691
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1263.92
Exploration_task0 Rewards Std     2894.72
Exploration_task0 Rewards Max    23148.6
Exploration_task0 Rewards Min       -9.3818
Exploration_task0 Returns Mean  191503
Exploration_task0 Returns Std   401181
Exploration_task0 Returns Max        2.5856e+06
Exploration_task0 Returns Min    -1172.11
Exploration_task0 Actions Mean      -0.0681484
Exploration_task0 Actions Std        0.799755
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             18652.8
AverageReturn_all_train_tasks    24774.1
AverageReturn_all_test_tasks     18652.8
Number of train steps total     143000
Number of env steps total            7.151e+06
Number of rollouts total         51915
Train Time (s)                     100.757
(Previous) Eval Time (s)            25.7934
Sample Time (s)                    107.16
Epoch Time (s)                     233.71
Total Train Time (s)             33119.2
Epoch                              142
------------------------------  ----------------
2019-06-27 09:44:51.501900 UTC | [dialturn] Iteration #142 | Epoch Duration: 233.55007481575012
2019-06-27 09:44:51.502155 UTC | [dialturn] Iteration #142 | Started Training: True
------------------------------  ----------------
Z mean train                         0.00100332
Z variance train                     0.999953
KL Divergence                        8.45706e-05
KL Loss                              8.45706e-06
QF Loss                              2.63067e+08
VF Loss                              2.00714e+06
RF Loss                          66697.4
Policy Loss                     -99766.3
Q Predictions Mean               97929.2
Q Predictions Std               133463
Q Predictions Max               389571
Q Predictions Min                 2792.25
V Predictions Mean               99320.6
V Predictions Std               134758
V Predictions Max               385822
V Predictions Min                 2992.78
R Predictions Mean                 668.006
R Predictions Std                 1766.05
R Predictions Max                 9776.42
R Predictions Min                  -73.8994
Log Pis Mean                        20.717
Log Pis Std                         10.2284
Log Pis Max                         65.85
Log Pis Min                         -1.39081
Policy mu Mean                      -0.658732
Policy mu Std                        7.82905
Policy mu Max                       48.3698
Policy mu Min                      -81.3432
Policy log std Mean                 -0.918808
Policy log std Std                   1.02162
Policy log std Max                   2
Policy log std Min                  -9.94796
_task0 Rewards Mean                140.489
_task0 Rewards Std                 300.733
_task0 Rewards Max                1550.61
_task0 Rewards Min                  -0.731501
_task0 Returns Mean              21073.4
_task0 Returns Std               43226.1
_task0 Returns Max              139508
_task0 Returns Min                 -84.8154
_task0 Actions Mean                 -0.142476
_task0 Actions Std                   0.757152
_task0 Actions Max                   1
_task0 Actions Min                  -1
Num Paths                          363
Exploration_task0 Rewards Mean    1005.68
Exploration_task0 Rewards Std     2616.26
Exploration_task0 Rewards Max    22181.7
Exploration_task0 Rewards Min       -8.08037
Exploration_task0 Returns Mean  152375
Exploration_task0 Returns Std   370112
Exploration_task0 Returns Max        2.4161e+06
Exploration_task0 Returns Min     -989.765
Exploration_task0 Actions Mean      -0.0596232
Exploration_task0 Actions Std        0.811229
Exploration_task0 Actions Max        1
Exploration_task0 Actions Min       -1
AverageReturn__task0             21073.4
AverageReturn_all_train_tasks     9547.96
AverageReturn_all_test_tasks     21073.4
Number of train steps total     144000
Number of env steps total            7.201e+06
Number of rollouts total         52278
Train Time (s)                     100.413
(Previous) Eval Time (s)            25.6318
Sample Time (s)                    106.455
Epoch Time (s)                     232.5
Total Train Time (s)             33351.7
Epoch                              143
------------------------------  ----------------
2019-06-27 09:48:44.000389 UTC | [dialturn] Iteration #143 | Epoch Duration: 232.49806928634644
2019-06-27 09:48:44.000607 UTC | [dialturn] Iteration #143 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000444107
Z variance train                      0.999907
KL Divergence                         2.24967e-05
KL Loss                               2.24967e-06
QF Loss                               2.86853e+08
VF Loss                               1.65991e+06
RF Loss                           79828
Policy Loss                     -106772
Q Predictions Mean               105761
Q Predictions Std                139742
Q Predictions Max                405512
Q Predictions Min                  2896.62
V Predictions Mean               106574
V Predictions Std                140706
V Predictions Max                401466
V Predictions Min                  3255.64
R Predictions Mean                 1558.32
R Predictions Std                  3298.34
R Predictions Max                 19395.7
R Predictions Min                   -11.6127
Log Pis Mean                         21.4526
Log Pis Std                          10.1206
Log Pis Max                          51.7515
Log Pis Min                          -4.47436
Policy mu Mean                        0.0565754
Policy mu Std                         7.29385
Policy mu Max                        49.7669
Policy mu Min                       -91.393
Policy log std Mean                  -0.948529
Policy log std Std                    1.02978
Policy log std Max                    2
Policy log std Min                   -6.9283
_task0 Rewards Mean                  75.8855
_task0 Rewards Std                  144.156
_task0 Rewards Max                  521.151
_task0 Rewards Min                   -0.775335
_task0 Returns Mean               11382.8
_task0 Returns Std                20958.4
_task0 Returns Max                55085.5
_task0 Returns Min                  -81.5448
_task0 Actions Mean                  -0.140432
_task0 Actions Std                    0.767103
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1293.16
Exploration_task0 Rewards Std      2999.98
Exploration_task0 Rewards Max     21743.9
Exploration_task0 Rewards Min        -9.37868
Exploration_task0 Returns Mean   195933
Exploration_task0 Returns Std    428365
Exploration_task0 Returns Max         2.32162e+06
Exploration_task0 Returns Min     -1228.41
Exploration_task0 Actions Mean       -0.0495325
Exploration_task0 Actions Std         0.818595
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11382.8
AverageReturn_all_train_tasks     23099.5
AverageReturn_all_test_tasks      11382.8
Number of train steps total      145000
Number of env steps total             7.251e+06
Number of rollouts total          52641
Train Time (s)                      101.158
(Previous) Eval Time (s)             25.6284
Sample Time (s)                     107.191
Epoch Time (s)                      233.977
Total Train Time (s)              33585.9
Epoch                               144
------------------------------  -----------------
2019-06-27 09:52:38.121478 UTC | [dialturn] Iteration #144 | Epoch Duration: 234.12070989608765
2019-06-27 09:52:38.121710 UTC | [dialturn] Iteration #144 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00140565
Z variance train                      0.999799
KL Divergence                         0.000238853
KL Loss                               2.38853e-05
QF Loss                               4.69012e+08
VF Loss                               2.46618e+06
RF Loss                          170636
Policy Loss                     -107025
Q Predictions Mean               105745
Q Predictions Std                140502
Q Predictions Max                409017
Q Predictions Min                  2976.14
V Predictions Mean               107813
V Predictions Std                142793
V Predictions Max                410283
V Predictions Min                  3427.12
R Predictions Mean                 1018.48
R Predictions Std                  2861.71
R Predictions Max                 19478.8
R Predictions Min                  -145.958
Log Pis Mean                         21.0154
Log Pis Std                          10.2049
Log Pis Max                          52.9923
Log Pis Min                          -3.31918
Policy mu Mean                       -0.437356
Policy mu Std                         8.24218
Policy mu Max                        42.5162
Policy mu Min                       -80.4274
Policy log std Mean                  -0.870282
Policy log std Std                    1.04862
Policy log std Max                    2
Policy log std Min                   -6.66823
_task0 Rewards Mean                 206.265
_task0 Rewards Std                  393.589
_task0 Rewards Max                 1794.35
_task0 Rewards Min                   -0.669064
_task0 Returns Mean               30939.7
_task0 Returns Std                55955.3
_task0 Returns Max               185209
_task0 Returns Min                  -87.6373
_task0 Actions Mean                  -0.0615311
_task0 Actions Std                    0.765862
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1063.65
Exploration_task0 Rewards Std      2642.32
Exploration_task0 Rewards Max     22993.5
Exploration_task0 Rewards Min        -9.38002
Exploration_task0 Returns Mean   161159
Exploration_task0 Returns Std    368694
Exploration_task0 Returns Max         2.32479e+06
Exploration_task0 Returns Min     -1191.24
Exploration_task0 Actions Mean       -0.0916281
Exploration_task0 Actions Std         0.793148
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              30939.7
AverageReturn_all_train_tasks        93.5484
AverageReturn_all_test_tasks      30939.7
Number of train steps total      146000
Number of env steps total             7.301e+06
Number of rollouts total          53004
Train Time (s)                       99.8773
(Previous) Eval Time (s)             25.7704
Sample Time (s)                     106.867
Epoch Time (s)                      232.514
Total Train Time (s)              33818.5
Epoch                               145
------------------------------  -----------------
2019-06-27 09:56:30.784797 UTC | [dialturn] Iteration #145 | Epoch Duration: 232.66292548179626
2019-06-27 09:56:30.784994 UTC | [dialturn] Iteration #145 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000552559
Z variance train                      0.99908
KL Divergence                         6.25449e-05
KL Loss                               6.25449e-06
QF Loss                               4.19364e+08
VF Loss                               1.46031e+06
RF Loss                           44970.3
Policy Loss                     -110883
Q Predictions Mean               109219
Q Predictions Std                147939
Q Predictions Max                426867
Q Predictions Min                  3241.04
V Predictions Mean               110986
V Predictions Std                149884
V Predictions Max                422868
V Predictions Min                  3584
R Predictions Mean                  819.672
R Predictions Std                  1965.54
R Predictions Max                 12486.3
R Predictions Min                  -172.433
Log Pis Mean                         21.1392
Log Pis Std                           9.38751
Log Pis Max                          50.8388
Log Pis Min                          -5.80175
Policy mu Mean                       -0.32016
Policy mu Std                         6.93877
Policy mu Max                        41.3383
Policy mu Min                       -87.9318
Policy log std Mean                  -1.02171
Policy log std Std                    0.975247
Policy log std Max                    2
Policy log std Min                   -6.94975
_task0 Rewards Mean                 115.537
_task0 Rewards Std                  227.219
_task0 Rewards Max                 1082.03
_task0 Rewards Min                   -0.554914
_task0 Returns Mean               17330.5
_task0 Returns Std                32544.6
_task0 Returns Max               117886
_task0 Returns Min                  -75.3315
_task0 Actions Mean                  -0.100439
_task0 Actions Std                    0.712191
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1376.88
Exploration_task0 Rewards Std      3649.49
Exploration_task0 Rewards Max     22140.6
Exploration_task0 Rewards Min        -9.24738
Exploration_task0 Returns Mean   208618
Exploration_task0 Returns Std    510886
Exploration_task0 Returns Max         2.29444e+06
Exploration_task0 Returns Min     -1220.68
Exploration_task0 Actions Mean       -0.0933543
Exploration_task0 Actions Std         0.800554
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17330.5
AverageReturn_all_train_tasks     14784
AverageReturn_all_test_tasks      17330.5
Number of train steps total      147000
Number of env steps total             7.351e+06
Number of rollouts total          53367
Train Time (s)                      101.779
(Previous) Eval Time (s)             25.9175
Sample Time (s)                     107.314
Epoch Time (s)                      235.01
Total Train Time (s)              34053.2
Epoch                               146
------------------------------  -----------------
2019-06-27 10:00:25.490154 UTC | [dialturn] Iteration #146 | Epoch Duration: 234.704998254776
2019-06-27 10:00:25.490370 UTC | [dialturn] Iteration #146 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000936836
Z variance train                      0.99862
KL Divergence                         0.000144509
KL Loss                               1.44509e-05
QF Loss                               5.82391e+08
VF Loss                               1.48991e+06
RF Loss                          304443
Policy Loss                     -115060
Q Predictions Mean               113676
Q Predictions Std                149703
Q Predictions Max                438422
Q Predictions Min                  3522.94
V Predictions Mean               115190
V Predictions Std                151361
V Predictions Max                433866
V Predictions Min                  3739.94
R Predictions Mean                 1085.3
R Predictions Std                  2697.28
R Predictions Max                 16724.5
R Predictions Min                   -26.2636
Log Pis Mean                         21.7954
Log Pis Std                           9.88219
Log Pis Max                          54.9706
Log Pis Min                          -2.84523
Policy mu Mean                       -0.297069
Policy mu Std                         8.03548
Policy mu Max                        63.5507
Policy mu Min                       -79.6629
Policy log std Mean                  -0.86992
Policy log std Std                    1.01367
Policy log std Max                    2
Policy log std Min                   -6.66986
_task0 Rewards Mean                 160.827
_task0 Rewards Std                  338.257
_task0 Rewards Max                 1457.29
_task0 Rewards Min                   -0.670527
_task0 Returns Mean               24124
_task0 Returns Std                48579.2
_task0 Returns Max               135870
_task0 Returns Min                  -89.1273
_task0 Actions Mean                  -0.333452
_task0 Actions Std                    0.770423
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1935.49
Exploration_task0 Rewards Std      4063.06
Exploration_task0 Rewards Max     23018.5
Exploration_task0 Rewards Min        -9.62124
Exploration_task0 Returns Mean   293256
Exploration_task0 Returns Std    574021
Exploration_task0 Returns Max         2.56804e+06
Exploration_task0 Returns Min     -1255.84
Exploration_task0 Actions Mean       -0.0375261
Exploration_task0 Actions Std         0.800329
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              24124
AverageReturn_all_train_tasks      6386.29
AverageReturn_all_test_tasks      24124
Number of train steps total      148000
Number of env steps total             7.401e+06
Number of rollouts total          53730
Train Time (s)                      101.393
(Previous) Eval Time (s)             25.6114
Sample Time (s)                     107.224
Epoch Time (s)                      234.228
Total Train Time (s)              34287.6
Epoch                               147
------------------------------  -----------------
2019-06-27 10:04:19.829954 UTC | [dialturn] Iteration #147 | Epoch Duration: 234.3393681049347
2019-06-27 10:04:19.830164 UTC | [dialturn] Iteration #147 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000942761
Z variance train                      0.998908
KL Divergence                         0.000149682
KL Loss                               1.49682e-05
QF Loss                               3.28838e+08
VF Loss                               2.27786e+06
RF Loss                          209938
Policy Loss                     -120238
Q Predictions Mean               118480
Q Predictions Std                156179
Q Predictions Max                445283
Q Predictions Min                  3404.24
V Predictions Mean               120245
V Predictions Std                157912
V Predictions Max                444337
V Predictions Min                  3457.68
R Predictions Mean                 1426.98
R Predictions Std                  3400.91
R Predictions Max                 18721.6
R Predictions Min                  -144.226
Log Pis Mean                         22.4358
Log Pis Std                           9.91138
Log Pis Max                          53.567
Log Pis Min                          -1.68994
Policy mu Mean                       -0.84442
Policy mu Std                         8.03682
Policy mu Max                        44.228
Policy mu Min                       -90.8988
Policy log std Mean                  -0.945433
Policy log std Std                    0.952943
Policy log std Max                    2
Policy log std Min                   -6.54625
_task0 Rewards Mean                 258.383
_task0 Rewards Std                  419.395
_task0 Rewards Max                 2008
_task0 Rewards Min                   -0.642993
_task0 Returns Mean               38757.5
_task0 Returns Std                59502
_task0 Returns Max               152121
_task0 Returns Min                  -88.6072
_task0 Actions Mean                  -0.0212479
_task0 Actions Std                    0.781602
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1633.99
Exploration_task0 Rewards Std      4126.39
Exploration_task0 Rewards Max     22932.2
Exploration_task0 Rewards Min        -8.55902
Exploration_task0 Returns Mean   247574
Exploration_task0 Returns Std    585999
Exploration_task0 Returns Max         2.4126e+06
Exploration_task0 Returns Min     -1558.56
Exploration_task0 Actions Mean       -0.123576
Exploration_task0 Actions Std         0.826781
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              38757.5
AverageReturn_all_train_tasks      5466.22
AverageReturn_all_test_tasks      38757.5
Number of train steps total      149000
Number of env steps total             7.451e+06
Number of rollouts total          54093
Train Time (s)                      100.596
(Previous) Eval Time (s)             25.7216
Sample Time (s)                     107.552
Epoch Time (s)                      233.869
Total Train Time (s)              34521.7
Epoch                               148
------------------------------  -----------------
2019-06-27 10:08:13.938080 UTC | [dialturn] Iteration #148 | Epoch Duration: 234.10775661468506
2019-06-27 10:08:13.938278 UTC | [dialturn] Iteration #148 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000361908
Z variance train                      0.999553
KL Divergence                         2.10421e-05
KL Loss                               2.10421e-06
QF Loss                               1.16665e+09
VF Loss                               3.0817e+06
RF Loss                          240451
Policy Loss                     -123151
Q Predictions Mean               122046
Q Predictions Std                160536
Q Predictions Max                462339
Q Predictions Min                  1911.88
V Predictions Mean               122282
V Predictions Std                160696
V Predictions Max                454999
V Predictions Min                  4119.74
R Predictions Mean                 1147.81
R Predictions Std                  2790.21
R Predictions Max                 16631.6
R Predictions Min                   -99.8758
Log Pis Mean                         21.9111
Log Pis Std                           9.83911
Log Pis Max                          53.0264
Log Pis Min                          -2.42258
Policy mu Mean                       -0.215806
Policy mu Std                         7.4787
Policy mu Max                        54.1883
Policy mu Min                       -78.771
Policy log std Mean                  -0.962528
Policy log std Std                    0.970404
Policy log std Max                    2
Policy log std Min                   -6.30176
_task0 Rewards Mean                 115.186
_task0 Rewards Std                  291.918
_task0 Rewards Max                 1635.36
_task0 Rewards Min                   -0.958645
_task0 Returns Mean               17277.9
_task0 Returns Std                41899.9
_task0 Returns Max               163499
_task0 Returns Min                 -101.234
_task0 Actions Mean                  -0.047791
_task0 Actions Std                    0.792584
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1548.57
Exploration_task0 Rewards Std      3432.27
Exploration_task0 Rewards Max     21770.7
Exploration_task0 Rewards Min        -9.82692
Exploration_task0 Returns Mean   234632
Exploration_task0 Returns Std    483056
Exploration_task0 Returns Max         2.19225e+06
Exploration_task0 Returns Min     -1089.85
Exploration_task0 Actions Mean       -0.0660289
Exploration_task0 Actions Std         0.821316
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17277.9
AverageReturn_all_train_tasks      3388.15
AverageReturn_all_test_tasks      17277.9
Number of train steps total      150000
Number of env steps total             7.501e+06
Number of rollouts total          54456
Train Time (s)                      100.688
(Previous) Eval Time (s)             25.9584
Sample Time (s)                     107.638
Epoch Time (s)                      234.284
Total Train Time (s)              34755.9
Epoch                               149
------------------------------  -----------------
2019-06-27 10:12:08.164102 UTC | [dialturn] Iteration #149 | Epoch Duration: 234.2255687713623
2019-06-27 10:12:08.164346 UTC | [dialturn] Iteration #149 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000844634
Z variance train                      0.999741
KL Divergence                         8.44575e-05
KL Loss                               8.44575e-06
QF Loss                               5.18549e+08
VF Loss                               1.51506e+06
RF Loss                          240923
Policy Loss                     -124183
Q Predictions Mean               122692
Q Predictions Std                162037
Q Predictions Max                467103
Q Predictions Min                  3769.1
V Predictions Mean               124230
V Predictions Std                163643
V Predictions Max                464652
V Predictions Min                  4330.84
R Predictions Mean                 1424.75
R Predictions Std                  3677.58
R Predictions Max                 20830.1
R Predictions Min                  -123.743
Log Pis Mean                         22.0028
Log Pis Std                          10.0071
Log Pis Max                          51.9298
Log Pis Min                          -3.33293
Policy mu Mean                       -0.943145
Policy mu Std                         9.64403
Policy mu Max                        56.1032
Policy mu Min                       -94.0874
Policy log std Mean                  -0.896117
Policy log std Std                    1.01752
Policy log std Max                    2
Policy log std Min                   -5.81094
_task0 Rewards Mean                  81.0531
_task0 Rewards Std                  203.961
_task0 Rewards Max                  877.692
_task0 Rewards Min                   -1.20316
_task0 Returns Mean               12158
_task0 Returns Std                29660.9
_task0 Returns Max               103928
_task0 Returns Min                  -97.5411
_task0 Actions Mean                  -0.122159
_task0 Actions Std                    0.791172
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      846.957
Exploration_task0 Rewards Std      2661.32
Exploration_task0 Rewards Max     22588.2
Exploration_task0 Rewards Min       -10.8513
Exploration_task0 Returns Mean   128327
Exploration_task0 Returns Std    376321
Exploration_task0 Returns Max         2.47359e+06
Exploration_task0 Returns Min     -1161.37
Exploration_task0 Actions Mean       -0.0828847
Exploration_task0 Actions Std         0.831669
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12158
AverageReturn_all_train_tasks     40697.9
AverageReturn_all_test_tasks      12158
Number of train steps total      151000
Number of env steps total             7.551e+06
Number of rollouts total          54819
Train Time (s)                      101.101
(Previous) Eval Time (s)             25.8987
Sample Time (s)                     107.871
Epoch Time (s)                      234.871
Total Train Time (s)              34990.6
Epoch                               150
------------------------------  -----------------
2019-06-27 10:16:02.899262 UTC | [dialturn] Iteration #150 | Epoch Duration: 234.73473501205444
2019-06-27 10:16:02.899490 UTC | [dialturn] Iteration #150 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00155006
Z variance train                      0.999682
KL Divergence                         0.000278178
KL Loss                               2.78178e-05
QF Loss                               2.78813e+08
VF Loss                               2.91614e+06
RF Loss                           74919.9
Policy Loss                     -122430
Q Predictions Mean               120599
Q Predictions Std                164579
Q Predictions Max                473666
Q Predictions Min                  3506.65
V Predictions Mean               121860
V Predictions Std                165719
V Predictions Max                472629
V Predictions Min                  3560.66
R Predictions Mean                  602.114
R Predictions Std                  2230.94
R Predictions Max                 19044.6
R Predictions Min                  -115.643
Log Pis Mean                         22.1741
Log Pis Std                           9.82916
Log Pis Max                          53.6198
Log Pis Min                          -2.1297
Policy mu Mean                       -0.729991
Policy mu Std                         8.3849
Policy mu Max                        42.3785
Policy mu Min                       -95.3041
Policy log std Mean                  -0.93138
Policy log std Std                    0.966185
Policy log std Max                    2
Policy log std Min                   -6.04156
_task0 Rewards Mean                 128.178
_task0 Rewards Std                  316.41
_task0 Rewards Max                 1576.82
_task0 Rewards Min                   -0.721922
_task0 Returns Mean               19226.8
_task0 Returns Std                45229.6
_task0 Returns Max               166624
_task0 Returns Min                  -95.9735
_task0 Actions Mean                  -0.133698
_task0 Actions Std                    0.794704
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1133.49
Exploration_task0 Rewards Std      3144.08
Exploration_task0 Rewards Max     22474
Exploration_task0 Rewards Min        -9.37629
Exploration_task0 Returns Mean   171741
Exploration_task0 Returns Std    446278
Exploration_task0 Returns Max         2.72281e+06
Exploration_task0 Returns Min     -1276.3
Exploration_task0 Actions Mean       -0.121699
Exploration_task0 Actions Std         0.814715
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19226.8
AverageReturn_all_train_tasks       121.675
AverageReturn_all_test_tasks      19226.8
Number of train steps total      152000
Number of env steps total             7.601e+06
Number of rollouts total          55182
Train Time (s)                      101.18
(Previous) Eval Time (s)             25.7613
Sample Time (s)                     107.137
Epoch Time (s)                      234.078
Total Train Time (s)              35224.6
Epoch                               151
------------------------------  -----------------
2019-06-27 10:19:56.868066 UTC | [dialturn] Iteration #151 | Epoch Duration: 233.96839928627014
2019-06-27 10:19:56.868305 UTC | [dialturn] Iteration #151 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00117554
Z variance train                      1.00145
KL Divergence                         0.000229249
KL Loss                               2.29249e-05
QF Loss                               2.7689e+08
VF Loss                               1.99877e+06
RF Loss                          238154
Policy Loss                     -127958
Q Predictions Mean               126340
Q Predictions Std                169094
Q Predictions Max                486910
Q Predictions Min                  4058.58
V Predictions Mean               128398
V Predictions Std                171611
V Predictions Max                489701
V Predictions Min                  4488.97
R Predictions Mean                 1156.3
R Predictions Std                  2867.52
R Predictions Max                 19342.6
R Predictions Min                   -21.6375
Log Pis Mean                         21.5249
Log Pis Std                           9.6416
Log Pis Max                          53.4052
Log Pis Min                          -2.79386
Policy mu Mean                       -0.73815
Policy mu Std                         8.27382
Policy mu Max                        46.2232
Policy mu Min                       -91.1699
Policy log std Mean                  -0.903125
Policy log std Std                    0.972635
Policy log std Max                    2
Policy log std Min                   -5.86116
_task0 Rewards Mean                 100.008
_task0 Rewards Std                  273.399
_task0 Rewards Max                 1503.88
_task0 Rewards Min                   -0.628215
_task0 Returns Mean               15001.3
_task0 Returns Std                39435.4
_task0 Returns Max               149938
_task0 Returns Min                  -76.0556
_task0 Actions Mean                  -0.150724
_task0 Actions Std                    0.751493
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1211.89
Exploration_task0 Rewards Std      2763.58
Exploration_task0 Rewards Max     22782.7
Exploration_task0 Rewards Min        -9.61268
Exploration_task0 Returns Mean   183620
Exploration_task0 Returns Std    392963
Exploration_task0 Returns Max         2.11276e+06
Exploration_task0 Returns Min     -1221.69
Exploration_task0 Actions Mean       -0.111938
Exploration_task0 Actions Std         0.804222
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15001.3
AverageReturn_all_train_tasks     21332.3
AverageReturn_all_test_tasks      15001.3
Number of train steps total      153000
Number of env steps total             7.651e+06
Number of rollouts total          55545
Train Time (s)                      101.608
(Previous) Eval Time (s)             25.6499
Sample Time (s)                     107.461
Epoch Time (s)                      234.719
Total Train Time (s)              35459.3
Epoch                               152
------------------------------  -----------------
2019-06-27 10:23:51.644631 UTC | [dialturn] Iteration #152 | Epoch Duration: 234.77615976333618
2019-06-27 10:23:51.644846 UTC | [dialturn] Iteration #152 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000470275
Z variance train                      0.999714
KL Divergence                         2.89921e-05
KL Loss                               2.89921e-06
QF Loss                               4.71672e+08
VF Loss                               1.43858e+06
RF Loss                           96568.2
Policy Loss                     -137993
Q Predictions Mean               136734
Q Predictions Std                177531
Q Predictions Max                500344
Q Predictions Min                  3395.76
V Predictions Mean               137661
V Predictions Std                178464
V Predictions Max                496513
V Predictions Min                  4376.25
R Predictions Mean                 1017.24
R Predictions Std                  3013.44
R Predictions Max                 19977
R Predictions Min                  -150.182
Log Pis Mean                         21.5993
Log Pis Std                          10.0065
Log Pis Max                          51.9089
Log Pis Min                          -2.16872
Policy mu Mean                       -1.24863
Policy mu Std                         9.24918
Policy mu Max                        59.318
Policy mu Min                       -94.5115
Policy log std Mean                  -0.892787
Policy log std Std                    1.00557
Policy log std Max                    2
Policy log std Min                   -6.48012
_task0 Rewards Mean                  28.9048
_task0 Rewards Std                   57.2236
_task0 Rewards Max                  213.135
_task0 Rewards Min                   -0.752289
_task0 Returns Mean                4335.72
_task0 Returns Std                 8441.34
_task0 Returns Max                22194.1
_task0 Returns Min                  -76.6136
_task0 Actions Mean                  -0.157093
_task0 Actions Std                    0.813938
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1303.21
Exploration_task0 Rewards Std      3131.9
Exploration_task0 Rewards Max     22962.3
Exploration_task0 Rewards Min        -9.91911
Exploration_task0 Returns Mean   197456
Exploration_task0 Returns Std    446868
Exploration_task0 Returns Max         2.66318e+06
Exploration_task0 Returns Min     -1493.42
Exploration_task0 Actions Mean       -0.143235
Exploration_task0 Actions Std         0.802348
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               4335.72
AverageReturn_all_train_tasks     39044.1
AverageReturn_all_test_tasks       4335.72
Number of train steps total      154000
Number of env steps total             7.701e+06
Number of rollouts total          55908
Train Time (s)                      101.753
(Previous) Eval Time (s)             25.7058
Sample Time (s)                     106.919
Epoch Time (s)                      234.377
Total Train Time (s)              35693.6
Epoch                               153
------------------------------  -----------------
2019-06-27 10:27:45.938992 UTC | [dialturn] Iteration #153 | Epoch Duration: 234.29397559165955
2019-06-27 10:27:45.939199 UTC | [dialturn] Iteration #153 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000563586
Z variance train                      0.999728
KL Divergence                         5.13309e-05
KL Loss                               5.13309e-06
QF Loss                               3.14628e+08
VF Loss                               8.41404e+06
RF Loss                          166308
Policy Loss                     -134763
Q Predictions Mean               133037
Q Predictions Std                178121
Q Predictions Max                510644
Q Predictions Min                  3625.75
V Predictions Mean               132806
V Predictions Std                178309
V Predictions Max                506528
V Predictions Min                  4287.24
R Predictions Mean                 1003.85
R Predictions Std                  2745.47
R Predictions Max                 22575.6
R Predictions Min                   -67.825
Log Pis Mean                         21.4764
Log Pis Std                           9.47422
Log Pis Max                          51.9346
Log Pis Min                          -3.30282
Policy mu Mean                       -0.874846
Policy mu Std                         8.313
Policy mu Max                        44.5434
Policy mu Min                       -86.7997
Policy log std Mean                  -0.958735
Policy log std Std                    0.980598
Policy log std Max                    2
Policy log std Min                   -6.38652
_task0 Rewards Mean                  11.2769
_task0 Rewards Std                   28.9984
_task0 Rewards Max                  136.33
_task0 Rewards Min                   -0.679704
_task0 Returns Mean                1691.53
_task0 Returns Std                 4167.23
_task0 Returns Max                14281.5
_task0 Returns Min                  -85.5859
_task0 Actions Mean                  -0.278287
_task0 Actions Std                    0.792919
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1833.39
Exploration_task0 Rewards Std      3547.29
Exploration_task0 Rewards Max     23079.4
Exploration_task0 Rewards Min       -12.2066
Exploration_task0 Returns Mean   277787
Exploration_task0 Returns Std    505857
Exploration_task0 Returns Max         2.53638e+06
Exploration_task0 Returns Min     -1102.28
Exploration_task0 Actions Mean       -0.126584
Exploration_task0 Actions Std         0.84353
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               1691.53
AverageReturn_all_train_tasks     17640.8
AverageReturn_all_test_tasks       1691.53
Number of train steps total      155000
Number of env steps total             7.751e+06
Number of rollouts total          56271
Train Time (s)                      100.33
(Previous) Eval Time (s)             25.6209
Sample Time (s)                     106.982
Epoch Time (s)                      232.933
Total Train Time (s)              35926.7
Epoch                               154
------------------------------  -----------------
2019-06-27 10:31:39.048811 UTC | [dialturn] Iteration #154 | Epoch Duration: 233.1094355583191
2019-06-27 10:31:39.049083 UTC | [dialturn] Iteration #154 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0015632
Z variance train                      1.00016
KL Divergence                         0.000225851
KL Loss                               2.25851e-05
QF Loss                               3.87194e+08
VF Loss                               2.65722e+06
RF Loss                          561374
Policy Loss                     -136934
Q Predictions Mean               134940
Q Predictions Std                182125
Q Predictions Max                517872
Q Predictions Min                  3471.16
V Predictions Mean               136206
V Predictions Std                183338
V Predictions Max                514926
V Predictions Min                  4193.9
R Predictions Mean                 1561.65
R Predictions Std                  3215.3
R Predictions Max                 20687.5
R Predictions Min                   -55.0876
Log Pis Mean                         21.8624
Log Pis Std                           9.85131
Log Pis Max                          50.357
Log Pis Min                          -0.164674
Policy mu Mean                       -0.639959
Policy mu Std                         8.83806
Policy mu Max                        56.8998
Policy mu Min                       -82.6581
Policy log std Mean                  -0.943304
Policy log std Std                    1.02917
Policy log std Max                    2
Policy log std Min                   -6.2901
_task0 Rewards Mean                  73.5525
_task0 Rewards Std                  195.117
_task0 Rewards Max                  899.574
_task0 Rewards Min                   -0.840518
_task0 Returns Mean               11032.9
_task0 Returns Std                28486.7
_task0 Returns Max               104217
_task0 Returns Min                 -109.816
_task0 Actions Mean                  -0.0712138
_task0 Actions Std                    0.804683
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1501.72
Exploration_task0 Rewards Std      3363.99
Exploration_task0 Rewards Max     22339
Exploration_task0 Rewards Min       -15.1606
Exploration_task0 Returns Mean   227533
Exploration_task0 Returns Std    479421
Exploration_task0 Returns Max         2.04194e+06
Exploration_task0 Returns Min     -1379.79
Exploration_task0 Actions Mean       -0.113666
Exploration_task0 Actions Std         0.830481
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11032.9
AverageReturn_all_train_tasks     15493.5
AverageReturn_all_test_tasks      11032.9
Number of train steps total      156000
Number of env steps total             7.801e+06
Number of rollouts total          56634
Train Time (s)                      100.178
(Previous) Eval Time (s)             25.7958
Sample Time (s)                     107.4
Epoch Time (s)                      233.374
Total Train Time (s)              36160.2
Epoch                               155
------------------------------  -----------------
2019-06-27 10:35:32.486298 UTC | [dialturn] Iteration #155 | Epoch Duration: 233.43698525428772
2019-06-27 10:35:32.486505 UTC | [dialturn] Iteration #155 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00107205
Z variance train                      0.999956
KL Divergence                         0.000110743
KL Loss                               1.10743e-05
QF Loss                               7.12216e+08
VF Loss                               8.73398e+06
RF Loss                           41126.4
Policy Loss                     -147831
Q Predictions Mean               146437
Q Predictions Std                191904
Q Predictions Max                528408
Q Predictions Min                  3496.16
V Predictions Mean               149494
V Predictions Std                195384
V Predictions Max                530587
V Predictions Min                  4188.31
R Predictions Mean                 1408
R Predictions Std                  3062.11
R Predictions Max                 15309.8
R Predictions Min                  -166.708
Log Pis Mean                         22.9108
Log Pis Std                           9.58707
Log Pis Max                          53.1551
Log Pis Min                          -1.67087
Policy mu Mean                       -1.20589
Policy mu Std                         9.9462
Policy mu Max                        62.4888
Policy mu Min                       -99.5104
Policy log std Mean                  -0.956839
Policy log std Std                    1.04302
Policy log std Max                    2
Policy log std Min                   -6.06376
_task0 Rewards Mean                 143.362
_task0 Rewards Std                  379.076
_task0 Rewards Max                 1794.43
_task0 Rewards Min                   -1.01114
_task0 Returns Mean               21504.3
_task0 Returns Std                53954.8
_task0 Returns Max               193526
_task0 Returns Min                 -128.785
_task0 Actions Mean                  -0.0926031
_task0 Actions Std                    0.782993
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1329.53
Exploration_task0 Rewards Std      3230.23
Exploration_task0 Rewards Max     22810.2
Exploration_task0 Rewards Min        -9.60176
Exploration_task0 Returns Mean   201443
Exploration_task0 Returns Std    453493
Exploration_task0 Returns Max         2.47408e+06
Exploration_task0 Returns Min     -1081.66
Exploration_task0 Actions Mean       -0.200144
Exploration_task0 Actions Std         0.827488
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21504.3
AverageReturn_all_train_tasks     17739.8
AverageReturn_all_test_tasks      21504.3
Number of train steps total      157000
Number of env steps total             7.851e+06
Number of rollouts total          56997
Train Time (s)                      101.501
(Previous) Eval Time (s)             25.8572
Sample Time (s)                     107.664
Epoch Time (s)                      235.023
Total Train Time (s)              36395.2
Epoch                               156
------------------------------  -----------------
2019-06-27 10:39:27.479118 UTC | [dialturn] Iteration #156 | Epoch Duration: 234.99245810508728
2019-06-27 10:39:27.479348 UTC | [dialturn] Iteration #156 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00042255
Z variance train                      0.99871
KL Divergence                         4.92224e-05
KL Loss                               4.92224e-06
QF Loss                               7.97796e+08
VF Loss                               3.47501e+06
RF Loss                           55401.5
Policy Loss                     -151894
Q Predictions Mean               149892
Q Predictions Std                197115
Q Predictions Max                539370
Q Predictions Min                  3231.24
V Predictions Mean               150952
V Predictions Std                198342
V Predictions Max                536015
V Predictions Min                  4152.92
R Predictions Mean                  894.365
R Predictions Std                  2388.24
R Predictions Max                 19010.9
R Predictions Min                   -71.3677
Log Pis Mean                         22.4277
Log Pis Std                           9.90654
Log Pis Max                          52.765
Log Pis Min                          -4.23802
Policy mu Mean                       -0.419042
Policy mu Std                         8.4802
Policy mu Max                        60.1619
Policy mu Min                       -89.0213
Policy log std Mean                  -0.947307
Policy log std Std                    1.02917
Policy log std Max                    2
Policy log std Min                   -6.14701
_task0 Rewards Mean                  61.995
_task0 Rewards Std                  126.969
_task0 Rewards Max                  541.24
_task0 Rewards Min                   -0.862899
_task0 Returns Mean                9299.25
_task0 Returns Std                18475.3
_task0 Returns Max                64067.3
_task0 Returns Min                  -90.4061
_task0 Actions Mean                  -0.232979
_task0 Actions Std                    0.798361
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1465.23
Exploration_task0 Rewards Std      3838.48
Exploration_task0 Rewards Max     23061.5
Exploration_task0 Rewards Min       -10.6529
Exploration_task0 Returns Mean   222005
Exploration_task0 Returns Std    541589
Exploration_task0 Returns Max         2.62359e+06
Exploration_task0 Returns Min     -1416.53
Exploration_task0 Actions Mean       -0.0971188
Exploration_task0 Actions Std         0.828786
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               9299.25
AverageReturn_all_train_tasks      2279.46
AverageReturn_all_test_tasks       9299.25
Number of train steps total      158000
Number of env steps total             7.901e+06
Number of rollouts total          57360
Train Time (s)                      101.184
(Previous) Eval Time (s)             25.8255
Sample Time (s)                     107.402
Epoch Time (s)                      234.412
Total Train Time (s)              36629.5
Epoch                               157
------------------------------  -----------------
2019-06-27 10:43:21.775636 UTC | [dialturn] Iteration #157 | Epoch Duration: 234.29613375663757
2019-06-27 10:43:21.775842 UTC | [dialturn] Iteration #157 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00141027
Z variance train                      0.99876
KL Divergence                         0.000438677
KL Loss                               4.38677e-05
QF Loss                               1.12981e+09
VF Loss                               3.82698e+06
RF Loss                           60484.9
Policy Loss                     -152028
Q Predictions Mean               150428
Q Predictions Std                199466
Q Predictions Max                544978
Q Predictions Min                  3700.6
V Predictions Mean               150887
V Predictions Std                200087
V Predictions Max                543022
V Predictions Min                  4146.29
R Predictions Mean                  874.454
R Predictions Std                  2422.83
R Predictions Max                 20607.9
R Predictions Min                  -108.006
Log Pis Mean                         22.2831
Log Pis Std                          10.4197
Log Pis Max                          51.7099
Log Pis Min                          -2.29452
Policy mu Mean                       -0.42934
Policy mu Std                         8.36714
Policy mu Max                        61.0015
Policy mu Min                       -97.2665
Policy log std Mean                  -0.951568
Policy log std Std                    1.02117
Policy log std Max                    2
Policy log std Min                   -5.08303
_task0 Rewards Mean                 129.272
_task0 Rewards Std                  345.04
_task0 Rewards Max                 1574.21
_task0 Rewards Min                   -0.766075
_task0 Returns Mean               19390.8
_task0 Returns Std                49659.3
_task0 Returns Max               165021
_task0 Returns Min                  -92.6865
_task0 Actions Mean                  -0.200461
_task0 Actions Std                    0.826791
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1208.95
Exploration_task0 Rewards Std      2657.02
Exploration_task0 Rewards Max     22941.5
Exploration_task0 Rewards Min        -9.80043
Exploration_task0 Returns Mean   183174
Exploration_task0 Returns Std    377895
Exploration_task0 Returns Max         1.8365e+06
Exploration_task0 Returns Min     -1206
Exploration_task0 Actions Mean       -0.0835016
Exploration_task0 Actions Std         0.854638
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19390.8
AverageReturn_all_train_tasks      2852.82
AverageReturn_all_test_tasks      19390.8
Number of train steps total      159000
Number of env steps total             7.951e+06
Number of rollouts total          57723
Train Time (s)                       99.8466
(Previous) Eval Time (s)             25.7085
Sample Time (s)                     106.99
Epoch Time (s)                      232.545
Total Train Time (s)              36861.9
Epoch                               158
------------------------------  -----------------
2019-06-27 10:47:14.168964 UTC | [dialturn] Iteration #158 | Epoch Duration: 232.39296436309814
2019-06-27 10:47:14.169172 UTC | [dialturn] Iteration #158 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000542666
Z variance train                      0.999547
KL Divergence                         4.96088e-05
KL Loss                               4.96088e-06
QF Loss                               8.09186e+08
VF Loss                               3.96426e+06
RF Loss                           24437.9
Policy Loss                     -154712
Q Predictions Mean               152604
Q Predictions Std                203604
Q Predictions Max                552654
Q Predictions Min                  3192.46
V Predictions Mean               153621
V Predictions Std                204819
V Predictions Max                552417
V Predictions Min                  4102.2
R Predictions Mean                  677.657
R Predictions Std                  1976.7
R Predictions Max                 16338.7
R Predictions Min                  -131.675
Log Pis Mean                         23.5262
Log Pis Std                           9.96564
Log Pis Max                          56.3911
Log Pis Min                          -2.26716
Policy mu Mean                       -0.770036
Policy mu Std                         8.54726
Policy mu Max                        75.7841
Policy mu Min                       -98.6376
Policy log std Mean                  -0.912758
Policy log std Std                    1.104
Policy log std Max                    2
Policy log std Min                   -4.83693
_task0 Rewards Mean                 118.128
_task0 Rewards Std                  233.844
_task0 Rewards Max                  810.639
_task0 Rewards Min                   -0.72937
_task0 Returns Mean               17719.2
_task0 Returns Std                33994.9
_task0 Returns Max               100536
_task0 Returns Min                  -83.059
_task0 Actions Mean                  -0.0609575
_task0 Actions Std                    0.795524
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1271.66
Exploration_task0 Rewards Std      3243.67
Exploration_task0 Rewards Max     21532.4
Exploration_task0 Rewards Min       -10.1989
Exploration_task0 Returns Mean   192675
Exploration_task0 Returns Std    457264
Exploration_task0 Returns Max         2.1202e+06
Exploration_task0 Returns Min     -1245.22
Exploration_task0 Actions Mean       -0.123543
Exploration_task0 Actions Std         0.851392
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17719.2
AverageReturn_all_train_tasks     10917.6
AverageReturn_all_test_tasks      17719.2
Number of train steps total      160000
Number of env steps total             8.001e+06
Number of rollouts total          58086
Train Time (s)                      101.636
(Previous) Eval Time (s)             25.5551
Sample Time (s)                     107.087
Epoch Time (s)                      234.278
Total Train Time (s)              37096.4
Epoch                               159
------------------------------  -----------------
2019-06-27 10:51:08.675127 UTC | [dialturn] Iteration #159 | Epoch Duration: 234.50578999519348
2019-06-27 10:51:08.675393 UTC | [dialturn] Iteration #159 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000450744
Z variance train                      1.00024
KL Divergence                         1.61282e-05
KL Loss                               1.61282e-06
QF Loss                               1.48863e+09
VF Loss                               1.66361e+06
RF Loss                          284591
Policy Loss                     -154960
Q Predictions Mean               153285
Q Predictions Std                204939
Q Predictions Max                565262
Q Predictions Min                  3372.58
V Predictions Mean               154971
V Predictions Std                206686
V Predictions Max                564215
V Predictions Min                  3228.7
R Predictions Mean                 1359.62
R Predictions Std                  3139.2
R Predictions Max                 18050.1
R Predictions Min                  -104.312
Log Pis Mean                         23.7355
Log Pis Std                           9.61661
Log Pis Max                          57.0122
Log Pis Min                          -2.0105
Policy mu Mean                       -0.868257
Policy mu Std                        10.0225
Policy mu Max                        68.4226
Policy mu Min                      -107.17
Policy log std Mean                  -0.89007
Policy log std Std                    1.13885
Policy log std Max                    2
Policy log std Min                   -7.27987
_task0 Rewards Mean                 195.061
_task0 Rewards Std                  421.475
_task0 Rewards Max                 1809.44
_task0 Rewards Min                   -0.969358
_task0 Returns Mean               29259.2
_task0 Returns Std                59758.1
_task0 Returns Max               191892
_task0 Returns Min                 -114.78
_task0 Actions Mean                  -0.148904
_task0 Actions Std                    0.84196
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      914.901
Exploration_task0 Rewards Std      2527.67
Exploration_task0 Rewards Max     23071.8
Exploration_task0 Rewards Min       -10.6076
Exploration_task0 Returns Mean   138621
Exploration_task0 Returns Std    346389
Exploration_task0 Returns Max         2.54654e+06
Exploration_task0 Returns Min     -1037.01
Exploration_task0 Actions Mean       -0.123119
Exploration_task0 Actions Std         0.867602
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              29259.2
AverageReturn_all_train_tasks     36866.3
AverageReturn_all_test_tasks      29259.2
Number of train steps total      161000
Number of env steps total             8.051e+06
Number of rollouts total          58449
Train Time (s)                      101.746
(Previous) Eval Time (s)             25.7815
Sample Time (s)                     107.307
Epoch Time (s)                      234.835
Total Train Time (s)              37331.2
Epoch                               160
------------------------------  -----------------
2019-06-27 10:55:03.513584 UTC | [dialturn] Iteration #160 | Epoch Duration: 234.83797597885132
2019-06-27 10:55:03.513797 UTC | [dialturn] Iteration #160 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00108557
Z variance train                      0.999495
KL Divergence                         0.00020587
KL Loss                               2.0587e-05
QF Loss                               5.02149e+08
VF Loss                               8.93525e+06
RF Loss                          171453
Policy Loss                     -154119
Q Predictions Mean               152467
Q Predictions Std                207080
Q Predictions Max                566071
Q Predictions Min                  3007.73
V Predictions Mean               155638
V Predictions Std                210922
V Predictions Max                569700
V Predictions Min                  3790.05
R Predictions Mean                 1609.88
R Predictions Std                  3352.18
R Predictions Max                 16395.9
R Predictions Min                   -54.9159
Log Pis Mean                         22.535
Log Pis Std                           9.78539
Log Pis Max                          54.2332
Log Pis Min                          -4.64633
Policy mu Mean                       -0.961328
Policy mu Std                         9.55278
Policy mu Max                        63.3145
Policy mu Min                      -127.451
Policy log std Mean                  -0.966518
Policy log std Std                    1.11335
Policy log std Max                    2
Policy log std Min                   -6.00108
_task0 Rewards Mean                 189.864
_task0 Rewards Std                  355.668
_task0 Rewards Max                 1749.79
_task0 Rewards Min                   -0.646536
_task0 Returns Mean               28479.6
_task0 Returns Std                50322.5
_task0 Returns Max               166138
_task0 Returns Min                  -78.2255
_task0 Actions Mean                  -0.114187
_task0 Actions Std                    0.844661
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1449.48
Exploration_task0 Rewards Std      3268.54
Exploration_task0 Rewards Max     22296.7
Exploration_task0 Rewards Min       -12.464
Exploration_task0 Returns Mean   219618
Exploration_task0 Returns Std    464682
Exploration_task0 Returns Max         2.35259e+06
Exploration_task0 Returns Min     -1459.28
Exploration_task0 Actions Mean       -0.117252
Exploration_task0 Actions Std         0.852453
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              28479.6
AverageReturn_all_train_tasks     30905.3
AverageReturn_all_test_tasks      28479.6
Number of train steps total      162000
Number of env steps total             8.101e+06
Number of rollouts total          58812
Train Time (s)                      102.376
(Previous) Eval Time (s)             25.7834
Sample Time (s)                     107.408
Epoch Time (s)                      235.568
Total Train Time (s)              37566.7
Epoch                               161
------------------------------  -----------------
2019-06-27 10:58:59.025828 UTC | [dialturn] Iteration #161 | Epoch Duration: 235.5118203163147
2019-06-27 10:58:59.026025 UTC | [dialturn] Iteration #161 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00118977
Z variance train                      1.00013
KL Divergence                         0.000138335
KL Loss                               1.38335e-05
QF Loss                               1.11101e+09
VF Loss                               2.97615e+06
RF Loss                          200598
Policy Loss                     -161841
Q Predictions Mean               160066
Q Predictions Std                214390
Q Predictions Max                578707
Q Predictions Min                  3341.15
V Predictions Mean               162734
V Predictions Std                217461
V Predictions Max                580686
V Predictions Min                  3063.93
R Predictions Mean                 1202.75
R Predictions Std                  2444.16
R Predictions Max                 11998.2
R Predictions Min                  -175.572
Log Pis Mean                         22.9973
Log Pis Std                          10.3888
Log Pis Max                          53.5111
Log Pis Min                          -2.94686
Policy mu Mean                       -0.719014
Policy mu Std                         9.7013
Policy mu Max                        53.026
Policy mu Min                      -147.308
Policy log std Mean                  -0.974275
Policy log std Std                    1.12463
Policy log std Max                    2
Policy log std Min                   -5.65982
_task0 Rewards Mean                 185.36
_task0 Rewards Std                  354.019
_task0 Rewards Max                 1729.55
_task0 Rewards Min                   -0.926444
_task0 Returns Mean               27804
_task0 Returns Std                50804.5
_task0 Returns Max               166103
_task0 Returns Min                 -119.979
_task0 Actions Mean                  -0.0907698
_task0 Actions Std                    0.82871
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      997.281
Exploration_task0 Rewards Std      2700.89
Exploration_task0 Rewards Max     22556.4
Exploration_task0 Rewards Min       -10.7547
Exploration_task0 Returns Mean   151103
Exploration_task0 Returns Std    376441
Exploration_task0 Returns Max         2.34488e+06
Exploration_task0 Returns Min     -1293.74
Exploration_task0 Actions Mean       -0.133512
Exploration_task0 Actions Std         0.86678
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27804
AverageReturn_all_train_tasks      3268.67
AverageReturn_all_test_tasks      27804
Number of train steps total      163000
Number of env steps total             8.151e+06
Number of rollouts total          59175
Train Time (s)                      101.264
(Previous) Eval Time (s)             25.7262
Sample Time (s)                     107.589
Epoch Time (s)                      234.579
Total Train Time (s)              37801.2
Epoch                               162
------------------------------  -----------------
2019-06-27 11:02:53.514287 UTC | [dialturn] Iteration #162 | Epoch Duration: 234.48809909820557
2019-06-27 11:02:53.514509 UTC | [dialturn] Iteration #162 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000361167
Z variance train                      0.99921
KL Divergence                         2.6798e-05
KL Loss                               2.6798e-06
QF Loss                               1.29533e+09
VF Loss                               2.54265e+06
RF Loss                           83419.1
Policy Loss                     -167239
Q Predictions Mean               165611
Q Predictions Std                220690
Q Predictions Max                586937
Q Predictions Min                  2886.93
V Predictions Mean               166696
V Predictions Std                221937
V Predictions Max                582478
V Predictions Min                  3090.73
R Predictions Mean                 1226.93
R Predictions Std                  2794.21
R Predictions Max                 20586.4
R Predictions Min                   -48.7296
Log Pis Mean                         23.9394
Log Pis Std                          10.1636
Log Pis Max                          52.7933
Log Pis Min                           0.913434
Policy mu Mean                       -0.424305
Policy mu Std                         9.83356
Policy mu Max                        49.6105
Policy mu Min                      -117.738
Policy log std Mean                  -0.979932
Policy log std Std                    1.13277
Policy log std Max                    2
Policy log std Min                   -5.84432
_task0 Rewards Mean                 112.375
_task0 Rewards Std                  333.406
_task0 Rewards Max                 2044.43
_task0 Rewards Min                   -0.937312
_task0 Returns Mean               16856.3
_task0 Returns Std                48020.7
_task0 Returns Max               182327
_task0 Returns Min                 -119.096
_task0 Actions Mean                  -0.110716
_task0 Actions Std                    0.868369
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1215.95
Exploration_task0 Rewards Std      2638.89
Exploration_task0 Rewards Max     22949.4
Exploration_task0 Rewards Min       -10.3745
Exploration_task0 Returns Mean   184235
Exploration_task0 Returns Std    372697
Exploration_task0 Returns Max         2.36866e+06
Exploration_task0 Returns Min     -1183.84
Exploration_task0 Actions Mean       -0.059738
Exploration_task0 Actions Std         0.850478
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16856.3
AverageReturn_all_train_tasks      8308.58
AverageReturn_all_test_tasks      16856.3
Number of train steps total      164000
Number of env steps total             8.201e+06
Number of rollouts total          59538
Train Time (s)                      101.144
(Previous) Eval Time (s)             25.6343
Sample Time (s)                     107.391
Epoch Time (s)                      234.169
Total Train Time (s)              38035.4
Epoch                               163
------------------------------  -----------------
2019-06-27 11:06:47.704091 UTC | [dialturn] Iteration #163 | Epoch Duration: 234.18940830230713
2019-06-27 11:06:47.704297 UTC | [dialturn] Iteration #163 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000587151
Z variance train                      1.00023
KL Divergence                         4.71333e-05
KL Loss                               4.71333e-06
QF Loss                               1.24184e+09
VF Loss                               1.5915e+06
RF Loss                          128797
Policy Loss                     -166319
Q Predictions Mean               164835
Q Predictions Std                221308
Q Predictions Max                586616
Q Predictions Min                  3017.42
V Predictions Mean               166560
V Predictions Std                223213
V Predictions Max                587272
V Predictions Min                  3153.24
R Predictions Mean                 1272.31
R Predictions Std                  3338.29
R Predictions Max                 20820.5
R Predictions Min                   -12.9532
Log Pis Mean                         22.496
Log Pis Std                           9.85541
Log Pis Max                          56.659
Log Pis Min                          -4.87773
Policy mu Mean                       -1.14508
Policy mu Std                        12.0053
Policy mu Max                        57.3509
Policy mu Min                      -146.225
Policy log std Mean                  -0.915358
Policy log std Std                    1.16328
Policy log std Max                    2
Policy log std Min                   -6.05692
_task0 Rewards Mean                  65.015
_task0 Rewards Std                  149.361
_task0 Rewards Max                  981.646
_task0 Rewards Min                   -0.91131
_task0 Returns Mean                9752.25
_task0 Returns Std                21449.5
_task0 Returns Max                73631.4
_task0 Returns Min                  -91.6879
_task0 Actions Mean                  -0.112188
_task0 Actions Std                    0.857014
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1026.25
Exploration_task0 Rewards Std      2718.58
Exploration_task0 Rewards Max     22992.1
Exploration_task0 Rewards Min       -11.3436
Exploration_task0 Returns Mean   155492
Exploration_task0 Returns Std    385462
Exploration_task0 Returns Max         2.25318e+06
Exploration_task0 Returns Min     -1310.91
Exploration_task0 Actions Mean       -0.0757589
Exploration_task0 Actions Std         0.881081
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               9752.25
AverageReturn_all_train_tasks      6194.51
AverageReturn_all_test_tasks       9752.25
Number of train steps total      165000
Number of env steps total             8.251e+06
Number of rollouts total          59901
Train Time (s)                      100.711
(Previous) Eval Time (s)             25.6529
Sample Time (s)                     107.224
Epoch Time (s)                      233.588
Total Train Time (s)              38268.8
Epoch                               164
------------------------------  -----------------
2019-06-27 11:10:41.133577 UTC | [dialturn] Iteration #164 | Epoch Duration: 233.42912435531616
2019-06-27 11:10:41.133776 UTC | [dialturn] Iteration #164 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000555507
Z variance train                      1.00001
KL Divergence                         2.3608e-05
KL Loss                               2.3608e-06
QF Loss                               1.04441e+09
VF Loss                               7.7323e+06
RF Loss                           24310
Policy Loss                     -169224
Q Predictions Mean               167405
Q Predictions Std                225225
Q Predictions Max                596574
Q Predictions Min                  2658.94
V Predictions Mean               170983
V Predictions Std                229243
V Predictions Max                599748
V Predictions Min                  3024.7
R Predictions Mean                  623.692
R Predictions Std                  1931.82
R Predictions Max                 14862.9
R Predictions Min                  -163.383
Log Pis Mean                         22.6075
Log Pis Std                          10.0437
Log Pis Max                          57.4271
Log Pis Min                          -1.3764
Policy mu Mean                       -0.843448
Policy mu Std                        10.5141
Policy mu Max                        96.4704
Policy mu Min                      -168.693
Policy log std Mean                  -1.01047
Policy log std Std                    1.14275
Policy log std Max                    2
Policy log std Min                   -6.16751
_task0 Rewards Mean                 131.273
_task0 Rewards Std                  231.663
_task0 Rewards Max                 1269.83
_task0 Rewards Min                   -0.896954
_task0 Returns Mean               19691
_task0 Returns Std                32653.3
_task0 Returns Max               101805
_task0 Returns Min                  -89.4149
_task0 Actions Mean                  -0.0913915
_task0 Actions Std                    0.827331
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1056.91
Exploration_task0 Rewards Std      2334.58
Exploration_task0 Rewards Max     17988.8
Exploration_task0 Rewards Min       -11.6276
Exploration_task0 Returns Mean   160137
Exploration_task0 Returns Std    330618
Exploration_task0 Returns Max         1.94536e+06
Exploration_task0 Returns Min     -1337.97
Exploration_task0 Actions Mean       -0.171756
Exploration_task0 Actions Std         0.83991
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19691
AverageReturn_all_train_tasks      9928.16
AverageReturn_all_test_tasks      19691
Number of train steps total      166000
Number of env steps total             8.301e+06
Number of rollouts total          60264
Train Time (s)                      100.674
(Previous) Eval Time (s)             25.493
Sample Time (s)                     107.113
Epoch Time (s)                      233.28
Total Train Time (s)              38502.4
Epoch                               165
------------------------------  -----------------
2019-06-27 11:14:34.742451 UTC | [dialturn] Iteration #165 | Epoch Duration: 233.60850024223328
2019-06-27 11:14:34.742666 UTC | [dialturn] Iteration #165 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000650578
Z variance train                      1.00022
KL Divergence                         3.88277e-05
KL Loss                               3.88277e-06
QF Loss                               8.14614e+08
VF Loss                               8.24452e+06
RF Loss                          214626
Policy Loss                     -172485
Q Predictions Mean               170782
Q Predictions Std                225565
Q Predictions Max                600250
Q Predictions Min                   863.001
V Predictions Mean               174117
V Predictions Std                229337
V Predictions Max                604972
V Predictions Min                  3009.49
R Predictions Mean                 1325.54
R Predictions Std                  3120.35
R Predictions Max                 18169.5
R Predictions Min                  -142.287
Log Pis Mean                         22.7956
Log Pis Std                           9.97282
Log Pis Max                          54.4299
Log Pis Min                          -2.02918
Policy mu Mean                       -0.978651
Policy mu Std                        11.8827
Policy mu Max                       176.164
Policy mu Min                      -253.893
Policy log std Mean                  -0.968746
Policy log std Std                    1.15831
Policy log std Max                    2
Policy log std Min                   -5.94562
_task0 Rewards Mean                 225.227
_task0 Rewards Std                  447.927
_task0 Rewards Max                 2269.91
_task0 Rewards Min                   -0.862269
_task0 Returns Mean               33784
_task0 Returns Std                63879.9
_task0 Returns Max               228949
_task0 Returns Min                 -103.211
_task0 Actions Mean                  -0.0728042
_task0 Actions Std                    0.879077
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1074.43
Exploration_task0 Rewards Std      2594.77
Exploration_task0 Rewards Max     22415.1
Exploration_task0 Rewards Min       -11.9281
Exploration_task0 Returns Mean   162792
Exploration_task0 Returns Std    362653
Exploration_task0 Returns Max         2.01744e+06
Exploration_task0 Returns Min     -1429.72
Exploration_task0 Actions Mean       -0.103533
Exploration_task0 Actions Std         0.861516
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              33784
AverageReturn_all_train_tasks     44172.5
AverageReturn_all_test_tasks      33784
Number of train steps total      167000
Number of env steps total             8.351e+06
Number of rollouts total          60627
Train Time (s)                      101.856
(Previous) Eval Time (s)             25.8205
Sample Time (s)                     107.707
Epoch Time (s)                      235.383
Total Train Time (s)              38737.7
Epoch                               166
------------------------------  -----------------
2019-06-27 11:18:30.084136 UTC | [dialturn] Iteration #166 | Epoch Duration: 235.34131288528442
2019-06-27 11:18:30.084383 UTC | [dialturn] Iteration #166 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00111644
Z variance train                      1.00006
KL Divergence                         0.000186313
KL Loss                               1.86313e-05
QF Loss                               1.22997e+09
VF Loss                               1.89576e+07
RF Loss                          205352
Policy Loss                     -180748
Q Predictions Mean               179230
Q Predictions Std                235361
Q Predictions Max                610840
Q Predictions Min                  2741.46
V Predictions Mean               183369
V Predictions Std                240388
V Predictions Max                617358
V Predictions Min                  2972.99
R Predictions Mean                 1928.49
R Predictions Std                  3693.24
R Predictions Max                 18059.4
R Predictions Min                   -27.1123
Log Pis Mean                         22.5082
Log Pis Std                           9.9331
Log Pis Max                          56.221
Log Pis Min                          -5.493
Policy mu Mean                       -0.634104
Policy mu Std                        11.0691
Policy mu Max                        88.1069
Policy mu Min                      -161.18
Policy log std Mean                  -1.00601
Policy log std Std                    1.19397
Policy log std Max                    2
Policy log std Min                   -7.76158
_task0 Rewards Mean                  50.1435
_task0 Rewards Std                  113.03
_task0 Rewards Max                  468.335
_task0 Rewards Min                   -0.934035
_task0 Returns Mean                7521.53
_task0 Returns Std                16570
_task0 Returns Max                58872.3
_task0 Returns Min                 -115.483
_task0 Actions Mean                  -0.135227
_task0 Actions Std                    0.894542
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1531.86
Exploration_task0 Rewards Std      3235.09
Exploration_task0 Rewards Max     23169.4
Exploration_task0 Rewards Min       -11.0536
Exploration_task0 Returns Mean   232100
Exploration_task0 Returns Std    460034
Exploration_task0 Returns Max         2.63276e+06
Exploration_task0 Returns Min     -1557.27
Exploration_task0 Actions Mean       -0.0084036
Exploration_task0 Actions Std         0.8592
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7521.53
AverageReturn_all_train_tasks      6692.32
AverageReturn_all_test_tasks       7521.53
Number of train steps total      168000
Number of env steps total             8.401e+06
Number of rollouts total          60990
Train Time (s)                      101.325
(Previous) Eval Time (s)             25.7773
Sample Time (s)                     107.896
Epoch Time (s)                      234.998
Total Train Time (s)              38972.6
Epoch                               167
------------------------------  -----------------
2019-06-27 11:22:24.940751 UTC | [dialturn] Iteration #167 | Epoch Duration: 234.85617971420288
2019-06-27 11:22:24.940969 UTC | [dialturn] Iteration #167 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000751094
Z variance train                      0.99986
KL Divergence                         0.000138239
KL Loss                               1.38239e-05
QF Loss                               1.20053e+09
VF Loss                               1.0623e+07
RF Loss                          114303
Policy Loss                     -176976
Q Predictions Mean               175485
Q Predictions Std                233079
Q Predictions Max                616965
Q Predictions Min                  3116.26
V Predictions Mean               178883
V Predictions Std                237000
V Predictions Max                621506
V Predictions Min                  3122.32
R Predictions Mean                 1152.4
R Predictions Std                  3009.81
R Predictions Max                 15598.7
R Predictions Min                  -288.933
Log Pis Mean                         23.6535
Log Pis Std                          10.2939
Log Pis Max                          58.6336
Log Pis Min                          -1.46559
Policy mu Mean                       -2.00234
Policy mu Std                        13.8045
Policy mu Max                        62.2498
Policy mu Min                      -157.3
Policy log std Mean                  -0.909856
Policy log std Std                    1.19914
Policy log std Max                    2
Policy log std Min                   -5.6244
_task0 Rewards Mean                 247.348
_task0 Rewards Std                  432.868
_task0 Rewards Max                 1829.72
_task0 Rewards Min                   -0.836703
_task0 Returns Mean               37102.2
_task0 Returns Std                61646.4
_task0 Returns Max               180358
_task0 Returns Min                 -101.294
_task0 Actions Mean                  -0.0747337
_task0 Actions Std                    0.847608
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1288.58
Exploration_task0 Rewards Std      3067.44
Exploration_task0 Rewards Max     22116.7
Exploration_task0 Rewards Min       -11.8799
Exploration_task0 Returns Mean   195239
Exploration_task0 Returns Std    423845
Exploration_task0 Returns Max         1.76805e+06
Exploration_task0 Returns Min     -1478.35
Exploration_task0 Actions Mean       -0.192068
Exploration_task0 Actions Std         0.883425
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              37102.2
AverageReturn_all_train_tasks     14591.6
AverageReturn_all_test_tasks      37102.2
Number of train steps total      169000
Number of env steps total             8.451e+06
Number of rollouts total          61353
Train Time (s)                      100.913
(Previous) Eval Time (s)             25.6336
Sample Time (s)                     107.481
Epoch Time (s)                      234.027
Total Train Time (s)              39206.7
Epoch                               168
------------------------------  -----------------
2019-06-27 11:26:19.011957 UTC | [dialturn] Iteration #168 | Epoch Duration: 234.07083129882812
2019-06-27 11:26:19.012196 UTC | [dialturn] Iteration #168 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000382529
Z variance train                      1.0001
KL Divergence                         1.72046e-05
KL Loss                               1.72046e-06
QF Loss                               1.48274e+09
VF Loss                               1.67471e+07
RF Loss                          129896
Policy Loss                     -181942
Q Predictions Mean               180107
Q Predictions Std                238524
Q Predictions Max                623757
Q Predictions Min                  2792.46
V Predictions Mean               184462
V Predictions Std                243448
V Predictions Max                627409
V Predictions Min                  2592.26
R Predictions Mean                 1085.37
R Predictions Std                  2511.82
R Predictions Max                 14741.3
R Predictions Min                  -137.447
Log Pis Mean                         23.2996
Log Pis Std                          10.3596
Log Pis Max                          61.7972
Log Pis Min                          -2.06473
Policy mu Mean                       -2.04032
Policy mu Std                        15.2693
Policy mu Max                       143.779
Policy mu Min                      -177.556
Policy log std Mean                  -0.896218
Policy log std Std                    1.21966
Policy log std Max                    2
Policy log std Min                   -6.11038
_task0 Rewards Mean                 107.162
_task0 Rewards Std                  205.871
_task0 Rewards Max                 1143.6
_task0 Rewards Min                   -0.826166
_task0 Returns Mean               16074.3
_task0 Returns Std                29858.2
_task0 Returns Max               121092
_task0 Returns Min                 -104.088
_task0 Actions Mean                  -0.0335865
_task0 Actions Std                    0.854507
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1977.69
Exploration_task0 Rewards Std      4042.37
Exploration_task0 Rewards Max     22989.6
Exploration_task0 Rewards Min       -10.8473
Exploration_task0 Returns Mean   299649
Exploration_task0 Returns Std    570089
Exploration_task0 Returns Max         2.24261e+06
Exploration_task0 Returns Min     -1196.1
Exploration_task0 Actions Mean       -0.120916
Exploration_task0 Actions Std         0.83846
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16074.3
AverageReturn_all_train_tasks     29177.6
AverageReturn_all_test_tasks      16074.3
Number of train steps total      170000
Number of env steps total             8.501e+06
Number of rollouts total          61716
Train Time (s)                      101.512
(Previous) Eval Time (s)             25.6756
Sample Time (s)                     107.071
Epoch Time (s)                      234.258
Total Train Time (s)              39441
Epoch                               169
------------------------------  -----------------
2019-06-27 11:30:13.327667 UTC | [dialturn] Iteration #169 | Epoch Duration: 234.31525802612305
2019-06-27 11:30:13.327874 UTC | [dialturn] Iteration #169 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000736082
Z variance train                      0.998435
KL Divergence                         0.000167634
KL Loss                               1.67634e-05
QF Loss                               1.90212e+09
VF Loss                               6.76335e+06
RF Loss                          140910
Policy Loss                     -182079
Q Predictions Mean               180607
Q Predictions Std                242526
Q Predictions Max                630094
Q Predictions Min                  2968.76
V Predictions Mean               183579
V Predictions Std                246197
V Predictions Max                633703
V Predictions Min                  3303.06
R Predictions Mean                 1252.02
R Predictions Std                  2727.97
R Predictions Max                 18504.6
R Predictions Min                   -19.102
Log Pis Mean                         22.9412
Log Pis Std                          10.8032
Log Pis Max                          52.9905
Log Pis Min                          -2.1868
Policy mu Mean                       -1.94343
Policy mu Std                        16.2631
Policy mu Max                        87.5003
Policy mu Min                      -184.08
Policy log std Mean                  -0.909068
Policy log std Std                    1.19729
Policy log std Max                    2
Policy log std Min                   -6.60826
_task0 Rewards Mean                 153.856
_task0 Rewards Std                  278.351
_task0 Rewards Max                 1404.93
_task0 Rewards Min                   -0.823527
_task0 Returns Mean               23078.4
_task0 Returns Std                39449.5
_task0 Returns Max               124511
_task0 Returns Min                  -93.2195
_task0 Actions Mean                  -0.0158738
_task0 Actions Std                    0.845727
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1547.4
Exploration_task0 Rewards Std      3338.92
Exploration_task0 Rewards Max     22366.3
Exploration_task0 Rewards Min       -10.6099
Exploration_task0 Returns Mean   234454
Exploration_task0 Returns Std    476633
Exploration_task0 Returns Max         2.33673e+06
Exploration_task0 Returns Min     -1495.92
Exploration_task0 Actions Mean       -0.087314
Exploration_task0 Actions Std         0.85022
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              23078.4
AverageReturn_all_train_tasks     13158.1
AverageReturn_all_test_tasks      23078.4
Number of train steps total      171000
Number of env steps total             8.551e+06
Number of rollouts total          62079
Train Time (s)                       99.8594
(Previous) Eval Time (s)             25.7317
Sample Time (s)                     106.841
Epoch Time (s)                      232.432
Total Train Time (s)              39673.4
Epoch                               170
------------------------------  -----------------
2019-06-27 11:34:05.786909 UTC | [dialturn] Iteration #170 | Epoch Duration: 232.45887064933777
2019-06-27 11:34:05.787122 UTC | [dialturn] Iteration #170 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000878494
Z variance train                      1.0002
KL Divergence                         0.000123052
KL Loss                               1.23052e-05
QF Loss                               1.26488e+09
VF Loss                               3.08508e+06
RF Loss                          226171
Policy Loss                     -185266
Q Predictions Mean               183518
Q Predictions Std                243579
Q Predictions Max                633188
Q Predictions Min                  3180.73
V Predictions Mean               186143
V Predictions Std                246698
V Predictions Max                632114
V Predictions Min                  3217.13
R Predictions Mean                 1583.47
R Predictions Std                  3144.75
R Predictions Max                 16954.2
R Predictions Min                   -13.5978
Log Pis Mean                         23.1144
Log Pis Std                          10.4125
Log Pis Max                          52.6233
Log Pis Min                          -1.58403
Policy mu Mean                       -1.80095
Policy mu Std                        15.2314
Policy mu Max                       120.086
Policy mu Min                      -185.702
Policy log std Mean                  -0.944808
Policy log std Std                    1.23534
Policy log std Max                    2
Policy log std Min                   -5.70419
_task0 Rewards Mean                  75.7391
_task0 Rewards Std                  257.527
_task0 Rewards Max                 1411.86
_task0 Rewards Min                   -0.885574
_task0 Returns Mean               11360.9
_task0 Returns Std                37125.1
_task0 Returns Max               160682
_task0 Returns Min                 -106.887
_task0 Actions Mean                  -0.175265
_task0 Actions Std                    0.89958
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1713.29
Exploration_task0 Rewards Std      3810.13
Exploration_task0 Rewards Max     22214.2
Exploration_task0 Rewards Min       -10.3059
Exploration_task0 Returns Mean   259589
Exploration_task0 Returns Std    539967
Exploration_task0 Returns Max         2.42338e+06
Exploration_task0 Returns Min     -1197.26
Exploration_task0 Actions Mean       -0.0976517
Exploration_task0 Actions Std         0.881754
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11360.9
AverageReturn_all_train_tasks     39976.2
AverageReturn_all_test_tasks      11360.9
Number of train steps total      172000
Number of env steps total             8.601e+06
Number of rollouts total          62442
Train Time (s)                      101.391
(Previous) Eval Time (s)             25.7571
Sample Time (s)                     107.106
Epoch Time (s)                      234.254
Total Train Time (s)              39907.6
Epoch                               171
------------------------------  -----------------
2019-06-27 11:37:59.928300 UTC | [dialturn] Iteration #171 | Epoch Duration: 234.1410162448883
2019-06-27 11:37:59.928518 UTC | [dialturn] Iteration #171 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000371984
Z variance train                      0.998575
KL Divergence                         6.43993e-05
KL Loss                               6.43993e-06
QF Loss                               1.25265e+09
VF Loss                               3.19409e+06
RF Loss                          112731
Policy Loss                     -189267
Q Predictions Mean               187845
Q Predictions Std                247458
Q Predictions Max                639845
Q Predictions Min                  2599.36
V Predictions Mean               188547
V Predictions Std                248419
V Predictions Max                638465
V Predictions Min                  3099.82
R Predictions Mean                  944.675
R Predictions Std                  2245.23
R Predictions Max                 13067.4
R Predictions Min                   -96.7739
Log Pis Mean                         23.1324
Log Pis Std                          10.8944
Log Pis Max                          52.6018
Log Pis Min                          -1.8867
Policy mu Mean                       -2.17923
Policy mu Std                        16.106
Policy mu Max                        62.4788
Policy mu Min                      -162.361
Policy log std Mean                  -0.880419
Policy log std Std                    1.23612
Policy log std Max                    2
Policy log std Min                   -7.45471
_task0 Rewards Mean                 161.912
_task0 Rewards Std                  325.401
_task0 Rewards Max                 1641.6
_task0 Rewards Min                   -0.900801
_task0 Returns Mean               24286.8
_task0 Returns Std                46772.5
_task0 Returns Max               132765
_task0 Returns Min                 -113.872
_task0 Actions Mean                  -0.073382
_task0 Actions Std                    0.852547
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      978.534
Exploration_task0 Rewards Std      2737.44
Exploration_task0 Rewards Max     23155.6
Exploration_task0 Rewards Min       -11.1113
Exploration_task0 Returns Mean   148263
Exploration_task0 Returns Std    382087
Exploration_task0 Returns Max         2.3525e+06
Exploration_task0 Returns Min     -1244.42
Exploration_task0 Actions Mean       -0.131969
Exploration_task0 Actions Std         0.897131
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              24286.8
AverageReturn_all_train_tasks     25497.1
AverageReturn_all_test_tasks      24286.8
Number of train steps total      173000
Number of env steps total             8.651e+06
Number of rollouts total          62805
Train Time (s)                      101.131
(Previous) Eval Time (s)             25.6423
Sample Time (s)                     107.623
Epoch Time (s)                      234.396
Total Train Time (s)              40142.2
Epoch                               172
------------------------------  -----------------
2019-06-27 11:41:54.604636 UTC | [dialturn] Iteration #172 | Epoch Duration: 234.67594265937805
2019-06-27 11:41:54.604874 UTC | [dialturn] Iteration #172 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00054569
Z variance train                      1.00005
KL Divergence                         3.23853e-05
KL Loss                               3.23853e-06
QF Loss                               2.03698e+09
VF Loss                          990905
RF Loss                          226744
Policy Loss                     -188273
Q Predictions Mean               185934
Q Predictions Std                248656
Q Predictions Max                647699
Q Predictions Min                  2663.16
V Predictions Mean               188082
V Predictions Std                251311
V Predictions Max                643882
V Predictions Min                  1629.23
R Predictions Mean                 1292.25
R Predictions Std                  3423.22
R Predictions Max                 21534
R Predictions Min                  -270.825
Log Pis Mean                         22.6292
Log Pis Std                          10.089
Log Pis Max                          50.387
Log Pis Min                          -1.61084
Policy mu Mean                       -1.88145
Policy mu Std                        15.9125
Policy mu Max                        95.4131
Policy mu Min                      -171.793
Policy log std Mean                  -0.845715
Policy log std Std                    1.2715
Policy log std Max                    2
Policy log std Min                   -6.10552
_task0 Rewards Mean                  53.5856
_task0 Rewards Std                  120.804
_task0 Rewards Max                  564.843
_task0 Rewards Min                   -0.925271
_task0 Returns Mean                8037.84
_task0 Returns Std                17313.2
_task0 Returns Max                63014.7
_task0 Returns Min                 -105.354
_task0 Actions Mean                  -0.0790645
_task0 Actions Std                    0.842991
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1671.1
Exploration_task0 Rewards Std      4031.28
Exploration_task0 Rewards Max     23150.2
Exploration_task0 Rewards Min       -12.0619
Exploration_task0 Returns Mean   253197
Exploration_task0 Returns Std    573203
Exploration_task0 Returns Max         3.25122e+06
Exploration_task0 Returns Min     -1208.2
Exploration_task0 Actions Mean       -0.108648
Exploration_task0 Actions Std         0.876365
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               8037.84
AverageReturn_all_train_tasks     56190
AverageReturn_all_test_tasks       8037.84
Number of train steps total      174000
Number of env steps total             8.701e+06
Number of rollouts total          63168
Train Time (s)                      100.969
(Previous) Eval Time (s)             25.9204
Sample Time (s)                     107.906
Epoch Time (s)                      234.795
Total Train Time (s)              40377
Epoch                               173
------------------------------  -----------------
2019-06-27 11:45:49.350969 UTC | [dialturn] Iteration #173 | Epoch Duration: 234.74587869644165
2019-06-27 11:45:49.351182 UTC | [dialturn] Iteration #173 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000491099
Z variance train                      1.00007
KL Divergence                         2.12672e-05
KL Loss                               2.12672e-06
QF Loss                               2.49441e+09
VF Loss                               1.18807e+07
RF Loss                          220688
Policy Loss                     -193388
Q Predictions Mean               191554
Q Predictions Std                253674
Q Predictions Max                655161
Q Predictions Min                  2988.44
V Predictions Mean               191543
V Predictions Std                253445
V Predictions Max                644763
V Predictions Min                  2876.6
R Predictions Mean                 1096.02
R Predictions Std                  2840.56
R Predictions Max                 19513.7
R Predictions Min                   -89.4903
Log Pis Mean                         23.9112
Log Pis Std                          11.1236
Log Pis Max                          57.3462
Log Pis Min                          -1.46046
Policy mu Mean                       -2.21604
Policy mu Std                        17.3918
Policy mu Max                       146.074
Policy mu Min                      -175.117
Policy log std Mean                  -0.810978
Policy log std Std                    1.28259
Policy log std Max                    2
Policy log std Min                   -7.72646
_task0 Rewards Mean                  97.6159
_task0 Rewards Std                  186.766
_task0 Rewards Max                  962.237
_task0 Rewards Min                   -0.937856
_task0 Returns Mean               14642.4
_task0 Returns Std                26939
_task0 Returns Max               105841
_task0 Returns Min                 -111.452
_task0 Actions Mean                  -0.235139
_task0 Actions Std                    0.842669
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1308.46
Exploration_task0 Rewards Std      3406.78
Exploration_task0 Rewards Max     22960.1
Exploration_task0 Rewards Min       -10.3752
Exploration_task0 Returns Mean   198252
Exploration_task0 Returns Std    478091
Exploration_task0 Returns Max         2.63826e+06
Exploration_task0 Returns Min     -1375.83
Exploration_task0 Actions Mean       -0.0871732
Exploration_task0 Actions Std         0.870753
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14642.4
AverageReturn_all_train_tasks       234.988
AverageReturn_all_test_tasks      14642.4
Number of train steps total      175000
Number of env steps total             8.751e+06
Number of rollouts total          63531
Train Time (s)                      100.819
(Previous) Eval Time (s)             25.8702
Sample Time (s)                     106.293
Epoch Time (s)                      232.982
Total Train Time (s)              40609.9
Epoch                               174
------------------------------  -----------------
2019-06-27 11:49:42.265416 UTC | [dialturn] Iteration #174 | Epoch Duration: 232.9140305519104
2019-06-27 11:49:42.265643 UTC | [dialturn] Iteration #174 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000485637
Z variance train                      0.999905
KL Divergence                         3.38455e-05
KL Loss                               3.38455e-06
QF Loss                               1.12111e+09
VF Loss                               3.52807e+06
RF Loss                          353236
Policy Loss                     -191796
Q Predictions Mean               189942
Q Predictions Std                254453
Q Predictions Max                654855
Q Predictions Min                  2914.66
V Predictions Mean               192267
V Predictions Std                257258
V Predictions Max                656321
V Predictions Min                  2850.26
R Predictions Mean                 1397.56
R Predictions Std                  3668.59
R Predictions Max                 22091.3
R Predictions Min                   -86.599
Log Pis Mean                         23.402
Log Pis Std                          10.712
Log Pis Max                          54.5795
Log Pis Min                          -1.60116
Policy mu Mean                       -2.68968
Policy mu Std                        17.7934
Policy mu Max                       137.837
Policy mu Min                      -166.57
Policy log std Mean                  -0.770379
Policy log std Std                    1.29034
Policy log std Max                    2
Policy log std Min                   -8.05688
_task0 Rewards Mean                 255.77
_task0 Rewards Std                  464.528
_task0 Rewards Max                 1801.84
_task0 Rewards Min                   -0.851928
_task0 Returns Mean               38365.4
_task0 Returns Std                66068.8
_task0 Returns Max               167715
_task0 Returns Min                 -100.354
_task0 Actions Mean                  -0.0785265
_task0 Actions Std                    0.858952
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1776.06
Exploration_task0 Rewards Std      3973.64
Exploration_task0 Rewards Max     22931
Exploration_task0 Rewards Min        -9.79825
Exploration_task0 Returns Mean   269100
Exploration_task0 Returns Std    562306
Exploration_task0 Returns Max         2.66242e+06
Exploration_task0 Returns Min     -1352.76
Exploration_task0 Actions Mean       -0.154707
Exploration_task0 Actions Std         0.842757
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              38365.4
AverageReturn_all_train_tasks     14283
AverageReturn_all_test_tasks      38365.4
Number of train steps total      176000
Number of env steps total             8.801e+06
Number of rollouts total          63894
Train Time (s)                      101.725
(Previous) Eval Time (s)             25.8009
Sample Time (s)                     107.473
Epoch Time (s)                      234.999
Total Train Time (s)              40844.6
Epoch                               175
------------------------------  -----------------
2019-06-27 11:53:36.946575 UTC | [dialturn] Iteration #175 | Epoch Duration: 234.68075346946716
2019-06-27 11:53:36.946784 UTC | [dialturn] Iteration #175 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00123136
Z variance train                      0.999096
KL Divergence                         0.000262152
KL Loss                               2.62152e-05
QF Loss                               1.39641e+09
VF Loss                               4.63938e+06
RF Loss                          220967
Policy Loss                     -198244
Q Predictions Mean               196240
Q Predictions Std                259276
Q Predictions Max                661835
Q Predictions Min                  2209.44
V Predictions Mean               197180
V Predictions Std                260320
V Predictions Max                657991
V Predictions Min                  2346.42
R Predictions Mean                 1460.35
R Predictions Std                  3546.08
R Predictions Max                 20230
R Predictions Min                  -115.527
Log Pis Mean                         23.4494
Log Pis Std                          10.9063
Log Pis Max                          55.0415
Log Pis Min                          -0.594204
Policy mu Mean                       -2.53544
Policy mu Std                        16.3636
Policy mu Max                        66.8067
Policy mu Min                      -176.714
Policy log std Mean                  -0.850065
Policy log std Std                    1.26846
Policy log std Max                    2
Policy log std Min                   -5.78238
_task0 Rewards Mean                  51.3191
_task0 Rewards Std                  139.491
_task0 Rewards Max                  760.66
_task0 Rewards Min                   -0.910869
_task0 Returns Mean                7697.86
_task0 Returns Std                20474.7
_task0 Returns Max                84207.9
_task0 Returns Min                 -106.017
_task0 Actions Mean                  -0.264738
_task0 Actions Std                    0.852325
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      905.419
Exploration_task0 Rewards Std      2642.85
Exploration_task0 Rewards Max     22363.6
Exploration_task0 Rewards Min       -10.1162
Exploration_task0 Returns Mean   137185
Exploration_task0 Returns Std    372074
Exploration_task0 Returns Max         2.16085e+06
Exploration_task0 Returns Min     -1421.21
Exploration_task0 Actions Mean       -0.136803
Exploration_task0 Actions Std         0.874188
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7697.86
AverageReturn_all_train_tasks     17731.9
AverageReturn_all_test_tasks       7697.86
Number of train steps total      177000
Number of env steps total             8.851e+06
Number of rollouts total          64257
Train Time (s)                      101.068
(Previous) Eval Time (s)             25.4809
Sample Time (s)                     107.493
Epoch Time (s)                      234.042
Total Train Time (s)              41078.9
Epoch                               176
------------------------------  -----------------
2019-06-27 11:57:31.317273 UTC | [dialturn] Iteration #176 | Epoch Duration: 234.37033224105835
2019-06-27 11:57:31.317467 UTC | [dialturn] Iteration #176 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00116625
Z variance train                      1.00075
KL Divergence                         0.000191385
KL Loss                               1.91385e-05
QF Loss                               2.00566e+09
VF Loss                               3.43664e+06
RF Loss                           90848
Policy Loss                     -190968
Q Predictions Mean               189579
Q Predictions Std                259912
Q Predictions Max                663691
Q Predictions Min                  1828.45
V Predictions Mean               190782
V Predictions Std                261567
V Predictions Max                661182
V Predictions Min                  2267.69
R Predictions Mean                 1051.44
R Predictions Std                  2759.68
R Predictions Max                 18767.4
R Predictions Min                  -116.752
Log Pis Mean                         22.7511
Log Pis Std                          10.6244
Log Pis Max                          53.8993
Log Pis Min                          -0.837626
Policy mu Mean                       -1.93079
Policy mu Std                        15.028
Policy mu Max                        67.7693
Policy mu Min                      -184.584
Policy log std Mean                  -0.863616
Policy log std Std                    1.24513
Policy log std Max                    2
Policy log std Min                   -6.88862
_task0 Rewards Mean                 225.11
_task0 Rewards Std                  494.323
_task0 Rewards Max                 1834.51
_task0 Rewards Min                   -0.817343
_task0 Returns Mean               33766.6
_task0 Returns Std                70202.2
_task0 Returns Max               205717
_task0 Returns Min                 -100.383
_task0 Actions Mean                  -0.152042
_task0 Actions Std                    0.870213
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1252.6
Exploration_task0 Rewards Std      3288.82
Exploration_task0 Rewards Max     22667
Exploration_task0 Rewards Min       -10.3986
Exploration_task0 Returns Mean   189787
Exploration_task0 Returns Std    462474
Exploration_task0 Returns Max         2.28421e+06
Exploration_task0 Returns Min     -1294.6
Exploration_task0 Actions Mean       -0.156605
Exploration_task0 Actions Std         0.870597
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              33766.6
AverageReturn_all_train_tasks      7705.77
AverageReturn_all_test_tasks      33766.6
Number of train steps total      178000
Number of env steps total             8.901e+06
Number of rollouts total          64620
Train Time (s)                      101.734
(Previous) Eval Time (s)             25.8079
Sample Time (s)                     107.405
Epoch Time (s)                      234.947
Total Train Time (s)              41313.8
Epoch                               177
------------------------------  -----------------
2019-06-27 12:01:26.227466 UTC | [dialturn] Iteration #177 | Epoch Duration: 234.9098401069641
2019-06-27 12:01:26.227680 UTC | [dialturn] Iteration #177 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000699756
Z variance train                      1.00001
KL Divergence                         5.1715e-05
KL Loss                               5.1715e-06
QF Loss                               1.63563e+09
VF Loss                               1.48727e+06
RF Loss                          134793
Policy Loss                     -198146
Q Predictions Mean               195911
Q Predictions Std                260058
Q Predictions Max                663625
Q Predictions Min                  1596.58
V Predictions Mean               198161
V Predictions Std                262809
V Predictions Max                663568
V Predictions Min                  2274.09
R Predictions Mean                 1087.4
R Predictions Std                  2575.02
R Predictions Max                 17976.4
R Predictions Min                   -17.6208
Log Pis Mean                         24.1067
Log Pis Std                          10.5479
Log Pis Max                          55.2632
Log Pis Min                          -3.18385
Policy mu Mean                       -2.27217
Policy mu Std                        14.9842
Policy mu Max                        81.7942
Policy mu Min                      -166.6
Policy log std Mean                  -0.811062
Policy log std Std                    1.24549
Policy log std Max                    2
Policy log std Min                   -5.46495
_task0 Rewards Mean                  94.7803
_task0 Rewards Std                  248.977
_task0 Rewards Max                 1056.3
_task0 Rewards Min                   -0.853225
_task0 Returns Mean               14217
_task0 Returns Std                35562.9
_task0 Returns Max               122122
_task0 Returns Min                 -110.33
_task0 Actions Mean                  -0.155089
_task0 Actions Std                    0.879979
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      944.083
Exploration_task0 Rewards Std      2469.58
Exploration_task0 Rewards Max     23146.7
Exploration_task0 Rewards Min        -9.40101
Exploration_task0 Returns Mean   143043
Exploration_task0 Returns Std    349976
Exploration_task0 Returns Max         2.24943e+06
Exploration_task0 Returns Min     -1325.31
Exploration_task0 Actions Mean       -0.202027
Exploration_task0 Actions Std         0.862007
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14217
AverageReturn_all_train_tasks     27266.5
AverageReturn_all_test_tasks      14217
Number of train steps total      179000
Number of env steps total             8.951e+06
Number of rollouts total          64983
Train Time (s)                      100.682
(Previous) Eval Time (s)             25.7697
Sample Time (s)                     107.834
Epoch Time (s)                      234.286
Total Train Time (s)              41548.1
Epoch                               178
------------------------------  -----------------
2019-06-27 12:05:20.522203 UTC | [dialturn] Iteration #178 | Epoch Duration: 234.29435896873474
2019-06-27 12:05:20.522407 UTC | [dialturn] Iteration #178 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000463133
Z variance train                      1.00027
KL Divergence                         2.06371e-05
KL Loss                               2.06371e-06
QF Loss                               1.52619e+09
VF Loss                               3.75217e+06
RF Loss                          157818
Policy Loss                     -188990
Q Predictions Mean               187313
Q Predictions Std                256226
Q Predictions Max                663112
Q Predictions Min                  2176.9
V Predictions Mean               189954
V Predictions Std                259115
V Predictions Max                664445
V Predictions Min                  2327.18
R Predictions Mean                 1165.14
R Predictions Std                  2660.09
R Predictions Max                 15310.1
R Predictions Min                   -98.3765
Log Pis Mean                         23.9373
Log Pis Std                          10.4879
Log Pis Max                          56.4788
Log Pis Min                          -1.26637
Policy mu Mean                       -1.52765
Policy mu Std                        13.8437
Policy mu Max                        85.5517
Policy mu Min                      -191.159
Policy log std Mean                  -0.834248
Policy log std Std                    1.22013
Policy log std Max                    2
Policy log std Min                   -6.39143
_task0 Rewards Mean                 144.172
_task0 Rewards Std                  359.223
_task0 Rewards Max                 1934.16
_task0 Rewards Min                   -0.919575
_task0 Returns Mean               21625.7
_task0 Returns Std                51294
_task0 Returns Max               200989
_task0 Returns Min                 -116.302
_task0 Actions Mean                  -0.194566
_task0 Actions Std                    0.81062
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1069.57
Exploration_task0 Rewards Std      2680.23
Exploration_task0 Rewards Max     22672.6
Exploration_task0 Rewards Min        -9.33688
Exploration_task0 Returns Mean   162056
Exploration_task0 Returns Std    383128
Exploration_task0 Returns Max         2.32989e+06
Exploration_task0 Returns Min     -1526.13
Exploration_task0 Actions Mean       -0.14062
Exploration_task0 Actions Std         0.884597
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21625.7
AverageReturn_all_train_tasks     10149.7
AverageReturn_all_test_tasks      21625.7
Number of train steps total      180000
Number of env steps total             9.001e+06
Number of rollouts total          65346
Train Time (s)                      101.125
(Previous) Eval Time (s)             25.7765
Sample Time (s)                     108.204
Epoch Time (s)                      235.106
Total Train Time (s)              41783.2
Epoch                               179
------------------------------  -----------------
2019-06-27 12:09:15.633230 UTC | [dialturn] Iteration #179 | Epoch Duration: 235.11064529418945
2019-06-27 12:09:15.633440 UTC | [dialturn] Iteration #179 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00092413
Z variance train                      1.00015
KL Divergence                         0.00010865
KL Loss                               1.0865e-05
QF Loss                               1.84662e+09
VF Loss                               4.39184e+06
RF Loss                          188510
Policy Loss                     -192264
Q Predictions Mean               190256
Q Predictions Std                257880
Q Predictions Max                668090
Q Predictions Min                  1864.85
V Predictions Mean               191254
V Predictions Std                258979
V Predictions Max                663818
V Predictions Min                  1515.24
R Predictions Mean                 1582.31
R Predictions Std                  3656.68
R Predictions Max                 20745.9
R Predictions Min                  -169.273
Log Pis Mean                         24.0003
Log Pis Std                          10.9773
Log Pis Max                          56.5287
Log Pis Min                          -1.31351
Policy mu Mean                       -2.17794
Policy mu Std                        17.0946
Policy mu Max                       103.968
Policy mu Min                      -225.812
Policy log std Mean                  -0.78939
Policy log std Std                    1.23144
Policy log std Max                    2
Policy log std Min                   -6.60539
_task0 Rewards Mean                 161.15
_task0 Rewards Std                  331.997
_task0 Rewards Max                 1817.8
_task0 Rewards Min                   -0.874234
_task0 Returns Mean               24172.6
_task0 Returns Std                47266.1
_task0 Returns Max               181049
_task0 Returns Min                 -107.066
_task0 Actions Mean                  -0.175198
_task0 Actions Std                    0.854622
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1317.72
Exploration_task0 Rewards Std      3660.11
Exploration_task0 Rewards Max     22902.8
Exploration_task0 Rewards Min        -9.42131
Exploration_task0 Returns Mean   199654
Exploration_task0 Returns Std    517330
Exploration_task0 Returns Max         2.24269e+06
Exploration_task0 Returns Min     -1539.8
Exploration_task0 Actions Mean       -0.226115
Exploration_task0 Actions Std         0.881396
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              24172.6
AverageReturn_all_train_tasks     54930
AverageReturn_all_test_tasks      24172.6
Number of train steps total      181000
Number of env steps total             9.051e+06
Number of rollouts total          65709
Train Time (s)                      101.249
(Previous) Eval Time (s)             25.7799
Sample Time (s)                     107.214
Epoch Time (s)                      234.243
Total Train Time (s)              42017.5
Epoch                               180
------------------------------  -----------------
2019-06-27 12:13:09.849566 UTC | [dialturn] Iteration #180 | Epoch Duration: 234.2159686088562
2019-06-27 12:13:09.849766 UTC | [dialturn] Iteration #180 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000668455
Z variance train                      1.00046
KL Divergence                         7.09678e-05
KL Loss                               7.09678e-06
QF Loss                               1.16899e+09
VF Loss                               9.78644e+06
RF Loss                           50468.6
Policy Loss                     -192940
Q Predictions Mean               190729
Q Predictions Std                258904
Q Predictions Max                667563
Q Predictions Min                  1120.22
V Predictions Mean               194823
V Predictions Std                263709
V Predictions Max                670010
V Predictions Min                  1011.23
R Predictions Mean                 1233.62
R Predictions Std                  3367.98
R Predictions Max                 20194.6
R Predictions Min                  -174.087
Log Pis Mean                         24.4279
Log Pis Std                          10.8881
Log Pis Max                          57.5586
Log Pis Min                          -0.697364
Policy mu Mean                       -1.6604
Policy mu Std                        15.8455
Policy mu Max                       107.434
Policy mu Min                      -226.589
Policy log std Mean                  -0.749554
Policy log std Std                    1.19162
Policy log std Max                    2
Policy log std Min                   -7.01976
_task0 Rewards Mean                 210.519
_task0 Rewards Std                  454.93
_task0 Rewards Max                 2191.6
_task0 Rewards Min                   -1.09907
_task0 Returns Mean               31577.8
_task0 Returns Std                63320.7
_task0 Returns Max               196998
_task0 Returns Min                 -117.668
_task0 Actions Mean                  -0.0804281
_task0 Actions Std                    0.886854
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      800.465
Exploration_task0 Rewards Std      2085.17
Exploration_task0 Rewards Max     23118.8
Exploration_task0 Rewards Min        -9.42046
Exploration_task0 Returns Mean   121283
Exploration_task0 Returns Std    288051
Exploration_task0 Returns Max         2.28445e+06
Exploration_task0 Returns Min     -1478.54
Exploration_task0 Actions Mean       -0.126496
Exploration_task0 Actions Std         0.89331
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              31577.8
AverageReturn_all_train_tasks     42422
AverageReturn_all_test_tasks      31577.8
Number of train steps total      182000
Number of env steps total             9.101e+06
Number of rollouts total          66072
Train Time (s)                      100.65
(Previous) Eval Time (s)             25.7513
Sample Time (s)                     107.705
Epoch Time (s)                      234.106
Total Train Time (s)              42251.4
Epoch                               181
------------------------------  -----------------
2019-06-27 12:17:03.825726 UTC | [dialturn] Iteration #181 | Epoch Duration: 233.97580528259277
2019-06-27 12:17:03.825934 UTC | [dialturn] Iteration #181 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00127076
Z variance train                      1.00057
KL Divergence                         0.000288603
KL Loss                               2.88603e-05
QF Loss                               1.30476e+09
VF Loss                               3.63779e+06
RF Loss                           89258.1
Policy Loss                     -192500
Q Predictions Mean               190450
Q Predictions Std                260677
Q Predictions Max                670606
Q Predictions Min                   984.81
V Predictions Mean               191480
V Predictions Std                262137
V Predictions Max                669214
V Predictions Min                  1751.9
R Predictions Mean                 1243.32
R Predictions Std                  2922.41
R Predictions Max                 16299.6
R Predictions Min                   -41.2049
Log Pis Mean                         23.5383
Log Pis Std                          10.4107
Log Pis Max                          55.6687
Log Pis Min                          -0.478289
Policy mu Mean                       -1.34611
Policy mu Std                        14.8452
Policy mu Max                        99.682
Policy mu Min                      -215.278
Policy log std Mean                  -0.746183
Policy log std Std                    1.18212
Policy log std Max                    2
Policy log std Min                   -5.35825
_task0 Rewards Mean                 155.819
_task0 Rewards Std                  364.656
_task0 Rewards Max                 1680.02
_task0 Rewards Min                   -0.861954
_task0 Returns Mean               23372.9
_task0 Returns Std                52504.9
_task0 Returns Max               185574
_task0 Returns Min                 -110.876
_task0 Actions Mean                  -0.111818
_task0 Actions Std                    0.880813
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1316.05
Exploration_task0 Rewards Std      3253.11
Exploration_task0 Rewards Max     22345.1
Exploration_task0 Rewards Min        -9.92706
Exploration_task0 Returns Mean   199402
Exploration_task0 Returns Std    459371
Exploration_task0 Returns Max         2.21521e+06
Exploration_task0 Returns Min     -1140.93
Exploration_task0 Actions Mean       -0.177986
Exploration_task0 Actions Std         0.875171
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              23372.9
AverageReturn_all_train_tasks     27847.8
AverageReturn_all_test_tasks      23372.9
Number of train steps total      183000
Number of env steps total             9.151e+06
Number of rollouts total          66435
Train Time (s)                      101
(Previous) Eval Time (s)             25.6196
Sample Time (s)                     107.437
Epoch Time (s)                      234.056
Total Train Time (s)              42485.4
Epoch                               182
------------------------------  -----------------
2019-06-27 12:20:57.764297 UTC | [dialturn] Iteration #182 | Epoch Duration: 233.93818306922913
2019-06-27 12:20:57.764546 UTC | [dialturn] Iteration #182 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00123164
Z variance train                      0.999354
KL Divergence                         0.000182253
KL Loss                               1.82253e-05
QF Loss                               1.13275e+09
VF Loss                               3.96168e+06
RF Loss                           42215.8
Policy Loss                     -192250
Q Predictions Mean               189708
Q Predictions Std                261380
Q Predictions Max                678257
Q Predictions Min                  1632.01
V Predictions Mean               191611
V Predictions Std                263624
V Predictions Max                672903
V Predictions Min                  1756.8
R Predictions Mean                 1036.47
R Predictions Std                  2693.08
R Predictions Max                 16203.3
R Predictions Min                  -125.947
Log Pis Mean                         23.3689
Log Pis Std                          10.5479
Log Pis Max                          51.9278
Log Pis Min                          -1.707
Policy mu Mean                       -0.919585
Policy mu Std                        14.2049
Policy mu Max                        80.9898
Policy mu Min                      -220.126
Policy log std Mean                  -0.751355
Policy log std Std                    1.10418
Policy log std Max                    2
Policy log std Min                   -6.7708
_task0 Rewards Mean                 210.605
_task0 Rewards Std                  493.656
_task0 Rewards Max                 2255.76
_task0 Rewards Min                   -0.86027
_task0 Returns Mean               31590.8
_task0 Returns Std                70098.2
_task0 Returns Max               245124
_task0 Returns Min                 -107.485
_task0 Actions Mean                  -0.141242
_task0 Actions Std                    0.86462
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1604.39
Exploration_task0 Rewards Std      3435.75
Exploration_task0 Rewards Max     22679.4
Exploration_task0 Rewards Min       -10.8158
Exploration_task0 Returns Mean   243090
Exploration_task0 Returns Std    484641
Exploration_task0 Returns Max         2.3301e+06
Exploration_task0 Returns Min     -1340.56
Exploration_task0 Actions Mean       -0.0945046
Exploration_task0 Actions Std         0.862334
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              31590.8
AverageReturn_all_train_tasks      4079.33
AverageReturn_all_test_tasks      31590.8
Number of train steps total      184000
Number of env steps total             9.201e+06
Number of rollouts total          66798
Train Time (s)                      101.165
(Previous) Eval Time (s)             25.4999
Sample Time (s)                     107.239
Epoch Time (s)                      233.904
Total Train Time (s)              42719.5
Epoch                               183
------------------------------  -----------------
2019-06-27 12:24:51.895340 UTC | [dialturn] Iteration #183 | Epoch Duration: 234.13061785697937
2019-06-27 12:24:51.895547 UTC | [dialturn] Iteration #183 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00100556
Z variance train                      0.999077
KL Divergence                         0.000151381
KL Loss                               1.51381e-05
QF Loss                               1.81891e+09
VF Loss                               3.27565e+06
RF Loss                          164532
Policy Loss                     -194962
Q Predictions Mean               192746
Q Predictions Std                262202
Q Predictions Max                678460
Q Predictions Min                   944.199
V Predictions Mean               193924
V Predictions Std                263923
V Predictions Max                674939
V Predictions Min                   581.394
R Predictions Mean                 1128.37
R Predictions Std                  2845.59
R Predictions Max                 20106.7
R Predictions Min                  -234.558
Log Pis Mean                         23.7704
Log Pis Std                          10.558
Log Pis Max                          53.251
Log Pis Min                          -0.301851
Policy mu Mean                       -0.643428
Policy mu Std                        11.9387
Policy mu Max                        89.9366
Policy mu Min                      -208.052
Policy log std Mean                  -0.740418
Policy log std Std                    1.10668
Policy log std Max                    2
Policy log std Min                   -4.85023
_task0 Rewards Mean                  97.2238
_task0 Rewards Std                  189.601
_task0 Rewards Max                  909.096
_task0 Rewards Min                   -0.967557
_task0 Returns Mean               14583.6
_task0 Returns Std                26998.7
_task0 Returns Max                73191.2
_task0 Returns Min                 -111.027
_task0 Actions Mean                  -0.0684541
_task0 Actions Std                    0.877193
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      801.065
Exploration_task0 Rewards Std      2508.74
Exploration_task0 Rewards Max     22699.9
Exploration_task0 Rewards Min        -9.0669
Exploration_task0 Returns Mean   121374
Exploration_task0 Returns Std    350648
Exploration_task0 Returns Max         2.21151e+06
Exploration_task0 Returns Min     -1278.65
Exploration_task0 Actions Mean       -0.202396
Exploration_task0 Actions Std         0.875891
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14583.6
AverageReturn_all_train_tasks     12776.2
AverageReturn_all_test_tasks      14583.6
Number of train steps total      185000
Number of env steps total             9.251e+06
Number of rollouts total          67161
Train Time (s)                      100.851
(Previous) Eval Time (s)             25.7246
Sample Time (s)                     107.837
Epoch Time (s)                      234.413
Total Train Time (s)              42953.9
Epoch                               184
------------------------------  -----------------
2019-06-27 12:28:46.330046 UTC | [dialturn] Iteration #184 | Epoch Duration: 234.43433737754822
2019-06-27 12:28:46.330266 UTC | [dialturn] Iteration #184 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000497493
Z variance train                      0.999396
KL Divergence                         3.69077e-05
KL Loss                               3.69077e-06
QF Loss                               2.2055e+09
VF Loss                               9.66122e+06
RF Loss                          149119
Policy Loss                     -197682
Q Predictions Mean               195553
Q Predictions Std                264329
Q Predictions Max                680034
Q Predictions Min                  1000.08
V Predictions Mean               195904
V Predictions Std                264572
V Predictions Max                677099
V Predictions Min                  1454.06
R Predictions Mean                 1463.38
R Predictions Std                  3430.09
R Predictions Max                 16035.6
R Predictions Min                   -99.5026
Log Pis Mean                         24.1786
Log Pis Std                          10.7524
Log Pis Max                          54.432
Log Pis Min                          -3.4291
Policy mu Mean                       -0.93578
Policy mu Std                        15.6274
Policy mu Max                       100.929
Policy mu Min                      -239.048
Policy log std Mean                  -0.720171
Policy log std Std                    1.18266
Policy log std Max                    2
Policy log std Min                   -7.17787
_task0 Rewards Mean                 155.788
_task0 Rewards Std                  317.649
_task0 Rewards Max                 1856.56
_task0 Rewards Min                   -0.901514
_task0 Returns Mean               23368.2
_task0 Returns Std                45528.1
_task0 Returns Max               177511
_task0 Returns Min                 -113.342
_task0 Actions Mean                  -0.116258
_task0 Actions Std                    0.813434
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1237.31
Exploration_task0 Rewards Std      3022.45
Exploration_task0 Rewards Max     22387.4
Exploration_task0 Rewards Min        -9.34155
Exploration_task0 Returns Mean   187471
Exploration_task0 Returns Std    422353
Exploration_task0 Returns Max         2.32154e+06
Exploration_task0 Returns Min     -1503.21
Exploration_task0 Actions Mean       -0.121622
Exploration_task0 Actions Std         0.896978
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              23368.2
AverageReturn_all_train_tasks      2662.32
AverageReturn_all_test_tasks      23368.2
Number of train steps total      186000
Number of env steps total             9.301e+06
Number of rollouts total          67524
Train Time (s)                      101.059
(Previous) Eval Time (s)             25.7442
Sample Time (s)                     107.49
Epoch Time (s)                      234.293
Total Train Time (s)              43188.2
Epoch                               185
------------------------------  -----------------
2019-06-27 12:32:40.566810 UTC | [dialturn] Iteration #185 | Epoch Duration: 234.23637318611145
2019-06-27 12:32:40.567022 UTC | [dialturn] Iteration #185 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000416042
Z variance train                      1.00138
KL Divergence                         8.6465e-05
KL Loss                               8.6465e-06
QF Loss                               2.28925e+09
VF Loss                               2.6894e+06
RF Loss                          157736
Policy Loss                     -202133
Q Predictions Mean               200412
Q Predictions Std                266769
Q Predictions Max                687804
Q Predictions Min                   442.845
V Predictions Mean               202768
V Predictions Std                269679
V Predictions Max                688025
V Predictions Min                   832.392
R Predictions Mean                 1524.09
R Predictions Std                  3451.75
R Predictions Max                 16164.2
R Predictions Min                  -108.963
Log Pis Mean                         23.3351
Log Pis Std                          10.4303
Log Pis Max                          53.9758
Log Pis Min                          -1.41846
Policy mu Mean                       -0.494993
Policy mu Std                        14.0958
Policy mu Max                        88.1795
Policy mu Min                      -219.87
Policy log std Mean                  -0.764418
Policy log std Std                    1.12619
Policy log std Max                    2
Policy log std Min                   -5.10729
_task0 Rewards Mean                 205.734
_task0 Rewards Std                  415.689
_task0 Rewards Max                 2091.98
_task0 Rewards Min                   -0.874577
_task0 Returns Mean               30860
_task0 Returns Std                58889
_task0 Returns Max               209991
_task0 Returns Min                 -108.991
_task0 Actions Mean                  -0.0847199
_task0 Actions Std                    0.848546
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1155.65
Exploration_task0 Rewards Std      2797.34
Exploration_task0 Rewards Max     23106.5
Exploration_task0 Rewards Min        -9.89752
Exploration_task0 Returns Mean   175098
Exploration_task0 Returns Std    395773
Exploration_task0 Returns Max         2.52076e+06
Exploration_task0 Returns Min     -1497.35
Exploration_task0 Actions Mean       -0.127525
Exploration_task0 Actions Std         0.895247
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              30860
AverageReturn_all_train_tasks       754.102
AverageReturn_all_test_tasks      30860
Number of train steps total      187000
Number of env steps total             9.351e+06
Number of rollouts total          67887
Train Time (s)                      100.885
(Previous) Eval Time (s)             25.686
Sample Time (s)                     107.472
Epoch Time (s)                      234.043
Total Train Time (s)              43422.3
Epoch                               186
------------------------------  -----------------
2019-06-27 12:36:34.742366 UTC | [dialturn] Iteration #186 | Epoch Duration: 234.1751275062561
2019-06-27 12:36:34.742582 UTC | [dialturn] Iteration #186 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000737214
Z variance train                      0.999473
KL Divergence                         6.24271e-05
KL Loss                               6.24271e-06
QF Loss                               1.64217e+09
VF Loss                               8.27623e+06
RF Loss                          214013
Policy Loss                     -192777
Q Predictions Mean               190798
Q Predictions Std                263329
Q Predictions Max                688627
Q Predictions Min                  1065.3
V Predictions Mean               191261
V Predictions Std                263843
V Predictions Max                680746
V Predictions Min                   390.545
R Predictions Mean                 1774.29
R Predictions Std                  3789.22
R Predictions Max                 18926.3
R Predictions Min                  -139.746
Log Pis Mean                         23.779
Log Pis Std                          10.6133
Log Pis Max                          52.7277
Log Pis Min                          -1.66444
Policy mu Mean                       -1.56095
Policy mu Std                        14.5086
Policy mu Max                        92.3404
Policy mu Min                      -232.856
Policy log std Mean                  -0.745701
Policy log std Std                    1.21706
Policy log std Max                    2
Policy log std Min                   -6.6006
_task0 Rewards Mean                 108.487
_task0 Rewards Std                  227.998
_task0 Rewards Max                 1010.7
_task0 Rewards Min                   -0.940045
_task0 Returns Mean               16273
_task0 Returns Std                32688.4
_task0 Returns Max               100410
_task0 Returns Min                 -114.219
_task0 Actions Mean                  -0.024025
_task0 Actions Std                    0.890736
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1135.94
Exploration_task0 Rewards Std      2878.21
Exploration_task0 Rewards Max     22705
Exploration_task0 Rewards Min        -9.25626
Exploration_task0 Returns Mean   172112
Exploration_task0 Returns Std    405121
Exploration_task0 Returns Max         2.49519e+06
Exploration_task0 Returns Min     -1409.7
Exploration_task0 Actions Mean       -0.15426
Exploration_task0 Actions Std         0.865704
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16273
AverageReturn_all_train_tasks     10870.8
AverageReturn_all_test_tasks      16273
Number of train steps total      188000
Number of env steps total             9.401e+06
Number of rollouts total          68250
Train Time (s)                      101.093
(Previous) Eval Time (s)             25.8165
Sample Time (s)                     107.946
Epoch Time (s)                      234.855
Total Train Time (s)              43657.1
Epoch                               187
------------------------------  -----------------
2019-06-27 12:40:29.556928 UTC | [dialturn] Iteration #187 | Epoch Duration: 234.81418704986572
2019-06-27 12:40:29.557132 UTC | [dialturn] Iteration #187 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000615994
Z variance train                      0.999998
KL Divergence                         4.1526e-05
KL Loss                               4.1526e-06
QF Loss                               1.20157e+09
VF Loss                               1.0113e+07
RF Loss                           84475.6
Policy Loss                     -209869
Q Predictions Mean               207701
Q Predictions Std                271386
Q Predictions Max                695328
Q Predictions Min                   838.521
V Predictions Mean               208120
V Predictions Std                271732
V Predictions Max                690105
V Predictions Min                   644.659
R Predictions Mean                  928.057
R Predictions Std                  2538.36
R Predictions Max                 15955.8
R Predictions Min                  -220.33
Log Pis Mean                         24.1765
Log Pis Std                          10.4651
Log Pis Max                          52.4492
Log Pis Min                          -1.82116
Policy mu Mean                       -0.226241
Policy mu Std                        12.0034
Policy mu Max                        99.7822
Policy mu Min                      -201.538
Policy log std Mean                  -0.770579
Policy log std Std                    1.24492
Policy log std Max                    2
Policy log std Min                   -7.59613
_task0 Rewards Mean                  19.6631
_task0 Rewards Std                   53.0412
_task0 Rewards Max                  435.014
_task0 Rewards Min                   -0.886342
_task0 Returns Mean                2949.46
_task0 Returns Std                 7397.17
_task0 Returns Max                26962.9
_task0 Returns Min                 -101.805
_task0 Actions Mean                  -0.0946959
_task0 Actions Std                    0.830738
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1282.25
Exploration_task0 Rewards Std      2865.76
Exploration_task0 Rewards Max     21620.2
Exploration_task0 Rewards Min        -9.40075
Exploration_task0 Returns Mean   194281
Exploration_task0 Returns Std    403562
Exploration_task0 Returns Max         2.11643e+06
Exploration_task0 Returns Min     -1171.56
Exploration_task0 Actions Mean       -0.0737281
Exploration_task0 Actions Std         0.864435
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               2949.46
AverageReturn_all_train_tasks     11273.1
AverageReturn_all_test_tasks       2949.46
Number of train steps total      189000
Number of env steps total             9.451e+06
Number of rollouts total          68613
Train Time (s)                       98.5503
(Previous) Eval Time (s)             25.7741
Sample Time (s)                     105.755
Epoch Time (s)                      230.079
Total Train Time (s)              43886.8
Epoch                               188
------------------------------  -----------------
2019-06-27 12:44:19.232223 UTC | [dialturn] Iteration #188 | Epoch Duration: 229.67487168312073
2019-06-27 12:44:19.232445 UTC | [dialturn] Iteration #188 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000507975
Z variance train                      1.00034
KL Divergence                         2.20971e-05
KL Loss                               2.20971e-06
QF Loss                               1.52635e+09
VF Loss                               2.63809e+07
RF Loss                          141084
Policy Loss                     -197871
Q Predictions Mean               195374
Q Predictions Std                266838
Q Predictions Max                701513
Q Predictions Min                   210.986
V Predictions Mean               194704
V Predictions Std                266191
V Predictions Max                693604
V Predictions Min                   162.475
R Predictions Mean                 1189.43
R Predictions Std                  3254.1
R Predictions Max                 19889.5
R Predictions Min                  -210.4
Log Pis Mean                         23.1856
Log Pis Std                          10.2372
Log Pis Max                          53.8376
Log Pis Min                          -0.885196
Policy mu Mean                       -0.853847
Policy mu Std                        14.1979
Policy mu Max                       100.168
Policy mu Min                      -212.791
Policy log std Mean                  -0.73547
Policy log std Std                    1.19862
Policy log std Max                    2
Policy log std Min                   -6.70104
_task0 Rewards Mean                  64.7663
_task0 Rewards Std                  147.154
_task0 Rewards Max                 1175.37
_task0 Rewards Min                   -0.846916
_task0 Returns Mean                9714.95
_task0 Returns Std                19255.4
_task0 Returns Max                61454.5
_task0 Returns Min                 -108.985
_task0 Actions Mean                  -0.0861283
_task0 Actions Std                    0.849797
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2012.64
Exploration_task0 Rewards Std      4251.19
Exploration_task0 Rewards Max     23166.4
Exploration_task0 Rewards Min        -9.64963
Exploration_task0 Returns Mean   304945
Exploration_task0 Returns Std    600197
Exploration_task0 Returns Max         2.70516e+06
Exploration_task0 Returns Min     -1423.32
Exploration_task0 Actions Mean       -0.0706699
Exploration_task0 Actions Std         0.843693
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               9714.95
AverageReturn_all_train_tasks     24557.6
AverageReturn_all_test_tasks       9714.95
Number of train steps total      190000
Number of env steps total             9.501e+06
Number of rollouts total          68976
Train Time (s)                       99.8727
(Previous) Eval Time (s)             25.3684
Sample Time (s)                     105.916
Epoch Time (s)                      231.157
Total Train Time (s)              44118.1
Epoch                               189
------------------------------  -----------------
2019-06-27 12:48:10.529396 UTC | [dialturn] Iteration #189 | Epoch Duration: 231.29676151275635
2019-06-27 12:48:10.529636 UTC | [dialturn] Iteration #189 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000909535
Z variance train                      1.00028
KL Divergence                         0.000101279
KL Loss                               1.01279e-05
QF Loss                               2.87818e+09
VF Loss                               2.62945e+06
RF Loss                          342017
Policy Loss                     -202945
Q Predictions Mean               201102
Q Predictions Std                270339
Q Predictions Max                702669
Q Predictions Min                   739.741
V Predictions Mean               203551
V Predictions Std                273414
V Predictions Max                702644
V Predictions Min                  -456.426
R Predictions Mean                 1768.41
R Predictions Std                  4403.93
R Predictions Max                 22782.5
R Predictions Min                  -209.382
Log Pis Mean                         23.3379
Log Pis Std                          10.5305
Log Pis Max                          52.3666
Log Pis Min                          -1.27144
Policy mu Mean                       -0.606894
Policy mu Std                        14.1781
Policy mu Max                       114.593
Policy mu Min                      -219.809
Policy log std Mean                  -0.698474
Policy log std Std                    1.18684
Policy log std Max                    2
Policy log std Min                   -5.54695
_task0 Rewards Mean                 205.093
_task0 Rewards Std                  365.725
_task0 Rewards Max                 1748.21
_task0 Rewards Min                   -0.873309
_task0 Returns Mean               30763.9
_task0 Returns Std                52194.3
_task0 Returns Max               193914
_task0 Returns Min                 -103.871
_task0 Actions Mean                  -0.0332048
_task0 Actions Std                    0.812412
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2325.83
Exploration_task0 Rewards Std      4668.72
Exploration_task0 Rewards Max     22856.3
Exploration_task0 Rewards Min        -9.86284
Exploration_task0 Returns Mean   352399
Exploration_task0 Returns Std    656618
Exploration_task0 Returns Max         2.64924e+06
Exploration_task0 Returns Min     -1185.5
Exploration_task0 Actions Mean       -0.0720573
Exploration_task0 Actions Std         0.856677
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              30763.9
AverageReturn_all_train_tasks     29536.7
AverageReturn_all_test_tasks      30763.9
Number of train steps total      191000
Number of env steps total             9.551e+06
Number of rollouts total          69339
Train Time (s)                      100.202
(Previous) Eval Time (s)             25.5069
Sample Time (s)                     107.174
Epoch Time (s)                      232.883
Total Train Time (s)              44350.8
Epoch                               190
------------------------------  -----------------
2019-06-27 12:52:03.244464 UTC | [dialturn] Iteration #190 | Epoch Duration: 232.71466612815857
2019-06-27 12:52:03.244668 UTC | [dialturn] Iteration #190 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000602932
Z variance train                      0.999185
KL Divergence                         4.19457e-05
KL Loss                               4.19457e-06
QF Loss                               1.54037e+09
VF Loss                               1.02973e+07
RF Loss                          137526
Policy Loss                     -204305
Q Predictions Mean               201756
Q Predictions Std                272339
Q Predictions Max                710917
Q Predictions Min                   694.701
V Predictions Mean               202527
V Predictions Std                273191
V Predictions Max                702051
V Predictions Min                   964.394
R Predictions Mean                 1101.61
R Predictions Std                  2877.63
R Predictions Max                 18249.3
R Predictions Min                   -76.7608
Log Pis Mean                         23.5458
Log Pis Std                          10.5754
Log Pis Max                          52.8296
Log Pis Min                          -7.20596
Policy mu Mean                       -0.436514
Policy mu Std                        12.5114
Policy mu Max                        92.038
Policy mu Min                      -214.13
Policy log std Mean                  -0.77498
Policy log std Std                    1.2021
Policy log std Max                    2
Policy log std Min                   -5.19032
_task0 Rewards Mean                  83.8879
_task0 Rewards Std                  230.371
_task0 Rewards Max                 1254.5
_task0 Rewards Min                   -0.845425
_task0 Returns Mean               12583.2
_task0 Returns Std                32858
_task0 Returns Max               138055
_task0 Returns Min                 -109.893
_task0 Actions Mean                  -0.101302
_task0 Actions Std                    0.83605
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1267.33
Exploration_task0 Rewards Std      2886.43
Exploration_task0 Rewards Max     22513.2
Exploration_task0 Rewards Min        -9.50751
Exploration_task0 Returns Mean   192019
Exploration_task0 Returns Std    408674
Exploration_task0 Returns Max         2.52188e+06
Exploration_task0 Returns Min     -1258.14
Exploration_task0 Actions Mean       -0.0313084
Exploration_task0 Actions Std         0.837896
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12583.2
AverageReturn_all_train_tasks     28672.7
AverageReturn_all_test_tasks      12583.2
Number of train steps total      192000
Number of env steps total             9.601e+06
Number of rollouts total          69702
Train Time (s)                       99.8033
(Previous) Eval Time (s)             25.3374
Sample Time (s)                     106.454
Epoch Time (s)                      231.595
Total Train Time (s)              44582.8
Epoch                               191
------------------------------  -----------------
2019-06-27 12:55:55.269035 UTC | [dialturn] Iteration #191 | Epoch Duration: 232.02420496940613
2019-06-27 12:55:55.269275 UTC | [dialturn] Iteration #191 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00075254
Z variance train                      1.0001
KL Divergence                         5.09209e-05
KL Loss                               5.09209e-06
QF Loss                               1.15481e+09
VF Loss                               1.93747e+07
RF Loss                          136795
Policy Loss                     -196763
Q Predictions Mean               194729
Q Predictions Std                268400
Q Predictions Max                707059
Q Predictions Min                    32.6298
V Predictions Mean               194092
V Predictions Std                267676
V Predictions Max                701546
V Predictions Min                   -65.942
R Predictions Mean                 1266.82
R Predictions Std                  3528.66
R Predictions Max                 19079.1
R Predictions Min                  -116.308
Log Pis Mean                         23.1754
Log Pis Std                          10.7047
Log Pis Max                          53.8876
Log Pis Min                          -2.20941
Policy mu Mean                       -0.237194
Policy mu Std                        12.7979
Policy mu Max                       112.911
Policy mu Min                      -199.217
Policy log std Mean                  -0.778046
Policy log std Std                    1.12653
Policy log std Max                    2
Policy log std Min                   -6.10323
_task0 Rewards Mean                 235.4
_task0 Rewards Std                  552.467
_task0 Rewards Max                 2302.66
_task0 Rewards Min                   -0.869461
_task0 Returns Mean               35310
_task0 Returns Std                78295.8
_task0 Returns Max               272514
_task0 Returns Min                 -107.595
_task0 Actions Mean                  -0.131682
_task0 Actions Std                    0.832748
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1351.75
Exploration_task0 Rewards Std      3351.26
Exploration_task0 Rewards Max     21689.2
Exploration_task0 Rewards Min        -9.08405
Exploration_task0 Returns Mean   204811
Exploration_task0 Returns Std    473655
Exploration_task0 Returns Max         1.86566e+06
Exploration_task0 Returns Min     -1531.42
Exploration_task0 Actions Mean       -0.0581295
Exploration_task0 Actions Std         0.884612
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              35310
AverageReturn_all_train_tasks     43680.4
AverageReturn_all_test_tasks      35310
Number of train steps total      193000
Number of env steps total             9.651e+06
Number of rollouts total          70065
Train Time (s)                      100.097
(Previous) Eval Time (s)             25.7657
Sample Time (s)                     106.904
Epoch Time (s)                      232.766
Total Train Time (s)              44815.1
Epoch                               192
------------------------------  -----------------
2019-06-27 12:59:47.528159 UTC | [dialturn] Iteration #192 | Epoch Duration: 232.25871109962463
2019-06-27 12:59:47.528368 UTC | [dialturn] Iteration #192 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000925319
Z variance train                      1.00057
KL Divergence                         0.000124601
KL Loss                               1.24601e-05
QF Loss                               1.48847e+09
VF Loss                               1.28901e+07
RF Loss                           75954.5
Policy Loss                     -190327
Q Predictions Mean               188053
Q Predictions Std                264746
Q Predictions Max                707854
Q Predictions Min                  -310.728
V Predictions Mean               192433
V Predictions Std                270124
V Predictions Max                713011
V Predictions Min                  -679.498
R Predictions Mean                 1041.17
R Predictions Std                  2579.06
R Predictions Max                 15251.3
R Predictions Min                   -81.8592
Log Pis Mean                         22.7374
Log Pis Std                          10.9872
Log Pis Max                          53.2387
Log Pis Min                          -1.7342
Policy mu Mean                       -0.462749
Policy mu Std                        12.5332
Policy mu Max                        91.1381
Policy mu Min                      -216.548
Policy log std Mean                  -0.788244
Policy log std Std                    1.08578
Policy log std Max                    2
Policy log std Min                   -5.4681
_task0 Rewards Mean                 193.525
_task0 Rewards Std                  447.399
_task0 Rewards Max                 2037.64
_task0 Rewards Min                   -0.874978
_task0 Returns Mean               29028.7
_task0 Returns Std                63486.3
_task0 Returns Max               214472
_task0 Returns Min                 -112.182
_task0 Actions Mean                  -0.115162
_task0 Actions Std                    0.823566
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1305.06
Exploration_task0 Rewards Std      3175.05
Exploration_task0 Rewards Max     21751.9
Exploration_task0 Rewards Min        -8.91805
Exploration_task0 Returns Mean   197737
Exploration_task0 Returns Std    451036
Exploration_task0 Returns Max         2.284e+06
Exploration_task0 Returns Min     -1254.29
Exploration_task0 Actions Mean       -0.0767723
Exploration_task0 Actions Std         0.854719
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              29028.7
AverageReturn_all_train_tasks     13930.8
AverageReturn_all_test_tasks      29028.7
Number of train steps total      194000
Number of env steps total             9.701e+06
Number of rollouts total          70428
Train Time (s)                       99.6633
(Previous) Eval Time (s)             25.2566
Sample Time (s)                     105.953
Epoch Time (s)                      230.873
Total Train Time (s)              45046.3
Epoch                               193
------------------------------  -----------------
2019-06-27 13:03:38.731004 UTC | [dialturn] Iteration #193 | Epoch Duration: 231.20246934890747
2019-06-27 13:03:38.731219 UTC | [dialturn] Iteration #193 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000632058
Z variance train                      1.00077
KL Divergence                         4.82924e-05
KL Loss                               4.82924e-06
QF Loss                               1.22129e+09
VF Loss                               5.24e+06
RF Loss                          267485
Policy Loss                     -191282
Q Predictions Mean               189367
Q Predictions Std                266314
Q Predictions Max                715933
Q Predictions Min                   691.568
V Predictions Mean               192387
V Predictions Std                270232
V Predictions Max                716002
V Predictions Min                   692.587
R Predictions Mean                 1310.83
R Predictions Std                  3220.04
R Predictions Max                 19734.8
R Predictions Min                  -103.971
Log Pis Mean                         22.77
Log Pis Std                          10.4623
Log Pis Max                          53.6546
Log Pis Min                          -2.00898
Policy mu Mean                       -0.599484
Policy mu Std                        14.9483
Policy mu Max                       110.086
Policy mu Min                      -231.286
Policy log std Mean                  -0.734117
Policy log std Std                    1.10019
Policy log std Max                    2
Policy log std Min                   -5.9769
_task0 Rewards Mean                 135.881
_task0 Rewards Std                  312.961
_task0 Rewards Max                 1798.12
_task0 Rewards Min                   -0.857332
_task0 Returns Mean               20382.2
_task0 Returns Std                44864
_task0 Returns Max               170548
_task0 Returns Min                 -109.476
_task0 Actions Mean                  -0.0806776
_task0 Actions Std                    0.794898
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1369.7
Exploration_task0 Rewards Std      3550.54
Exploration_task0 Rewards Max     23081.6
Exploration_task0 Rewards Min        -9.3178
Exploration_task0 Returns Mean   207530
Exploration_task0 Returns Std    501381
Exploration_task0 Returns Max         2.78726e+06
Exploration_task0 Returns Min     -1511.15
Exploration_task0 Actions Mean       -0.0291962
Exploration_task0 Actions Std         0.868503
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              20382.2
AverageReturn_all_train_tasks     24527.1
AverageReturn_all_test_tasks      20382.2
Number of train steps total      195000
Number of env steps total             9.751e+06
Number of rollouts total          70791
Train Time (s)                       99.8643
(Previous) Eval Time (s)             25.585
Sample Time (s)                     106.888
Epoch Time (s)                      232.337
Total Train Time (s)              45278.5
Epoch                               194
------------------------------  -----------------
2019-06-27 13:07:30.974806 UTC | [dialturn] Iteration #194 | Epoch Duration: 232.24337124824524
2019-06-27 13:07:30.975079 UTC | [dialturn] Iteration #194 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0010897
Z variance train                      1.00064
KL Divergence                         0.000129838
KL Loss                               1.29838e-05
QF Loss                               1.00163e+09
VF Loss                               2.11712e+07
RF Loss                          174552
Policy Loss                     -202878
Q Predictions Mean               200380
Q Predictions Std                271392
Q Predictions Max                713191
Q Predictions Min                  -588.276
V Predictions Mean               200205
V Predictions Std                270946
V Predictions Max                704269
V Predictions Min                   398.148
R Predictions Mean                 1460.06
R Predictions Std                  3665.45
R Predictions Max                 23089.9
R Predictions Min                   -89.4802
Log Pis Mean                         23.3104
Log Pis Std                          11.0477
Log Pis Max                          54.4611
Log Pis Min                          -4.30654
Policy mu Mean                       -0.0471013
Policy mu Std                        15.3741
Policy mu Max                       110.622
Policy mu Min                      -249.156
Policy log std Mean                  -0.802298
Policy log std Std                    1.11546
Policy log std Max                    2
Policy log std Min                   -6.28841
_task0 Rewards Mean                 170.169
_task0 Rewards Std                  387.74
_task0 Rewards Max                 2026.14
_task0 Rewards Min                   -0.762843
_task0 Returns Mean               25525.3
_task0 Returns Std                55571.6
_task0 Returns Max               200518
_task0 Returns Min                  -95.1712
_task0 Actions Mean                  -0.0179555
_task0 Actions Std                    0.824797
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      915.251
Exploration_task0 Rewards Std      2538.14
Exploration_task0 Rewards Max     22738.6
Exploration_task0 Rewards Min       -10.2841
Exploration_task0 Returns Mean   138674
Exploration_task0 Returns Std    357566
Exploration_task0 Returns Max         2.54952e+06
Exploration_task0 Returns Min     -1114.64
Exploration_task0 Actions Mean       -0.0382705
Exploration_task0 Actions Std         0.875152
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              25525.3
AverageReturn_all_train_tasks     59907.8
AverageReturn_all_test_tasks      25525.3
Number of train steps total      196000
Number of env steps total             9.801e+06
Number of rollouts total          71154
Train Time (s)                      100.416
(Previous) Eval Time (s)             25.4894
Sample Time (s)                     106.821
Epoch Time (s)                      232.726
Total Train Time (s)              45511.1
Epoch                               195
------------------------------  -----------------
2019-06-27 13:11:23.551282 UTC | [dialturn] Iteration #195 | Epoch Duration: 232.57597589492798
2019-06-27 13:11:23.551484 UTC | [dialturn] Iteration #195 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000950934
Z variance train                      1.00036
KL Divergence                         0.00010062
KL Loss                               1.0062e-05
QF Loss                               5.58942e+08
VF Loss                               4.14811e+06
RF Loss                          191489
Policy Loss                     -195060
Q Predictions Mean               192942
Q Predictions Std                269305
Q Predictions Max                715948
Q Predictions Min                   -72.5715
V Predictions Mean               195705
V Predictions Std                272435
V Predictions Max                718968
V Predictions Min                    67.7515
R Predictions Mean                 1134.37
R Predictions Std                  3607.59
R Predictions Max                 21529.8
R Predictions Min                  -220.397
Log Pis Mean                         22.6402
Log Pis Std                          11.1908
Log Pis Max                          55.2645
Log Pis Min                          -2.63167
Policy mu Mean                       -0.800815
Policy mu Std                        14.2539
Policy mu Max                        82.468
Policy mu Min                      -224.356
Policy log std Mean                  -0.828659
Policy log std Std                    1.09435
Policy log std Max                    2
Policy log std Min                   -6.34045
_task0 Rewards Mean                  53.2778
_task0 Rewards Std                  131.516
_task0 Rewards Max                  928.686
_task0 Rewards Min                   -1.03746
_task0 Returns Mean                7991.67
_task0 Returns Std                18736
_task0 Returns Max                69536
_task0 Returns Min                 -118.748
_task0 Actions Mean                  -0.00884396
_task0 Actions Std                    0.879853
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1354.95
Exploration_task0 Rewards Std      3831.13
Exploration_task0 Rewards Max     23068
Exploration_task0 Rewards Min       -10.064
Exploration_task0 Returns Mean   205296
Exploration_task0 Returns Std    534084
Exploration_task0 Returns Max         2.52861e+06
Exploration_task0 Returns Min     -1401.49
Exploration_task0 Actions Mean       -0.0727895
Exploration_task0 Actions Std         0.882048
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7991.67
AverageReturn_all_train_tasks      8774.22
AverageReturn_all_test_tasks       7991.67
Number of train steps total      197000
Number of env steps total             9.851e+06
Number of rollouts total          71517
Train Time (s)                       99.4354
(Previous) Eval Time (s)             25.3377
Sample Time (s)                     106.477
Epoch Time (s)                      231.25
Total Train Time (s)              45742.4
Epoch                               196
------------------------------  -----------------
2019-06-27 13:15:14.864415 UTC | [dialturn] Iteration #196 | Epoch Duration: 231.31273245811462
2019-06-27 13:15:14.864623 UTC | [dialturn] Iteration #196 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000869199
Z variance train                      1.00032
KL Divergence                         7.86811e-05
KL Loss                               7.86811e-06
QF Loss                               1.27601e+09
VF Loss                               6.9107e+06
RF Loss                          134400
Policy Loss                     -206055
Q Predictions Mean               204076
Q Predictions Std                273634
Q Predictions Max                718130
Q Predictions Min                  -342.385
V Predictions Mean               204706
V Predictions Std                274231
V Predictions Max                713802
V Predictions Min                 -1919.92
R Predictions Mean                 1776.39
R Predictions Std                  4268.94
R Predictions Max                 20172.1
R Predictions Min                   -55.1005
Log Pis Mean                         23.6151
Log Pis Std                          11.4611
Log Pis Max                          54.1566
Log Pis Min                          -4.06333
Policy mu Mean                       -0.902393
Policy mu Std                        16.3164
Policy mu Max                        86.2913
Policy mu Min                      -240.859
Policy log std Mean                  -0.806254
Policy log std Std                    1.14598
Policy log std Max                    2
Policy log std Min                   -5.23913
_task0 Rewards Mean                  47.2113
_task0 Rewards Std                   92.8459
_task0 Rewards Max                  669.514
_task0 Rewards Min                   -0.747008
_task0 Returns Mean                7081.69
_task0 Returns Std                11989.1
_task0 Returns Max                32848.2
_task0 Returns Min                  -93.2238
_task0 Actions Mean                   0.034636
_task0 Actions Std                    0.814496
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1352.01
Exploration_task0 Rewards Std      3591.02
Exploration_task0 Rewards Max     22767.4
Exploration_task0 Rewards Min       -11.2631
Exploration_task0 Returns Mean   204851
Exploration_task0 Returns Std    513647
Exploration_task0 Returns Max         2.53962e+06
Exploration_task0 Returns Min     -1539.77
Exploration_task0 Actions Mean       -0.0635893
Exploration_task0 Actions Std         0.872963
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7081.69
AverageReturn_all_train_tasks      9642.8
AverageReturn_all_test_tasks       7081.69
Number of train steps total      198000
Number of env steps total             9.901e+06
Number of rollouts total          71880
Train Time (s)                      101.226
(Previous) Eval Time (s)             25.3988
Sample Time (s)                     107.049
Epoch Time (s)                      233.674
Total Train Time (s)              45976.3
Epoch                               197
------------------------------  -----------------
2019-06-27 13:19:08.744051 UTC | [dialturn] Iteration #197 | Epoch Duration: 233.87918996810913
2019-06-27 13:19:08.744302 UTC | [dialturn] Iteration #197 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000922779
Z variance train                      1.00036
KL Divergence                         7.55575e-05
KL Loss                               7.55575e-06
QF Loss                               1.08374e+09
VF Loss                               2.84691e+06
RF Loss                          162263
Policy Loss                     -197485
Q Predictions Mean               195095
Q Predictions Std                270791
Q Predictions Max                722361
Q Predictions Min                  -485.241
V Predictions Mean               196722
V Predictions Std                272966
V Predictions Max                722879
V Predictions Min                 -1110.15
R Predictions Mean                  831.27
R Predictions Std                  3000.95
R Predictions Max                 22132.4
R Predictions Min                   -53.5945
Log Pis Mean                         23.4539
Log Pis Std                          11.8699
Log Pis Max                          54.1545
Log Pis Min                          -2.91864
Policy mu Mean                       -0.972987
Policy mu Std                        15.2294
Policy mu Max                        89.8206
Policy mu Min                      -237.573
Policy log std Mean                  -0.792748
Policy log std Std                    1.17985
Policy log std Max                    2
Policy log std Min                   -5.65258
_task0 Rewards Mean                 140.881
_task0 Rewards Std                  251.159
_task0 Rewards Max                 1099.05
_task0 Rewards Min                   -0.875
_task0 Returns Mean               21132.1
_task0 Returns Std                36279.3
_task0 Returns Max               126377
_task0 Returns Min                 -100.994
_task0 Actions Mean                  -0.0470627
_task0 Actions Std                    0.836164
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      887.36
Exploration_task0 Rewards Std      2602.81
Exploration_task0 Rewards Max     23121.5
Exploration_task0 Rewards Min       -10.2245
Exploration_task0 Returns Mean   134449
Exploration_task0 Returns Std    366141
Exploration_task0 Returns Max         2.7854e+06
Exploration_task0 Returns Min     -1331.02
Exploration_task0 Actions Mean       -0.0854337
Exploration_task0 Actions Std         0.887095
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21132.1
AverageReturn_all_train_tasks      6509.14
AverageReturn_all_test_tasks      21132.1
Number of train steps total      199000
Number of env steps total             9.951e+06
Number of rollouts total          72243
Train Time (s)                      100.333
(Previous) Eval Time (s)             25.6023
Sample Time (s)                     106.818
Epoch Time (s)                      232.754
Total Train Time (s)              46208.8
Epoch                               198
------------------------------  -----------------
2019-06-27 13:23:01.296491 UTC | [dialturn] Iteration #198 | Epoch Duration: 232.55200791358948
2019-06-27 13:23:01.296699 UTC | [dialturn] Iteration #198 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000481299
Z variance train                      0.999435
KL Divergence                         3.84805e-05
KL Loss                               3.84805e-06
QF Loss                               1.32121e+09
VF Loss                               5.09945e+06
RF Loss                          164101
Policy Loss                     -196715
Q Predictions Mean               194634
Q Predictions Std                269550
Q Predictions Max                722075
Q Predictions Min                  -255.449
V Predictions Mean               197823
V Predictions Std                273489
V Predictions Max                720336
V Predictions Min                   -65.4276
R Predictions Mean                 1316.21
R Predictions Std                  3697.24
R Predictions Max                 21284.2
R Predictions Min                  -101.803
Log Pis Mean                         23.2389
Log Pis Std                          11.3695
Log Pis Max                          55.4027
Log Pis Min                          -4.8969
Policy mu Mean                       -0.476975
Policy mu Std                        12.9056
Policy mu Max                        87.0862
Policy mu Min                      -218.494
Policy log std Mean                  -0.809843
Policy log std Std                    1.15882
Policy log std Max                    2
Policy log std Min                   -6.87241
_task0 Rewards Mean                  33.5883
_task0 Rewards Std                   79.5343
_task0 Rewards Max                  506.096
_task0 Rewards Min                   -0.841738
_task0 Returns Mean                5038.24
_task0 Returns Std                11108.8
_task0 Returns Max                38589.8
_task0 Returns Min                 -110.9
_task0 Actions Mean                   0.0160404
_task0 Actions Std                    0.90332
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      789.333
Exploration_task0 Rewards Std      2510.29
Exploration_task0 Rewards Max     23086.9
Exploration_task0 Rewards Min       -10.3759
Exploration_task0 Returns Mean   119596
Exploration_task0 Returns Std    342833
Exploration_task0 Returns Max         2.52518e+06
Exploration_task0 Returns Min     -1289.11
Exploration_task0 Actions Mean        0.0174853
Exploration_task0 Actions Std         0.906782
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               5038.24
AverageReturn_all_train_tasks     12008.4
AverageReturn_all_test_tasks       5038.24
Number of train steps total      200000
Number of env steps total             1.0001e+07
Number of rollouts total          72606
Train Time (s)                       99.7405
(Previous) Eval Time (s)             25.399
Sample Time (s)                     106.492
Epoch Time (s)                      231.632
Total Train Time (s)              46440.4
Epoch                               199
------------------------------  -----------------
2019-06-27 13:26:52.877969 UTC | [dialturn] Iteration #199 | Epoch Duration: 231.58109283447266
2019-06-27 13:26:52.878177 UTC | [dialturn] Iteration #199 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00086923
Z variance train                      0.999862
KL Divergence                         7.09442e-05
KL Loss                               7.09442e-06
QF Loss                               1.64285e+09
VF Loss                               2.59119e+06
RF Loss                          172576
Policy Loss                     -189999
Q Predictions Mean               188181
Q Predictions Std                266160
Q Predictions Max                721470
Q Predictions Min                  -581.495
V Predictions Mean               189953
V Predictions Std                268608
V Predictions Max                720620
V Predictions Min                  -582.597
R Predictions Mean                 1548.65
R Predictions Std                  3121.29
R Predictions Max                 15796.9
R Predictions Min                   -17.3278
Log Pis Mean                         22.9494
Log Pis Std                          10.9007
Log Pis Max                          57.1813
Log Pis Min                          -2.24531
Policy mu Mean                       -0.288384
Policy mu Std                        13.0961
Policy mu Max                        85.4942
Policy mu Min                      -214.048
Policy log std Mean                  -0.78723
Policy log std Std                    1.11514
Policy log std Max                    2
Policy log std Min                   -6.94699
_task0 Rewards Mean                 124.834
_task0 Rewards Std                  428.721
_task0 Rewards Max                 2312.22
_task0 Rewards Min                   -0.906441
_task0 Returns Mean               18725
_task0 Returns Std                60679.4
_task0 Returns Max               261940
_task0 Returns Min                 -115.292
_task0 Actions Mean                   0.0292815
_task0 Actions Std                    0.870881
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1826.46
Exploration_task0 Rewards Std      4135.48
Exploration_task0 Rewards Max     23036.5
Exploration_task0 Rewards Min        -9.63861
Exploration_task0 Returns Mean   276736
Exploration_task0 Returns Std    587145
Exploration_task0 Returns Max         2.79373e+06
Exploration_task0 Returns Min     -1233.31
Exploration_task0 Actions Mean        0.0012184
Exploration_task0 Actions Std         0.858901
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              18725
AverageReturn_all_train_tasks       248.854
AverageReturn_all_test_tasks      18725
Number of train steps total      201000
Number of env steps total             1.0051e+07
Number of rollouts total          72969
Train Time (s)                       99.473
(Previous) Eval Time (s)             25.3468
Sample Time (s)                     106.23
Epoch Time (s)                      231.05
Total Train Time (s)              46671.7
Epoch                               200
------------------------------  -----------------
2019-06-27 13:30:44.180321 UTC | [dialturn] Iteration #200 | Epoch Duration: 231.30198287963867
2019-06-27 13:30:44.180525 UTC | [dialturn] Iteration #200 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000992314
Z variance train                      0.999518
KL Divergence                         0.000161892
KL Loss                               1.61892e-05
QF Loss                               1.39178e+09
VF Loss                               1.31195e+07
RF Loss                           49384.5
Policy Loss                     -196193
Q Predictions Mean               194935
Q Predictions Std                271636
Q Predictions Max                731053
Q Predictions Min                  -451.575
V Predictions Mean               198206
V Predictions Std                275637
V Predictions Max                732268
V Predictions Min                   -76.9091
R Predictions Mean                 1091.91
R Predictions Std                  2543.48
R Predictions Max                 17811.1
R Predictions Min                   -76.2248
Log Pis Mean                         22.6392
Log Pis Std                          11.6392
Log Pis Max                          56.6872
Log Pis Min                          -2.22899
Policy mu Mean                       -1.13524
Policy mu Std                        15.3376
Policy mu Max                       110.208
Policy mu Min                      -230.777
Policy log std Mean                  -0.808158
Policy log std Std                    1.20689
Policy log std Max                    2
Policy log std Min                   -6.69756
_task0 Rewards Mean                  39.8094
_task0 Rewards Std                  117.521
_task0 Rewards Max                  672.63
_task0 Rewards Min                   -0.935021
_task0 Returns Mean                5971.41
_task0 Returns Std                17146.8
_task0 Returns Max                72030.3
_task0 Returns Min                 -108.129
_task0 Actions Mean                   0.000890015
_task0 Actions Std                    0.873154
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      882.79
Exploration_task0 Rewards Std      2367.26
Exploration_task0 Rewards Max     22275.7
Exploration_task0 Rewards Min        -9.47598
Exploration_task0 Returns Mean   133756
Exploration_task0 Returns Std    332211
Exploration_task0 Returns Max         2.34623e+06
Exploration_task0 Returns Min     -1129.39
Exploration_task0 Actions Mean       -0.0140469
Exploration_task0 Actions Std         0.883935
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               5971.41
AverageReturn_all_train_tasks     54907.2
AverageReturn_all_test_tasks       5971.41
Number of train steps total      202000
Number of env steps total             1.0101e+07
Number of rollouts total          73332
Train Time (s)                       99.2613
(Previous) Eval Time (s)             25.5973
Sample Time (s)                     106.676
Epoch Time (s)                      231.534
Total Train Time (s)              46903.4
Epoch                               201
------------------------------  -----------------
2019-06-27 13:34:35.843080 UTC | [dialturn] Iteration #201 | Epoch Duration: 231.6623833179474
2019-06-27 13:34:35.843286 UTC | [dialturn] Iteration #201 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000413447
Z variance train                      1.00003
KL Divergence                         2.62582e-05
KL Loss                               2.62582e-06
QF Loss                               8.01041e+08
VF Loss                               2.64528e+06
RF Loss                          816560
Policy Loss                     -196044
Q Predictions Mean               193865
Q Predictions Std                270488
Q Predictions Max                733156
Q Predictions Min                  -559.001
V Predictions Mean               195647
V Predictions Std                272404
V Predictions Max                728574
V Predictions Min                  -996.135
R Predictions Mean                 2182.46
R Predictions Std                  4737.43
R Predictions Max                 20690.8
R Predictions Min                   -95.9861
Log Pis Mean                         22.3173
Log Pis Std                          11.943
Log Pis Max                          56.1884
Log Pis Min                          -2.6732
Policy mu Mean                       -0.943781
Policy mu Std                        15.9048
Policy mu Max                       101.984
Policy mu Min                      -211.114
Policy log std Mean                  -0.748659
Policy log std Std                    1.1239
Policy log std Max                    2
Policy log std Min                   -7.16149
_task0 Rewards Mean                 178.628
_task0 Rewards Std                  400.57
_task0 Rewards Max                 2212.9
_task0 Rewards Min                   -0.892091
_task0 Returns Mean               26794.2
_task0 Returns Std                55848.7
_task0 Returns Max               218206
_task0 Returns Min                 -110.461
_task0 Actions Mean                  -0.0239973
_task0 Actions Std                    0.83132
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2149.3
Exploration_task0 Rewards Std      4628.23
Exploration_task0 Rewards Max     23121.4
Exploration_task0 Rewards Min       -10.0207
Exploration_task0 Returns Mean   325652
Exploration_task0 Returns Std    664668
Exploration_task0 Returns Max         3.90355e+06
Exploration_task0 Returns Min     -1337.25
Exploration_task0 Actions Mean       -0.000306993
Exploration_task0 Actions Std         0.856078
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26794.2
AverageReturn_all_train_tasks     56536.3
AverageReturn_all_test_tasks      26794.2
Number of train steps total      203000
Number of env steps total             1.0151e+07
Number of rollouts total          73695
Train Time (s)                      101.013
(Previous) Eval Time (s)             25.7241
Sample Time (s)                     106.872
Epoch Time (s)                      233.609
Total Train Time (s)              47137
Epoch                               202
------------------------------  -----------------
2019-06-27 13:38:29.482536 UTC | [dialturn] Iteration #202 | Epoch Duration: 233.63909125328064
2019-06-27 13:38:29.482741 UTC | [dialturn] Iteration #202 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00135094
Z variance train                      0.999679
KL Divergence                         0.000189326
KL Loss                               1.89326e-05
QF Loss                               4.80519e+08
VF Loss                               4.4883e+06
RF Loss                          163519
Policy Loss                     -199246
Q Predictions Mean               196820
Q Predictions Std                272497
Q Predictions Max                732872
Q Predictions Min                  -140.819
V Predictions Mean               198633
V Predictions Std                274737
V Predictions Max                729605
V Predictions Min                   -29.2002
R Predictions Mean                 1276.36
R Predictions Std                  3375.81
R Predictions Max                 21104.1
R Predictions Min                  -111.121
Log Pis Mean                         22.0919
Log Pis Std                          11.3919
Log Pis Max                          56.4024
Log Pis Min                          -4.7449
Policy mu Mean                       -1.08677
Policy mu Std                        14.0633
Policy mu Max                        89.0683
Policy mu Min                      -200.774
Policy log std Mean                  -0.844082
Policy log std Std                    1.15211
Policy log std Max                    2
Policy log std Min                   -6.19292
_task0 Rewards Mean                 109.415
_task0 Rewards Std                  273.886
_task0 Rewards Max                 1091.63
_task0 Rewards Min                   -0.89201
_task0 Returns Mean               16412.2
_task0 Returns Std                39385.8
_task0 Returns Max               126296
_task0 Returns Min                 -115.432
_task0 Actions Mean                   0.0443731
_task0 Actions Std                    0.861509
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1885.56
Exploration_task0 Rewards Std      3870.44
Exploration_task0 Rewards Max     22785
Exploration_task0 Rewards Min       -11.2545
Exploration_task0 Returns Mean   285691
Exploration_task0 Returns Std    540448
Exploration_task0 Returns Max         2.5372e+06
Exploration_task0 Returns Min     -1377.21
Exploration_task0 Actions Mean       -0.0475007
Exploration_task0 Actions Std         0.831971
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16412.2
AverageReturn_all_train_tasks      5071.82
AverageReturn_all_test_tasks      16412.2
Number of train steps total      204000
Number of env steps total             1.0201e+07
Number of rollouts total          74058
Train Time (s)                      100.26
(Previous) Eval Time (s)             25.7523
Sample Time (s)                     106.946
Epoch Time (s)                      232.959
Total Train Time (s)              47370
Epoch                               203
------------------------------  -----------------
2019-06-27 13:42:22.419099 UTC | [dialturn] Iteration #203 | Epoch Duration: 232.93619918823242
2019-06-27 13:42:22.419322 UTC | [dialturn] Iteration #203 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0010355
Z variance train                      0.99989
KL Divergence                         0.00016962
KL Loss                               1.6962e-05
QF Loss                               1.568e+09
VF Loss                               7.53913e+06
RF Loss                          212557
Policy Loss                     -196201
Q Predictions Mean               195022
Q Predictions Std                270741
Q Predictions Max                735604
Q Predictions Min                 -1115.55
V Predictions Mean               197463
V Predictions Std                273697
V Predictions Max                737847
V Predictions Min                  -984.903
R Predictions Mean                 1796.92
R Predictions Std                  3959
R Predictions Max                 19026.2
R Predictions Min                   -41.8044
Log Pis Mean                         22.0415
Log Pis Std                          11.5707
Log Pis Max                          55.0716
Log Pis Min                          -0.717775
Policy mu Mean                       -1.22582
Policy mu Std                        14.379
Policy mu Max                       119.375
Policy mu Min                      -227.632
Policy log std Mean                  -0.8254
Policy log std Std                    1.13875
Policy log std Max                    2
Policy log std Min                   -6.87095
_task0 Rewards Mean                  38.9164
_task0 Rewards Std                  106.805
_task0 Rewards Max                  845.367
_task0 Rewards Min                   -1.03751
_task0 Returns Mean                5837.46
_task0 Returns Std                13561.2
_task0 Returns Max                45830.6
_task0 Returns Min                 -119.791
_task0 Actions Mean                  -0.0645204
_task0 Actions Std                    0.822657
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2115.41
Exploration_task0 Rewards Std      4878.67
Exploration_task0 Rewards Max     23114.6
Exploration_task0 Rewards Min       -11.4287
Exploration_task0 Returns Mean   320517
Exploration_task0 Returns Std    687506
Exploration_task0 Returns Max         3.02676e+06
Exploration_task0 Returns Min     -1289.44
Exploration_task0 Actions Mean       -0.0254885
Exploration_task0 Actions Std         0.868014
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               5837.46
AverageReturn_all_train_tasks      4627.81
AverageReturn_all_test_tasks       5837.46
Number of train steps total      205000
Number of env steps total             1.0251e+07
Number of rollouts total          74421
Train Time (s)                      100.912
(Previous) Eval Time (s)             25.7283
Sample Time (s)                     107.268
Epoch Time (s)                      233.908
Total Train Time (s)              47603.9
Epoch                               204
------------------------------  -----------------
2019-06-27 13:46:16.370701 UTC | [dialturn] Iteration #204 | Epoch Duration: 233.95113921165466
2019-06-27 13:46:16.370917 UTC | [dialturn] Iteration #204 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000508542
Z variance train                      0.999981
KL Divergence                         3.19176e-05
KL Loss                               3.19176e-06
QF Loss                               1.07588e+09
VF Loss                               4.63758e+06
RF Loss                           42125.8
Policy Loss                     -194832
Q Predictions Mean               192880
Q Predictions Std                273110
Q Predictions Max                744055
Q Predictions Min                 -1301.92
V Predictions Mean               195633
V Predictions Std                276545
V Predictions Max                742380
V Predictions Min                 -1412.27
R Predictions Mean                  717.664
R Predictions Std                  2122.61
R Predictions Max                 14404.2
R Predictions Min                   -64.894
Log Pis Mean                         22.3515
Log Pis Std                          11.8621
Log Pis Max                          54.9513
Log Pis Min                          -3.94417
Policy mu Mean                       -0.928041
Policy mu Std                        14.4345
Policy mu Max                        95.2878
Policy mu Min                      -184.973
Policy log std Mean                  -0.815804
Policy log std Std                    1.09564
Policy log std Max                    2
Policy log std Min                   -5.42612
_task0 Rewards Mean                 128.385
_task0 Rewards Std                  198.051
_task0 Rewards Max                 1013.38
_task0 Rewards Min                   -1.01102
_task0 Returns Mean               19257.8
_task0 Returns Std                27954
_task0 Returns Max                72711.8
_task0 Returns Min                 -112.589
_task0 Actions Mean                  -0.0534218
_task0 Actions Std                    0.821369
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1681.76
Exploration_task0 Rewards Std      3455.69
Exploration_task0 Rewards Max     22401
Exploration_task0 Rewards Min       -11.0816
Exploration_task0 Returns Mean   254812
Exploration_task0 Returns Std    494356
Exploration_task0 Returns Max         2.22527e+06
Exploration_task0 Returns Min     -1392.26
Exploration_task0 Actions Mean       -0.0146414
Exploration_task0 Actions Std         0.869707
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19257.8
AverageReturn_all_train_tasks     12763.2
AverageReturn_all_test_tasks      19257.8
Number of train steps total      206000
Number of env steps total             1.0301e+07
Number of rollouts total          74784
Train Time (s)                      100.034
(Previous) Eval Time (s)             25.7702
Sample Time (s)                     106.91
Epoch Time (s)                      232.714
Total Train Time (s)              47836.8
Epoch                               205
------------------------------  -----------------
2019-06-27 13:50:09.227664 UTC | [dialturn] Iteration #205 | Epoch Duration: 232.85656595230103
2019-06-27 13:50:09.227916 UTC | [dialturn] Iteration #205 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000576557
Z variance train                      1.00015
KL Divergence                         3.44618e-05
KL Loss                               3.44618e-06
QF Loss                               1.56623e+09
VF Loss                               5.63329e+06
RF Loss                          403687
Policy Loss                     -197735
Q Predictions Mean               195816
Q Predictions Std                273166
Q Predictions Max                740112
Q Predictions Min                 -1983.99
V Predictions Mean               197047
V Predictions Std                274652
V Predictions Max                741406
V Predictions Min                 -1553.54
R Predictions Mean                 1370.65
R Predictions Std                  3688.39
R Predictions Max                 19735.1
R Predictions Min                   -83.1676
Log Pis Mean                         22.2231
Log Pis Std                          11.5238
Log Pis Max                          54.86
Log Pis Min                          -2.79166
Policy mu Mean                       -0.688574
Policy mu Std                        13.0009
Policy mu Max                       141.269
Policy mu Min                      -255.745
Policy log std Mean                  -0.810235
Policy log std Std                    1.11615
Policy log std Max                    2
Policy log std Min                   -5.65421
_task0 Rewards Mean                 246.563
_task0 Rewards Std                  540.966
_task0 Rewards Max                 2119.62
_task0 Rewards Min                   -0.900243
_task0 Returns Mean               36984.5
_task0 Returns Std                76719
_task0 Returns Max               227225
_task0 Returns Min                 -111.365
_task0 Actions Mean                  -0.109113
_task0 Actions Std                    0.856989
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1981.51
Exploration_task0 Rewards Std      5015.11
Exploration_task0 Rewards Max     23074.9
Exploration_task0 Rewards Min       -11.6875
Exploration_task0 Returns Mean   300229
Exploration_task0 Returns Std    707090
Exploration_task0 Returns Max         2.70098e+06
Exploration_task0 Returns Min     -1311.99
Exploration_task0 Actions Mean       -0.0638821
Exploration_task0 Actions Std         0.875083
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              36984.5
AverageReturn_all_train_tasks     25359.9
AverageReturn_all_test_tasks      36984.5
Number of train steps total      207000
Number of env steps total             1.0351e+07
Number of rollouts total          75147
Train Time (s)                      100.125
(Previous) Eval Time (s)             25.9115
Sample Time (s)                     106.158
Epoch Time (s)                      232.195
Total Train Time (s)              48068.7
Epoch                               206
------------------------------  -----------------
2019-06-27 13:54:01.211550 UTC | [dialturn] Iteration #206 | Epoch Duration: 231.98340678215027
2019-06-27 13:54:01.211772 UTC | [dialturn] Iteration #206 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00148505
Z variance train                      1.00007
KL Divergence                         0.000231009
KL Loss                               2.31009e-05
QF Loss                               1.10043e+09
VF Loss                               8.73191e+06
RF Loss                          363712
Policy Loss                     -201589
Q Predictions Mean               199697
Q Predictions Std                273526
Q Predictions Max                746770
Q Predictions Min                 -1130.2
V Predictions Mean               200226
V Predictions Std                274064
V Predictions Max                742302
V Predictions Min                 -1198.63
R Predictions Mean                 1551.16
R Predictions Std                  4142.49
R Predictions Max                 22293.5
R Predictions Min                  -128.964
Log Pis Mean                         22.6913
Log Pis Std                          11.6966
Log Pis Max                          57.3424
Log Pis Min                          -2.71851
Policy mu Mean                       -1.26531
Policy mu Std                        16.6329
Policy mu Max                       150.754
Policy mu Min                      -280.82
Policy log std Mean                  -0.792378
Policy log std Std                    1.16582
Policy log std Max                    2
Policy log std Min                   -6.40283
_task0 Rewards Mean                 117.868
_task0 Rewards Std                  276.365
_task0 Rewards Max                 1485.6
_task0 Rewards Min                   -0.888894
_task0 Returns Mean               17680.2
_task0 Returns Std                39524.6
_task0 Returns Max               152396
_task0 Returns Min                 -100.162
_task0 Actions Mean                  -0.0287199
_task0 Actions Std                    0.8491
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1201.23
Exploration_task0 Rewards Std      3436.43
Exploration_task0 Rewards Max     23042.7
Exploration_task0 Rewards Min       -10.3159
Exploration_task0 Returns Mean   182004
Exploration_task0 Returns Std    482200
Exploration_task0 Returns Max         2.78273e+06
Exploration_task0 Returns Min     -1253.01
Exploration_task0 Actions Mean       -0.114033
Exploration_task0 Actions Std         0.891896
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17680.2
AverageReturn_all_train_tasks     45567
AverageReturn_all_test_tasks      17680.2
Number of train steps total      208000
Number of env steps total             1.0401e+07
Number of rollouts total          75510
Train Time (s)                       99.8641
(Previous) Eval Time (s)             25.6988
Sample Time (s)                     106.619
Epoch Time (s)                      232.182
Total Train Time (s)              48300.8
Epoch                               207
------------------------------  -----------------
2019-06-27 13:57:53.234704 UTC | [dialturn] Iteration #207 | Epoch Duration: 232.02274870872498
2019-06-27 13:57:53.234924 UTC | [dialturn] Iteration #207 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000977816
Z variance train                      1.00009
KL Divergence                         0.000131554
KL Loss                               1.31554e-05
QF Loss                               2.0167e+09
VF Loss                               1.98486e+07
RF Loss                          411129
Policy Loss                     -192348
Q Predictions Mean               191205
Q Predictions Std                271474
Q Predictions Max                745590
Q Predictions Min                 -1036.84
V Predictions Mean               194650
V Predictions Std                275990
V Predictions Max                749993
V Predictions Min                 -1152.02
R Predictions Mean                 2366.93
R Predictions Std                  5310.52
R Predictions Max                 22799
R Predictions Min                  -103.267
Log Pis Mean                         22.3693
Log Pis Std                          11.6559
Log Pis Max                          58.6061
Log Pis Min                          -2.02415
Policy mu Mean                       -1.1275
Policy mu Std                        14.4949
Policy mu Max                       100.8
Policy mu Min                      -189.41
Policy log std Mean                  -0.816474
Policy log std Std                    1.11749
Policy log std Max                    2
Policy log std Min                   -5.71875
_task0 Rewards Mean                 207.638
_task0 Rewards Std                  380.23
_task0 Rewards Max                 1700
_task0 Rewards Min                   -0.882947
_task0 Returns Mean               31145.6
_task0 Returns Std                54054.9
_task0 Returns Max               175716
_task0 Returns Min                 -102.81
_task0 Actions Mean                  -0.045247
_task0 Actions Std                    0.815868
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1702.22
Exploration_task0 Rewards Std      4103.9
Exploration_task0 Rewards Max     22421.3
Exploration_task0 Rewards Min       -10.8673
Exploration_task0 Returns Mean   257912
Exploration_task0 Returns Std    580532
Exploration_task0 Returns Max         2.50396e+06
Exploration_task0 Returns Min     -1282.06
Exploration_task0 Actions Mean       -0.127677
Exploration_task0 Actions Std         0.866612
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              31145.6
AverageReturn_all_train_tasks      6187.68
AverageReturn_all_test_tasks      31145.6
Number of train steps total      209000
Number of env steps total             1.0451e+07
Number of rollouts total          75873
Train Time (s)                      100.806
(Previous) Eval Time (s)             25.5383
Sample Time (s)                     106.78
Epoch Time (s)                      233.124
Total Train Time (s)              48534
Epoch                               208
------------------------------  -----------------
2019-06-27 14:01:46.481818 UTC | [dialturn] Iteration #208 | Epoch Duration: 233.2467257976532
2019-06-27 14:01:46.482027 UTC | [dialturn] Iteration #208 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000355015
Z variance train                      0.999956
KL Divergence                         1.43032e-05
KL Loss                               1.43032e-06
QF Loss                               1.30956e+09
VF Loss                               6.18694e+06
RF Loss                          387972
Policy Loss                     -195847
Q Predictions Mean               193778
Q Predictions Std                272804
Q Predictions Max                750430
Q Predictions Min                 -1027.34
V Predictions Mean               195679
V Predictions Std                274917
V Predictions Max                749656
V Predictions Min                 -1407.6
R Predictions Mean                 1734.02
R Predictions Std                  3930.35
R Predictions Max                 20180.6
R Predictions Min                   -52.9743
Log Pis Mean                         21.9568
Log Pis Std                          11.5256
Log Pis Max                          55.7707
Log Pis Min                          -6.18885
Policy mu Mean                       -1.49289
Policy mu Std                        14.5255
Policy mu Max                        94.7051
Policy mu Min                      -190.886
Policy log std Mean                  -0.788771
Policy log std Std                    1.13001
Policy log std Max                    2
Policy log std Min                   -6.22204
_task0 Rewards Mean                 370.959
_task0 Rewards Std                  738.935
_task0 Rewards Max                 2282.87
_task0 Rewards Min                   -0.747936
_task0 Returns Mean               55643.8
_task0 Returns Std               104584
_task0 Returns Max               278260
_task0 Returns Min                  -91.6859
_task0 Actions Mean                  -0.0641192
_task0 Actions Std                    0.852023
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1659.88
Exploration_task0 Rewards Std      3639.7
Exploration_task0 Rewards Max     22502.1
Exploration_task0 Rewards Min       -11.0548
Exploration_task0 Returns Mean   251497
Exploration_task0 Returns Std    511171
Exploration_task0 Returns Max         2.56859e+06
Exploration_task0 Returns Min     -1246.79
Exploration_task0 Actions Mean       -0.0248003
Exploration_task0 Actions Std         0.857071
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              55643.8
AverageReturn_all_train_tasks     39386.8
AverageReturn_all_test_tasks      55643.8
Number of train steps total      210000
Number of env steps total             1.0501e+07
Number of rollouts total          76236
Train Time (s)                      100.812
(Previous) Eval Time (s)             25.6594
Sample Time (s)                     106.192
Epoch Time (s)                      232.663
Total Train Time (s)              48766.7
Epoch                               209
------------------------------  -----------------
2019-06-27 14:05:39.162044 UTC | [dialturn] Iteration #209 | Epoch Duration: 232.67978620529175
2019-06-27 14:05:39.162274 UTC | [dialturn] Iteration #209 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000588327
Z variance train                      0.998671
KL Divergence                         5.83173e-05
KL Loss                               5.83173e-06
QF Loss                               1.73757e+09
VF Loss                               5.30669e+06
RF Loss                          198720
Policy Loss                     -199853
Q Predictions Mean               197497
Q Predictions Std                275296
Q Predictions Max                753021
Q Predictions Min                   205.112
V Predictions Mean               199070
V Predictions Std                276690
V Predictions Max                751166
V Predictions Min                   236.718
R Predictions Mean                 1330.28
R Predictions Std                  3375.57
R Predictions Max                 20398.8
R Predictions Min                   -88.0205
Log Pis Mean                         22.2876
Log Pis Std                          11.7699
Log Pis Max                          56.2996
Log Pis Min                          -3.31198
Policy mu Mean                       -1.64707
Policy mu Std                        14.4836
Policy mu Max                       100.856
Policy mu Min                      -209.154
Policy log std Mean                  -0.882386
Policy log std Std                    1.123
Policy log std Max                    2
Policy log std Min                   -5.59089
_task0 Rewards Mean                 100.934
_task0 Rewards Std                  229.515
_task0 Rewards Max                 1256.25
_task0 Rewards Min                   -0.868703
_task0 Returns Mean               15140.1
_task0 Returns Std                32159.7
_task0 Returns Max               111182
_task0 Returns Min                 -110.832
_task0 Actions Mean                  -0.0846955
_task0 Actions Std                    0.813296
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1857.37
Exploration_task0 Rewards Std      4357.59
Exploration_task0 Rewards Max     22806.8
Exploration_task0 Rewards Min       -11.2133
Exploration_task0 Returns Mean   281419
Exploration_task0 Returns Std    619857
Exploration_task0 Returns Max         2.57809e+06
Exploration_task0 Returns Min     -1472.52
Exploration_task0 Actions Mean       -0.0800562
Exploration_task0 Actions Std         0.877445
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15140.1
AverageReturn_all_train_tasks      7692.77
AverageReturn_all_test_tasks      15140.1
Number of train steps total      211000
Number of env steps total             1.0551e+07
Number of rollouts total          76599
Train Time (s)                       99.5219
(Previous) Eval Time (s)             25.6745
Sample Time (s)                     107.155
Epoch Time (s)                      232.351
Total Train Time (s)              48999.1
Epoch                               210
------------------------------  -----------------
2019-06-27 14:09:31.550534 UTC | [dialturn] Iteration #210 | Epoch Duration: 232.38809895515442
2019-06-27 14:09:31.550758 UTC | [dialturn] Iteration #210 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000365074
Z variance train                      0.999925
KL Divergence                         1.0723e-05
KL Loss                               1.0723e-06
QF Loss                               1.72979e+09
VF Loss                               4.93097e+06
RF Loss                          236454
Policy Loss                     -208222
Q Predictions Mean               206613
Q Predictions Std                279181
Q Predictions Max                756441
Q Predictions Min                 -1466.5
V Predictions Mean               208935
V Predictions Std                281812
V Predictions Max                757591
V Predictions Min                 -1203.79
R Predictions Mean                 1685.79
R Predictions Std                  3931.52
R Predictions Max                 19586.2
R Predictions Min                   -68.3031
Log Pis Mean                         22.8239
Log Pis Std                          12.1304
Log Pis Max                          55.2905
Log Pis Min                          -1.31014
Policy mu Mean                       -1.33879
Policy mu Std                        15.1697
Policy mu Max                       116.268
Policy mu Min                      -227.334
Policy log std Mean                  -0.827912
Policy log std Std                    1.21078
Policy log std Max                    2
Policy log std Min                   -6.7359
_task0 Rewards Mean                 352.234
_task0 Rewards Std                  585.279
_task0 Rewards Max                 2154.78
_task0 Rewards Min                   -1.03738
_task0 Returns Mean               52835
_task0 Returns Std                82909.9
_task0 Returns Max               215817
_task0 Returns Min                 -117.24
_task0 Actions Mean                  -0.138754
_task0 Actions Std                    0.805722
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1416.11
Exploration_task0 Rewards Std      2987.54
Exploration_task0 Rewards Max     22717.2
Exploration_task0 Rewards Min       -10.7404
Exploration_task0 Returns Mean   214562
Exploration_task0 Returns Std    415563
Exploration_task0 Returns Max         2.57074e+06
Exploration_task0 Returns Min     -1317.99
Exploration_task0 Actions Mean       -0.0458027
Exploration_task0 Actions Std         0.857788
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              52835
AverageReturn_all_train_tasks     42124.6
AverageReturn_all_test_tasks      52835
Number of train steps total      212000
Number of env steps total             1.0601e+07
Number of rollouts total          76962
Train Time (s)                      101.228
(Previous) Eval Time (s)             25.7101
Sample Time (s)                     107.122
Epoch Time (s)                      234.06
Total Train Time (s)              49233.2
Epoch                               211
------------------------------  -----------------
2019-06-27 14:13:25.672586 UTC | [dialturn] Iteration #211 | Epoch Duration: 234.12164855003357
2019-06-27 14:13:25.672791 UTC | [dialturn] Iteration #211 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000566545
Z variance train                      1.0004
KL Divergence                         5.99108e-05
KL Loss                               5.99108e-06
QF Loss                               2.29961e+09
VF Loss                               3.63344e+06
RF Loss                          356673
Policy Loss                     -197878
Q Predictions Mean               195931
Q Predictions Std                277845
Q Predictions Max                757786
Q Predictions Min                  -888.979
V Predictions Mean               197803
V Predictions Std                279945
V Predictions Max                755111
V Predictions Min                  -878.558
R Predictions Mean                 1864.47
R Predictions Std                  4112.43
R Predictions Max                 19006.7
R Predictions Min                  -108.989
Log Pis Mean                         22.301
Log Pis Std                          11.9634
Log Pis Max                          54.5473
Log Pis Min                          -3.05266
Policy mu Mean                       -1.6493
Policy mu Std                        15.9496
Policy mu Max                       122.755
Policy mu Min                      -242.38
Policy log std Mean                  -0.816381
Policy log std Std                    1.16354
Policy log std Max                    2
Policy log std Min                   -5.99294
_task0 Rewards Mean                 151.527
_task0 Rewards Std                  297.818
_task0 Rewards Max                 1554.02
_task0 Rewards Min                   -0.883958
_task0 Returns Mean               22729
_task0 Returns Std                42734.9
_task0 Returns Max               119664
_task0 Returns Min                 -114.737
_task0 Actions Mean                  -0.116424
_task0 Actions Std                    0.839613
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1859.65
Exploration_task0 Rewards Std      4375.74
Exploration_task0 Rewards Max     23130.6
Exploration_task0 Rewards Min       -10.3559
Exploration_task0 Returns Mean   281764
Exploration_task0 Returns Std    618980
Exploration_task0 Returns Max         2.56911e+06
Exploration_task0 Returns Min     -1406.26
Exploration_task0 Actions Mean       -0.0717181
Exploration_task0 Actions Std         0.899768
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              22729
AverageReturn_all_train_tasks      2650.63
AverageReturn_all_test_tasks      22729
Number of train steps total      213000
Number of env steps total             1.0651e+07
Number of rollouts total          77325
Train Time (s)                      100.292
(Previous) Eval Time (s)             25.7701
Sample Time (s)                     107.396
Epoch Time (s)                      233.458
Total Train Time (s)              49466.6
Epoch                               212
------------------------------  -----------------
2019-06-27 14:17:19.066943 UTC | [dialturn] Iteration #212 | Epoch Duration: 233.39398980140686
2019-06-27 14:17:19.067158 UTC | [dialturn] Iteration #212 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000981874
Z variance train                      0.999378
KL Divergence                         0.000132363
KL Loss                               1.32363e-05
QF Loss                               2.02663e+09
VF Loss                               2.00452e+07
RF Loss                          160153
Policy Loss                     -202022
Q Predictions Mean               200167
Q Predictions Std                278422
Q Predictions Max                763413
Q Predictions Min                 -1448.63
V Predictions Mean               204610
V Predictions Std                283782
V Predictions Max                769747
V Predictions Min                 -1567.71
R Predictions Mean                 1592.62
R Predictions Std                  3445.9
R Predictions Max                 18294.5
R Predictions Min                  -167.268
Log Pis Mean                         22.9446
Log Pis Std                          12.3939
Log Pis Max                          55.8639
Log Pis Min                          -3.37352
Policy mu Mean                       -2.01601
Policy mu Std                        19.2341
Policy mu Max                       123.139
Policy mu Min                      -253.949
Policy log std Mean                  -0.792403
Policy log std Std                    1.19997
Policy log std Max                    2
Policy log std Min                   -6.93322
_task0 Rewards Mean                  47.6879
_task0 Rewards Std                  129.282
_task0 Rewards Max                  616.978
_task0 Rewards Min                   -0.888086
_task0 Returns Mean                7153.18
_task0 Returns Std                18848.1
_task0 Returns Max                67679.3
_task0 Returns Min                 -115.076
_task0 Actions Mean                   0.072751
_task0 Actions Std                    0.899648
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1156.09
Exploration_task0 Rewards Std      2813.15
Exploration_task0 Rewards Max     22877.2
Exploration_task0 Rewards Min       -11.1071
Exploration_task0 Returns Mean   175165
Exploration_task0 Returns Std    385882
Exploration_task0 Returns Max         2.53458e+06
Exploration_task0 Returns Min     -1258.67
Exploration_task0 Actions Mean       -0.0119242
Exploration_task0 Actions Std         0.866706
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7153.18
AverageReturn_all_train_tasks     11025.6
AverageReturn_all_test_tasks       7153.18
Number of train steps total      214000
Number of env steps total             1.0701e+07
Number of rollouts total          77688
Train Time (s)                      100.59
(Previous) Eval Time (s)             25.7041
Sample Time (s)                     107.272
Epoch Time (s)                      233.566
Total Train Time (s)              49700
Epoch                               213
------------------------------  -----------------
2019-06-27 14:21:12.550537 UTC | [dialturn] Iteration #213 | Epoch Duration: 233.4831624031067
2019-06-27 14:21:12.550764 UTC | [dialturn] Iteration #213 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000592421
Z variance train                      0.999904
KL Divergence                         4.53939e-05
KL Loss                               4.53939e-06
QF Loss                               2.38613e+09
VF Loss                               4.19589e+06
RF Loss                           77373.5
Policy Loss                     -203593
Q Predictions Mean               201965
Q Predictions Std                280824
Q Predictions Max                774838
Q Predictions Min                 -1271.85
V Predictions Mean               204312
V Predictions Std                283273
V Predictions Max                774313
V Predictions Min                 -1210.12
R Predictions Mean                 1018.39
R Predictions Std                  2530.13
R Predictions Max                 13465.4
R Predictions Min                   -88.453
Log Pis Mean                         22.7056
Log Pis Std                          12.4641
Log Pis Max                          59.2601
Log Pis Min                          -4.06204
Policy mu Mean                       -1.53396
Policy mu Std                        17.6476
Policy mu Max                       131.152
Policy mu Min                      -236.328
Policy log std Mean                  -0.779274
Policy log std Std                    1.21738
Policy log std Max                    2
Policy log std Min                   -8.32989
_task0 Rewards Mean                 296.889
_task0 Rewards Std                  596.409
_task0 Rewards Max                 2312.06
_task0 Rewards Min                   -0.883958
_task0 Returns Mean               44533.3
_task0 Returns Std                84999.2
_task0 Returns Max               282053
_task0 Returns Min                 -114.734
_task0 Actions Mean                  -0.00963337
_task0 Actions Std                    0.875688
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1886.21
Exploration_task0 Rewards Std      4013.38
Exploration_task0 Rewards Max     22591.5
Exploration_task0 Rewards Min       -10.8939
Exploration_task0 Returns Mean   285789
Exploration_task0 Returns Std    567818
Exploration_task0 Returns Max         2.46348e+06
Exploration_task0 Returns Min     -1306.38
Exploration_task0 Actions Mean       -0.0552495
Exploration_task0 Actions Std         0.850922
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              44533.3
AverageReturn_all_train_tasks      6591.91
AverageReturn_all_test_tasks      44533.3
Number of train steps total      215000
Number of env steps total             1.0751e+07
Number of rollouts total          78051
Train Time (s)                      100.505
(Previous) Eval Time (s)             25.6199
Sample Time (s)                     106.983
Epoch Time (s)                      233.107
Total Train Time (s)              49933.1
Epoch                               214
------------------------------  -----------------
2019-06-27 14:25:05.627445 UTC | [dialturn] Iteration #214 | Epoch Duration: 233.07650303840637
2019-06-27 14:25:05.627648 UTC | [dialturn] Iteration #214 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00119329
Z variance train                      0.999992
KL Divergence                         0.000170049
KL Loss                               1.70049e-05
QF Loss                               1.53554e+09
VF Loss                               2.15441e+07
RF Loss                          264130
Policy Loss                     -208977
Q Predictions Mean               206460
Q Predictions Std                283178
Q Predictions Max                774344
Q Predictions Min                 -1521.36
V Predictions Mean               206289
V Predictions Std                282957
V Predictions Max                766866
V Predictions Min                 -1873.11
R Predictions Mean                 1351.05
R Predictions Std                  3191.27
R Predictions Max                 17277.1
R Predictions Min                   -76.7327
Log Pis Mean                         23.5214
Log Pis Std                          12.395
Log Pis Max                          58.7174
Log Pis Min                          -5.05683
Policy mu Mean                       -1.43439
Policy mu Std                        17.5948
Policy mu Max                       103.045
Policy mu Min                      -186.87
Policy log std Mean                  -0.787776
Policy log std Std                    1.23838
Policy log std Max                    2
Policy log std Min                   -8.91954
_task0 Rewards Mean                 194.057
_task0 Rewards Std                  425.976
_task0 Rewards Max                 2017.99
_task0 Rewards Min                   -0.883958
_task0 Returns Mean               29108.5
_task0 Returns Std                60814.5
_task0 Returns Max               218158
_task0 Returns Min                 -114.538
_task0 Actions Mean                  -0.19407
_task0 Actions Std                    0.848231
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1530.52
Exploration_task0 Rewards Std      3289.38
Exploration_task0 Rewards Max     23003.9
Exploration_task0 Rewards Min       -11.2468
Exploration_task0 Returns Mean   231897
Exploration_task0 Returns Std    464449
Exploration_task0 Returns Max         2.57638e+06
Exploration_task0 Returns Min     -1237.77
Exploration_task0 Actions Mean       -0.0709008
Exploration_task0 Actions Std         0.868868
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              29108.5
AverageReturn_all_train_tasks     10817.7
AverageReturn_all_test_tasks      29108.5
Number of train steps total      216000
Number of env steps total             1.0801e+07
Number of rollouts total          78414
Train Time (s)                      100.458
(Previous) Eval Time (s)             25.5876
Sample Time (s)                     107.464
Epoch Time (s)                      233.509
Total Train Time (s)              50166.7
Epoch                               215
------------------------------  -----------------
2019-06-27 14:28:59.166264 UTC | [dialturn] Iteration #215 | Epoch Duration: 233.53846049308777
2019-06-27 14:28:59.166464 UTC | [dialturn] Iteration #215 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000326174
Z variance train                      1.00007
KL Divergence                         9.65006e-06
KL Loss                               9.65006e-07
QF Loss                               1.87636e+09
VF Loss                               2.16126e+07
RF Loss                          313702
Policy Loss                     -207929
Q Predictions Mean               205458
Q Predictions Std                283999
Q Predictions Max                781700
Q Predictions Min                 -1456.79
V Predictions Mean               205196
V Predictions Std                283595
V Predictions Max                775858
V Predictions Min                 -1570.96
R Predictions Mean                 1597.65
R Predictions Std                  3680.38
R Predictions Max                 18972.3
R Predictions Min                   -86.4781
Log Pis Mean                         23.2821
Log Pis Std                          11.8964
Log Pis Max                          55.8814
Log Pis Min                          -2.08386
Policy mu Mean                       -2.64869
Policy mu Std                        18.5652
Policy mu Max                       104.014
Policy mu Min                      -195.383
Policy log std Mean                  -0.767274
Policy log std Std                    1.23636
Policy log std Max                    2
Policy log std Min                   -7.74664
_task0 Rewards Mean                  78.5021
_task0 Rewards Std                  194.395
_task0 Rewards Max                 1089.39
_task0 Rewards Min                   -1.04307
_task0 Returns Mean               11775.3
_task0 Returns Std                28181.5
_task0 Returns Max               117434
_task0 Returns Min                 -119.096
_task0 Actions Mean                   0.0517764
_task0 Actions Std                    0.888264
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1382.38
Exploration_task0 Rewards Std      4083.6
Exploration_task0 Rewards Max     23127.9
Exploration_task0 Rewards Min       -10.374
Exploration_task0 Returns Mean   209451
Exploration_task0 Returns Std    570103
Exploration_task0 Returns Max         2.75793e+06
Exploration_task0 Returns Min     -1674.82
Exploration_task0 Actions Mean       -0.0489019
Exploration_task0 Actions Std         0.921208
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11775.3
AverageReturn_all_train_tasks      6150.73
AverageReturn_all_test_tasks      11775.3
Number of train steps total      217000
Number of env steps total             1.0851e+07
Number of rollouts total          78777
Train Time (s)                      101.002
(Previous) Eval Time (s)             25.6154
Sample Time (s)                     106.88
Epoch Time (s)                      233.498
Total Train Time (s)              50400.3
Epoch                               216
------------------------------  -----------------
2019-06-27 14:32:52.852802 UTC | [dialturn] Iteration #216 | Epoch Duration: 233.68617868423462
2019-06-27 14:32:52.853059 UTC | [dialturn] Iteration #216 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000293162
Z variance train                      0.998981
KL Divergence                         2.85912e-05
KL Loss                               2.85912e-06
QF Loss                               1.81535e+09
VF Loss                               4.05076e+06
RF Loss                          207226
Policy Loss                     -215276
Q Predictions Mean               214018
Q Predictions Std                287888
Q Predictions Max                784708
Q Predictions Min                 -1604.8
V Predictions Mean               214904
V Predictions Std                288894
V Predictions Max                783926
V Predictions Min                 -1959.32
R Predictions Mean                 1879.9
R Predictions Std                  4217.33
R Predictions Max                 20138.2
R Predictions Min                   -90.0175
Log Pis Mean                         23.5296
Log Pis Std                          12.3197
Log Pis Max                          55.7066
Log Pis Min                          -2.38547
Policy mu Mean                       -3.19208
Policy mu Std                        21.918
Policy mu Max                        97.4043
Policy mu Min                      -211.012
Policy log std Mean                  -0.777706
Policy log std Std                    1.27537
Policy log std Max                    2
Policy log std Min                   -9.42495
_task0 Rewards Mean                  46.7034
_task0 Rewards Std                   99.1646
_task0 Rewards Max                  692.634
_task0 Rewards Min                   -0.886401
_task0 Returns Mean                7005.52
_task0 Returns Std                13810.8
_task0 Returns Max                48989.6
_task0 Returns Min                 -114.732
_task0 Actions Mean                   0.0117943
_task0 Actions Std                    0.872136
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1236.77
Exploration_task0 Rewards Std      3250.06
Exploration_task0 Rewards Max     23023.8
Exploration_task0 Rewards Min       -11.2024
Exploration_task0 Returns Mean   187389
Exploration_task0 Returns Std    455174
Exploration_task0 Returns Max         2.57816e+06
Exploration_task0 Returns Min     -1249.22
Exploration_task0 Actions Mean       -0.00527405
Exploration_task0 Actions Std         0.907998
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7005.52
AverageReturn_all_train_tasks     17296.5
AverageReturn_all_test_tasks       7005.52
Number of train steps total      218000
Number of env steps total             1.0901e+07
Number of rollouts total          79140
Train Time (s)                      101.065
(Previous) Eval Time (s)             25.8024
Sample Time (s)                     107.309
Epoch Time (s)                      234.177
Total Train Time (s)              50634.5
Epoch                               217
------------------------------  -----------------
2019-06-27 14:36:47.011690 UTC | [dialturn] Iteration #217 | Epoch Duration: 234.15839076042175
2019-06-27 14:36:47.011914 UTC | [dialturn] Iteration #217 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00160315
Z variance train                      1.00014
KL Divergence                         0.000306131
KL Loss                               3.06131e-05
QF Loss                               1.61026e+09
VF Loss                               7.66621e+06
RF Loss                          193710
Policy Loss                     -199685
Q Predictions Mean               198040
Q Predictions Std                282422
Q Predictions Max                784622
Q Predictions Min                 -1982.39
V Predictions Mean               200647
V Predictions Std                285484
V Predictions Max                787592
V Predictions Min                 -2298.71
R Predictions Mean                 1682.56
R Predictions Std                  4074.74
R Predictions Max                 20389.4
R Predictions Min                   -74.2547
Log Pis Mean                         22.9442
Log Pis Std                          12.2345
Log Pis Max                          55.5879
Log Pis Min                          -3.117
Policy mu Mean                       -2.84414
Policy mu Std                        21.5338
Policy mu Max                       127.009
Policy mu Min                      -200.639
Policy log std Mean                  -0.712383
Policy log std Std                    1.25228
Policy log std Max                    2
Policy log std Min                   -6.55786
_task0 Rewards Mean                 177.893
_task0 Rewards Std                  450.301
_task0 Rewards Max                 2286.82
_task0 Rewards Min                   -0.93991
_task0 Returns Mean               26684
_task0 Returns Std                64061.9
_task0 Returns Max               271314
_task0 Returns Min                 -114.617
_task0 Actions Mean                   0.111732
_task0 Actions Std                    0.850369
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1608.87
Exploration_task0 Rewards Std      4368.28
Exploration_task0 Rewards Max     23069.9
Exploration_task0 Rewards Min       -10.6711
Exploration_task0 Returns Mean   243768
Exploration_task0 Returns Std    614021
Exploration_task0 Returns Max         2.65068e+06
Exploration_task0 Returns Min     -1399.58
Exploration_task0 Actions Mean        0.0273344
Exploration_task0 Actions Std         0.900158
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26684
AverageReturn_all_train_tasks     22333
AverageReturn_all_test_tasks      26684
Number of train steps total      219000
Number of env steps total             1.0951e+07
Number of rollouts total          79503
Train Time (s)                      101.021
(Previous) Eval Time (s)             25.7826
Sample Time (s)                     107.308
Epoch Time (s)                      234.112
Total Train Time (s)              50868.5
Epoch                               218
------------------------------  -----------------
2019-06-27 14:40:41.035785 UTC | [dialturn] Iteration #218 | Epoch Duration: 234.02366518974304
2019-06-27 14:40:41.035996 UTC | [dialturn] Iteration #218 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000656451
Z variance train                      1.00069
KL Divergence                         5.7854e-05
KL Loss                               5.7854e-06
QF Loss                               1.05236e+09
VF Loss                               1.06641e+07
RF Loss                          330485
Policy Loss                     -206842
Q Predictions Mean               204388
Q Predictions Std                286242
Q Predictions Max                791528
Q Predictions Min                 -1765.37
V Predictions Mean               205024
V Predictions Std                286805
V Predictions Max                788895
V Predictions Min                 -1681.19
R Predictions Mean                 1904.21
R Predictions Std                  4209.69
R Predictions Max                 19498.6
R Predictions Min                   -20.0058
Log Pis Mean                         23.7497
Log Pis Std                          12.032
Log Pis Max                          56.1079
Log Pis Min                          -4.0111
Policy mu Mean                       -2.42556
Policy mu Std                        20.579
Policy mu Max                       143.308
Policy mu Min                      -192.311
Policy log std Mean                  -0.757156
Policy log std Std                    1.25206
Policy log std Max                    2
Policy log std Min                   -7.14172
_task0 Rewards Mean                  68.0221
_task0 Rewards Std                  180.213
_task0 Rewards Max                 1264.45
_task0 Rewards Min                   -0.975496
_task0 Returns Mean               10203.3
_task0 Returns Std                25776.4
_task0 Returns Max               110021
_task0 Returns Min                 -113.273
_task0 Actions Mean                   0.00330154
_task0 Actions Std                    0.875771
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2065.48
Exploration_task0 Rewards Std      4604.58
Exploration_task0 Rewards Max     23143.7
Exploration_task0 Rewards Min       -10.3758
Exploration_task0 Returns Mean   312951
Exploration_task0 Returns Std    650975
Exploration_task0 Returns Max         2.73688e+06
Exploration_task0 Returns Min     -1416.52
Exploration_task0 Actions Mean        0.0309986
Exploration_task0 Actions Std         0.873495
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              10203.3
AverageReturn_all_train_tasks     38316
AverageReturn_all_test_tasks      10203.3
Number of train steps total      220000
Number of env steps total             1.1001e+07
Number of rollouts total          79866
Train Time (s)                      100.077
(Previous) Eval Time (s)             25.6931
Sample Time (s)                     107.435
Epoch Time (s)                      233.205
Total Train Time (s)              51101.4
Epoch                               219
------------------------------  -----------------
2019-06-27 14:44:33.957801 UTC | [dialturn] Iteration #219 | Epoch Duration: 232.9215636253357
2019-06-27 14:44:33.958014 UTC | [dialturn] Iteration #219 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00070391
Z variance train                      0.999744
KL Divergence                         5.88371e-05
KL Loss                               5.88371e-06
QF Loss                               1.03437e+09
VF Loss                               7.20456e+06
RF Loss                          229335
Policy Loss                     -203221
Q Predictions Mean               201054
Q Predictions Std                283964
Q Predictions Max                794471
Q Predictions Min                 -1851.31
V Predictions Mean               204390
V Predictions Std                288228
V Predictions Max                798703
V Predictions Min                 -2242.46
R Predictions Mean                 1042.87
R Predictions Std                  2912.88
R Predictions Max                 16871.9
R Predictions Min                  -145.493
Log Pis Mean                         23.1816
Log Pis Std                          12.3241
Log Pis Max                          55.4639
Log Pis Min                          -1.75819
Policy mu Mean                       -1.68874
Policy mu Std                        19.5726
Policy mu Max                       134.815
Policy mu Min                      -216.59
Policy log std Mean                  -0.800187
Policy log std Std                    1.25932
Policy log std Max                    2
Policy log std Min                   -6.05504
_task0 Rewards Mean                  31.4851
_task0 Rewards Std                   74.0861
_task0 Rewards Max                  417.012
_task0 Rewards Min                   -0.873914
_task0 Returns Mean                4722.77
_task0 Returns Std                10620.3
_task0 Returns Max                38092.2
_task0 Returns Min                 -113.1
_task0 Actions Mean                   0.168155
_task0 Actions Std                    0.938209
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1109.31
Exploration_task0 Rewards Std      2900.53
Exploration_task0 Rewards Max     23048.6
Exploration_task0 Rewards Min       -10.3686
Exploration_task0 Returns Mean   168077
Exploration_task0 Returns Std    407622
Exploration_task0 Returns Max         2.5893e+06
Exploration_task0 Returns Min     -1360.55
Exploration_task0 Actions Mean        0.0552503
Exploration_task0 Actions Std         0.909464
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               4722.77
AverageReturn_all_train_tasks     14109.1
AverageReturn_all_test_tasks       4722.77
Number of train steps total      221000
Number of env steps total             1.1051e+07
Number of rollouts total          80229
Train Time (s)                       99.9491
(Previous) Eval Time (s)             25.4083
Sample Time (s)                     106.846
Epoch Time (s)                      232.203
Total Train Time (s)              51334
Epoch                               220
------------------------------  -----------------
2019-06-27 14:48:26.554758 UTC | [dialturn] Iteration #220 | Epoch Duration: 232.59657859802246
2019-06-27 14:48:26.555042 UTC | [dialturn] Iteration #220 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000535735
Z variance train                      0.999957
KL Divergence                         3.75971e-05
KL Loss                               3.75971e-06
QF Loss                               7.6816e+08
VF Loss                               6.15478e+06
RF Loss                          264854
Policy Loss                     -212131
Q Predictions Mean               210524
Q Predictions Std                293825
Q Predictions Max                802204
Q Predictions Min                 -2327.23
V Predictions Mean               211393
V Predictions Std                294347
V Predictions Max                798029
V Predictions Min                 -2003.34
R Predictions Mean                 1591.8
R Predictions Std                  3693.21
R Predictions Max                 20299.2
R Predictions Min                   -73.5593
Log Pis Mean                         23.2795
Log Pis Std                          12.7471
Log Pis Max                          55.1745
Log Pis Min                          -3.26774
Policy mu Mean                       -1.51495
Policy mu Std                        19.4946
Policy mu Max                       121.071
Policy mu Min                      -215.039
Policy log std Mean                  -0.773213
Policy log std Std                    1.23198
Policy log std Max                    2
Policy log std Min                   -7.00593
_task0 Rewards Mean                 171.623
_task0 Rewards Std                  399.113
_task0 Rewards Max                 1801.24
_task0 Rewards Min                   -0.883958
_task0 Returns Mean               25743.5
_task0 Returns Std                57162.5
_task0 Returns Max               222137
_task0 Returns Min                 -113.969
_task0 Actions Mean                  -0.00252951
_task0 Actions Std                    0.887195
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1399.07
Exploration_task0 Rewards Std      3239.34
Exploration_task0 Rewards Max     22885.3
Exploration_task0 Rewards Min       -10.4274
Exploration_task0 Returns Mean   211981
Exploration_task0 Returns Std    452083
Exploration_task0 Returns Max         2.46783e+06
Exploration_task0 Returns Min     -1168.81
Exploration_task0 Actions Mean        0.0284067
Exploration_task0 Actions Std         0.897769
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              25743.5
AverageReturn_all_train_tasks      1670.48
AverageReturn_all_test_tasks      25743.5
Number of train steps total      222000
Number of env steps total             1.1101e+07
Number of rollouts total          80592
Train Time (s)                      100.828
(Previous) Eval Time (s)             25.8005
Sample Time (s)                     107.128
Epoch Time (s)                      233.757
Total Train Time (s)              51567.8
Epoch                               221
------------------------------  -----------------
2019-06-27 14:52:20.301822 UTC | [dialturn] Iteration #221 | Epoch Duration: 233.74659872055054
2019-06-27 14:52:20.302037 UTC | [dialturn] Iteration #221 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000465443
Z variance train                      1.00111
KL Divergence                         3.67564e-05
KL Loss                               3.67564e-06
QF Loss                               2.50201e+09
VF Loss                               3.6105e+07
RF Loss                          135034
Policy Loss                     -206477
Q Predictions Mean               203859
Q Predictions Std                288833
Q Predictions Max                808235
Q Predictions Min                 -3382.51
V Predictions Mean               203325
V Predictions Std                288062
V Predictions Max                801618
V Predictions Min                 -3365.82
R Predictions Mean                 1285.42
R Predictions Std                  3192.61
R Predictions Max                 19285.1
R Predictions Min                   -57.8162
Log Pis Mean                         23.8463
Log Pis Std                          12.4787
Log Pis Max                          55.0752
Log Pis Min                          -5.34899
Policy mu Mean                       -1.93204
Policy mu Std                        20.8305
Policy mu Max                       139.853
Policy mu Min                      -226.69
Policy log std Mean                  -0.760286
Policy log std Std                    1.25132
Policy log std Max                    2
Policy log std Min                   -6.50455
_task0 Rewards Mean                 333.705
_task0 Rewards Std                  582.949
_task0 Rewards Max                 2304.91
_task0 Rewards Min                   -0.783888
_task0 Returns Mean               50055.7
_task0 Returns Std                82742.2
_task0 Returns Max               279189
_task0 Returns Min                  -91.6985
_task0 Actions Mean                  -0.0713265
_task0 Actions Std                    0.840898
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1720.92
Exploration_task0 Rewards Std      3702.77
Exploration_task0 Rewards Max     22809.3
Exploration_task0 Rewards Min       -10.1334
Exploration_task0 Returns Mean   260745
Exploration_task0 Returns Std    520250
Exploration_task0 Returns Max         2.43696e+06
Exploration_task0 Returns Min     -1544.93
Exploration_task0 Actions Mean       -0.00214352
Exploration_task0 Actions Std         0.902411
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              50055.7
AverageReturn_all_train_tasks      2115
AverageReturn_all_test_tasks      50055.7
Number of train steps total      223000
Number of env steps total             1.1151e+07
Number of rollouts total          80955
Train Time (s)                      100.507
(Previous) Eval Time (s)             25.7889
Sample Time (s)                     107.452
Epoch Time (s)                      233.748
Total Train Time (s)              51801.3
Epoch                               222
------------------------------  -----------------
2019-06-27 14:56:13.842187 UTC | [dialturn] Iteration #222 | Epoch Duration: 233.53999018669128
2019-06-27 14:56:13.842395 UTC | [dialturn] Iteration #222 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00152061
Z variance train                      1.00066
KL Divergence                         0.000197142
KL Loss                               1.97142e-05
QF Loss                               1.74022e+09
VF Loss                               1.019e+07
RF Loss                          226013
Policy Loss                     -206215
Q Predictions Mean               204182
Q Predictions Std                291296
Q Predictions Max                808037
Q Predictions Min                 -1323.35
V Predictions Mean               207870
V Predictions Std                295679
V Predictions Max                814702
V Predictions Min                 -1453.27
R Predictions Mean                 1778.77
R Predictions Std                  4165.06
R Predictions Max                 23503.6
R Predictions Min                   -39.7312
Log Pis Mean                         23.5934
Log Pis Std                          12.5551
Log Pis Max                          55.6828
Log Pis Min                          -1.12534
Policy mu Mean                       -3.27759
Policy mu Std                        22.4484
Policy mu Max                       133.826
Policy mu Min                      -236.298
Policy log std Mean                  -0.70163
Policy log std Std                    1.29842
Policy log std Max                    2
Policy log std Min                   -6.44746
_task0 Rewards Mean                 132.341
_task0 Rewards Std                  283.896
_task0 Rewards Max                 1498.04
_task0 Rewards Min                   -1.0247
_task0 Returns Mean               19851.1
_task0 Returns Std                40814.5
_task0 Returns Max               144645
_task0 Returns Min                 -114.81
_task0 Actions Mean                  -0.0141059
_task0 Actions Std                    0.918704
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1653.38
Exploration_task0 Rewards Std      3790.88
Exploration_task0 Rewards Max     23172.1
Exploration_task0 Rewards Min        -9.9691
Exploration_task0 Returns Mean   250512
Exploration_task0 Returns Std    541441
Exploration_task0 Returns Max         3.44053e+06
Exploration_task0 Returns Min     -1213.95
Exploration_task0 Actions Mean        0.00479107
Exploration_task0 Actions Std         0.898592
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19851.1
AverageReturn_all_train_tasks      2336.07
AverageReturn_all_test_tasks      19851.1
Number of train steps total      224000
Number of env steps total             1.1201e+07
Number of rollouts total          81318
Train Time (s)                      102.02
(Previous) Eval Time (s)             25.5791
Sample Time (s)                     107.051
Epoch Time (s)                      234.65
Total Train Time (s)              52036.2
Epoch                               223
------------------------------  -----------------
2019-06-27 15:00:08.737005 UTC | [dialturn] Iteration #223 | Epoch Duration: 234.89444041252136
2019-06-27 15:00:08.737211 UTC | [dialturn] Iteration #223 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0013097
Z variance train                      0.999877
KL Divergence                         0.00016945
KL Loss                               1.6945e-05
QF Loss                               1.40488e+09
VF Loss                               5.59149e+06
RF Loss                          391136
Policy Loss                     -208586
Q Predictions Mean               206111
Q Predictions Std                291589
Q Predictions Max                814533
Q Predictions Min                 -2171.47
V Predictions Mean               209233
V Predictions Std                295560
V Predictions Max                815676
V Predictions Min                 -2440.75
R Predictions Mean                 1701.78
R Predictions Std                  4128.81
R Predictions Max                 20233.1
R Predictions Min                  -195.343
Log Pis Mean                         24.108
Log Pis Std                          13.153
Log Pis Max                          56.4175
Log Pis Min                          -4.39346
Policy mu Mean                       -2.0553
Policy mu Std                        21.8923
Policy mu Max                       136.548
Policy mu Min                      -217.221
Policy log std Mean                  -0.703215
Policy log std Std                    1.23042
Policy log std Max                    2
Policy log std Min                   -6.61642
_task0 Rewards Mean                 203.621
_task0 Rewards Std                  494.144
_task0 Rewards Max                 2276.37
_task0 Rewards Min                   -0.914325
_task0 Returns Mean               30543.2
_task0 Returns Std                70165.6
_task0 Returns Max               238165
_task0 Returns Min                 -115.08
_task0 Actions Mean                  -0.107393
_task0 Actions Std                    0.880117
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1085.17
Exploration_task0 Rewards Std      2813.82
Exploration_task0 Rewards Max     22563
Exploration_task0 Rewards Min        -9.95813
Exploration_task0 Returns Mean   164420
Exploration_task0 Returns Std    397813
Exploration_task0 Returns Max         2.54044e+06
Exploration_task0 Returns Min     -1274.12
Exploration_task0 Actions Mean       -0.05151
Exploration_task0 Actions Std         0.914909
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              30543.2
AverageReturn_all_train_tasks      1124.95
AverageReturn_all_test_tasks      30543.2
Number of train steps total      225000
Number of env steps total             1.1251e+07
Number of rollouts total          81681
Train Time (s)                      100.794
(Previous) Eval Time (s)             25.822
Sample Time (s)                     107.192
Epoch Time (s)                      233.807
Total Train Time (s)              52270.1
Epoch                               224
------------------------------  -----------------
2019-06-27 15:04:02.677815 UTC | [dialturn] Iteration #224 | Epoch Duration: 233.9404377937317
2019-06-27 15:04:02.678105 UTC | [dialturn] Iteration #224 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000660593
Z variance train                      1.00007
KL Divergence                         5.19503e-05
KL Loss                               5.19503e-06
QF Loss                               1.95137e+09
VF Loss                               3.8265e+06
RF Loss                          436797
Policy Loss                     -215360
Q Predictions Mean               212614
Q Predictions Std                294136
Q Predictions Max                814832
Q Predictions Min                 -1887.82
V Predictions Mean               215880
V Predictions Std                297698
V Predictions Max                819419
V Predictions Min                 -1892.34
R Predictions Mean                 1500.04
R Predictions Std                  4141.6
R Predictions Max                 20857.4
R Predictions Min                  -147.84
Log Pis Mean                         23.7214
Log Pis Std                          12.8006
Log Pis Max                          56.3809
Log Pis Min                          -3.09187
Policy mu Mean                       -3.17816
Policy mu Std                        23.3256
Policy mu Max                       137.502
Policy mu Min                      -211.725
Policy log std Mean                  -0.792027
Policy log std Std                    1.33387
Policy log std Max                    2
Policy log std Min                   -5.87392
_task0 Rewards Mean                 212.728
_task0 Rewards Std                  451.227
_task0 Rewards Max                 2078.59
_task0 Rewards Min                   -0.882531
_task0 Returns Mean               31909.3
_task0 Returns Std                64365.2
_task0 Returns Max               187894
_task0 Returns Min                 -105.49
_task0 Actions Mean                  -0.0541077
_task0 Actions Std                    0.863419
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1405.94
Exploration_task0 Rewards Std      3314.68
Exploration_task0 Rewards Max     22940.6
Exploration_task0 Rewards Min       -13.6286
Exploration_task0 Returns Mean   213021
Exploration_task0 Returns Std    470374
Exploration_task0 Returns Max         2.46032e+06
Exploration_task0 Returns Min     -1267.26
Exploration_task0 Actions Mean       -0.0332845
Exploration_task0 Actions Std         0.888605
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              31909.3
AverageReturn_all_train_tasks      6124.89
AverageReturn_all_test_tasks      31909.3
Number of train steps total      226000
Number of env steps total             1.1301e+07
Number of rollouts total          82044
Train Time (s)                      101.077
(Previous) Eval Time (s)             25.9537
Sample Time (s)                     107.793
Epoch Time (s)                      234.824
Total Train Time (s)              52504.8
Epoch                               225
------------------------------  -----------------
2019-06-27 15:07:57.336149 UTC | [dialturn] Iteration #225 | Epoch Duration: 234.65782046318054
2019-06-27 15:07:57.336360 UTC | [dialturn] Iteration #225 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000308645
Z variance train                      1.0004
KL Divergence                         1.06657e-05
KL Loss                               1.06657e-06
QF Loss                               2.0339e+09
VF Loss                               9.54529e+06
RF Loss                           98511.9
Policy Loss                     -217334
Q Predictions Mean               214785
Q Predictions Std                299308
Q Predictions Max                825544
Q Predictions Min                  1033.82
V Predictions Mean               216087
V Predictions Std                300549
V Predictions Max                820108
V Predictions Min                   434.457
R Predictions Mean                  974.617
R Predictions Std                  2702.04
R Predictions Max                 19250.3
R Predictions Min                   -68.4667
Log Pis Mean                         25.053
Log Pis Std                          12.2721
Log Pis Max                          53.9666
Log Pis Min                          -2.41081
Policy mu Mean                       -2.18543
Policy mu Std                        22.7485
Policy mu Max                       157.443
Policy mu Min                      -209.68
Policy log std Mean                  -0.684611
Policy log std Std                    1.30811
Policy log std Max                    2
Policy log std Min                   -5.82715
_task0 Rewards Mean                 117.357
_task0 Rewards Std                  313.257
_task0 Rewards Max                 1669.98
_task0 Rewards Min                   -0.918886
_task0 Returns Mean               17603.6
_task0 Returns Std                44977.2
_task0 Returns Max               156444
_task0 Returns Min                 -115.155
_task0 Actions Mean                   0.054285
_task0 Actions Std                    0.888903
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1122.93
Exploration_task0 Rewards Std      2856.84
Exploration_task0 Rewards Max     23177.1
Exploration_task0 Rewards Min       -10.3471
Exploration_task0 Returns Mean   170140
Exploration_task0 Returns Std    401213
Exploration_task0 Returns Max         2.70423e+06
Exploration_task0 Returns Min     -1387.8
Exploration_task0 Actions Mean        0.0197668
Exploration_task0 Actions Std         0.892385
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17603.6
AverageReturn_all_train_tasks      1936.14
AverageReturn_all_test_tasks      17603.6
Number of train steps total      227000
Number of env steps total             1.1351e+07
Number of rollouts total          82407
Train Time (s)                      101.872
(Previous) Eval Time (s)             25.7863
Sample Time (s)                     107.123
Epoch Time (s)                      234.782
Total Train Time (s)              52739.4
Epoch                               226
------------------------------  -----------------
2019-06-27 15:11:51.955923 UTC | [dialturn] Iteration #226 | Epoch Duration: 234.61939311027527
2019-06-27 15:11:51.956180 UTC | [dialturn] Iteration #226 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000724644
Z variance train                      1.00036
KL Divergence                         7.90963e-05
KL Loss                               7.90963e-06
QF Loss                               3.21515e+09
VF Loss                               3.96165e+06
RF Loss                          496417
Policy Loss                     -217666
Q Predictions Mean               214924
Q Predictions Std                297523
Q Predictions Max                831010
Q Predictions Min                 -1325.19
V Predictions Mean               218093
V Predictions Std                300950
V Predictions Max                831674
V Predictions Min                 -1639.19
R Predictions Mean                 1881.6
R Predictions Std                  4261.71
R Predictions Max                 20389.7
R Predictions Min                  -102.59
Log Pis Mean                         24.8841
Log Pis Std                          12.5886
Log Pis Max                          53.9632
Log Pis Min                          -5.34688
Policy mu Mean                       -2.55875
Policy mu Std                        25.5887
Policy mu Max                       148.017
Policy mu Min                      -210.029
Policy log std Mean                  -0.645045
Policy log std Std                    1.27496
Policy log std Max                    2
Policy log std Min                   -5.30351
_task0 Rewards Mean                  71.1896
_task0 Rewards Std                  161.858
_task0 Rewards Max                  899.634
_task0 Rewards Min                   -0.912733
_task0 Returns Mean               10678.4
_task0 Returns Std                23073.4
_task0 Returns Max                87748.9
_task0 Returns Min                 -110.727
_task0 Actions Mean                   0.00144314
_task0 Actions Std                    0.866198
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1507.27
Exploration_task0 Rewards Std      3766.02
Exploration_task0 Rewards Max     21968.1
Exploration_task0 Rewards Min        -9.40022
Exploration_task0 Returns Mean   228375
Exploration_task0 Returns Std    532730
Exploration_task0 Returns Max         2.46541e+06
Exploration_task0 Returns Min     -1410.54
Exploration_task0 Actions Mean       -0.000113381
Exploration_task0 Actions Std         0.889368
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              10678.4
AverageReturn_all_train_tasks      7245.34
AverageReturn_all_test_tasks      10678.4
Number of train steps total      228000
Number of env steps total             1.1401e+07
Number of rollouts total          82770
Train Time (s)                      100.775
(Previous) Eval Time (s)             25.6226
Sample Time (s)                     107.387
Epoch Time (s)                      233.785
Total Train Time (s)              52973.2
Epoch                               227
------------------------------  -----------------
2019-06-27 15:15:45.806661 UTC | [dialturn] Iteration #227 | Epoch Duration: 233.8503189086914
2019-06-27 15:15:45.806883 UTC | [dialturn] Iteration #227 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000442134
Z variance train                      0.999698
KL Divergence                         1.63782e-05
KL Loss                               1.63782e-06
QF Loss                               2.44688e+09
VF Loss                               4.53825e+06
RF Loss                           58815.5
Policy Loss                     -212831
Q Predictions Mean               211157
Q Predictions Std                300121
Q Predictions Max                838755
Q Predictions Min                 -1484.43
V Predictions Mean               212887
V Predictions Std                302001
V Predictions Max                839057
V Predictions Min                 -1679.77
R Predictions Mean                  824.588
R Predictions Std                  2577.03
R Predictions Max                 17619.8
R Predictions Min                  -388.28
Log Pis Mean                         24.6193
Log Pis Std                          12.3401
Log Pis Max                          53.4459
Log Pis Min                          -0.203189
Policy mu Mean                       -2.54771
Policy mu Std                        23.5181
Policy mu Max                       155.85
Policy mu Min                      -218.168
Policy log std Mean                  -0.588935
Policy log std Std                    1.27375
Policy log std Max                    2
Policy log std Min                   -5.6213
_task0 Rewards Mean                  22.016
_task0 Rewards Std                   73.0433
_task0 Rewards Max                  640.479
_task0 Rewards Min                   -0.971137
_task0 Returns Mean                3302.4
_task0 Returns Std                 9475.51
_task0 Returns Max                34025
_task0 Returns Min                 -121.838
_task0 Actions Mean                  -0.0625739
_task0 Actions Std                    0.910182
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1845.46
Exploration_task0 Rewards Std      4280.18
Exploration_task0 Rewards Max     22855.3
Exploration_task0 Rewards Min        -9.89423
Exploration_task0 Returns Mean   279615
Exploration_task0 Returns Std    607031
Exploration_task0 Returns Max         2.3306e+06
Exploration_task0 Returns Min     -1492.37
Exploration_task0 Actions Mean       -0.0685195
Exploration_task0 Actions Std         0.892312
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               3302.4
AverageReturn_all_train_tasks     28005.6
AverageReturn_all_test_tasks       3302.4
Number of train steps total      229000
Number of env steps total             1.1451e+07
Number of rollouts total          83133
Train Time (s)                      100.942
(Previous) Eval Time (s)             25.6867
Sample Time (s)                     107.4
Epoch Time (s)                      234.029
Total Train Time (s)              53207.4
Epoch                               228
------------------------------  -----------------
2019-06-27 15:19:39.999164 UTC | [dialturn] Iteration #228 | Epoch Duration: 234.19204449653625
2019-06-27 15:19:39.999433 UTC | [dialturn] Iteration #228 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00048492
Z variance train                      0.9999
KL Divergence                         2.41359e-05
KL Loss                               2.41359e-06
QF Loss                               1.58657e+09
VF Loss                               4.90278e+06
RF Loss                           99267
Policy Loss                     -216391
Q Predictions Mean               213458
Q Predictions Std                301618
Q Predictions Max                835038
Q Predictions Min                 -1019.18
V Predictions Mean               215585
V Predictions Std                304148
V Predictions Max                836368
V Predictions Min                  -834.327
R Predictions Mean                 1066.06
R Predictions Std                  2583.43
R Predictions Max                 19281.4
R Predictions Min                  -122.927
Log Pis Mean                         24.5666
Log Pis Std                          12.1626
Log Pis Max                          53.9184
Log Pis Min                          -2.59011
Policy mu Mean                       -3.04587
Policy mu Std                        25.1518
Policy mu Max                       139.985
Policy mu Min                      -210.952
Policy log std Mean                  -0.615006
Policy log std Std                    1.27642
Policy log std Max                    2
Policy log std Min                   -5.48902
_task0 Rewards Mean                  82.5577
_task0 Rewards Std                  328.124
_task0 Rewards Max                 2143.9
_task0 Rewards Min                   -0.929772
_task0 Returns Mean               12383.6
_task0 Returns Std                46356.2
_task0 Returns Max               200496
_task0 Returns Min                 -110.117
_task0 Actions Mean                  -0.0581365
_task0 Actions Std                    0.890326
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1313.17
Exploration_task0 Rewards Std      3011.43
Exploration_task0 Rewards Max     22801
Exploration_task0 Rewards Min        -9.90773
Exploration_task0 Returns Mean   198965
Exploration_task0 Returns Std    422041
Exploration_task0 Returns Max         2.47222e+06
Exploration_task0 Returns Min     -1420.49
Exploration_task0 Actions Mean       -0.0266789
Exploration_task0 Actions Std         0.894847
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12383.6
AverageReturn_all_train_tasks     16212.2
AverageReturn_all_test_tasks      12383.6
Number of train steps total      230000
Number of env steps total             1.1501e+07
Number of rollouts total          83496
Train Time (s)                      100.928
(Previous) Eval Time (s)             25.8484
Sample Time (s)                     107.316
Epoch Time (s)                      234.092
Total Train Time (s)              53441.4
Epoch                               229
------------------------------  -----------------
2019-06-27 15:23:33.970314 UTC | [dialturn] Iteration #229 | Epoch Duration: 233.97068786621094
2019-06-27 15:23:33.970518 UTC | [dialturn] Iteration #229 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000652269
Z variance train                      1.00018
KL Divergence                         5.89271e-05
KL Loss                               5.89271e-06
QF Loss                               2.10553e+09
VF Loss                               8.29786e+06
RF Loss                          238088
Policy Loss                     -219046
Q Predictions Mean               216645
Q Predictions Std                306473
Q Predictions Max                844779
Q Predictions Min                 -2128.13
V Predictions Mean               220503
V Predictions Std                310847
V Predictions Max                848147
V Predictions Min                 -2453.77
R Predictions Mean                 1190.92
R Predictions Std                  2982.35
R Predictions Max                 16083.7
R Predictions Min                   -96.2402
Log Pis Mean                         24.9272
Log Pis Std                          12.6273
Log Pis Max                          54.8241
Log Pis Min                          -2.89005
Policy mu Mean                       -3.02422
Policy mu Std                        24.1044
Policy mu Max                       130.672
Policy mu Min                      -203.515
Policy log std Mean                  -0.632404
Policy log std Std                    1.34296
Policy log std Max                    2
Policy log std Min                   -5.85141
_task0 Rewards Mean                  42.7455
_task0 Rewards Std                   99.4848
_task0 Rewards Max                  739.321
_task0 Rewards Min                   -0.974248
_task0 Returns Mean                6411.83
_task0 Returns Std                13406.9
_task0 Returns Max                48088.1
_task0 Returns Min                 -108.722
_task0 Actions Mean                   0.0283198
_task0 Actions Std                    0.878144
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1285.99
Exploration_task0 Rewards Std      3288.62
Exploration_task0 Rewards Max     21562.9
Exploration_task0 Rewards Min       -10.5073
Exploration_task0 Returns Mean   194847
Exploration_task0 Returns Std    464417
Exploration_task0 Returns Max         2.09232e+06
Exploration_task0 Returns Min     -1399.73
Exploration_task0 Actions Mean        0.0013328
Exploration_task0 Actions Std         0.902653
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               6411.83
AverageReturn_all_train_tasks      1507.27
AverageReturn_all_test_tasks       6411.83
Number of train steps total      231000
Number of env steps total             1.1551e+07
Number of rollouts total          83859
Train Time (s)                      100.649
(Previous) Eval Time (s)             25.7252
Sample Time (s)                     107.529
Epoch Time (s)                      233.903
Total Train Time (s)              53675.3
Epoch                               230
------------------------------  -----------------
2019-06-27 15:27:27.883888 UTC | [dialturn] Iteration #230 | Epoch Duration: 233.9132103919983
2019-06-27 15:27:27.884114 UTC | [dialturn] Iteration #230 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000212192
Z variance train                      0.999642
KL Divergence                         9.75206e-06
KL Loss                               9.75206e-07
QF Loss                               2.40542e+09
VF Loss                               3.92355e+06
RF Loss                          178028
Policy Loss                     -218809
Q Predictions Mean               216338
Q Predictions Std                304614
Q Predictions Max                852712
Q Predictions Min                 -1158.9
V Predictions Mean               219483
V Predictions Std                308273
V Predictions Max                855940
V Predictions Min                 -1651.14
R Predictions Mean                 1468.3
R Predictions Std                  3687.46
R Predictions Max                 19419.9
R Predictions Min                  -120.474
Log Pis Mean                         25.2567
Log Pis Std                          12.1778
Log Pis Max                          53.5343
Log Pis Min                           0.740617
Policy mu Mean                       -3.11324
Policy mu Std                        25.0265
Policy mu Max                       123.031
Policy mu Min                      -207.995
Policy log std Mean                  -0.582289
Policy log std Std                    1.3143
Policy log std Max                    2
Policy log std Min                   -5.89565
_task0 Rewards Mean                 111.906
_task0 Rewards Std                  268.665
_task0 Rewards Max                 1433.09
_task0 Rewards Min                   -0.902842
_task0 Returns Mean               16785.9
_task0 Returns Std                37978.3
_task0 Returns Max               153769
_task0 Returns Min                 -113.896
_task0 Actions Mean                  -0.0537889
_task0 Actions Std                    0.911464
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1400.16
Exploration_task0 Rewards Std      3297.63
Exploration_task0 Rewards Max     22872.9
Exploration_task0 Rewards Min       -10.1472
Exploration_task0 Returns Mean   212146
Exploration_task0 Returns Std    465943
Exploration_task0 Returns Max         2.757e+06
Exploration_task0 Returns Min     -1389.89
Exploration_task0 Actions Mean        0.0433405
Exploration_task0 Actions Std         0.894357
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16785.9
AverageReturn_all_train_tasks      1598.24
AverageReturn_all_test_tasks      16785.9
Number of train steps total      232000
Number of env steps total             1.1601e+07
Number of rollouts total          84222
Train Time (s)                      100.201
(Previous) Eval Time (s)             25.734
Sample Time (s)                     107.22
Epoch Time (s)                      233.155
Total Train Time (s)              53908.4
Epoch                               231
------------------------------  -----------------
2019-06-27 15:31:20.943406 UTC | [dialturn] Iteration #231 | Epoch Duration: 233.05913305282593
2019-06-27 15:31:20.943620 UTC | [dialturn] Iteration #231 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000827516
Z variance train                      1.00003
KL Divergence                         0.000133602
KL Loss                               1.33602e-05
QF Loss                               7.97863e+08
VF Loss                               2.64954e+07
RF Loss                          582402
Policy Loss                     -211526
Q Predictions Mean               208717
Q Predictions Std                298969
Q Predictions Max                849285
Q Predictions Min                 -2335.24
V Predictions Mean               214607
V Predictions Std                305926
V Predictions Max                860786
V Predictions Min                 -1788.24
R Predictions Mean                 1418.9
R Predictions Std                  3688.09
R Predictions Max                 21262.7
R Predictions Min                  -101.097
Log Pis Mean                         24.5618
Log Pis Std                          12.3832
Log Pis Max                          55.6872
Log Pis Min                          -3.19769
Policy mu Mean                       -3.40506
Policy mu Std                        25.056
Policy mu Max                       142.78
Policy mu Min                      -231.386
Policy log std Mean                  -0.611266
Policy log std Std                    1.29866
Policy log std Max                    2
Policy log std Min                   -5.7427
_task0 Rewards Mean                  18.6226
_task0 Rewards Std                   42.7449
_task0 Rewards Max                  182.374
_task0 Rewards Min                   -1.00876
_task0 Returns Mean                2793.39
_task0 Returns Std                 6140.18
_task0 Returns Max                18699.3
_task0 Returns Min                 -122.308
_task0 Actions Mean                   0.0553653
_task0 Actions Std                    0.930818
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1236.09
Exploration_task0 Rewards Std      3295.34
Exploration_task0 Rewards Max     22778.2
Exploration_task0 Rewards Min       -10.2266
Exploration_task0 Returns Mean   187287
Exploration_task0 Returns Std    463603
Exploration_task0 Returns Max         2.3056e+06
Exploration_task0 Returns Min     -1667.83
Exploration_task0 Actions Mean       -0.028555
Exploration_task0 Actions Std         0.9111
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               2793.39
AverageReturn_all_train_tasks       217.088
AverageReturn_all_test_tasks       2793.39
Number of train steps total      233000
Number of env steps total             1.1651e+07
Number of rollouts total          84585
Train Time (s)                      100.693
(Previous) Eval Time (s)             25.6368
Sample Time (s)                     106.888
Epoch Time (s)                      233.218
Total Train Time (s)              54141.6
Epoch                               232
------------------------------  -----------------
2019-06-27 15:35:14.200203 UTC | [dialturn] Iteration #232 | Epoch Duration: 233.25642156600952
2019-06-27 15:35:14.200426 UTC | [dialturn] Iteration #232 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000537341
Z variance train                      1.0001
KL Divergence                         2.4787e-05
KL Loss                               2.4787e-06
QF Loss                               2.2283e+09
VF Loss                               9.32722e+06
RF Loss                          256533
Policy Loss                     -224831
Q Predictions Mean               221922
Q Predictions Std                313990
Q Predictions Max                868397
Q Predictions Min                 -2443.27
V Predictions Mean               223905
V Predictions Std                316314
V Predictions Max                868570
V Predictions Min                 -2277.87
R Predictions Mean                 1402.55
R Predictions Std                  3699.63
R Predictions Max                 22790.7
R Predictions Min                  -195.027
Log Pis Mean                         25.0793
Log Pis Std                          12.5151
Log Pis Max                          57.4192
Log Pis Min                          -0.0393727
Policy mu Mean                       -3.86477
Policy mu Std                        26.6193
Policy mu Max                       138.482
Policy mu Min                      -241.562
Policy log std Mean                  -0.638602
Policy log std Std                    1.34233
Policy log std Max                    2
Policy log std Min                   -6.42666
_task0 Rewards Mean                 177.916
_task0 Rewards Std                  374.249
_task0 Rewards Max                 2156.3
_task0 Rewards Min                   -0.901664
_task0 Returns Mean               26687.5
_task0 Returns Std                53293.1
_task0 Returns Max               217632
_task0 Returns Min                  -99.2073
_task0 Actions Mean                  -0.0289082
_task0 Actions Std                    0.859499
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1226.59
Exploration_task0 Rewards Std      2999.86
Exploration_task0 Rewards Max     22887.6
Exploration_task0 Rewards Min       -10.2386
Exploration_task0 Returns Mean   185847
Exploration_task0 Returns Std    425557
Exploration_task0 Returns Max         2.13972e+06
Exploration_task0 Returns Min     -1437.15
Exploration_task0 Actions Mean        0.00741243
Exploration_task0 Actions Std         0.883056
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26687.5
AverageReturn_all_train_tasks     16879.5
AverageReturn_all_test_tasks      26687.5
Number of train steps total      234000
Number of env steps total             1.1701e+07
Number of rollouts total          84948
Train Time (s)                      101.824
(Previous) Eval Time (s)             25.6739
Sample Time (s)                     107.057
Epoch Time (s)                      234.555
Total Train Time (s)              54376.2
Epoch                               233
------------------------------  -----------------
2019-06-27 15:39:08.808560 UTC | [dialturn] Iteration #233 | Epoch Duration: 234.607971906662
2019-06-27 15:39:08.808764 UTC | [dialturn] Iteration #233 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000767402
Z variance train                      1.00006
KL Divergence                         4.89199e-05
KL Loss                               4.89199e-06
QF Loss                               1.66658e+09
VF Loss                               1.42942e+07
RF Loss                          176750
Policy Loss                     -226545
Q Predictions Mean               223736
Q Predictions Std                312565
Q Predictions Max                875916
Q Predictions Min                  -807.023
V Predictions Mean               228183
V Predictions Std                317847
V Predictions Max                878634
V Predictions Min                  -701.867
R Predictions Mean                  897.569
R Predictions Std                  2533.33
R Predictions Max                 15831.7
R Predictions Min                  -100.246
Log Pis Mean                         24.1047
Log Pis Std                          12.6175
Log Pis Max                          56.344
Log Pis Min                          -4.40359
Policy mu Mean                       -3.51501
Policy mu Std                        24.653
Policy mu Max                       139.313
Policy mu Min                      -228.539
Policy log std Mean                  -0.616998
Policy log std Std                    1.2957
Policy log std Max                    2
Policy log std Min                   -5.83503
_task0 Rewards Mean                 180.982
_task0 Rewards Std                  354.88
_task0 Rewards Max                 1555.59
_task0 Rewards Min                   -1.00213
_task0 Returns Mean               27147.3
_task0 Returns Std                51120.6
_task0 Returns Max               149236
_task0 Returns Min                 -127.023
_task0 Actions Mean                  -0.0645441
_task0 Actions Std                    0.848881
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1332.48
Exploration_task0 Rewards Std      3208.57
Exploration_task0 Rewards Max     23045.7
Exploration_task0 Rewards Min       -10.345
Exploration_task0 Returns Mean   201891
Exploration_task0 Returns Std    450446
Exploration_task0 Returns Max         2.38202e+06
Exploration_task0 Returns Min     -1229.46
Exploration_task0 Actions Mean       -0.0293689
Exploration_task0 Actions Std         0.877335
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27147.3
AverageReturn_all_train_tasks      8603.99
AverageReturn_all_test_tasks      27147.3
Number of train steps total      235000
Number of env steps total             1.1751e+07
Number of rollouts total          85311
Train Time (s)                      101.116
(Previous) Eval Time (s)             25.7253
Sample Time (s)                     107.099
Epoch Time (s)                      233.94
Total Train Time (s)              54610.1
Epoch                               234
------------------------------  -----------------
2019-06-27 15:43:02.693125 UTC | [dialturn] Iteration #234 | Epoch Duration: 233.88414692878723
2019-06-27 15:43:02.693336 UTC | [dialturn] Iteration #234 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000752007
Z variance train                      0.999916
KL Divergence                         0.000128814
KL Loss                               1.28814e-05
QF Loss                               2.07522e+09
VF Loss                               4.38985e+07
RF Loss                          144169
Policy Loss                     -231625
Q Predictions Mean               228921
Q Predictions Std                315857
Q Predictions Max                877221
Q Predictions Min                 -1092.26
V Predictions Mean               235666
V Predictions Std                323830
V Predictions Max                891854
V Predictions Min                 -1429.37
R Predictions Mean                 1382.07
R Predictions Std                  3116.73
R Predictions Max                 19430.4
R Predictions Min                  -104.88
Log Pis Mean                         24.724
Log Pis Std                          12.6886
Log Pis Max                          54.7005
Log Pis Min                          -1.73182
Policy mu Mean                       -3.92806
Policy mu Std                        30.1589
Policy mu Max                       139.588
Policy mu Min                      -250.608
Policy log std Mean                  -0.568796
Policy log std Std                    1.32405
Policy log std Max                    2
Policy log std Min                   -5.93095
_task0 Rewards Mean                 100.005
_task0 Rewards Std                  201.344
_task0 Rewards Max                 1109.2
_task0 Rewards Min                   -0.974737
_task0 Returns Mean               15000.7
_task0 Returns Std                28771.2
_task0 Returns Max               117278
_task0 Returns Min                 -113.813
_task0 Actions Mean                  -0.0499582
_task0 Actions Std                    0.892976
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1669.4
Exploration_task0 Rewards Std      3643.78
Exploration_task0 Rewards Max     23056.4
Exploration_task0 Rewards Min       -10.5914
Exploration_task0 Returns Mean   252940
Exploration_task0 Returns Std    515180
Exploration_task0 Returns Max         2.82181e+06
Exploration_task0 Returns Min     -1358.09
Exploration_task0 Actions Mean       -0.0187821
Exploration_task0 Actions Std         0.863766
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15000.7
AverageReturn_all_train_tasks     24413
AverageReturn_all_test_tasks      15000.7
Number of train steps total      236000
Number of env steps total             1.1801e+07
Number of rollouts total          85674
Train Time (s)                      101.867
(Previous) Eval Time (s)             25.6679
Sample Time (s)                     107.253
Epoch Time (s)                      234.788
Total Train Time (s)              54844.9
Epoch                               235
------------------------------  -----------------
2019-06-27 15:46:57.457348 UTC | [dialturn] Iteration #235 | Epoch Duration: 234.76385140419006
2019-06-27 15:46:57.457563 UTC | [dialturn] Iteration #235 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00050077
Z variance train                      0.999747
KL Divergence                         2.93436e-05
KL Loss                               2.93436e-06
QF Loss                               2.44059e+09
VF Loss                               5.96835e+06
RF Loss                           98532.3
Policy Loss                     -219283
Q Predictions Mean               217590
Q Predictions Std                313703
Q Predictions Max                887979
Q Predictions Min                 -2076.63
V Predictions Mean               220126
V Predictions Std                316859
V Predictions Max                890785
V Predictions Min                 -2932.88
R Predictions Mean                 1111.61
R Predictions Std                  3055.35
R Predictions Max                 19877.6
R Predictions Min                   -60.3781
Log Pis Mean                         24.0976
Log Pis Std                          12.0879
Log Pis Max                          55.014
Log Pis Min                           0.0358671
Policy mu Mean                       -3.13391
Policy mu Std                        25.226
Policy mu Max                       150.621
Policy mu Min                      -243.801
Policy log std Mean                  -0.62585
Policy log std Std                    1.29385
Policy log std Max                    2
Policy log std Min                   -5.94333
_task0 Rewards Mean                  84.7637
_task0 Rewards Std                  199.689
_task0 Rewards Max                  934.973
_task0 Rewards Min                   -0.923696
_task0 Returns Mean               12714.6
_task0 Returns Std                28555.9
_task0 Returns Max               108976
_task0 Returns Min                 -115.101
_task0 Actions Mean                   0.0837288
_task0 Actions Std                    0.904638
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1316.68
Exploration_task0 Rewards Std      3215.69
Exploration_task0 Rewards Max     22972.3
Exploration_task0 Rewards Min       -10.1996
Exploration_task0 Returns Mean   199497
Exploration_task0 Returns Std    447494
Exploration_task0 Returns Max         2.65326e+06
Exploration_task0 Returns Min     -1534.54
Exploration_task0 Actions Mean       -0.0592894
Exploration_task0 Actions Std         0.882432
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12714.6
AverageReturn_all_train_tasks      4786.23
AverageReturn_all_test_tasks      12714.6
Number of train steps total      237000
Number of env steps total             1.1851e+07
Number of rollouts total          86037
Train Time (s)                      101.424
(Previous) Eval Time (s)             25.6423
Sample Time (s)                     107.322
Epoch Time (s)                      234.389
Total Train Time (s)              55079.3
Epoch                               236
------------------------------  -----------------
2019-06-27 15:50:51.886893 UTC | [dialturn] Iteration #236 | Epoch Duration: 234.4291636943817
2019-06-27 15:50:51.887091 UTC | [dialturn] Iteration #236 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000710247
Z variance train                      0.99923
KL Divergence                         0.000104189
KL Loss                               1.04189e-05
QF Loss                               2.0176e+09
VF Loss                               1.25395e+07
RF Loss                          176004
Policy Loss                     -223381
Q Predictions Mean               220441
Q Predictions Std                317762
Q Predictions Max                889699
Q Predictions Min                 -1590.34
V Predictions Mean               221780
V Predictions Std                319337
V Predictions Max                890195
V Predictions Min                 -2398.79
R Predictions Mean                 1261.58
R Predictions Std                  3098.82
R Predictions Max                 16372.4
R Predictions Min                  -188.624
Log Pis Mean                         24.3483
Log Pis Std                          12.2369
Log Pis Max                          55
Log Pis Min                          -1.26496
Policy mu Mean                       -2.75802
Policy mu Std                        24.369
Policy mu Max                       152.468
Policy mu Min                      -237.509
Policy log std Mean                  -0.632594
Policy log std Std                    1.29079
Policy log std Max                    2
Policy log std Min                   -5.35626
_task0 Rewards Mean                 228.588
_task0 Rewards Std                  402.216
_task0 Rewards Max                 1933.42
_task0 Rewards Min                   -1.01889
_task0 Returns Mean               34288.2
_task0 Returns Std                56284.5
_task0 Returns Max               170632
_task0 Returns Min                 -111.847
_task0 Actions Mean                   0.0493339
_task0 Actions Std                    0.839139
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1255.71
Exploration_task0 Rewards Std      3470.18
Exploration_task0 Rewards Max     22990.9
Exploration_task0 Rewards Min        -9.99501
Exploration_task0 Returns Mean   190260
Exploration_task0 Returns Std    477715
Exploration_task0 Returns Max         2.19429e+06
Exploration_task0 Returns Min     -1212.83
Exploration_task0 Actions Mean       -0.0194785
Exploration_task0 Actions Std         0.905629
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              34288.2
AverageReturn_all_train_tasks     22487.5
AverageReturn_all_test_tasks      34288.2
Number of train steps total      238000
Number of env steps total             1.1901e+07
Number of rollouts total          86400
Train Time (s)                      100.972
(Previous) Eval Time (s)             25.6814
Sample Time (s)                     107.03
Epoch Time (s)                      233.683
Total Train Time (s)              55313
Epoch                               237
------------------------------  -----------------
2019-06-27 15:54:45.600920 UTC | [dialturn] Iteration #237 | Epoch Duration: 233.71364092826843
2019-06-27 15:54:45.601154 UTC | [dialturn] Iteration #237 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000670212
Z variance train                      1.00005
KL Divergence                         7.29424e-05
KL Loss                               7.29424e-06
QF Loss                               1.66969e+09
VF Loss                               1.63889e+07
RF Loss                          106643
Policy Loss                     -225417
Q Predictions Mean               223019
Q Predictions Std                319161
Q Predictions Max                902373
Q Predictions Min                  -564.533
V Predictions Mean               226753
V Predictions Std                324207
V Predictions Max                907582
V Predictions Min                  -864.484
R Predictions Mean                 1661.89
R Predictions Std                  3493.52
R Predictions Max                 16333.6
R Predictions Min                  -211.883
Log Pis Mean                         24.4767
Log Pis Std                          13.1789
Log Pis Max                          52.5164
Log Pis Min                          -2.50592
Policy mu Mean                       -3.19755
Policy mu Std                        27.2197
Policy mu Max                       137.774
Policy mu Min                      -252.227
Policy log std Mean                  -0.581461
Policy log std Std                    1.35187
Policy log std Max                    2
Policy log std Min                   -5.44473
_task0 Rewards Mean                  89.8486
_task0 Rewards Std                  203.267
_task0 Rewards Max                 1132.17
_task0 Rewards Min                   -0.931995
_task0 Returns Mean               13477.3
_task0 Returns Std                27974.7
_task0 Returns Max                93542.1
_task0 Returns Min                 -118.034
_task0 Actions Mean                  -0.0406039
_task0 Actions Std                    0.868712
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1338.04
Exploration_task0 Rewards Std      3378.19
Exploration_task0 Rewards Max     22802.2
Exploration_task0 Rewards Min       -10.4408
Exploration_task0 Returns Mean   202733
Exploration_task0 Returns Std    474814
Exploration_task0 Returns Max         2.33707e+06
Exploration_task0 Returns Min     -1380.86
Exploration_task0 Actions Mean       -0.00152671
Exploration_task0 Actions Std         0.871377
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13477.3
AverageReturn_all_train_tasks      1940.03
AverageReturn_all_test_tasks      13477.3
Number of train steps total      239000
Number of env steps total             1.1951e+07
Number of rollouts total          86763
Train Time (s)                      101.158
(Previous) Eval Time (s)             25.7102
Sample Time (s)                     107.64
Epoch Time (s)                      234.508
Total Train Time (s)              55547.4
Epoch                               238
------------------------------  -----------------
2019-06-27 15:58:40.038984 UTC | [dialturn] Iteration #238 | Epoch Duration: 234.43761372566223
2019-06-27 15:58:40.039195 UTC | [dialturn] Iteration #238 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000192579
Z variance train                      0.999976
KL Divergence                         3.84182e-06
KL Loss                               3.84182e-07
QF Loss                               1.22602e+09
VF Loss                               2.38968e+07
RF Loss                          113971
Policy Loss                     -230690
Q Predictions Mean               227462
Q Predictions Std                320271
Q Predictions Max                899516
Q Predictions Min                 -2765.57
V Predictions Mean               233107
V Predictions Std                327252
V Predictions Max                912814
V Predictions Min                 -2514.91
R Predictions Mean                 1173.19
R Predictions Std                  2904.97
R Predictions Max                 17159.9
R Predictions Min                   -81.108
Log Pis Mean                         24.7333
Log Pis Std                          12.6621
Log Pis Max                          56.2817
Log Pis Min                          -2.53375
Policy mu Mean                       -3.41087
Policy mu Std                        26.6958
Policy mu Max                       146.235
Policy mu Min                      -253.065
Policy log std Mean                  -0.543287
Policy log std Std                    1.36645
Policy log std Max                    2
Policy log std Min                   -5.37537
_task0 Rewards Mean                 137.719
_task0 Rewards Std                  350.025
_task0 Rewards Max                 2046.1
_task0 Rewards Min                   -0.879808
_task0 Returns Mean               20657.9
_task0 Returns Std                49762.9
_task0 Returns Max               208576
_task0 Returns Min                 -114.025
_task0 Actions Mean                  -0.0427008
_task0 Actions Std                    0.873102
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2122.93
Exploration_task0 Rewards Std      4453.48
Exploration_task0 Rewards Max     23135.1
Exploration_task0 Rewards Min       -13.0816
Exploration_task0 Returns Mean   321655
Exploration_task0 Returns Std    621423
Exploration_task0 Returns Max         2.34098e+06
Exploration_task0 Returns Min     -1429.81
Exploration_task0 Actions Mean       -0.0325037
Exploration_task0 Actions Std         0.867906
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              20657.9
AverageReturn_all_train_tasks      5717.37
AverageReturn_all_test_tasks      20657.9
Number of train steps total      240000
Number of env steps total             1.2001e+07
Number of rollouts total          87126
Train Time (s)                      100.578
(Previous) Eval Time (s)             25.6381
Sample Time (s)                     106.94
Epoch Time (s)                      233.156
Total Train Time (s)              55780.6
Epoch                               239
------------------------------  -----------------
2019-06-27 16:02:33.212176 UTC | [dialturn] Iteration #239 | Epoch Duration: 233.17281889915466
2019-06-27 16:02:33.212403 UTC | [dialturn] Iteration #239 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000505049
Z variance train                      0.999907
KL Divergence                         2.65601e-05
KL Loss                               2.65601e-06
QF Loss                               2.24489e+09
VF Loss                               2.7173e+06
RF Loss                          118750
Policy Loss                     -232350
Q Predictions Mean               229998
Q Predictions Std                328825
Q Predictions Max                914242
Q Predictions Min                 -1134.43
V Predictions Mean               232421
V Predictions Std                331775
V Predictions Max                916115
V Predictions Min                  -401.798
R Predictions Mean                 1050.97
R Predictions Std                  2942.46
R Predictions Max                 19116.1
R Predictions Min                   -79.7166
Log Pis Mean                         24.4113
Log Pis Std                          12.7335
Log Pis Max                          55.087
Log Pis Min                          -2.01227
Policy mu Mean                       -3.6996
Policy mu Std                        26.8644
Policy mu Max                       158.592
Policy mu Min                      -265.684
Policy log std Mean                  -0.579204
Policy log std Std                    1.37716
Policy log std Max                    2
Policy log std Min                   -5.21854
_task0 Rewards Mean                  83.1335
_task0 Rewards Std                  174.196
_task0 Rewards Max                  931.932
_task0 Rewards Min                   -0.884696
_task0 Returns Mean               12470
_task0 Returns Std                24563.8
_task0 Returns Max                92656.2
_task0 Returns Min                 -114.399
_task0 Actions Mean                   0.0234792
_task0 Actions Std                    0.909424
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1578
Exploration_task0 Rewards Std      3836.33
Exploration_task0 Rewards Max     23052.5
Exploration_task0 Rewards Min       -11.4654
Exploration_task0 Returns Mean   239091
Exploration_task0 Returns Std    536507
Exploration_task0 Returns Max         2.38738e+06
Exploration_task0 Returns Min     -1292.23
Exploration_task0 Actions Mean        0.00234246
Exploration_task0 Actions Std         0.882573
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12470
AverageReturn_all_train_tasks     37391.7
AverageReturn_all_test_tasks      12470
Number of train steps total      241000
Number of env steps total             1.2051e+07
Number of rollouts total          87489
Train Time (s)                      100.029
(Previous) Eval Time (s)             25.6529
Sample Time (s)                     106.529
Epoch Time (s)                      232.211
Total Train Time (s)              56012.6
Epoch                               240
------------------------------  -----------------
2019-06-27 16:06:25.178471 UTC | [dialturn] Iteration #240 | Epoch Duration: 231.96571898460388
2019-06-27 16:06:25.178680 UTC | [dialturn] Iteration #240 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000374183
Z variance train                      1.0001
KL Divergence                         1.40178e-05
KL Loss                               1.40178e-06
QF Loss                               1.08607e+09
VF Loss                               6.40862e+06
RF Loss                          256009
Policy Loss                     -223620
Q Predictions Mean               220787
Q Predictions Std                322414
Q Predictions Max                921483
Q Predictions Min                 -2296.79
V Predictions Mean               223888
V Predictions Std                326099
V Predictions Max                923403
V Predictions Min                 -1864.12
R Predictions Mean                 1207.45
R Predictions Std                  2864.37
R Predictions Max                 17869.4
R Predictions Min                  -125.459
Log Pis Mean                         24.4577
Log Pis Std                          13.0178
Log Pis Max                          55.2615
Log Pis Min                          -3.97737
Policy mu Mean                       -3.61873
Policy mu Std                        28.3691
Policy mu Max                       182.936
Policy mu Min                      -262.417
Policy log std Mean                  -0.635887
Policy log std Std                    1.39242
Policy log std Max                    2
Policy log std Min                   -6.14232
_task0 Rewards Mean                 112.605
_task0 Rewards Std                  275.434
_task0 Rewards Max                 1125.09
_task0 Rewards Min                   -0.96383
_task0 Returns Mean               16890.8
_task0 Returns Std                39799.6
_task0 Returns Max               134042
_task0 Returns Min                 -115.754
_task0 Actions Mean                   0.131309
_task0 Actions Std                    0.897859
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1385.16
Exploration_task0 Rewards Std      3475.66
Exploration_task0 Rewards Max     23119.4
Exploration_task0 Rewards Min       -10.4187
Exploration_task0 Returns Mean   209873
Exploration_task0 Returns Std    478924
Exploration_task0 Returns Max         2.60089e+06
Exploration_task0 Returns Min     -1321.32
Exploration_task0 Actions Mean       -0.0247718
Exploration_task0 Actions Std         0.909319
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16890.8
AverageReturn_all_train_tasks      7277.28
AverageReturn_all_test_tasks      16890.8
Number of train steps total      242000
Number of env steps total             1.2101e+07
Number of rollouts total          87852
Train Time (s)                      100.584
(Previous) Eval Time (s)             25.4061
Sample Time (s)                     106.849
Epoch Time (s)                      232.839
Total Train Time (s)              56245.7
Epoch                               241
------------------------------  -----------------
2019-06-27 16:10:18.274163 UTC | [dialturn] Iteration #241 | Epoch Duration: 233.09532380104065
2019-06-27 16:10:18.274370 UTC | [dialturn] Iteration #241 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00112505
Z variance train                      0.999811
KL Divergence                         0.000161505
KL Loss                               1.61505e-05
QF Loss                               1.39666e+09
VF Loss                               1.27661e+07
RF Loss                          397845
Policy Loss                     -238255
Q Predictions Mean               235711
Q Predictions Std                329035
Q Predictions Max                930833
Q Predictions Min                  -879.018
V Predictions Mean               237498
V Predictions Std                331044
V Predictions Max                927887
V Predictions Min                 -1324.01
R Predictions Mean                 1971.02
R Predictions Std                  4262.93
R Predictions Max                 19410.6
R Predictions Min                   -85.3863
Log Pis Mean                         26.4473
Log Pis Std                          12.9609
Log Pis Max                          55.9458
Log Pis Min                          -1.61867
Policy mu Mean                       -3.51889
Policy mu Std                        30.4604
Policy mu Max                       181.056
Policy mu Min                      -263.629
Policy log std Mean                  -0.502684
Policy log std Std                    1.44117
Policy log std Max                    2
Policy log std Min                   -7.73439
_task0 Rewards Mean                 111.419
_task0 Rewards Std                  257.695
_task0 Rewards Max                 1284.13
_task0 Rewards Min                   -0.890285
_task0 Returns Mean               16712.9
_task0 Returns Std                36513.9
_task0 Returns Max               139787
_task0 Returns Min                 -109.091
_task0 Actions Mean                   0.0365257
_task0 Actions Std                    0.874202
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1598.19
Exploration_task0 Rewards Std      3408.26
Exploration_task0 Rewards Max     23122.1
Exploration_task0 Rewards Min       -12.3637
Exploration_task0 Returns Mean   242150
Exploration_task0 Returns Std    470840
Exploration_task0 Returns Max         2.36939e+06
Exploration_task0 Returns Min     -1294.12
Exploration_task0 Actions Mean       -0.00338904
Exploration_task0 Actions Std         0.871121
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16712.9
AverageReturn_all_train_tasks     14858.6
AverageReturn_all_test_tasks      16712.9
Number of train steps total      243000
Number of env steps total             1.2151e+07
Number of rollouts total          88215
Train Time (s)                      100.041
(Previous) Eval Time (s)             25.6612
Sample Time (s)                     106.745
Epoch Time (s)                      232.448
Total Train Time (s)              56478.1
Epoch                               242
------------------------------  -----------------
2019-06-27 16:14:10.705065 UTC | [dialturn] Iteration #242 | Epoch Duration: 232.4305236339569
2019-06-27 16:14:10.705265 UTC | [dialturn] Iteration #242 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000426441
Z variance train                      1.0001
KL Divergence                         2.86497e-05
KL Loss                               2.86497e-06
QF Loss                               2.06423e+09
VF Loss                               3.77531e+06
RF Loss                          247903
Policy Loss                     -241182
Q Predictions Mean               239326
Q Predictions Std                335740
Q Predictions Max                942411
Q Predictions Min                 -1778.18
V Predictions Mean               241105
V Predictions Std                337921
V Predictions Max                939658
V Predictions Min                 -1789.76
R Predictions Mean                 1805.15
R Predictions Std                  4298.38
R Predictions Max                 19986.2
R Predictions Min                   -46.3079
Log Pis Mean                         24.6493
Log Pis Std                          13.4239
Log Pis Max                          54.2231
Log Pis Min                          -3.5096
Policy mu Mean                       -2.89051
Policy mu Std                        28.3314
Policy mu Max                       161.113
Policy mu Min                      -257.783
Policy log std Mean                  -0.588566
Policy log std Std                    1.4154
Policy log std Max                    2
Policy log std Min                   -7.00132
_task0 Rewards Mean                 119.954
_task0 Rewards Std                  266.285
_task0 Rewards Max                 1674.91
_task0 Rewards Min                   -0.905189
_task0 Returns Mean               17993.2
_task0 Returns Std                36953.8
_task0 Returns Max               153914
_task0 Returns Min                 -118.93
_task0 Actions Mean                   0.0206087
_task0 Actions Std                    0.888822
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1536.31
Exploration_task0 Rewards Std      3548.74
Exploration_task0 Rewards Max     23062.6
Exploration_task0 Rewards Min       -13.3289
Exploration_task0 Returns Mean   232774
Exploration_task0 Returns Std    490291
Exploration_task0 Returns Max         2.48384e+06
Exploration_task0 Returns Min     -1297.18
Exploration_task0 Actions Mean        0.0303835
Exploration_task0 Actions Std         0.896558
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17993.2
AverageReturn_all_train_tasks     14490.1
AverageReturn_all_test_tasks      17993.2
Number of train steps total      244000
Number of env steps total             1.2201e+07
Number of rollouts total          88578
Train Time (s)                       99.5671
(Previous) Eval Time (s)             25.6421
Sample Time (s)                     106.64
Epoch Time (s)                      231.849
Total Train Time (s)              56709.9
Epoch                               243
------------------------------  -----------------
2019-06-27 16:18:02.541498 UTC | [dialturn] Iteration #243 | Epoch Duration: 231.8360698223114
2019-06-27 16:18:02.541732 UTC | [dialturn] Iteration #243 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000823129
Z variance train                      1.00017
KL Divergence                         7.85059e-05
KL Loss                               7.85059e-06
QF Loss                               2.9668e+09
VF Loss                               5.8208e+06
RF Loss                           48505.4
Policy Loss                     -237462
Q Predictions Mean               235388
Q Predictions Std                330916
Q Predictions Max                941321
Q Predictions Min                  -797.911
V Predictions Mean               238083
V Predictions Std                334304
V Predictions Max                942904
V Predictions Min                  -851.476
R Predictions Mean                  777.506
R Predictions Std                  2027.05
R Predictions Max                 20184
R Predictions Min                  -216.793
Log Pis Mean                         25.4952
Log Pis Std                          12.8895
Log Pis Max                          55.1715
Log Pis Min                          -5.94953
Policy mu Mean                       -2.26452
Policy mu Std                        26.6858
Policy mu Max                       152.629
Policy mu Min                      -225.719
Policy log std Mean                  -0.568423
Policy log std Std                    1.36779
Policy log std Max                    2
Policy log std Min                   -6.71972
_task0 Rewards Mean                 114.664
_task0 Rewards Std                  255.159
_task0 Rewards Max                 1339.25
_task0 Rewards Min                   -0.865539
_task0 Returns Mean               17199.6
_task0 Returns Std                36841.7
_task0 Returns Max               141617
_task0 Returns Min                 -103.086
_task0 Actions Mean                  -0.0687211
_task0 Actions Std                    0.832353
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      931.823
Exploration_task0 Rewards Std      2527.36
Exploration_task0 Rewards Max     22800
Exploration_task0 Rewards Min       -10.3229
Exploration_task0 Returns Mean   141185
Exploration_task0 Returns Std    347244
Exploration_task0 Returns Max         2.69765e+06
Exploration_task0 Returns Min     -1385.96
Exploration_task0 Actions Mean       -0.00467142
Exploration_task0 Actions Std         0.906986
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17199.6
AverageReturn_all_train_tasks     17953.1
AverageReturn_all_test_tasks      17199.6
Number of train steps total      245000
Number of env steps total             1.2251e+07
Number of rollouts total          88941
Train Time (s)                       99.4985
(Previous) Eval Time (s)             25.628
Sample Time (s)                     106.586
Epoch Time (s)                      231.712
Total Train Time (s)              56941.6
Epoch                               244
------------------------------  -----------------
2019-06-27 16:21:54.212633 UTC | [dialturn] Iteration #244 | Epoch Duration: 231.67069244384766
2019-06-27 16:21:54.212836 UTC | [dialturn] Iteration #244 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000536816
Z variance train                      1.00044
KL Divergence                         3.11441e-05
KL Loss                               3.11441e-06
QF Loss                               1.90356e+09
VF Loss                               7.33786e+06
RF Loss                          192282
Policy Loss                     -234471
Q Predictions Mean               231775
Q Predictions Std                332116
Q Predictions Max                952653
Q Predictions Min                 -1379.04
V Predictions Mean               233255
V Predictions Std                333873
V Predictions Max                949097
V Predictions Min                 -1290.94
R Predictions Mean                 1729.87
R Predictions Std                  3724.27
R Predictions Max                 21363.4
R Predictions Min                   -98.6256
Log Pis Mean                         25.1821
Log Pis Std                          13.1387
Log Pis Max                          57.1729
Log Pis Min                          -3.32703
Policy mu Mean                       -2.35114
Policy mu Std                        26.2036
Policy mu Max                       153.969
Policy mu Min                      -235.955
Policy log std Mean                  -0.639633
Policy log std Std                    1.40821
Policy log std Max                    2
Policy log std Min                   -7.60714
_task0 Rewards Mean                  87.7755
_task0 Rewards Std                  249.422
_task0 Rewards Max                 1269.16
_task0 Rewards Min                   -0.905144
_task0 Returns Mean               13166.3
_task0 Returns Std                35599.1
_task0 Returns Max               145992
_task0 Returns Min                 -115.614
_task0 Actions Mean                  -0.0191033
_task0 Actions Std                    0.910903
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1912.11
Exploration_task0 Rewards Std      4118.81
Exploration_task0 Rewards Max     22938.2
Exploration_task0 Rewards Min       -16.7475
Exploration_task0 Returns Mean   289713
Exploration_task0 Returns Std    582619
Exploration_task0 Returns Max         2.59207e+06
Exploration_task0 Returns Min     -1355.32
Exploration_task0 Actions Mean        0.0108083
Exploration_task0 Actions Std         0.886577
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13166.3
AverageReturn_all_train_tasks      2396.68
AverageReturn_all_test_tasks      13166.3
Number of train steps total      246000
Number of env steps total             1.2301e+07
Number of rollouts total          89304
Train Time (s)                      100.212
(Previous) Eval Time (s)             25.5852
Sample Time (s)                     106.601
Epoch Time (s)                      232.399
Total Train Time (s)              57174
Epoch                               245
------------------------------  -----------------
2019-06-27 16:25:46.622164 UTC | [dialturn] Iteration #245 | Epoch Duration: 232.4091649055481
2019-06-27 16:25:46.622370 UTC | [dialturn] Iteration #245 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0010055
Z variance train                      1.00061
KL Divergence                         9.06989e-05
KL Loss                               9.06989e-06
QF Loss                               2.7615e+09
VF Loss                               6.96226e+06
RF Loss                          131075
Policy Loss                     -243846
Q Predictions Mean               240817
Q Predictions Std                333916
Q Predictions Max                958059
Q Predictions Min                 -1673.9
V Predictions Mean               243096
V Predictions Std                336495
V Predictions Max                948924
V Predictions Min                 -1586
R Predictions Mean                 1136.06
R Predictions Std                  3209.47
R Predictions Max                 20742
R Predictions Min                   -35.3215
Log Pis Mean                         25.8521
Log Pis Std                          12.3309
Log Pis Max                          54.3569
Log Pis Min                          -3.42369
Policy mu Mean                       -2.69469
Policy mu Std                        29.6399
Policy mu Max                       166.688
Policy mu Min                      -250.955
Policy log std Mean                  -0.592795
Policy log std Std                    1.41441
Policy log std Max                    2
Policy log std Min                   -6.19711
_task0 Rewards Mean                 229.896
_task0 Rewards Std                  410.765
_task0 Rewards Max                 1665.71
_task0 Rewards Min                   -0.844421
_task0 Returns Mean               34484.4
_task0 Returns Std                58186
_task0 Returns Max               153780
_task0 Returns Min                 -106.985
_task0 Actions Mean                   0.00287895
_task0 Actions Std                    0.841416
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1169.54
Exploration_task0 Rewards Std      3259.35
Exploration_task0 Rewards Max     23106.6
Exploration_task0 Rewards Min       -10.1128
Exploration_task0 Returns Mean   177203
Exploration_task0 Returns Std    455099
Exploration_task0 Returns Max         2.66999e+06
Exploration_task0 Returns Min     -1686.73
Exploration_task0 Actions Mean        0.0126193
Exploration_task0 Actions Std         0.91395
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              34484.4
AverageReturn_all_train_tasks       812.584
AverageReturn_all_test_tasks      34484.4
Number of train steps total      247000
Number of env steps total             1.2351e+07
Number of rollouts total          89667
Train Time (s)                       99.9324
(Previous) Eval Time (s)             25.5941
Sample Time (s)                     105.982
Epoch Time (s)                      231.509
Total Train Time (s)              57405.5
Epoch                               246
------------------------------  -----------------
2019-06-27 16:29:38.101059 UTC | [dialturn] Iteration #246 | Epoch Duration: 231.47846674919128
2019-06-27 16:29:38.101269 UTC | [dialturn] Iteration #246 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000318293
Z variance train                      1.00011
KL Divergence                         1.10196e-05
KL Loss                               1.10196e-06
QF Loss                               2.1056e+09
VF Loss                               1.27956e+07
RF Loss                           70102.9
Policy Loss                     -232970
Q Predictions Mean               229803
Q Predictions Std                331611
Q Predictions Max                954984
Q Predictions Min                 -2788.59
V Predictions Mean               230947
V Predictions Std                333300
V Predictions Max                950870
V Predictions Min                 -2829.33
R Predictions Mean                 1027.17
R Predictions Std                  2256.65
R Predictions Max                 16012.8
R Predictions Min                   -22.1668
Log Pis Mean                         26.3673
Log Pis Std                          12.3764
Log Pis Max                          58.0584
Log Pis Min                          -1.09355
Policy mu Mean                       -2.53326
Policy mu Std                        30.3145
Policy mu Max                       180.336
Policy mu Min                      -251.503
Policy log std Mean                  -0.588167
Policy log std Std                    1.41252
Policy log std Max                    2
Policy log std Min                   -6.69138
_task0 Rewards Mean                  92.2741
_task0 Rewards Std                  193.133
_task0 Rewards Max                 1161.01
_task0 Rewards Min                   -0.862593
_task0 Returns Mean               13841.1
_task0 Returns Std                26680.7
_task0 Returns Max               102759
_task0 Returns Min                 -108.595
_task0 Actions Mean                   0.0413664
_task0 Actions Std                    0.814663
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1643.11
Exploration_task0 Rewards Std      3788.75
Exploration_task0 Rewards Max     22369.3
Exploration_task0 Rewards Min        -9.77787
Exploration_task0 Returns Mean   248957
Exploration_task0 Returns Std    534544
Exploration_task0 Returns Max         2.36064e+06
Exploration_task0 Returns Min     -1479.45
Exploration_task0 Actions Mean        0.0116526
Exploration_task0 Actions Std         0.876405
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13841.1
AverageReturn_all_train_tasks     25062.3
AverageReturn_all_test_tasks      13841.1
Number of train steps total      248000
Number of env steps total             1.2401e+07
Number of rollouts total          90030
Train Time (s)                       99.9578
(Previous) Eval Time (s)             25.5623
Sample Time (s)                     106.755
Epoch Time (s)                      232.275
Total Train Time (s)              57637.8
Epoch                               247
------------------------------  -----------------
2019-06-27 16:33:30.444039 UTC | [dialturn] Iteration #247 | Epoch Duration: 232.34251713752747
2019-06-27 16:33:30.444261 UTC | [dialturn] Iteration #247 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0011358
Z variance train                      0.999529
KL Divergence                         0.000184565
KL Loss                               1.84565e-05
QF Loss                               9.29445e+08
VF Loss                               5.91852e+06
RF Loss                          103098
Policy Loss                     -239937
Q Predictions Mean               237157
Q Predictions Std                340136
Q Predictions Max                963600
Q Predictions Min                 -1734.96
V Predictions Mean               240305
V Predictions Std                343809
V Predictions Max                966001
V Predictions Min                 -1668.25
R Predictions Mean                 1578.54
R Predictions Std                  3248.56
R Predictions Max                 21992.7
R Predictions Min                   -18.7643
Log Pis Mean                         26.6505
Log Pis Std                          12.2626
Log Pis Max                          57.5408
Log Pis Min                          -0.349694
Policy mu Mean                       -3.38579
Policy mu Std                        26.2147
Policy mu Max                       203.035
Policy mu Min                      -223.84
Policy log std Mean                  -0.610594
Policy log std Std                    1.44164
Policy log std Max                    2
Policy log std Min                   -7.37262
_task0 Rewards Mean                 115.267
_task0 Rewards Std                  246.295
_task0 Rewards Max                 1245.47
_task0 Rewards Min                   -0.794593
_task0 Returns Mean               17290.1
_task0 Returns Std                35706.8
_task0 Returns Max               144251
_task0 Returns Min                  -98.2099
_task0 Actions Mean                  -0.0821915
_task0 Actions Std                    0.867856
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1276.82
Exploration_task0 Rewards Std      2450.02
Exploration_task0 Rewards Max     21589
Exploration_task0 Rewards Min        -9.17319
Exploration_task0 Returns Mean   193458
Exploration_task0 Returns Std    338560
Exploration_task0 Returns Max         1.70532e+06
Exploration_task0 Returns Min     -1467.59
Exploration_task0 Actions Mean       -0.0178111
Exploration_task0 Actions Std         0.850701
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17290.1
AverageReturn_all_train_tasks      5893.53
AverageReturn_all_test_tasks      17290.1
Number of train steps total      249000
Number of env steps total             1.2451e+07
Number of rollouts total          90393
Train Time (s)                       99.5379
(Previous) Eval Time (s)             25.6285
Sample Time (s)                     107.162
Epoch Time (s)                      232.329
Total Train Time (s)              57870
Epoch                               248
------------------------------  -----------------
2019-06-27 16:37:22.631576 UTC | [dialturn] Iteration #248 | Epoch Duration: 232.18714833259583
2019-06-27 16:37:22.631774 UTC | [dialturn] Iteration #248 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000457725
Z variance train                      1.0007
KL Divergence                         4.47198e-05
KL Loss                               4.47198e-06
QF Loss                               2.55539e+09
VF Loss                               2.02677e+07
RF Loss                          138908
Policy Loss                     -238522
Q Predictions Mean               236221
Q Predictions Std                335237
Q Predictions Max                957943
Q Predictions Min                 -1169.75
V Predictions Mean               241227
V Predictions Std                340872
V Predictions Max                967553
V Predictions Min                 -1078.32
R Predictions Mean                 1808.06
R Predictions Std                  3728.33
R Predictions Max                 19670.5
R Predictions Min                   -19.3422
Log Pis Mean                         26.2439
Log Pis Std                          11.9998
Log Pis Max                          59.0192
Log Pis Min                          -2.37832
Policy mu Mean                       -2.28337
Policy mu Std                        28.2107
Policy mu Max                       165.218
Policy mu Min                      -214.436
Policy log std Mean                  -0.579718
Policy log std Std                    1.42915
Policy log std Max                    2
Policy log std Min                   -9.16971
_task0 Rewards Mean                 167.227
_task0 Rewards Std                  327.865
_task0 Rewards Max                 1372.6
_task0 Rewards Min                   -0.851412
_task0 Returns Mean               25084
_task0 Returns Std                47148.6
_task0 Returns Max               140909
_task0 Returns Min                 -103.344
_task0 Actions Mean                  -0.0619952
_task0 Actions Std                    0.871079
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1286.87
Exploration_task0 Rewards Std      3101.05
Exploration_task0 Rewards Max     22624.1
Exploration_task0 Rewards Min       -10.0955
Exploration_task0 Returns Mean   194981
Exploration_task0 Returns Std    433314
Exploration_task0 Returns Max         2.52549e+06
Exploration_task0 Returns Min     -1381.82
Exploration_task0 Actions Mean       -0.0035421
Exploration_task0 Actions Std         0.878373
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              25084
AverageReturn_all_train_tasks      7439.47
AverageReturn_all_test_tasks      25084
Number of train steps total      250000
Number of env steps total             1.2501e+07
Number of rollouts total          90756
Train Time (s)                      100.769
(Previous) Eval Time (s)             25.4855
Sample Time (s)                     106.303
Epoch Time (s)                      232.558
Total Train Time (s)              58102.7
Epoch                               249
------------------------------  -----------------
2019-06-27 16:41:15.318502 UTC | [dialturn] Iteration #249 | Epoch Duration: 232.6865110397339
2019-06-27 16:41:15.318737 UTC | [dialturn] Iteration #249 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000838006
Z variance train                      1.00003
KL Divergence                         8.65607e-05
KL Loss                               8.65607e-06
QF Loss                               2.118e+09
VF Loss                               2.10476e+07
RF Loss                          122721
Policy Loss                     -234960
Q Predictions Mean               232428
Q Predictions Std                337971
Q Predictions Max                979898
Q Predictions Min                  -926.152
V Predictions Mean               232459
V Predictions Std                337801
V Predictions Max                969824
V Predictions Min                 -2422.88
R Predictions Mean                 1636.83
R Predictions Std                  3343.49
R Predictions Max                 19437.5
R Predictions Min                   -15.3016
Log Pis Mean                         26.1141
Log Pis Std                          12.3434
Log Pis Max                          59.9036
Log Pis Min                          -0.794972
Policy mu Mean                       -1.56321
Policy mu Std                        30.4811
Policy mu Max                       186.773
Policy mu Min                      -233.799
Policy log std Mean                  -0.572954
Policy log std Std                    1.40235
Policy log std Max                    2
Policy log std Min                   -6.44833
_task0 Rewards Mean                 187.82
_task0 Rewards Std                  425.125
_task0 Rewards Max                 2228.06
_task0 Rewards Min                   -0.922586
_task0 Returns Mean               28173
_task0 Returns Std                60020
_task0 Returns Max               237570
_task0 Returns Min                 -107.386
_task0 Actions Mean                   0.0958215
_task0 Actions Std                    0.84679
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1504.7
Exploration_task0 Rewards Std      3780.93
Exploration_task0 Rewards Max     23000.7
Exploration_task0 Rewards Min       -10.0406
Exploration_task0 Returns Mean   227985
Exploration_task0 Returns Std    521250
Exploration_task0 Returns Max         2.69384e+06
Exploration_task0 Returns Min     -1284.4
Exploration_task0 Actions Mean        0.00699775
Exploration_task0 Actions Std         0.898311
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              28173
AverageReturn_all_train_tasks     24701.7
AverageReturn_all_test_tasks      28173
Number of train steps total      251000
Number of env steps total             1.2551e+07
Number of rollouts total          91119
Train Time (s)                      100.394
(Previous) Eval Time (s)             25.613
Sample Time (s)                     106.515
Epoch Time (s)                      232.522
Total Train Time (s)              58335.1
Epoch                               250
------------------------------  -----------------
2019-06-27 16:45:07.744784 UTC | [dialturn] Iteration #250 | Epoch Duration: 232.42586374282837
2019-06-27 16:45:07.744989 UTC | [dialturn] Iteration #250 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00121019
Z variance train                      1.00006
KL Divergence                         0.000167731
KL Loss                               1.67731e-05
QF Loss                               8.0898e+08
VF Loss                               1.13787e+07
RF Loss                          258685
Policy Loss                     -243019
Q Predictions Mean               238796
Q Predictions Std                341213
Q Predictions Max                972600
Q Predictions Min                 -1019.47
V Predictions Mean               241620
V Predictions Std                344528
V Predictions Max                973429
V Predictions Min                  -971.286
R Predictions Mean                 1971.96
R Predictions Std                  4030.38
R Predictions Max                 19465.5
R Predictions Min                   -85.999
Log Pis Mean                         26.5579
Log Pis Std                          12.2845
Log Pis Max                          56.9756
Log Pis Min                          -6.75103
Policy mu Mean                       -3.51479
Policy mu Std                        28.1898
Policy mu Max                       146.848
Policy mu Min                      -217.443
Policy log std Mean                  -0.522948
Policy log std Std                    1.4705
Policy log std Max                    2
Policy log std Min                   -8.01175
_task0 Rewards Mean                 117.181
_task0 Rewards Std                  232.895
_task0 Rewards Max                 1653.23
_task0 Rewards Min                   -0.868976
_task0 Returns Mean               17577.1
_task0 Returns Std                31250.5
_task0 Returns Max               110208
_task0 Returns Min                 -109.777
_task0 Actions Mean                  -0.00756731
_task0 Actions Std                    0.860731
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2104.86
Exploration_task0 Rewards Std      4410.27
Exploration_task0 Rewards Max     21156.4
Exploration_task0 Rewards Min        -9.09934
Exploration_task0 Returns Mean   318918
Exploration_task0 Returns Std    620233
Exploration_task0 Returns Max         2.36912e+06
Exploration_task0 Returns Min     -1324.11
Exploration_task0 Actions Mean        0.0184552
Exploration_task0 Actions Std         0.87941
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17577.1
AverageReturn_all_train_tasks     12087.1
AverageReturn_all_test_tasks      17577.1
Number of train steps total      252000
Number of env steps total             1.2601e+07
Number of rollouts total          91482
Train Time (s)                       99.3002
(Previous) Eval Time (s)             25.5151
Sample Time (s)                     106.541
Epoch Time (s)                      231.357
Total Train Time (s)              58566.5
Epoch                               251
------------------------------  -----------------
2019-06-27 16:48:59.187414 UTC | [dialturn] Iteration #251 | Epoch Duration: 231.44226479530334
2019-06-27 16:48:59.187617 UTC | [dialturn] Iteration #251 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000578296
Z variance train                      1.00023
KL Divergence                         4.77153e-05
KL Loss                               4.77153e-06
QF Loss                               1.09866e+09
VF Loss                               2.37452e+07
RF Loss                          180653
Policy Loss                     -240905
Q Predictions Mean               237454
Q Predictions Std                342600
Q Predictions Max                975886
Q Predictions Min                  -134.128
V Predictions Mean               238741
V Predictions Std                343926
V Predictions Max                974768
V Predictions Min                   -64.7434
R Predictions Mean                 1675.85
R Predictions Std                  4072.54
R Predictions Max                 21817.1
R Predictions Min                  -174.624
Log Pis Mean                         26.9616
Log Pis Std                          12.6753
Log Pis Max                          57.1304
Log Pis Min                          -5.57036
Policy mu Mean                       -3.30667
Policy mu Std                        27.6172
Policy mu Max                       157.417
Policy mu Min                      -207.248
Policy log std Mean                  -0.608953
Policy log std Std                    1.45209
Policy log std Max                    2
Policy log std Min                   -6.29539
_task0 Rewards Mean                 249.339
_task0 Rewards Std                  426.492
_task0 Rewards Max                 1846.42
_task0 Rewards Min                   -0.756627
_task0 Returns Mean               37400.9
_task0 Returns Std                60306.7
_task0 Returns Max               190945
_task0 Returns Min                 -100.45
_task0 Actions Mean                  -0.104108
_task0 Actions Std                    0.856344
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1370.81
Exploration_task0 Rewards Std      3026.99
Exploration_task0 Rewards Max     23166.1
Exploration_task0 Rewards Min       -10.0234
Exploration_task0 Returns Mean   207698
Exploration_task0 Returns Std    421949
Exploration_task0 Returns Max         2.70225e+06
Exploration_task0 Returns Min     -1717.01
Exploration_task0 Actions Mean        0.047614
Exploration_task0 Actions Std         0.902558
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              37400.9
AverageReturn_all_train_tasks     21489.3
AverageReturn_all_test_tasks      37400.9
Number of train steps total      253000
Number of env steps total             1.2651e+07
Number of rollouts total          91845
Train Time (s)                      100.509
(Previous) Eval Time (s)             25.5995
Sample Time (s)                     106.39
Epoch Time (s)                      232.498
Total Train Time (s)              58799
Epoch                               252
------------------------------  -----------------
2019-06-27 16:52:51.654618 UTC | [dialturn] Iteration #252 | Epoch Duration: 232.4668436050415
2019-06-27 16:52:51.654834 UTC | [dialturn] Iteration #252 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000395781
Z variance train                      0.99969
KL Divergence                         4.31553e-05
KL Loss                               4.31553e-06
QF Loss                               2.56395e+09
VF Loss                               1.09165e+07
RF Loss                          117895
Policy Loss                     -240889
Q Predictions Mean               239198
Q Predictions Std                339017
Q Predictions Max                980066
Q Predictions Min                 -1192.13
V Predictions Mean               242344
V Predictions Std                342884
V Predictions Max                985890
V Predictions Min                 -1186.66
R Predictions Mean                 1681.25
R Predictions Std                  3763.33
R Predictions Max                 20130.6
R Predictions Min                  -256.927
Log Pis Mean                         26.7985
Log Pis Std                          12.5746
Log Pis Max                          56.3716
Log Pis Min                          -0.681153
Policy mu Mean                       -3.1619
Policy mu Std                        29.1229
Policy mu Max                       176.793
Policy mu Min                      -211.825
Policy log std Mean                  -0.574295
Policy log std Std                    1.3875
Policy log std Max                    2
Policy log std Min                   -6.35122
_task0 Rewards Mean                 192.678
_task0 Rewards Std                  375.871
_task0 Rewards Max                 1982.82
_task0 Rewards Min                   -0.919849
_task0 Returns Mean               28901.8
_task0 Returns Std                53046.1
_task0 Returns Max               206906
_task0 Returns Min                 -103.593
_task0 Actions Mean                   0.0935993
_task0 Actions Std                    0.84862
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      981.368
Exploration_task0 Rewards Std      2819.42
Exploration_task0 Rewards Max     23040.4
Exploration_task0 Rewards Min       -11.8378
Exploration_task0 Returns Mean   148692
Exploration_task0 Returns Std    392466
Exploration_task0 Returns Max         2.58993e+06
Exploration_task0 Returns Min     -1374.71
Exploration_task0 Actions Mean        0.0617513
Exploration_task0 Actions Std         0.916185
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              28901.8
AverageReturn_all_train_tasks      6655.85
AverageReturn_all_test_tasks      28901.8
Number of train steps total      254000
Number of env steps total             1.2701e+07
Number of rollouts total          92208
Train Time (s)                      100.668
(Previous) Eval Time (s)             25.567
Sample Time (s)                     106.628
Epoch Time (s)                      232.863
Total Train Time (s)              59032
Epoch                               253
------------------------------  -----------------
2019-06-27 16:56:44.648394 UTC | [dialturn] Iteration #253 | Epoch Duration: 232.99335312843323
2019-06-27 16:56:44.648602 UTC | [dialturn] Iteration #253 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00072177
Z variance train                      1.00029
KL Divergence                         5.66177e-05
KL Loss                               5.66177e-06
QF Loss                               2.61816e+09
VF Loss                               9.4777e+06
RF Loss                          539081
Policy Loss                     -239896
Q Predictions Mean               237792
Q Predictions Std                342551
Q Predictions Max                983313
Q Predictions Min                 -1507.11
V Predictions Mean               241126
V Predictions Std                347107
V Predictions Max                987800
V Predictions Min                 -2572.1
R Predictions Mean                 1542.28
R Predictions Std                  4046.89
R Predictions Max                 22229.4
R Predictions Min                   -71.032
Log Pis Mean                         26.7673
Log Pis Std                          12.7172
Log Pis Max                          55.3372
Log Pis Min                          -6.61478
Policy mu Mean                       -2.93491
Policy mu Std                        26.6944
Policy mu Max                       147.557
Policy mu Min                      -194.631
Policy log std Mean                  -0.582511
Policy log std Std                    1.40012
Policy log std Max                    2
Policy log std Min                   -6.76387
_task0 Rewards Mean                 308.765
_task0 Rewards Std                  566.607
_task0 Rewards Max                 2079.79
_task0 Rewards Min                   -1.00625
_task0 Returns Mean               46314.7
_task0 Returns Std                79888.3
_task0 Returns Max               211662
_task0 Returns Min                 -102.174
_task0 Actions Mean                  -0.0133692
_task0 Actions Std                    0.86474
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1385.11
Exploration_task0 Rewards Std      4053.5
Exploration_task0 Rewards Max     23050.6
Exploration_task0 Rewards Min       -10.5113
Exploration_task0 Returns Mean   209865
Exploration_task0 Returns Std    566792
Exploration_task0 Returns Max         2.52378e+06
Exploration_task0 Returns Min     -1413.94
Exploration_task0 Actions Mean        0.106779
Exploration_task0 Actions Std         0.912326
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              46314.7
AverageReturn_all_train_tasks      4620.65
AverageReturn_all_test_tasks      46314.7
Number of train steps total      255000
Number of env steps total             1.2751e+07
Number of rollouts total          92571
Train Time (s)                      100.334
(Previous) Eval Time (s)             25.6958
Sample Time (s)                     106.724
Epoch Time (s)                      232.754
Total Train Time (s)              59264.5
Epoch                               254
------------------------------  -----------------
2019-06-27 17:00:37.140999 UTC | [dialturn] Iteration #254 | Epoch Duration: 232.49224066734314
2019-06-27 17:00:37.141211 UTC | [dialturn] Iteration #254 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0009753
Z variance train                      1.00011
KL Divergence                         9.36283e-05
KL Loss                               9.36283e-06
QF Loss                               8.56874e+08
VF Loss                               2.7585e+07
RF Loss                          150486
Policy Loss                     -235786
Q Predictions Mean               232007
Q Predictions Std                338614
Q Predictions Max                993234
Q Predictions Min                  -420.657
V Predictions Mean               233124
V Predictions Std                339978
V Predictions Max                987553
V Predictions Min                 -1210.65
R Predictions Mean                 1345.36
R Predictions Std                  3252.06
R Predictions Max                 21468.6
R Predictions Min                  -121.002
Log Pis Mean                         26.1898
Log Pis Std                          13.1368
Log Pis Max                          56.0775
Log Pis Min                          -6.24735
Policy mu Mean                       -3.3923
Policy mu Std                        28.8056
Policy mu Max                       154.869
Policy mu Min                      -206.298
Policy log std Mean                  -0.522267
Policy log std Std                    1.4432
Policy log std Max                    2
Policy log std Min                   -7.88524
_task0 Rewards Mean                 227.461
_task0 Rewards Std                  493.025
_task0 Rewards Max                 2302.76
_task0 Rewards Min                   -0.837821
_task0 Returns Mean               34119.1
_task0 Returns Std                69648.3
_task0 Returns Max               211629
_task0 Returns Min                 -103.761
_task0 Actions Mean                   0.071915
_task0 Actions Std                    0.850587
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1501.69
Exploration_task0 Rewards Std      3541.25
Exploration_task0 Rewards Max     23033.8
Exploration_task0 Rewards Min       -10.6156
Exploration_task0 Returns Mean   227528
Exploration_task0 Returns Std    496549
Exploration_task0 Returns Max         2.82862e+06
Exploration_task0 Returns Min     -1551.87
Exploration_task0 Actions Mean        0.0531784
Exploration_task0 Actions Std         0.904906
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              34119.1
AverageReturn_all_train_tasks     25450.9
AverageReturn_all_test_tasks      34119.1
Number of train steps total      256000
Number of env steps total             1.2801e+07
Number of rollouts total          92934
Train Time (s)                       99.5926
(Previous) Eval Time (s)             25.4328
Sample Time (s)                     106.612
Epoch Time (s)                      231.637
Total Train Time (s)              59496.4
Epoch                               255
------------------------------  -----------------
2019-06-27 17:04:29.105623 UTC | [dialturn] Iteration #255 | Epoch Duration: 231.96425771713257
2019-06-27 17:04:29.105825 UTC | [dialturn] Iteration #255 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000772077
Z variance train                      0.999777
KL Divergence                         6.05418e-05
KL Loss                               6.05418e-06
QF Loss                               2.83417e+09
VF Loss                               1.77603e+07
RF Loss                           91471.7
Policy Loss                     -241198
Q Predictions Mean               237858
Q Predictions Std                339251
Q Predictions Max                983094
Q Predictions Min                  -345.208
V Predictions Mean               243383
V Predictions Std                345724
V Predictions Max                994180
V Predictions Min                  -372.552
R Predictions Mean                 1225.73
R Predictions Std                  2516.5
R Predictions Max                 17583.3
R Predictions Min                   -58.006
Log Pis Mean                         26.2473
Log Pis Std                          12.8115
Log Pis Max                          56.3958
Log Pis Min                          -1.25511
Policy mu Mean                       -2.49357
Policy mu Std                        27.383
Policy mu Max                       158.534
Policy mu Min                      -204.305
Policy log std Mean                  -0.595592
Policy log std Std                    1.39783
Policy log std Max                    2
Policy log std Min                   -9.14095
_task0 Rewards Mean                  56.2231
_task0 Rewards Std                  197.524
_task0 Rewards Max                 1435.13
_task0 Rewards Min                   -1.03278
_task0 Returns Mean                8433.46
_task0 Returns Std                28482.6
_task0 Returns Max               123429
_task0 Returns Min                 -109.084
_task0 Actions Mean                   0.0409046
_task0 Actions Std                    0.907042
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1661.35
Exploration_task0 Rewards Std      3786.96
Exploration_task0 Rewards Max     23010.8
Exploration_task0 Rewards Min       -11.2232
Exploration_task0 Returns Mean   251719
Exploration_task0 Returns Std    527888
Exploration_task0 Returns Max         2.29934e+06
Exploration_task0 Returns Min     -1452.64
Exploration_task0 Actions Mean        0.0120755
Exploration_task0 Actions Std         0.879855
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               8433.46
AverageReturn_all_train_tasks     32331.4
AverageReturn_all_test_tasks       8433.46
Number of train steps total      257000
Number of env steps total             1.2851e+07
Number of rollouts total          93297
Train Time (s)                       99.812
(Previous) Eval Time (s)             25.7586
Sample Time (s)                     106.704
Epoch Time (s)                      232.274
Total Train Time (s)              59728.7
Epoch                               256
------------------------------  -----------------
2019-06-27 17:08:21.356549 UTC | [dialturn] Iteration #256 | Epoch Duration: 232.25055861473083
2019-06-27 17:08:21.356765 UTC | [dialturn] Iteration #256 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000815779
Z variance train                      0.99993
KL Divergence                         0.000100457
KL Loss                               1.00457e-05
QF Loss                               1.7321e+09
VF Loss                               1.7707e+07
RF Loss                          182653
Policy Loss                     -237486
Q Predictions Mean               234490
Q Predictions Std                340790
Q Predictions Max                995967
Q Predictions Min                 -1555.72
V Predictions Mean               235277
V Predictions Std                341600
V Predictions Max                991330
V Predictions Min                 -2773.66
R Predictions Mean                 1338.16
R Predictions Std                  2939.16
R Predictions Max                 19608.8
R Predictions Min                   -69.1669
Log Pis Mean                         26.5239
Log Pis Std                          13.1647
Log Pis Max                          59.1683
Log Pis Min                          -0.836677
Policy mu Mean                       -3.82895
Policy mu Std                        26.4906
Policy mu Max                       148.24
Policy mu Min                      -199.743
Policy log std Mean                  -0.606148
Policy log std Std                    1.3892
Policy log std Max                    2
Policy log std Min                   -9.06134
_task0 Rewards Mean                 148.899
_task0 Rewards Std                  340.776
_task0 Rewards Max                 1595.17
_task0 Rewards Min                   -1.05047
_task0 Returns Mean               22334.9
_task0 Returns Std                49048.8
_task0 Returns Max               161107
_task0 Returns Min                 -119.225
_task0 Actions Mean                   0.114529
_task0 Actions Std                    0.880813
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      995.779
Exploration_task0 Rewards Std      2408.42
Exploration_task0 Rewards Max     22728.5
Exploration_task0 Rewards Min       -11.3225
Exploration_task0 Returns Mean   150876
Exploration_task0 Returns Std    330368
Exploration_task0 Returns Max         2.29197e+06
Exploration_task0 Returns Min     -1538.44
Exploration_task0 Actions Mean        0.0187192
Exploration_task0 Actions Std         0.896123
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              22334.9
AverageReturn_all_train_tasks      2612.72
AverageReturn_all_test_tasks      22334.9
Number of train steps total      258000
Number of env steps total             1.2901e+07
Number of rollouts total          93660
Train Time (s)                      100.484
(Previous) Eval Time (s)             25.7335
Sample Time (s)                     106.584
Epoch Time (s)                      232.802
Total Train Time (s)              59961.4
Epoch                               257
------------------------------  -----------------
2019-06-27 17:12:14.068797 UTC | [dialturn] Iteration #257 | Epoch Duration: 232.71187233924866
2019-06-27 17:12:14.068995 UTC | [dialturn] Iteration #257 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0001539
Z variance train                      0.999194
KL Divergence                         2.42318e-05
KL Loss                               2.42318e-06
QF Loss                               1.27927e+09
VF Loss                               1.35917e+07
RF Loss                           54950.8
Policy Loss                     -243177
Q Predictions Mean               240704
Q Predictions Std                346205
Q Predictions Max                     1.00081e+06
Q Predictions Min                 -1010.78
V Predictions Mean               241286
V Predictions Std                346643
V Predictions Max                997440
V Predictions Min                  -961.571
R Predictions Mean                 1211.09
R Predictions Std                  3013.28
R Predictions Max                 16579.7
R Predictions Min                  -146.028
Log Pis Mean                         25.8209
Log Pis Std                          13.3892
Log Pis Max                          59.5428
Log Pis Min                          -1.00707
Policy mu Mean                       -4.07451
Policy mu Std                        28.8362
Policy mu Max                       163.124
Policy mu Min                      -206.986
Policy log std Mean                  -0.623866
Policy log std Std                    1.38803
Policy log std Max                    2
Policy log std Min                   -6.3989
_task0 Rewards Mean                  45.6075
_task0 Rewards Std                  143.7
_task0 Rewards Max                  835.765
_task0 Rewards Min                   -1.00108
_task0 Returns Mean                6841.12
_task0 Returns Std                20737.9
_task0 Returns Max                89688.2
_task0 Returns Min                  -98.0004
_task0 Actions Mean                   0.0349202
_task0 Actions Std                    0.924707
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1769.19
Exploration_task0 Rewards Std      3944.3
Exploration_task0 Rewards Max     22920.1
Exploration_task0 Rewards Min       -10.4853
Exploration_task0 Returns Mean   268059
Exploration_task0 Returns Std    549184
Exploration_task0 Returns Max         2.41767e+06
Exploration_task0 Returns Min     -1362.77
Exploration_task0 Actions Mean        0.0341284
Exploration_task0 Actions Std         0.883047
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               6841.12
AverageReturn_all_train_tasks      8717.45
AverageReturn_all_test_tasks       6841.12
Number of train steps total      259000
Number of env steps total             1.2951e+07
Number of rollouts total          94023
Train Time (s)                      100.179
(Previous) Eval Time (s)             25.6422
Sample Time (s)                     106.536
Epoch Time (s)                      232.358
Total Train Time (s)              60193.7
Epoch                               258
------------------------------  -----------------
2019-06-27 17:16:06.389343 UTC | [dialturn] Iteration #258 | Epoch Duration: 232.32018995285034
2019-06-27 17:16:06.389549 UTC | [dialturn] Iteration #258 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000736401
Z variance train                      0.999125
KL Divergence                         0.000147174
KL Loss                               1.47174e-05
QF Loss                               2.27593e+09
VF Loss                               1.90578e+07
RF Loss                          330442
Policy Loss                     -244498
Q Predictions Mean               243495
Q Predictions Std                344603
Q Predictions Max                     1.00485e+06
Q Predictions Min                   369.645
V Predictions Mean               246741
V Predictions Std                348678
V Predictions Max                     1.01067e+06
V Predictions Min                   204.722
R Predictions Mean                 1641.72
R Predictions Std                  3768.89
R Predictions Max                 18132.4
R Predictions Min                   -63.4583
Log Pis Mean                         26.1589
Log Pis Std                          13.7425
Log Pis Max                          56.8988
Log Pis Min                          -2.59808
Policy mu Mean                       -2.18222
Policy mu Std                        25.6789
Policy mu Max                       161.616
Policy mu Min                      -186.6
Policy log std Mean                  -0.647682
Policy log std Std                    1.40473
Policy log std Max                    2
Policy log std Min                   -8.12089
_task0 Rewards Mean                 118.656
_task0 Rewards Std                  239.729
_task0 Rewards Max                 1048.99
_task0 Rewards Min                   -0.907165
_task0 Returns Mean               17798.3
_task0 Returns Std                33849.8
_task0 Returns Max               109257
_task0 Returns Min                 -110.859
_task0 Actions Mean                   0.0692909
_task0 Actions Std                    0.898727
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1241.42
Exploration_task0 Rewards Std      3142.76
Exploration_task0 Rewards Max     22438.9
Exploration_task0 Rewards Min       -11.8161
Exploration_task0 Returns Mean   188094
Exploration_task0 Returns Std    434835
Exploration_task0 Returns Max         2.1925e+06
Exploration_task0 Returns Min     -1204.77
Exploration_task0 Actions Mean        0.038985
Exploration_task0 Actions Std         0.90458
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17798.3
AverageReturn_all_train_tasks     37796.1
AverageReturn_all_test_tasks      17798.3
Number of train steps total      260000
Number of env steps total             1.3001e+07
Number of rollouts total          94386
Train Time (s)                       99.9771
(Previous) Eval Time (s)             25.603
Sample Time (s)                     106.631
Epoch Time (s)                      232.211
Total Train Time (s)              60425.9
Epoch                               259
------------------------------  -----------------
2019-06-27 17:19:58.618968 UTC | [dialturn] Iteration #259 | Epoch Duration: 232.2292459011078
2019-06-27 17:19:58.619196 UTC | [dialturn] Iteration #259 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000882015
Z variance train                      0.999915
KL Divergence                         7.28431e-05
KL Loss                               7.28431e-06
QF Loss                               2.93329e+09
VF Loss                               3.23659e+06
RF Loss                          294031
Policy Loss                     -242731
Q Predictions Mean               240544
Q Predictions Std                345168
Q Predictions Max                     1.01274e+06
Q Predictions Min                 -1054.61
V Predictions Mean               242424
V Predictions Std                347262
V Predictions Max                     1.00604e+06
V Predictions Min                 -2010.41
R Predictions Mean                 2045.73
R Predictions Std                  4045
R Predictions Max                 18466.9
R Predictions Min                   -71.5195
Log Pis Mean                         25.8032
Log Pis Std                          13.6044
Log Pis Max                          59.6364
Log Pis Min                          -4.99005
Policy mu Mean                       -2.41396
Policy mu Std                        24.7377
Policy mu Max                       141.776
Policy mu Min                      -181.914
Policy log std Mean                  -0.666203
Policy log std Std                    1.41419
Policy log std Max                    2
Policy log std Min                   -7.47829
_task0 Rewards Mean                 121.484
_task0 Rewards Std                  349.124
_task0 Rewards Max                 2049.57
_task0 Rewards Min                   -1.05055
_task0 Returns Mean               18222.6
_task0 Returns Std                48542.5
_task0 Returns Max               174840
_task0 Returns Min                 -122.257
_task0 Actions Mean                   0.0283453
_task0 Actions Std                    0.884678
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1291.99
Exploration_task0 Rewards Std      3253.71
Exploration_task0 Rewards Max     23090.8
Exploration_task0 Rewards Min       -11.9776
Exploration_task0 Returns Mean   195756
Exploration_task0 Returns Std    452557
Exploration_task0 Returns Max         2.78991e+06
Exploration_task0 Returns Min     -1724.67
Exploration_task0 Actions Mean        0.0654615
Exploration_task0 Actions Std         0.911471
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              18222.6
AverageReturn_all_train_tasks      1673.48
AverageReturn_all_test_tasks      18222.6
Number of train steps total      261000
Number of env steps total             1.3051e+07
Number of rollouts total          94749
Train Time (s)                       99.4564
(Previous) Eval Time (s)             25.6194
Sample Time (s)                     107.28
Epoch Time (s)                      232.356
Total Train Time (s)              60658.2
Epoch                               260
------------------------------  -----------------
2019-06-27 17:23:50.835079 UTC | [dialturn] Iteration #260 | Epoch Duration: 232.2156765460968
2019-06-27 17:23:50.835293 UTC | [dialturn] Iteration #260 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00103401
Z variance train                      0.999715
KL Divergence                         0.000184586
KL Loss                               1.84586e-05
QF Loss                               2.50609e+09
VF Loss                               1.8822e+07
RF Loss                          417139
Policy Loss                     -242259
Q Predictions Mean               240191
Q Predictions Std                344139
Q Predictions Max                     1.01008e+06
Q Predictions Min                 -1051.43
V Predictions Mean               244517
V Predictions Std                349339
V Predictions Max                     1.01477e+06
V Predictions Min                 -1110.1
R Predictions Mean                 2041.48
R Predictions Std                  4489.39
R Predictions Max                 23654.2
R Predictions Min                   -56.6942
Log Pis Mean                         25.3177
Log Pis Std                          13.3792
Log Pis Max                          61.7619
Log Pis Min                          -0.750414
Policy mu Mean                       -3.39057
Policy mu Std                        26.1958
Policy mu Max                       141.234
Policy mu Min                      -194.273
Policy log std Mean                  -0.622386
Policy log std Std                    1.38309
Policy log std Max                    2
Policy log std Min                   -7.71347
_task0 Rewards Mean                 339.462
_task0 Rewards Std                  569.693
_task0 Rewards Max                 2105.58
_task0 Rewards Min                   -0.913136
_task0 Returns Mean               50919.3
_task0 Returns Std                80812.7
_task0 Returns Max               244986
_task0 Returns Min                  -98.7309
_task0 Actions Mean                   0.0679173
_task0 Actions Std                    0.88116
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1413.53
Exploration_task0 Rewards Std      3427.97
Exploration_task0 Rewards Max     23056.4
Exploration_task0 Rewards Min       -10.5046
Exploration_task0 Returns Mean   214171
Exploration_task0 Returns Std    481189
Exploration_task0 Returns Max         2.61556e+06
Exploration_task0 Returns Min     -1327.98
Exploration_task0 Actions Mean        0.0307642
Exploration_task0 Actions Std         0.895747
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              50919.3
AverageReturn_all_train_tasks      9482.91
AverageReturn_all_test_tasks      50919.3
Number of train steps total      262000
Number of env steps total             1.3101e+07
Number of rollouts total          95112
Train Time (s)                       99.5938
(Previous) Eval Time (s)             25.4777
Sample Time (s)                     106.546
Epoch Time (s)                      231.617
Total Train Time (s)              60889.8
Epoch                               261
------------------------------  -----------------
2019-06-27 17:27:42.522616 UTC | [dialturn] Iteration #261 | Epoch Duration: 231.68714690208435
2019-06-27 17:27:42.522831 UTC | [dialturn] Iteration #261 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000148733
Z variance train                      0.999492
KL Divergence                         4.84158e-06
KL Loss                               4.84159e-07
QF Loss                               1.98864e+09
VF Loss                               1.22864e+07
RF Loss                           53088.8
Policy Loss                     -252733
Q Predictions Mean               249465
Q Predictions Std                347562
Q Predictions Max                     1.01051e+06
Q Predictions Min                  -943.998
V Predictions Mean               254149
V Predictions Std                353448
V Predictions Max                     1.01644e+06
V Predictions Min                 -1076.1
R Predictions Mean                  770.197
R Predictions Std                  1986.76
R Predictions Max                 14754.3
R Predictions Min                   -41.2841
Log Pis Mean                         26.2547
Log Pis Std                          13.8838
Log Pis Max                          64.3486
Log Pis Min                          -3.22672
Policy mu Mean                       -3.28817
Policy mu Std                        26.7296
Policy mu Max                       137.638
Policy mu Min                      -182.627
Policy log std Mean                  -0.673034
Policy log std Std                    1.43393
Policy log std Max                    2
Policy log std Min                   -8.1824
_task0 Rewards Mean                  92.1609
_task0 Rewards Std                  183.607
_task0 Rewards Max                  665.052
_task0 Rewards Min                   -1.05062
_task0 Returns Mean               13824.1
_task0 Returns Std                26227.2
_task0 Returns Max                75241.7
_task0 Returns Min                 -123.716
_task0 Actions Mean                   0.0905566
_task0 Actions Std                    0.934362
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1959.12
Exploration_task0 Rewards Std      4665.37
Exploration_task0 Rewards Max     23173.9
Exploration_task0 Rewards Min       -11.5122
Exploration_task0 Returns Mean   296836
Exploration_task0 Returns Std    655261
Exploration_task0 Returns Max         2.56578e+06
Exploration_task0 Returns Min     -1436.47
Exploration_task0 Actions Mean        0.0984768
Exploration_task0 Actions Std         0.874752
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13824.1
AverageReturn_all_train_tasks     25821.3
AverageReturn_all_test_tasks      13824.1
Number of train steps total      263000
Number of env steps total             1.3151e+07
Number of rollouts total          95475
Train Time (s)                       99.421
(Previous) Eval Time (s)             25.5462
Sample Time (s)                     106.603
Epoch Time (s)                      231.571
Total Train Time (s)              61121.3
Epoch                               262
------------------------------  -----------------
2019-06-27 17:31:34.015384 UTC | [dialturn] Iteration #262 | Epoch Duration: 231.49238777160645
2019-06-27 17:31:34.015650 UTC | [dialturn] Iteration #262 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000410239
Z variance train                      1.00058
KL Divergence                         2.81032e-05
KL Loss                               2.81032e-06
QF Loss                               2.89257e+09
VF Loss                               1.96156e+07
RF Loss                          940241
Policy Loss                     -240350
Q Predictions Mean               237569
Q Predictions Std                338914
Q Predictions Max                     1.00959e+06
Q Predictions Min                  -944.151
V Predictions Mean               238029
V Predictions Std                339123
V Predictions Max                     1.00523e+06
V Predictions Min                 -1958.16
R Predictions Mean                 1771.42
R Predictions Std                  3696.13
R Predictions Max                 19878.9
R Predictions Min                  -213.554
Log Pis Mean                         24.5522
Log Pis Std                          13.5392
Log Pis Max                          56.9474
Log Pis Min                          -3.7268
Policy mu Mean                       -3.30194
Policy mu Std                        24.1859
Policy mu Max                       130.65
Policy mu Min                      -179.723
Policy log std Mean                  -0.675813
Policy log std Std                    1.36345
Policy log std Max                    2
Policy log std Min                   -9.17086
_task0 Rewards Mean                 165.198
_task0 Rewards Std                  448.154
_task0 Rewards Max                 2193.08
_task0 Rewards Min                   -0.941078
_task0 Returns Mean               24779.7
_task0 Returns Std                64117.2
_task0 Returns Max               254005
_task0 Returns Min                 -103.281
_task0 Actions Mean                   0.0616676
_task0 Actions Std                    0.892764
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1454.9
Exploration_task0 Rewards Std      3406.34
Exploration_task0 Rewards Max     22765
Exploration_task0 Rewards Min       -11.8699
Exploration_task0 Returns Mean   220440
Exploration_task0 Returns Std    473301
Exploration_task0 Returns Max         2.54043e+06
Exploration_task0 Returns Min     -1590.01
Exploration_task0 Actions Mean        0.0651778
Exploration_task0 Actions Std         0.91277
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              24779.7
AverageReturn_all_train_tasks     40924.1
AverageReturn_all_test_tasks      24779.7
Number of train steps total      264000
Number of env steps total             1.3201e+07
Number of rollouts total          95838
Train Time (s)                      100.801
(Previous) Eval Time (s)             25.4666
Sample Time (s)                     106.372
Epoch Time (s)                      232.64
Total Train Time (s)              61353.9
Epoch                               263
------------------------------  -----------------
2019-06-27 17:35:26.548992 UTC | [dialturn] Iteration #263 | Epoch Duration: 232.53316831588745
2019-06-27 17:35:26.549185 UTC | [dialturn] Iteration #263 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000325746
Z variance train                      0.999089
KL Divergence                         2.46992e-05
KL Loss                               2.46992e-06
QF Loss                               2.70193e+09
VF Loss                               8.57563e+06
RF Loss                          146885
Policy Loss                     -239769
Q Predictions Mean               237282
Q Predictions Std                341158
Q Predictions Max                     1.0026e+06
Q Predictions Min                 -1261.16
V Predictions Mean               240942
V Predictions Std                345706
V Predictions Max                     1.01823e+06
V Predictions Min                 -1023.65
R Predictions Mean                 1211.98
R Predictions Std                  3438.45
R Predictions Max                 20082.6
R Predictions Min                  -212.557
Log Pis Mean                         24.7734
Log Pis Std                          13.6339
Log Pis Max                          57.8065
Log Pis Min                          -3.54862
Policy mu Mean                       -2.65882
Policy mu Std                        27.6814
Policy mu Max                       143.745
Policy mu Min                      -202.337
Policy log std Mean                  -0.662783
Policy log std Std                    1.39964
Policy log std Max                    2
Policy log std Min                   -9.51797
_task0 Rewards Mean                 137.535
_task0 Rewards Std                  392.096
_task0 Rewards Max                 1984.81
_task0 Rewards Min                   -0.980534
_task0 Returns Mean               20630.3
_task0 Returns Std                55994.3
_task0 Returns Max               211099
_task0 Returns Min                 -107.062
_task0 Actions Mean                   0.0300994
_task0 Actions Std                    0.862554
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1317.27
Exploration_task0 Rewards Std      3357.75
Exploration_task0 Rewards Max     23125.4
Exploration_task0 Rewards Min       -11.5217
Exploration_task0 Returns Mean   199587
Exploration_task0 Returns Std    474943
Exploration_task0 Returns Max         2.56876e+06
Exploration_task0 Returns Min     -1720.27
Exploration_task0 Actions Mean        0.0435522
Exploration_task0 Actions Std         0.907121
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              20630.3
AverageReturn_all_train_tasks     21081.3
AverageReturn_all_test_tasks      20630.3
Number of train steps total      265000
Number of env steps total             1.3251e+07
Number of rollouts total          96201
Train Time (s)                       99.2462
(Previous) Eval Time (s)             25.3582
Sample Time (s)                     105.86
Epoch Time (s)                      230.464
Total Train Time (s)              61584.1
Epoch                               264
------------------------------  -----------------
2019-06-27 17:39:16.819957 UTC | [dialturn] Iteration #264 | Epoch Duration: 230.2705614566803
2019-06-27 17:39:16.820206 UTC | [dialturn] Iteration #264 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000412086
Z variance train                      0.999799
KL Divergence                         2.22174e-05
KL Loss                               2.22174e-06
QF Loss                               3.60705e+09
VF Loss                               1.77655e+07
RF Loss                          196444
Policy Loss                     -257331
Q Predictions Mean               254849
Q Predictions Std                357045
Q Predictions Max                     1.0226e+06
Q Predictions Min                  -525.44
V Predictions Mean               255245
V Predictions Std                357350
V Predictions Max                     1.01191e+06
V Predictions Min                  -757.04
R Predictions Mean                 1665.66
R Predictions Std                  3790.26
R Predictions Max                 20918.1
R Predictions Min                  -232.207
Log Pis Mean                         25.9015
Log Pis Std                          13.7205
Log Pis Max                          58.8154
Log Pis Min                          -1.45806
Policy mu Mean                       -4.30194
Policy mu Std                        26.0031
Policy mu Max                       148.102
Policy mu Min                      -190.012
Policy log std Mean                  -0.671938
Policy log std Std                    1.43583
Policy log std Max                    2
Policy log std Min                   -9.65704
_task0 Rewards Mean                  48.7678
_task0 Rewards Std                  143.449
_task0 Rewards Max                 1129.44
_task0 Rewards Min                   -0.827391
_task0 Returns Mean                7315.17
_task0 Returns Std                20071.7
_task0 Returns Max                72303.4
_task0 Returns Min                  -95.3112
_task0 Actions Mean                   0.0959467
_task0 Actions Std                    0.9039
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1968.52
Exploration_task0 Rewards Std      4623.64
Exploration_task0 Rewards Max     23188.1
Exploration_task0 Rewards Min       -11.1793
Exploration_task0 Returns Mean   298261
Exploration_task0 Returns Std    652688
Exploration_task0 Returns Max         2.83735e+06
Exploration_task0 Returns Min     -1274.35
Exploration_task0 Actions Mean        0.025827
Exploration_task0 Actions Std         0.884398
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7315.17
AverageReturn_all_train_tasks     12378.5
AverageReturn_all_test_tasks       7315.17
Number of train steps total      266000
Number of env steps total             1.3301e+07
Number of rollouts total          96564
Train Time (s)                       98.3574
(Previous) Eval Time (s)             25.1631
Sample Time (s)                     105.754
Epoch Time (s)                      229.275
Total Train Time (s)              61813.3
Epoch                               265
------------------------------  -----------------
2019-06-27 17:43:06.043087 UTC | [dialturn] Iteration #265 | Epoch Duration: 229.2227144241333
2019-06-27 17:43:06.043309 UTC | [dialturn] Iteration #265 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000299006
Z variance train                      1.00064
KL Divergence                         2.19209e-05
KL Loss                               2.19209e-06
QF Loss                               2.30186e+09
VF Loss                               5.15098e+06
RF Loss                          176894
Policy Loss                     -240007
Q Predictions Mean               237047
Q Predictions Std                338845
Q Predictions Max                     1.01275e+06
Q Predictions Min                  -785.686
V Predictions Mean               239216
V Predictions Std                341354
V Predictions Max                     1.01401e+06
V Predictions Min                  -845.699
R Predictions Mean                 1244.73
R Predictions Std                  2884.66
R Predictions Max                 18016.3
R Predictions Min                   -80.6082
Log Pis Mean                         25.0388
Log Pis Std                          13.7109
Log Pis Max                          57.5608
Log Pis Min                          -2.08661
Policy mu Mean                       -2.91708
Policy mu Std                        27.9571
Policy mu Max                       164.43
Policy mu Min                      -205.026
Policy log std Mean                  -0.595869
Policy log std Std                    1.41487
Policy log std Max                    2
Policy log std Min                   -8.05318
_task0 Rewards Mean                 191.866
_task0 Rewards Std                  491.016
_task0 Rewards Max                 1968.83
_task0 Rewards Min                   -0.968872
_task0 Returns Mean               28779.9
_task0 Returns Std                69851.8
_task0 Returns Max               206116
_task0 Returns Min                 -118.446
_task0 Actions Mean                   0.0621353
_task0 Actions Std                    0.883322
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1679.65
Exploration_task0 Rewards Std      3906.17
Exploration_task0 Rewards Max     21131.5
Exploration_task0 Rewards Min       -10.9259
Exploration_task0 Returns Mean   254493
Exploration_task0 Returns Std    544519
Exploration_task0 Returns Max         2.23896e+06
Exploration_task0 Returns Min     -1305.02
Exploration_task0 Actions Mean       -0.010034
Exploration_task0 Actions Std         0.880243
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              28779.9
AverageReturn_all_train_tasks     12095.1
AverageReturn_all_test_tasks      28779.9
Number of train steps total      267000
Number of env steps total             1.3351e+07
Number of rollouts total          96927
Train Time (s)                       98.9274
(Previous) Eval Time (s)             25.1095
Sample Time (s)                     105.175
Epoch Time (s)                      229.212
Total Train Time (s)              62042.9
Epoch                               266
------------------------------  -----------------
2019-06-27 17:46:55.601845 UTC | [dialturn] Iteration #266 | Epoch Duration: 229.5583300590515
2019-06-27 17:46:55.602063 UTC | [dialturn] Iteration #266 | Started Training: True
------------------------------  -----------------
Z mean train                          0.0010171
Z variance train                      1.00025
KL Divergence                         0.000141386
KL Loss                               1.41386e-05
QF Loss                               3.11123e+09
VF Loss                               3.16755e+06
RF Loss                          213943
Policy Loss                     -238429
Q Predictions Mean               235941
Q Predictions Std                339677
Q Predictions Max                     1.01694e+06
Q Predictions Min                  -800.183
V Predictions Mean               238162
V Predictions Std                342671
V Predictions Max                     1.01366e+06
V Predictions Min                  -822.973
R Predictions Mean                 1716.45
R Predictions Std                  4030.42
R Predictions Max                 22351.8
R Predictions Min                   -61.6774
Log Pis Mean                         24.1523
Log Pis Std                          14.2418
Log Pis Max                          57.6293
Log Pis Min                          -5.76023
Policy mu Mean                       -3.61597
Policy mu Std                        29.6199
Policy mu Max                       140.687
Policy mu Min                      -191.023
Policy log std Mean                  -0.576351
Policy log std Std                    1.44114
Policy log std Max                    2
Policy log std Min                   -8.80889
_task0 Rewards Mean                 105.85
_task0 Rewards Std                  256.921
_task0 Rewards Max                 1130.14
_task0 Rewards Min                   -0.869836
_task0 Returns Mean               15877.5
_task0 Returns Std                36265.4
_task0 Returns Max               133464
_task0 Returns Min                 -100.501
_task0 Actions Mean                  -0.0191202
_task0 Actions Std                    0.906659
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1404.7
Exploration_task0 Rewards Std      3301.05
Exploration_task0 Rewards Max     22853.3
Exploration_task0 Rewards Min       -11.1796
Exploration_task0 Returns Mean   212833
Exploration_task0 Returns Std    461708
Exploration_task0 Returns Max         2.70022e+06
Exploration_task0 Returns Min     -1380.37
Exploration_task0 Actions Mean        0.0248684
Exploration_task0 Actions Std         0.90746
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15877.5
AverageReturn_all_train_tasks     17775.9
AverageReturn_all_test_tasks      15877.5
Number of train steps total      268000
Number of env steps total             1.3401e+07
Number of rollouts total          97290
Train Time (s)                       99.5936
(Previous) Eval Time (s)             25.4542
Sample Time (s)                     106.022
Epoch Time (s)                      231.069
Total Train Time (s)              62273.9
Epoch                               267
------------------------------  -----------------
2019-06-27 17:50:46.579254 UTC | [dialturn] Iteration #267 | Epoch Duration: 230.9770164489746
2019-06-27 17:50:46.579473 UTC | [dialturn] Iteration #267 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000392467
Z variance train                      0.999714
KL Divergence                         1.33632e-05
KL Loss                               1.33632e-06
QF Loss                               2.11334e+09
VF Loss                               6.69428e+06
RF Loss                           72383.6
Policy Loss                     -249560
Q Predictions Mean               246418
Q Predictions Std                352094
Q Predictions Max                     1.02349e+06
Q Predictions Min                  -570
V Predictions Mean               249777
V Predictions Std                356428
V Predictions Max                     1.02557e+06
V Predictions Min                  -704.15
R Predictions Mean                 1051.17
R Predictions Std                  2859.89
R Predictions Max                 15444.5
R Predictions Min                   -98.2987
Log Pis Mean                         24.9348
Log Pis Std                          13.8732
Log Pis Max                          58.1021
Log Pis Min                          -1.81455
Policy mu Mean                       -4.76791
Policy mu Std                        28.3268
Policy mu Max                       132.664
Policy mu Min                      -184.338
Policy log std Mean                  -0.584751
Policy log std Std                    1.38712
Policy log std Max                    2
Policy log std Min                   -8.88551
_task0 Rewards Mean                 110.852
_task0 Rewards Std                  308.878
_task0 Rewards Max                 1557.69
_task0 Rewards Min                   -0.873924
_task0 Returns Mean               16627.8
_task0 Returns Std                44668.2
_task0 Returns Max               171739
_task0 Returns Min                 -104.903
_task0 Actions Mean                   0.0208584
_task0 Actions Std                    0.901889
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1363.28
Exploration_task0 Rewards Std      3364.87
Exploration_task0 Rewards Max     20616.3
Exploration_task0 Rewards Min       -10.4958
Exploration_task0 Returns Mean   206557
Exploration_task0 Returns Std    470201
Exploration_task0 Returns Max         2.00664e+06
Exploration_task0 Returns Min     -1479.66
Exploration_task0 Actions Mean        0.0383322
Exploration_task0 Actions Std         0.897188
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16627.8
AverageReturn_all_train_tasks     32667.8
AverageReturn_all_test_tasks      16627.8
Number of train steps total      269000
Number of env steps total             1.3451e+07
Number of rollouts total          97653
Train Time (s)                      100.712
(Previous) Eval Time (s)             25.3604
Sample Time (s)                     106.55
Epoch Time (s)                      232.623
Total Train Time (s)              62506.6
Epoch                               268
------------------------------  -----------------
2019-06-27 17:54:39.287460 UTC | [dialturn] Iteration #268 | Epoch Duration: 232.70782375335693
2019-06-27 17:54:39.287664 UTC | [dialturn] Iteration #268 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000266228
Z variance train                      0.998954
KL Divergence                         3.25672e-05
KL Loss                               3.25672e-06
QF Loss                               4.18149e+09
VF Loss                               8.24531e+06
RF Loss                          373666
Policy Loss                     -253617
Q Predictions Mean               252129
Q Predictions Std                357509
Q Predictions Max                     1.02433e+06
Q Predictions Min                  -878.366
V Predictions Mean               254867
V Predictions Std                360830
V Predictions Max                     1.02042e+06
V Predictions Min                  -875.88
R Predictions Mean                 1408.34
R Predictions Std                  3054.16
R Predictions Max                 15889.5
R Predictions Min                  -110.814
Log Pis Mean                         25.3421
Log Pis Std                          14.1044
Log Pis Max                          59.8448
Log Pis Min                          -4.09604
Policy mu Mean                       -3.64443
Policy mu Std                        26.2413
Policy mu Max                       114.535
Policy mu Min                      -181.467
Policy log std Mean                  -0.640699
Policy log std Std                    1.39086
Policy log std Max                    2
Policy log std Min                   -7.74915
_task0 Rewards Mean                 113.321
_task0 Rewards Std                  191.8
_task0 Rewards Max                 1037.71
_task0 Rewards Min                   -0.879955
_task0 Returns Mean               16998.2
_task0 Returns Std                26530.6
_task0 Returns Max                75328.7
_task0 Returns Min                 -108.793
_task0 Actions Mean                   0.00280979
_task0 Actions Std                    0.853723
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1377.17
Exploration_task0 Rewards Std      3151.12
Exploration_task0 Rewards Max     21905.2
Exploration_task0 Rewards Min       -10.4995
Exploration_task0 Returns Mean   208662
Exploration_task0 Returns Std    443252
Exploration_task0 Returns Max         2.10295e+06
Exploration_task0 Returns Min     -1528.7
Exploration_task0 Actions Mean       -0.0282239
Exploration_task0 Actions Std         0.870681
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16998.2
AverageReturn_all_train_tasks     28465.6
AverageReturn_all_test_tasks      16998.2
Number of train steps total      270000
Number of env steps total             1.3501e+07
Number of rollouts total          98016
Train Time (s)                      100.571
(Previous) Eval Time (s)             25.444
Sample Time (s)                     106.57
Epoch Time (s)                      232.585
Total Train Time (s)              62739.5
Epoch                               269
------------------------------  -----------------
2019-06-27 17:58:32.221922 UTC | [dialturn] Iteration #269 | Epoch Duration: 232.93409252166748
2019-06-27 17:58:32.222130 UTC | [dialturn] Iteration #269 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000604528
Z variance train                      1.00004
KL Divergence                         6.20767e-05
KL Loss                               6.20767e-06
QF Loss                               8.55496e+08
VF Loss                               1.00297e+07
RF Loss                          100288
Policy Loss                     -238339
Q Predictions Mean               235769
Q Predictions Std                343168
Q Predictions Max                     1.01833e+06
Q Predictions Min                    -4.60825
V Predictions Mean               237050
V Predictions Std                344673
V Predictions Max                     1.01876e+06
V Predictions Min                  -274.533
R Predictions Mean                 1501.41
R Predictions Std                  3286.97
R Predictions Max                 17431.8
R Predictions Min                  -180.304
Log Pis Mean                         25.0679
Log Pis Std                          14.1912
Log Pis Max                          60.3895
Log Pis Min                          -2.69345
Policy mu Mean                       -3.86008
Policy mu Std                        26.6429
Policy mu Max                       108.476
Policy mu Min                      -182.968
Policy log std Mean                  -0.682876
Policy log std Std                    1.37854
Policy log std Max                    2
Policy log std Min                   -7.12116
_task0 Rewards Mean                  15.6368
_task0 Rewards Std                   57.4469
_task0 Rewards Max                  409.508
_task0 Rewards Min                   -0.899293
_task0 Returns Mean                2345.52
_task0 Returns Std                 5993.06
_task0 Returns Max                21610.1
_task0 Returns Min                 -117.465
_task0 Actions Mean                  -0.0164206
_task0 Actions Std                    0.875796
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1571.76
Exploration_task0 Rewards Std      3578.17
Exploration_task0 Rewards Max     22828.1
Exploration_task0 Rewards Min       -12.7282
Exploration_task0 Returns Mean   238145
Exploration_task0 Returns Std    496619
Exploration_task0 Returns Max         2.09246e+06
Exploration_task0 Returns Min     -1570.93
Exploration_task0 Actions Mean       -0.0262527
Exploration_task0 Actions Std         0.882553
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               2345.52
AverageReturn_all_train_tasks     27729.7
AverageReturn_all_test_tasks       2345.52
Number of train steps total      271000
Number of env steps total             1.3551e+07
Number of rollouts total          98379
Train Time (s)                       99.7205
(Previous) Eval Time (s)             25.7912
Sample Time (s)                     106.802
Epoch Time (s)                      232.314
Total Train Time (s)              62971.5
Epoch                               270
------------------------------  -----------------
2019-06-27 18:02:24.270460 UTC | [dialturn] Iteration #270 | Epoch Duration: 232.04816818237305
2019-06-27 18:02:24.270657 UTC | [dialturn] Iteration #270 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000597584
Z variance train                      0.999963
KL Divergence                         4.80318e-05
KL Loss                               4.80318e-06
QF Loss                               1.09357e+09
VF Loss                               4.37847e+06
RF Loss                          126598
Policy Loss                     -235637
Q Predictions Mean               233022
Q Predictions Std                348259
Q Predictions Max                     1.02439e+06
Q Predictions Min                  -396.437
V Predictions Mean               235510
V Predictions Std                351103
V Predictions Max                     1.01791e+06
V Predictions Min                  -440.151
R Predictions Mean                 1323.33
R Predictions Std                  3190.19
R Predictions Max                 21543.4
R Predictions Min                   -75.4797
Log Pis Mean                         24.5956
Log Pis Std                          14.1846
Log Pis Max                          58.1752
Log Pis Min                          -3.00977
Policy mu Mean                       -4.25591
Policy mu Std                        27.6293
Policy mu Max                       129.921
Policy mu Min                      -187.76
Policy log std Mean                  -0.655543
Policy log std Std                    1.3706
Policy log std Max                    2
Policy log std Min                   -7.38828
_task0 Rewards Mean                  79.194
_task0 Rewards Std                  215.397
_task0 Rewards Max                 1019.2
_task0 Rewards Min                   -0.867891
_task0 Returns Mean               11879.1
_task0 Returns Std                31337.9
_task0 Returns Max               122312
_task0 Returns Min                 -105.162
_task0 Actions Mean                  -0.0724014
_task0 Actions Std                    0.889847
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1834.13
Exploration_task0 Rewards Std      4244.49
Exploration_task0 Rewards Max     22705.4
Exploration_task0 Rewards Min       -11.2113
Exploration_task0 Returns Mean   277898
Exploration_task0 Returns Std    599045
Exploration_task0 Returns Max         2.51034e+06
Exploration_task0 Returns Min     -1279.13
Exploration_task0 Actions Mean        0.00651967
Exploration_task0 Actions Std         0.897701
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11879.1
AverageReturn_all_train_tasks     31172.6
AverageReturn_all_test_tasks      11879.1
Number of train steps total      272000
Number of env steps total             1.3601e+07
Number of rollouts total          98742
Train Time (s)                      100.647
(Previous) Eval Time (s)             25.5244
Sample Time (s)                     106.779
Epoch Time (s)                      232.95
Total Train Time (s)              63204.5
Epoch                               271
------------------------------  -----------------
2019-06-27 18:06:17.266404 UTC | [dialturn] Iteration #271 | Epoch Duration: 232.99558877944946
2019-06-27 18:06:17.266634 UTC | [dialturn] Iteration #271 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000252931
Z variance train                      1.00021
KL Divergence                         7.26288e-06
KL Loss                               7.26288e-07
QF Loss                               1.61677e+09
VF Loss                               1.19135e+07
RF Loss                          127722
Policy Loss                     -254827
Q Predictions Mean               251785
Q Predictions Std                356071
Q Predictions Max                     1.01816e+06
Q Predictions Min                 -8128.24
V Predictions Mean               254262
V Predictions Std                358230
V Predictions Max                     1.01074e+06
V Predictions Min                 -2245.56
R Predictions Mean                 1438.94
R Predictions Std                  3100.89
R Predictions Max                 17873.8
R Predictions Min                   -78.8087
Log Pis Mean                         25.5559
Log Pis Std                          14.3444
Log Pis Max                          57.3936
Log Pis Min                          -4.59593
Policy mu Mean                       -5.577
Policy mu Std                        30.6513
Policy mu Max                       127.2
Policy mu Min                      -205.369
Policy log std Mean                  -0.55521
Policy log std Std                    1.39657
Policy log std Max                    2
Policy log std Min                   -7.00084
_task0 Rewards Mean                 184.17
_task0 Rewards Std                  392.787
_task0 Rewards Max                 2135.8
_task0 Rewards Min                   -1.00216
_task0 Returns Mean               27625.6
_task0 Returns Std                56133.4
_task0 Returns Max               201384
_task0 Returns Min                 -108.014
_task0 Actions Mean                  -0.0416676
_task0 Actions Std                    0.862925
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      914.441
Exploration_task0 Rewards Std      2898.09
Exploration_task0 Rewards Max     22858
Exploration_task0 Rewards Min       -11.1298
Exploration_task0 Returns Mean   138552
Exploration_task0 Returns Std    402965
Exploration_task0 Returns Max         2.50209e+06
Exploration_task0 Returns Min     -1852.63
Exploration_task0 Actions Mean       -0.0417008
Exploration_task0 Actions Std         0.912286
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27625.6
AverageReturn_all_train_tasks     17114.4
AverageReturn_all_test_tasks      27625.6
Number of train steps total      273000
Number of env steps total             1.3651e+07
Number of rollouts total          99105
Train Time (s)                       99.8609
(Previous) Eval Time (s)             25.5682
Sample Time (s)                     106.674
Epoch Time (s)                      232.103
Total Train Time (s)              63436.9
Epoch                               272
------------------------------  -----------------
2019-06-27 18:10:09.675865 UTC | [dialturn] Iteration #272 | Epoch Duration: 232.40901923179626
2019-06-27 18:10:09.676097 UTC | [dialturn] Iteration #272 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00058595
Z variance train                      0.999886
KL Divergence                         3.14791e-05
KL Loss                               3.14791e-06
QF Loss                               1.08988e+09
VF Loss                               1.57809e+07
RF Loss                          280003
Policy Loss                     -232280
Q Predictions Mean               229633
Q Predictions Std                340966
Q Predictions Max                     1.01747e+06
Q Predictions Min                  -211.171
V Predictions Mean               234296
V Predictions Std                346671
V Predictions Max                     1.02045e+06
V Predictions Min                  -579.504
R Predictions Mean                 1583.15
R Predictions Std                  3906.25
R Predictions Max                 20420
R Predictions Min                  -147.797
Log Pis Mean                         25.0637
Log Pis Std                          14.457
Log Pis Max                          59.9395
Log Pis Min                          -3.67882
Policy mu Mean                       -5.47059
Policy mu Std                        28.9788
Policy mu Max                       151.458
Policy mu Min                      -206.625
Policy log std Mean                  -0.591084
Policy log std Std                    1.33109
Policy log std Max                    2
Policy log std Min                   -6.13653
_task0 Rewards Mean                 176.019
_task0 Rewards Std                  360.923
_task0 Rewards Max                 1626.31
_task0 Rewards Min                   -0.841454
_task0 Returns Mean               26402.8
_task0 Returns Std                51762.7
_task0 Returns Max               186741
_task0 Returns Min                 -108.113
_task0 Actions Mean                   0.0120556
_task0 Actions Std                    0.851979
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1798.25
Exploration_task0 Rewards Std      4000.19
Exploration_task0 Rewards Max     23079.4
Exploration_task0 Rewards Min       -10.5059
Exploration_task0 Returns Mean   272463
Exploration_task0 Returns Std    564681
Exploration_task0 Returns Max         2.5364e+06
Exploration_task0 Returns Min     -1297.55
Exploration_task0 Actions Mean       -0.0485777
Exploration_task0 Actions Std         0.879665
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26402.8
AverageReturn_all_train_tasks      2833.78
AverageReturn_all_test_tasks      26402.8
Number of train steps total      274000
Number of env steps total             1.3701e+07
Number of rollouts total          99468
Train Time (s)                      100.173
(Previous) Eval Time (s)             25.8724
Sample Time (s)                     106.812
Epoch Time (s)                      232.858
Total Train Time (s)              63669.6
Epoch                               273
------------------------------  -----------------
2019-06-27 18:14:02.330353 UTC | [dialturn] Iteration #273 | Epoch Duration: 232.6540904045105
2019-06-27 18:14:02.330565 UTC | [dialturn] Iteration #273 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000622961
Z variance train                      1.00011
KL Divergence                         9.37673e-05
KL Loss                               9.37673e-06
QF Loss                               1.40152e+09
VF Loss                               2.65915e+07
RF Loss                          197433
Policy Loss                     -248016
Q Predictions Mean               245054
Q Predictions Std                351269
Q Predictions Max                     1.02162e+06
Q Predictions Min                   -79.8967
V Predictions Mean               245041
V Predictions Std                351377
V Predictions Max                     1.01579e+06
V Predictions Min                     8.22076
R Predictions Mean                 1175.16
R Predictions Std                  3136.94
R Predictions Max                 17986
R Predictions Min                  -156.17
Log Pis Mean                         25.5518
Log Pis Std                          14.6436
Log Pis Max                          56.9912
Log Pis Min                          -2.93519
Policy mu Mean                       -6.15866
Policy mu Std                        29.9777
Policy mu Max                       147.298
Policy mu Min                      -206.634
Policy log std Mean                  -0.563568
Policy log std Std                    1.37698
Policy log std Max                    2
Policy log std Min                   -8.09735
_task0 Rewards Mean                 127.195
_task0 Rewards Std                  264.1
_task0 Rewards Max                 1158.55
_task0 Rewards Min                   -0.882285
_task0 Returns Mean               19079.2
_task0 Returns Std                37311.4
_task0 Returns Max               138021
_task0 Returns Min                 -110.846
_task0 Actions Mean                  -0.0477462
_task0 Actions Std                    0.831906
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1179.98
Exploration_task0 Rewards Std      2845.42
Exploration_task0 Rewards Max     22653.4
Exploration_task0 Rewards Min       -10.9161
Exploration_task0 Returns Mean   178784
Exploration_task0 Returns Std    403886
Exploration_task0 Returns Max         2.63513e+06
Exploration_task0 Returns Min     -1754.11
Exploration_task0 Actions Mean        0.0156753
Exploration_task0 Actions Std         0.900896
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19079.2
AverageReturn_all_train_tasks     31001.2
AverageReturn_all_test_tasks      19079.2
Number of train steps total      275000
Number of env steps total             1.3751e+07
Number of rollouts total          99831
Train Time (s)                       99.3135
(Previous) Eval Time (s)             25.667
Sample Time (s)                     107.008
Epoch Time (s)                      231.989
Total Train Time (s)              63901.4
Epoch                               274
------------------------------  -----------------
2019-06-27 18:17:54.091571 UTC | [dialturn] Iteration #274 | Epoch Duration: 231.7608494758606
2019-06-27 18:17:54.091778 UTC | [dialturn] Iteration #274 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000172563
Z variance train                      1.00005
KL Divergence                         3.77252e-06
KL Loss                               3.77252e-07
QF Loss                               1.67422e+09
VF Loss                               2.15959e+07
RF Loss                           43691.6
Policy Loss                     -253291
Q Predictions Mean               249989
Q Predictions Std                356482
Q Predictions Max                     1.02206e+06
Q Predictions Min                   127.776
V Predictions Mean               250699
V Predictions Std                357095
V Predictions Max                     1.0144e+06
V Predictions Min                   115.966
R Predictions Mean                  854.083
R Predictions Std                  2410.03
R Predictions Max                 15248.5
R Predictions Min                  -245.077
Log Pis Mean                         26.6956
Log Pis Std                          14.594
Log Pis Max                          58.1542
Log Pis Min                          -4.29815
Policy mu Mean                       -4.30632
Policy mu Std                        28.8861
Policy mu Max                       124.972
Policy mu Min                      -205.234
Policy log std Mean                  -0.642607
Policy log std Std                    1.42123
Policy log std Max                    2
Policy log std Min                   -6.89703
_task0 Rewards Mean                 142.417
_task0 Rewards Std                  347.921
_task0 Rewards Max                 1572.02
_task0 Rewards Min                   -1.03558
_task0 Returns Mean               21362.6
_task0 Returns Std                50022.8
_task0 Returns Max               166227
_task0 Returns Min                 -127.708
_task0 Actions Mean                   0.0242018
_task0 Actions Std                    0.921678
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1049.25
Exploration_task0 Rewards Std      3084.31
Exploration_task0 Rewards Max     23146.4
Exploration_task0 Rewards Min       -11.4576
Exploration_task0 Returns Mean   158977
Exploration_task0 Returns Std    432043
Exploration_task0 Returns Max         2.55574e+06
Exploration_task0 Returns Min     -1472.33
Exploration_task0 Actions Mean       -0.0222024
Exploration_task0 Actions Std         0.903919
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21362.6
AverageReturn_all_train_tasks     11651.2
AverageReturn_all_test_tasks      21362.6
Number of train steps total      276000
Number of env steps total             1.3801e+07
Number of rollouts total         100194
Train Time (s)                      100.343
(Previous) Eval Time (s)             25.4376
Sample Time (s)                     106.631
Epoch Time (s)                      232.412
Total Train Time (s)              64133.7
Epoch                               275
------------------------------  -----------------
2019-06-27 18:21:46.400048 UTC | [dialturn] Iteration #275 | Epoch Duration: 232.30807328224182
2019-06-27 18:21:46.400297 UTC | [dialturn] Iteration #275 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000283707
Z variance train                      0.999982
KL Divergence                         1.10531e-05
KL Loss                               1.10531e-06
QF Loss                               1.24836e+09
VF Loss                               1.45207e+07
RF Loss                          137076
Policy Loss                     -245854
Q Predictions Mean               242843
Q Predictions Std                351078
Q Predictions Max                     1.02078e+06
Q Predictions Min                    72.0723
V Predictions Mean               244129
V Predictions Std                352516
V Predictions Max                     1.0197e+06
V Predictions Min                   159.735
R Predictions Mean                 1324.78
R Predictions Std                  2894.76
R Predictions Max                 15582.8
R Predictions Min                   -76.9126
Log Pis Mean                         26.161
Log Pis Std                          14.8782
Log Pis Max                          57.9201
Log Pis Min                          -5.13671
Policy mu Mean                       -4.55729
Policy mu Std                        26.4998
Policy mu Max                       137.871
Policy mu Min                      -174.301
Policy log std Mean                  -0.569989
Policy log std Std                    1.39625
Policy log std Max                    2
Policy log std Min                  -11.3004
_task0 Rewards Mean                  90.9134
_task0 Rewards Std                  199.056
_task0 Rewards Max                 1435.28
_task0 Rewards Min                   -0.90674
_task0 Returns Mean               13637
_task0 Returns Std                27463.3
_task0 Returns Max                86156
_task0 Returns Min                  -95.5148
_task0 Actions Mean                   0.0386803
_task0 Actions Std                    0.856563
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1229.94
Exploration_task0 Rewards Std      3024.61
Exploration_task0 Rewards Max     22550.5
Exploration_task0 Rewards Min       -11.2904
Exploration_task0 Returns Mean   186354
Exploration_task0 Returns Std    421720
Exploration_task0 Returns Max         2.57715e+06
Exploration_task0 Returns Min     -1496.79
Exploration_task0 Actions Mean       -0.0335492
Exploration_task0 Actions Std         0.889396
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13637
AverageReturn_all_train_tasks     47386.6
AverageReturn_all_test_tasks      13637
Number of train steps total      277000
Number of env steps total             1.3851e+07
Number of rollouts total         100557
Train Time (s)                       99.0008
(Previous) Eval Time (s)             25.3318
Sample Time (s)                     106.399
Epoch Time (s)                      230.731
Total Train Time (s)              64364.5
Epoch                               276
------------------------------  -----------------
2019-06-27 18:25:37.269155 UTC | [dialturn] Iteration #276 | Epoch Duration: 230.86864757537842
2019-06-27 18:25:37.269372 UTC | [dialturn] Iteration #276 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00076692
Z variance train                      1.00008
KL Divergence                         0.000111413
KL Loss                               1.11413e-05
QF Loss                               1.88506e+09
VF Loss                               8.91601e+06
RF Loss                          134366
Policy Loss                     -254965
Q Predictions Mean               252042
Q Predictions Std                352897
Q Predictions Max                     1.0253e+06
Q Predictions Min                 -3294.31
V Predictions Mean               253582
V Predictions Std                354646
V Predictions Max                     1.02255e+06
V Predictions Min                 -2914.94
R Predictions Mean                 1195.2
R Predictions Std                  3142.31
R Predictions Max                 21108.4
R Predictions Min                   -90.9678
Log Pis Mean                         26.1352
Log Pis Std                          14.6947
Log Pis Max                          57.9613
Log Pis Min                          -2.81462
Policy mu Mean                       -5.10181
Policy mu Std                        29.4863
Policy mu Max                       141.99
Policy mu Min                      -185.527
Policy log std Mean                  -0.513764
Policy log std Std                    1.4017
Policy log std Max                    2
Policy log std Min                   -8.58196
_task0 Rewards Mean                 115.608
_task0 Rewards Std                  352.87
_task0 Rewards Max                 1995.32
_task0 Rewards Min                   -0.873571
_task0 Returns Mean               17341.1
_task0 Returns Std                50180.8
_task0 Returns Max               217857
_task0 Returns Min                 -104.64
_task0 Actions Mean                  -0.0822272
_task0 Actions Std                    0.868678
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1013.48
Exploration_task0 Rewards Std      2529.18
Exploration_task0 Rewards Max     23091.4
Exploration_task0 Rewards Min       -10.6523
Exploration_task0 Returns Mean   153557
Exploration_task0 Returns Std    351860
Exploration_task0 Returns Max         2.76631e+06
Exploration_task0 Returns Min     -1297.64
Exploration_task0 Actions Mean       -0.018497
Exploration_task0 Actions Std         0.907147
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17341.1
AverageReturn_all_train_tasks     28526.8
AverageReturn_all_test_tasks      17341.1
Number of train steps total      278000
Number of env steps total             1.3901e+07
Number of rollouts total         100920
Train Time (s)                      100.484
(Previous) Eval Time (s)             25.4678
Sample Time (s)                     107.206
Epoch Time (s)                      233.158
Total Train Time (s)              64597.7
Epoch                               277
------------------------------  -----------------
2019-06-27 18:29:30.490431 UTC | [dialturn] Iteration #277 | Epoch Duration: 233.22089791297913
2019-06-27 18:29:30.490666 UTC | [dialturn] Iteration #277 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00027833
Z variance train                      0.999904
KL Divergence                         1.709e-05
KL Loss                               1.709e-06
QF Loss                               1.63585e+09
VF Loss                               9.6446e+06
RF Loss                           47344.3
Policy Loss                     -245687
Q Predictions Mean               243173
Q Predictions Std                349732
Q Predictions Max                     1.02161e+06
Q Predictions Min                   -58.4297
V Predictions Mean               245314
V Predictions Std                352257
V Predictions Max                     1.02004e+06
V Predictions Min                 -1732.83
R Predictions Mean                 1134.88
R Predictions Std                  2405.24
R Predictions Max                 11644.9
R Predictions Min                  -445.195
Log Pis Mean                         25.97
Log Pis Std                          14.7531
Log Pis Max                          56.1991
Log Pis Min                          -4.34414
Policy mu Mean                       -4.60451
Policy mu Std                        26.9814
Policy mu Max                       141.061
Policy mu Min                      -194.2
Policy log std Mean                  -0.456987
Policy log std Std                    1.36809
Policy log std Max                    2
Policy log std Min                   -7.02724
_task0 Rewards Mean                  39.4158
_task0 Rewards Std                  137.723
_task0 Rewards Max                 1630.36
_task0 Rewards Min                   -1.03327
_task0 Returns Mean                5912.37
_task0 Returns Std                15242.5
_task0 Returns Max                58537.2
_task0 Returns Min                 -107.56
_task0 Actions Mean                  -0.0512208
_task0 Actions Std                    0.919886
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1266.85
Exploration_task0 Rewards Std      3480.41
Exploration_task0 Rewards Max     22882.4
Exploration_task0 Rewards Min       -11.1787
Exploration_task0 Returns Mean   191947
Exploration_task0 Returns Std    483075
Exploration_task0 Returns Max         2.24364e+06
Exploration_task0 Returns Min     -1274.1
Exploration_task0 Actions Mean       -0.0205174
Exploration_task0 Actions Std         0.906967
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               5912.37
AverageReturn_all_train_tasks     29333.1
AverageReturn_all_test_tasks       5912.37
Number of train steps total      279000
Number of env steps total             1.3951e+07
Number of rollouts total         101283
Train Time (s)                      100.033
(Previous) Eval Time (s)             25.5294
Sample Time (s)                     106.325
Epoch Time (s)                      231.888
Total Train Time (s)              64829.6
Epoch                               278
------------------------------  -----------------
2019-06-27 18:33:22.396178 UTC | [dialturn] Iteration #278 | Epoch Duration: 231.90530490875244
2019-06-27 18:33:22.396428 UTC | [dialturn] Iteration #278 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000354316
Z variance train                      1.0001
KL Divergence                         1.45743e-05
KL Loss                               1.45743e-06
QF Loss                               2.74201e+09
VF Loss                               4.90619e+07
RF Loss                           34663
Policy Loss                     -229180
Q Predictions Mean               226482
Q Predictions Std                338597
Q Predictions Max                     1.02697e+06
Q Predictions Min                    87.8593
V Predictions Mean               225847
V Predictions Std                337463
V Predictions Max                     1.01186e+06
V Predictions Min                  -643.422
R Predictions Mean                  855.435
R Predictions Std                  2267.92
R Predictions Max                 16267.5
R Predictions Min                  -105.683
Log Pis Mean                         25.6112
Log Pis Std                          14.7201
Log Pis Max                          56.7322
Log Pis Min                          -4.17512
Policy mu Mean                       -4.07847
Policy mu Std                        28.51
Policy mu Max                       148.743
Policy mu Min                      -182.44
Policy log std Mean                  -0.468853
Policy log std Std                    1.32871
Policy log std Max                    2
Policy log std Min                   -8.22834
_task0 Rewards Mean                 236.026
_task0 Rewards Std                  492.518
_task0 Rewards Max                 2115.7
_task0 Rewards Min                   -1.0357
_task0 Returns Mean               35403.9
_task0 Returns Std                70548.6
_task0 Returns Max               231779
_task0 Returns Min                 -122.877
_task0 Actions Mean                   0.00251724
_task0 Actions Std                    0.886873
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1014.4
Exploration_task0 Rewards Std      2732.42
Exploration_task0 Rewards Max     22986.3
Exploration_task0 Rewards Min       -10.6315
Exploration_task0 Returns Mean   153696
Exploration_task0 Returns Std    381393
Exploration_task0 Returns Max         2.51026e+06
Exploration_task0 Returns Min     -1526.15
Exploration_task0 Actions Mean        0.0353646
Exploration_task0 Actions Std         0.898409
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              35403.9
AverageReturn_all_train_tasks     23692.3
AverageReturn_all_test_tasks      35403.9
Number of train steps total      280000
Number of env steps total             1.4001e+07
Number of rollouts total         101646
Train Time (s)                       99.1312
(Previous) Eval Time (s)             25.5457
Sample Time (s)                     106.306
Epoch Time (s)                      230.983
Total Train Time (s)              65060.5
Epoch                               279
------------------------------  -----------------
2019-06-27 18:37:13.256534 UTC | [dialturn] Iteration #279 | Epoch Duration: 230.85991430282593
2019-06-27 18:37:13.256753 UTC | [dialturn] Iteration #279 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00139277
Z variance train                      1.00035
KL Divergence                         0.00026172
KL Loss                               2.6172e-05
QF Loss                               9.13742e+08
VF Loss                               2.95554e+07
RF Loss                          171021
Policy Loss                     -247742
Q Predictions Mean               244370
Q Predictions Std                349981
Q Predictions Max                     1.02633e+06
Q Predictions Min                    22.8987
V Predictions Mean               244617
V Predictions Std                349911
V Predictions Max                     1.01747e+06
V Predictions Min                  -596.016
R Predictions Mean                 1436.74
R Predictions Std                  3894.11
R Predictions Max                 23953.4
R Predictions Min                   -73.881
Log Pis Mean                         25.6557
Log Pis Std                          14.5501
Log Pis Max                          55.9742
Log Pis Min                          -6.53606
Policy mu Mean                       -4.50788
Policy mu Std                        27.5512
Policy mu Max                       142.042
Policy mu Min                      -168.008
Policy log std Mean                  -0.444387
Policy log std Std                    1.39163
Policy log std Max                    2
Policy log std Min                   -7.19647
_task0 Rewards Mean                 107.487
_task0 Rewards Std                  290.749
_task0 Rewards Max                 1774.07
_task0 Rewards Min                   -0.901865
_task0 Returns Mean               16123.1
_task0 Returns Std                41458.8
_task0 Returns Max               148659
_task0 Returns Min                 -115.498
_task0 Actions Mean                   0.038967
_task0 Actions Std                    0.90343
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1326.94
Exploration_task0 Rewards Std      3442.48
Exploration_task0 Rewards Max     23096.4
Exploration_task0 Rewards Min       -11.3692
Exploration_task0 Returns Mean   201052
Exploration_task0 Returns Std    480276
Exploration_task0 Returns Max         2.80798e+06
Exploration_task0 Returns Min     -1468.73
Exploration_task0 Actions Mean        0.0077467
Exploration_task0 Actions Std         0.896636
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16123.1
AverageReturn_all_train_tasks     37037.7
AverageReturn_all_test_tasks      16123.1
Number of train steps total      281000
Number of env steps total             1.4051e+07
Number of rollouts total         102009
Train Time (s)                       99.0356
(Previous) Eval Time (s)             25.4209
Sample Time (s)                     106.485
Epoch Time (s)                      230.941
Total Train Time (s)              65291.6
Epoch                               280
------------------------------  -----------------
2019-06-27 18:41:04.372109 UTC | [dialturn] Iteration #280 | Epoch Duration: 231.1151897907257
2019-06-27 18:41:04.372328 UTC | [dialturn] Iteration #280 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00018032
Z variance train                      1.00013
KL Divergence                         3.88847e-06
KL Loss                               3.88847e-07
QF Loss                               1.45973e+09
VF Loss                               1.33077e+07
RF Loss                          152519
Policy Loss                     -249819
Q Predictions Mean               246377
Q Predictions Std                352324
Q Predictions Max                     1.02156e+06
Q Predictions Min                  -104.703
V Predictions Mean               251660
V Predictions Std                358430
V Predictions Max                     1.02731e+06
V Predictions Min                   112.997
R Predictions Mean                 2005.67
R Predictions Std                  4775.63
R Predictions Max                 22031.7
R Predictions Min                   -41.5938
Log Pis Mean                         25.7387
Log Pis Std                          14.7185
Log Pis Max                          57.2165
Log Pis Min                          -2.8163
Policy mu Mean                       -3.75644
Policy mu Std                        29.267
Policy mu Max                       152.692
Policy mu Min                      -177.553
Policy log std Mean                  -0.545939
Policy log std Std                    1.45638
Policy log std Max                    2
Policy log std Min                   -6.5768
_task0 Rewards Mean                  94.7153
_task0 Rewards Std                  205.756
_task0 Rewards Max                 1487.16
_task0 Rewards Min                   -1.17257
_task0 Returns Mean               14207.3
_task0 Returns Std                26778.9
_task0 Returns Max               103145
_task0 Returns Min                 -114.59
_task0 Actions Mean                   0.148392
_task0 Actions Std                    0.864329
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1330.54
Exploration_task0 Rewards Std      3273.01
Exploration_task0 Rewards Max     20873.8
Exploration_task0 Rewards Min       -11.0867
Exploration_task0 Returns Mean   201597
Exploration_task0 Returns Std    461768
Exploration_task0 Returns Max         2.21058e+06
Exploration_task0 Returns Min     -1449.19
Exploration_task0 Actions Mean        0.0227481
Exploration_task0 Actions Std         0.913246
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14207.3
AverageReturn_all_train_tasks     16653.4
AverageReturn_all_test_tasks      14207.3
Number of train steps total      282000
Number of env steps total             1.4101e+07
Number of rollouts total         102372
Train Time (s)                       99.5874
(Previous) Eval Time (s)             25.5935
Sample Time (s)                     106.776
Epoch Time (s)                      231.957
Total Train Time (s)              65523.5
Epoch                               281
------------------------------  -----------------
2019-06-27 18:44:56.258880 UTC | [dialturn] Iteration #281 | Epoch Duration: 231.88638854026794
2019-06-27 18:44:56.259088 UTC | [dialturn] Iteration #281 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000257155
Z variance train                      1.00013
KL Divergence                         7.65893e-06
KL Loss                               7.65893e-07
QF Loss                               2.66554e+09
VF Loss                               4.60151e+06
RF Loss                          263330
Policy Loss                     -241812
Q Predictions Mean               239139
Q Predictions Std                344391
Q Predictions Max                     1.02064e+06
Q Predictions Min                   568.996
V Predictions Mean               241143
V Predictions Std                347016
V Predictions Max                     1.01829e+06
V Predictions Min                  -796.202
R Predictions Mean                 1926.21
R Predictions Std                  4161.19
R Predictions Max                 21575.4
R Predictions Min                  -126.95
Log Pis Mean                         26.2174
Log Pis Std                          14.6593
Log Pis Max                          57.4861
Log Pis Min                          -3.02843
Policy mu Mean                       -4.79746
Policy mu Std                        29.711
Policy mu Max                       149.712
Policy mu Min                      -173.435
Policy log std Mean                  -0.50227
Policy log std Std                    1.41224
Policy log std Max                    2
Policy log std Min                   -7.39524
_task0 Rewards Mean                 121.807
_task0 Rewards Std                  405.319
_task0 Rewards Max                 2246.5
_task0 Rewards Min                   -1.01021
_task0 Returns Mean               18271.1
_task0 Returns Std                57965.5
_task0 Returns Max               250381
_task0 Returns Min                 -108.328
_task0 Actions Mean                  -0.0273838
_task0 Actions Std                    0.892422
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1772.28
Exploration_task0 Rewards Std      4171.63
Exploration_task0 Rewards Max     22978.7
Exploration_task0 Rewards Min       -11.0795
Exploration_task0 Returns Mean   268527
Exploration_task0 Returns Std    582617
Exploration_task0 Returns Max         2.78108e+06
Exploration_task0 Returns Min     -1201.64
Exploration_task0 Actions Mean        0.0501362
Exploration_task0 Actions Std         0.878446
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              18271.1
AverageReturn_all_train_tasks     12965.4
AverageReturn_all_test_tasks      18271.1
Number of train steps total      283000
Number of env steps total             1.4151e+07
Number of rollouts total         102735
Train Time (s)                       99.1533
(Previous) Eval Time (s)             25.5215
Sample Time (s)                     106.052
Epoch Time (s)                      230.727
Total Train Time (s)              65754.3
Epoch                               282
------------------------------  -----------------
2019-06-27 18:48:47.032144 UTC | [dialturn] Iteration #282 | Epoch Duration: 230.77289605140686
2019-06-27 18:48:47.032382 UTC | [dialturn] Iteration #282 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000942438
Z variance train                      1.00029
KL Divergence                         0.00010267
KL Loss                               1.0267e-05
QF Loss                               2.21671e+09
VF Loss                               7.35635e+06
RF Loss                          175177
Policy Loss                     -245173
Q Predictions Mean               242257
Q Predictions Std                346883
Q Predictions Max                     1.0225e+06
Q Predictions Min                 -3575.63
V Predictions Mean               245354
V Predictions Std                350661
V Predictions Max                     1.02251e+06
V Predictions Min                 -3265.49
R Predictions Mean                 1352.65
R Predictions Std                  3433.3
R Predictions Max                 18931.9
R Predictions Min                  -163.508
Log Pis Mean                         25.9958
Log Pis Std                          14.3942
Log Pis Max                          58.1585
Log Pis Min                          -4.4949
Policy mu Mean                       -5.15823
Policy mu Std                        30.1005
Policy mu Max                       143.045
Policy mu Min                      -164.479
Policy log std Mean                  -0.464478
Policy log std Std                    1.41096
Policy log std Max                    2
Policy log std Min                   -5.99331
_task0 Rewards Mean                 106.858
_task0 Rewards Std                  246.366
_task0 Rewards Max                 1506.14
_task0 Rewards Min                   -0.932487
_task0 Returns Mean               16028.7
_task0 Returns Std                32839.6
_task0 Returns Max               127137
_task0 Returns Min                 -121.113
_task0 Actions Mean                  -0.0029177
_task0 Actions Std                    0.895712
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      950.956
Exploration_task0 Rewards Std      2802.28
Exploration_task0 Rewards Max     22832.2
Exploration_task0 Rewards Min       -11.7619
Exploration_task0 Returns Mean   144084
Exploration_task0 Returns Std    377662
Exploration_task0 Returns Max         2.68102e+06
Exploration_task0 Returns Min     -1416.21
Exploration_task0 Actions Mean       -0.0181295
Exploration_task0 Actions Std         0.916544
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              16028.7
AverageReturn_all_train_tasks     37866
AverageReturn_all_test_tasks      16028.7
Number of train steps total      284000
Number of env steps total             1.4201e+07
Number of rollouts total         103098
Train Time (s)                       99.0537
(Previous) Eval Time (s)             25.5661
Sample Time (s)                     106.512
Epoch Time (s)                      231.132
Total Train Time (s)              65985.3
Epoch                               283
------------------------------  -----------------
2019-06-27 18:52:38.119092 UTC | [dialturn] Iteration #283 | Epoch Duration: 231.08651494979858
2019-06-27 18:52:38.119299 UTC | [dialturn] Iteration #283 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000931331
Z variance train                      1.00011
KL Divergence                         8.7908e-05
KL Loss                               8.7908e-06
QF Loss                               1.47044e+09
VF Loss                               1.33916e+07
RF Loss                          159740
Policy Loss                     -240768
Q Predictions Mean               237856
Q Predictions Std                344020
Q Predictions Max                     1.01485e+06
Q Predictions Min                   457.341
V Predictions Mean               241520
V Predictions Std                348493
V Predictions Max                     1.01906e+06
V Predictions Min                   135.223
R Predictions Mean                 1610.59
R Predictions Std                  3608.47
R Predictions Max                 17547.9
R Predictions Min                   -98.5366
Log Pis Mean                         25.2924
Log Pis Std                          14.5965
Log Pis Max                          59.3365
Log Pis Min                          -2.72993
Policy mu Mean                       -5.02375
Policy mu Std                        30.9121
Policy mu Max                       138.847
Policy mu Min                      -194.947
Policy log std Mean                  -0.43787
Policy log std Std                    1.43865
Policy log std Max                    2
Policy log std Min                   -5.86957
_task0 Rewards Mean                 101.939
_task0 Rewards Std                  291.48
_task0 Rewards Max                 1624.27
_task0 Rewards Min                   -0.877353
_task0 Returns Mean               15290.9
_task0 Returns Std                42263
_task0 Returns Max               133244
_task0 Returns Min                 -112.756
_task0 Actions Mean                  -0.0848367
_task0 Actions Std                    0.857902
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      958.987
Exploration_task0 Rewards Std      2702.49
Exploration_task0 Rewards Max     23070.3
Exploration_task0 Rewards Min       -10.7141
Exploration_task0 Returns Mean   145301
Exploration_task0 Returns Std    374564
Exploration_task0 Returns Max         2.57589e+06
Exploration_task0 Returns Min     -1441.22
Exploration_task0 Actions Mean        0.014543
Exploration_task0 Actions Std         0.90691
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15290.9
AverageReturn_all_train_tasks     26116.7
AverageReturn_all_test_tasks      15290.9
Number of train steps total      285000
Number of env steps total             1.4251e+07
Number of rollouts total         103461
Train Time (s)                       99.753
(Previous) Eval Time (s)             25.5192
Sample Time (s)                     106.922
Epoch Time (s)                      232.194
Total Train Time (s)              66217.7
Epoch                               284
------------------------------  -----------------
2019-06-27 18:56:30.457544 UTC | [dialturn] Iteration #284 | Epoch Duration: 232.33807730674744
2019-06-27 18:56:30.457782 UTC | [dialturn] Iteration #284 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000695271
Z variance train                      1.00009
KL Divergence                         6.37228e-05
KL Loss                               6.37228e-06
QF Loss                               1.18378e+09
VF Loss                               2.38746e+07
RF Loss                          153434
Policy Loss                     -236835
Q Predictions Mean               234023
Q Predictions Std                342326
Q Predictions Max                     1.01431e+06
Q Predictions Min                  -103.167
V Predictions Mean               234177
V Predictions Std                342411
V Predictions Max                     1.0087e+06
V Predictions Min                  -341.559
R Predictions Mean                 1403.82
R Predictions Std                  3594.37
R Predictions Max                 17062.3
R Predictions Min                  -120.156
Log Pis Mean                         25.4487
Log Pis Std                          14.8688
Log Pis Max                          57.425
Log Pis Min                          -4.675
Policy mu Mean                       -3.72299
Policy mu Std                        28.659
Policy mu Max                       136.526
Policy mu Min                      -169.871
Policy log std Mean                  -0.551838
Policy log std Std                    1.42719
Policy log std Max                    2
Policy log std Min                   -6.24658
_task0 Rewards Mean                 142.051
_task0 Rewards Std                  323.726
_task0 Rewards Max                 1521.46
_task0 Rewards Min                   -0.928499
_task0 Returns Mean               21307.7
_task0 Returns Std                45419
_task0 Returns Max               158094
_task0 Returns Min                 -119.313
_task0 Actions Mean                  -0.173183
_task0 Actions Std                    0.886351
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1372.35
Exploration_task0 Rewards Std      4070.69
Exploration_task0 Rewards Max     23075.5
Exploration_task0 Rewards Min       -10.5518
Exploration_task0 Returns Mean   207931
Exploration_task0 Returns Std    564940
Exploration_task0 Returns Max         2.7338e+06
Exploration_task0 Returns Min     -1362.43
Exploration_task0 Actions Mean       -0.00590712
Exploration_task0 Actions Std         0.903663
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21307.7
AverageReturn_all_train_tasks      1979.24
AverageReturn_all_test_tasks      21307.7
Number of train steps total      286000
Number of env steps total             1.4301e+07
Number of rollouts total         103824
Train Time (s)                       99.2475
(Previous) Eval Time (s)             25.6618
Sample Time (s)                     106.794
Epoch Time (s)                      231.703
Total Train Time (s)              66449.4
Epoch                               285
------------------------------  -----------------
2019-06-27 19:00:22.158061 UTC | [dialturn] Iteration #285 | Epoch Duration: 231.70008897781372
2019-06-27 19:00:22.158294 UTC | [dialturn] Iteration #285 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00067358
Z variance train                      1.00051
KL Divergence                         5.11177e-05
KL Loss                               5.11177e-06
QF Loss                               3.53466e+09
VF Loss                               2.35232e+07
RF Loss                          965444
Policy Loss                     -240193
Q Predictions Mean               237947
Q Predictions Std                345812
Q Predictions Max                     1.01416e+06
Q Predictions Min                 -3480.9
V Predictions Mean               242894
V Predictions Std                351445
V Predictions Max                     1.01967e+06
V Predictions Min                 -2949.07
R Predictions Mean                 1420.72
R Predictions Std                  3541.22
R Predictions Max                 22401.4
R Predictions Min                  -100.612
Log Pis Mean                         24.7761
Log Pis Std                          15.0967
Log Pis Max                          56.0843
Log Pis Min                          -6.64038
Policy mu Mean                       -4.4465
Policy mu Std                        29.6183
Policy mu Max                       139.596
Policy mu Min                      -160.967
Policy log std Mean                  -0.533623
Policy log std Std                    1.38088
Policy log std Max                    2
Policy log std Min                   -6.26383
_task0 Rewards Mean                 178.454
_task0 Rewards Std                  519.813
_task0 Rewards Max                 2232.29
_task0 Rewards Min                   -0.938002
_task0 Returns Mean               26768.1
_task0 Returns Std                74219.9
_task0 Returns Max               266736
_task0 Returns Min                 -119.77
_task0 Actions Mean                  -0.130494
_task0 Actions Std                    0.855892
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1685.13
Exploration_task0 Rewards Std      4323.03
Exploration_task0 Rewards Max     23115.8
Exploration_task0 Rewards Min       -10.4306
Exploration_task0 Returns Mean   255323
Exploration_task0 Returns Std    598896
Exploration_task0 Returns Max         2.56699e+06
Exploration_task0 Returns Min     -1315.86
Exploration_task0 Actions Mean        0.000448095
Exploration_task0 Actions Std         0.892473
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26768.1
AverageReturn_all_train_tasks     27813.5
AverageReturn_all_test_tasks      26768.1
Number of train steps total      287000
Number of env steps total             1.4351e+07
Number of rollouts total         104187
Train Time (s)                       99.0665
(Previous) Eval Time (s)             25.6572
Sample Time (s)                     106.206
Epoch Time (s)                      230.929
Total Train Time (s)              66680.3
Epoch                               286
------------------------------  -----------------
2019-06-27 19:04:13.102669 UTC | [dialturn] Iteration #286 | Epoch Duration: 230.94421291351318
2019-06-27 19:04:13.102906 UTC | [dialturn] Iteration #286 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000935735
Z variance train                      0.999841
KL Divergence                         0.000100947
KL Loss                               1.00947e-05
QF Loss                               8.93065e+08
VF Loss                               2.00712e+07
RF Loss                          304313
Policy Loss                     -233941
Q Predictions Mean               231164
Q Predictions Std                341829
Q Predictions Max                     1.01508e+06
Q Predictions Min                 -2326.41
V Predictions Mean               231435
V Predictions Std                342313
V Predictions Max                     1.01043e+06
V Predictions Min                 -2153.66
R Predictions Mean                 1083.28
R Predictions Std                  2880.48
R Predictions Max                 17748.8
R Predictions Min                  -108.527
Log Pis Mean                         24.8706
Log Pis Std                          15.2215
Log Pis Max                          58.4953
Log Pis Min                          -4.12676
Policy mu Mean                       -4.8294
Policy mu Std                        28.1135
Policy mu Max                       134.45
Policy mu Min                      -169.948
Policy log std Mean                  -0.661432
Policy log std Std                    1.37314
Policy log std Max                    2
Policy log std Min                   -6.82893
_task0 Rewards Mean                 119.983
_task0 Rewards Std                  280.592
_task0 Rewards Max                 1384.36
_task0 Rewards Min                   -1.09289
_task0 Returns Mean               17997.4
_task0 Returns Std                39198.1
_task0 Returns Max               125567
_task0 Returns Min                 -121.589
_task0 Actions Mean                  -0.00298873
_task0 Actions Std                    0.887602
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1115.28
Exploration_task0 Rewards Std      2970.09
Exploration_task0 Rewards Max     23005.6
Exploration_task0 Rewards Min       -10.2911
Exploration_task0 Returns Mean   168982
Exploration_task0 Returns Std    406148
Exploration_task0 Returns Max         2.58655e+06
Exploration_task0 Returns Min     -1454.22
Exploration_task0 Actions Mean       -0.025105
Exploration_task0 Actions Std         0.882151
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17997.4
AverageReturn_all_train_tasks     73697.3
AverageReturn_all_test_tasks      17997.4
Number of train steps total      288000
Number of env steps total             1.4401e+07
Number of rollouts total         104550
Train Time (s)                       99.3404
(Previous) Eval Time (s)             25.6707
Sample Time (s)                     106.459
Epoch Time (s)                      231.47
Total Train Time (s)              66911.8
Epoch                               287
------------------------------  -----------------
2019-06-27 19:08:04.561451 UTC | [dialturn] Iteration #287 | Epoch Duration: 231.45838403701782
2019-06-27 19:08:04.561643 UTC | [dialturn] Iteration #287 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000732776
Z variance train                      1.00022
KL Divergence                         6.76085e-05
KL Loss                               6.76085e-06
QF Loss                               3.7275e+09
VF Loss                               1.966e+07
RF Loss                          180575
Policy Loss                     -241467
Q Predictions Mean               239935
Q Predictions Std                344864
Q Predictions Max                     1.01977e+06
Q Predictions Min                 -3946.71
V Predictions Mean               243655
V Predictions Std                349199
V Predictions Max                     1.02034e+06
V Predictions Min                 -3219.95
R Predictions Mean                 1493.38
R Predictions Std                  3702.11
R Predictions Max                 19064
R Predictions Min                   -72.3484
Log Pis Mean                         25.1791
Log Pis Std                          15.0587
Log Pis Max                          58.1759
Log Pis Min                          -3.4515
Policy mu Mean                       -4.40351
Policy mu Std                        28.7155
Policy mu Max                       134.465
Policy mu Min                      -158.146
Policy log std Mean                  -0.546022
Policy log std Std                    1.41422
Policy log std Max                    2
Policy log std Min                   -6.59773
_task0 Rewards Mean                 127.699
_task0 Rewards Std                  305.791
_task0 Rewards Max                 1420.03
_task0 Rewards Min                   -0.914209
_task0 Returns Mean               19154.9
_task0 Returns Std                44114.4
_task0 Returns Max               154662
_task0 Returns Min                 -106.483
_task0 Actions Mean                  -0.0538991
_task0 Actions Std                    0.864365
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1440.12
Exploration_task0 Rewards Std      3689.61
Exploration_task0 Rewards Max     23093.7
Exploration_task0 Rewards Min       -10.8632
Exploration_task0 Returns Mean   218201
Exploration_task0 Returns Std    521705
Exploration_task0 Returns Max         2.61106e+06
Exploration_task0 Returns Min     -1268.46
Exploration_task0 Actions Mean       -0.0430385
Exploration_task0 Actions Std         0.90266
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19154.9
AverageReturn_all_train_tasks      1302.97
AverageReturn_all_test_tasks      19154.9
Number of train steps total      289000
Number of env steps total             1.4451e+07
Number of rollouts total         104913
Train Time (s)                       98.8279
(Previous) Eval Time (s)             25.6574
Sample Time (s)                     106.422
Epoch Time (s)                      230.907
Total Train Time (s)              67142.6
Epoch                               288
------------------------------  -----------------
2019-06-27 19:11:55.380233 UTC | [dialturn] Iteration #288 | Epoch Duration: 230.8184370994568
2019-06-27 19:11:55.380433 UTC | [dialturn] Iteration #288 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000439847
Z variance train                      0.999863
KL Divergence                         3.03543e-05
KL Loss                               3.03543e-06
QF Loss                               1.71823e+09
VF Loss                               6.37548e+06
RF Loss                          156084
Policy Loss                     -244649
Q Predictions Mean               241507
Q Predictions Std                341098
Q Predictions Max                     1.02201e+06
Q Predictions Min                  -786.263
V Predictions Mean               243612
V Predictions Std                343516
V Predictions Max                     1.0211e+06
V Predictions Min                  -639.112
R Predictions Mean                 1640.15
R Predictions Std                  3983.64
R Predictions Max                 18360
R Predictions Min                  -103.795
Log Pis Mean                         25.1471
Log Pis Std                          14.896
Log Pis Max                          58.7117
Log Pis Min                          -2.11708
Policy mu Mean                       -3.59761
Policy mu Std                        29.335
Policy mu Max                       152.552
Policy mu Min                      -174.031
Policy log std Mean                  -0.604009
Policy log std Std                    1.48441
Policy log std Max                    2
Policy log std Min                   -7.29804
_task0 Rewards Mean                 144.571
_task0 Rewards Std                  381.512
_task0 Rewards Max                 2127.21
_task0 Rewards Min                   -0.901662
_task0 Returns Mean               21685.7
_task0 Returns Std                52703.4
_task0 Returns Max               223825
_task0 Returns Min                 -101.716
_task0 Actions Mean                  -0.0225504
_task0 Actions Std                    0.884919
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      984.464
Exploration_task0 Rewards Std      2507.81
Exploration_task0 Rewards Max     23078.2
Exploration_task0 Rewards Min        -9.38245
Exploration_task0 Returns Mean   149161
Exploration_task0 Returns Std    332301
Exploration_task0 Returns Max         2.16393e+06
Exploration_task0 Returns Min     -1382.12
Exploration_task0 Actions Mean       -0.014656
Exploration_task0 Actions Std         0.90322
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21685.7
AverageReturn_all_train_tasks     59856.3
AverageReturn_all_test_tasks      21685.7
Number of train steps total      290000
Number of env steps total             1.4501e+07
Number of rollouts total         105276
Train Time (s)                       99.0846
(Previous) Eval Time (s)             25.5671
Sample Time (s)                     106.97
Epoch Time (s)                      231.621
Total Train Time (s)              67374.2
Epoch                               289
------------------------------  -----------------
2019-06-27 19:15:47.047459 UTC | [dialturn] Iteration #289 | Epoch Duration: 231.66685390472412
2019-06-27 19:15:47.047663 UTC | [dialturn] Iteration #289 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000250151
Z variance train                      0.999908
KL Divergence                         6.16814e-06
KL Loss                               6.16814e-07
QF Loss                               1.5738e+09
VF Loss                               2.73321e+07
RF Loss                          232587
Policy Loss                     -243305
Q Predictions Mean               240758
Q Predictions Std                345852
Q Predictions Max                     1.01542e+06
Q Predictions Min                 -6858.54
V Predictions Mean               246116
V Predictions Std                351719
V Predictions Max                     1.02571e+06
V Predictions Min                 -5932.14
R Predictions Mean                 1623.19
R Predictions Std                  3905.35
R Predictions Max                 19251.4
R Predictions Min                   -51.3999
Log Pis Mean                         25.0211
Log Pis Std                          15.1769
Log Pis Max                          59.0349
Log Pis Min                          -4.84738
Policy mu Mean                       -4.25978
Policy mu Std                        30.4092
Policy mu Max                       134.531
Policy mu Min                      -173.69
Policy log std Mean                  -0.689249
Policy log std Std                    1.55439
Policy log std Max                    2
Policy log std Min                   -7.79117
_task0 Rewards Mean                 121.053
_task0 Rewards Std                  458.65
_task0 Rewards Max                 2282.16
_task0 Rewards Min                   -0.94006
_task0 Returns Mean               18157.9
_task0 Returns Std                65589.5
_task0 Returns Max               282946
_task0 Returns Min                 -120.875
_task0 Actions Mean                   0.0109048
_task0 Actions Std                    0.884046
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      900.493
Exploration_task0 Rewards Std      2712.73
Exploration_task0 Rewards Max     22735.6
Exploration_task0 Rewards Min        -9.37971
Exploration_task0 Returns Mean   136438
Exploration_task0 Returns Std    374648
Exploration_task0 Returns Max         2.56743e+06
Exploration_task0 Returns Min     -1444.96
Exploration_task0 Actions Mean       -0.0293363
Exploration_task0 Actions Std         0.903405
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              18157.9
AverageReturn_all_train_tasks     40757.8
AverageReturn_all_test_tasks      18157.9
Number of train steps total      291000
Number of env steps total             1.4551e+07
Number of rollouts total         105639
Train Time (s)                       98.799
(Previous) Eval Time (s)             25.6113
Sample Time (s)                     107.056
Epoch Time (s)                      231.467
Total Train Time (s)              67605.7
Epoch                               290
------------------------------  -----------------
2019-06-27 19:19:38.456918 UTC | [dialturn] Iteration #290 | Epoch Duration: 231.40909099578857
2019-06-27 19:19:38.457112 UTC | [dialturn] Iteration #290 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000888784
Z variance train                      0.999967
KL Divergence                         0.000135165
KL Loss                               1.35165e-05
QF Loss                               2.15957e+09
VF Loss                               5.69788e+06
RF Loss                          251112
Policy Loss                     -236523
Q Predictions Mean               232840
Q Predictions Std                339137
Q Predictions Max                     1.02796e+06
Q Predictions Min                 -1496.12
V Predictions Mean               237226
V Predictions Std                344162
V Predictions Max                     1.02796e+06
V Predictions Min                 -2074.09
R Predictions Mean                 1193.85
R Predictions Std                  2916.09
R Predictions Max                 18937.5
R Predictions Min                  -375.172
Log Pis Mean                         24.6506
Log Pis Std                          15.188
Log Pis Max                          57.5942
Log Pis Min                          -5.39751
Policy mu Mean                       -3.27766
Policy mu Std                        28.843
Policy mu Max                       138.401
Policy mu Min                      -178.023
Policy log std Mean                  -0.69347
Policy log std Std                    1.50494
Policy log std Max                    2
Policy log std Min                   -6.2577
_task0 Rewards Mean                 130.723
_task0 Rewards Std                  359.1
_task0 Rewards Max                 1854.26
_task0 Rewards Min                   -0.913909
_task0 Returns Mean               19608.4
_task0 Returns Std                51233.1
_task0 Returns Max               197671
_task0 Returns Min                 -105.953
_task0 Actions Mean                  -0.0156455
_task0 Actions Std                    0.882329
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      988.876
Exploration_task0 Rewards Std      2643.48
Exploration_task0 Rewards Max     22401.1
Exploration_task0 Rewards Min        -9.56713
Exploration_task0 Returns Mean   149830
Exploration_task0 Returns Std    367961
Exploration_task0 Returns Max         2.4249e+06
Exploration_task0 Returns Min     -1394.41
Exploration_task0 Actions Mean       -0.0491505
Exploration_task0 Actions Std         0.882558
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              19608.4
AverageReturn_all_train_tasks     31507.3
AverageReturn_all_test_tasks      19608.4
Number of train steps total      292000
Number of env steps total             1.4601e+07
Number of rollouts total         106002
Train Time (s)                       99.8045
(Previous) Eval Time (s)             25.5523
Sample Time (s)                     106.972
Epoch Time (s)                      232.329
Total Train Time (s)              67837.9
Epoch                               291
------------------------------  -----------------
2019-06-27 19:23:30.672864 UTC | [dialturn] Iteration #291 | Epoch Duration: 232.21559023857117
2019-06-27 19:23:30.673067 UTC | [dialturn] Iteration #291 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00052087
Z variance train                      1.00016
KL Divergence                         4.65846e-05
KL Loss                               4.65846e-06
QF Loss                               2.96415e+09
VF Loss                               8.46239e+06
RF Loss                          153753
Policy Loss                     -240290
Q Predictions Mean               236988
Q Predictions Std                341385
Q Predictions Max                     1.02762e+06
Q Predictions Min                   718.28
V Predictions Mean               239632
V Predictions Std                344089
V Predictions Max                     1.02298e+06
V Predictions Min                   398.5
R Predictions Mean                 1247.41
R Predictions Std                  3559.65
R Predictions Max                 20981.8
R Predictions Min                   -68.7617
Log Pis Mean                         25.3792
Log Pis Std                          15.0704
Log Pis Max                          57.7859
Log Pis Min                          -5.60471
Policy mu Mean                       -3.75521
Policy mu Std                        28.3931
Policy mu Max                       134.062
Policy mu Min                      -154.021
Policy log std Mean                  -0.597681
Policy log std Std                    1.4947
Policy log std Max                    2
Policy log std Min                   -7.04994
_task0 Rewards Mean                 135.726
_task0 Rewards Std                  303.955
_task0 Rewards Max                 2263.74
_task0 Rewards Min                   -0.953924
_task0 Returns Mean               20359
_task0 Returns Std                42759.7
_task0 Returns Max               145106
_task0 Returns Min                 -113.532
_task0 Actions Mean                   0.0338153
_task0 Actions Std                    0.890317
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1380.01
Exploration_task0 Rewards Std      3746.96
Exploration_task0 Rewards Max     22890.3
Exploration_task0 Rewards Min        -9.38279
Exploration_task0 Returns Mean   209093
Exploration_task0 Returns Std    528759
Exploration_task0 Returns Max         2.39357e+06
Exploration_task0 Returns Min     -1186.78
Exploration_task0 Actions Mean       -0.0565341
Exploration_task0 Actions Std         0.890421
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              20359
AverageReturn_all_train_tasks       619.337
AverageReturn_all_test_tasks      20359
Number of train steps total      293000
Number of env steps total             1.4651e+07
Number of rollouts total         106365
Train Time (s)                       99.8331
(Previous) Eval Time (s)             25.4378
Sample Time (s)                     106.676
Epoch Time (s)                      231.947
Total Train Time (s)              68069.7
Epoch                               292
------------------------------  -----------------
2019-06-27 19:27:22.557348 UTC | [dialturn] Iteration #292 | Epoch Duration: 231.88409328460693
2019-06-27 19:27:22.557554 UTC | [dialturn] Iteration #292 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000762108
Z variance train                      0.999752
KL Divergence                         8.06482e-05
KL Loss                               8.06482e-06
QF Loss                               2.72449e+09
VF Loss                               6.05887e+06
RF Loss                           76360.3
Policy Loss                     -243784
Q Predictions Mean               240865
Q Predictions Std                345761
Q Predictions Max                     1.03458e+06
Q Predictions Min                   881.173
V Predictions Mean               242737
V Predictions Std                348013
V Predictions Max                     1.02711e+06
V Predictions Min                   478.72
R Predictions Mean                  875.895
R Predictions Std                  2574.61
R Predictions Max                 22015.7
R Predictions Min                  -221.086
Log Pis Mean                         25.3801
Log Pis Std                          14.9168
Log Pis Max                          58.0091
Log Pis Min                          -5.36904
Policy mu Mean                       -4.70224
Policy mu Std                        30.1893
Policy mu Max                       125.403
Policy mu Min                      -181.426
Policy log std Mean                  -0.625409
Policy log std Std                    1.51747
Policy log std Max                    2
Policy log std Min                   -6.63698
_task0 Rewards Mean                  89.4719
_task0 Rewards Std                  255.173
_task0 Rewards Max                 1585.02
_task0 Rewards Min                   -0.898161
_task0 Returns Mean               13420.8
_task0 Returns Std                34442.4
_task0 Returns Max               143345
_task0 Returns Min                 -113.132
_task0 Actions Mean                  -0.0811574
_task0 Actions Std                    0.937488
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1276.25
Exploration_task0 Rewards Std      3340.74
Exploration_task0 Rewards Max     22989.4
Exploration_task0 Rewards Min        -9.83501
Exploration_task0 Returns Mean   193371
Exploration_task0 Returns Std    464090
Exploration_task0 Returns Max         2.40119e+06
Exploration_task0 Returns Min     -1289.24
Exploration_task0 Actions Mean       -0.0466402
Exploration_task0 Actions Std         0.890218
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13420.8
AverageReturn_all_train_tasks      5970.8
AverageReturn_all_test_tasks      13420.8
Number of train steps total      294000
Number of env steps total             1.4701e+07
Number of rollouts total         106728
Train Time (s)                       99.1056
(Previous) Eval Time (s)             25.3732
Sample Time (s)                     106.694
Epoch Time (s)                      231.172
Total Train Time (s)              68301.1
Epoch                               293
------------------------------  -----------------
2019-06-27 19:31:13.957059 UTC | [dialturn] Iteration #293 | Epoch Duration: 231.39932370185852
2019-06-27 19:31:13.957328 UTC | [dialturn] Iteration #293 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000867871
Z variance train                      0.999951
KL Divergence                         0.000137509
KL Loss                               1.37509e-05
QF Loss                               3.00784e+09
VF Loss                               3.6899e+07
RF Loss                          171806
Policy Loss                     -245852
Q Predictions Mean               242831
Q Predictions Std                343529
Q Predictions Max                     1.0185e+06
Q Predictions Min                   487.202
V Predictions Mean               249278
V Predictions Std                350416
V Predictions Max                     1.02862e+06
V Predictions Min                   483.901
R Predictions Mean                 1232.91
R Predictions Std                  2891.33
R Predictions Max                 21035.3
R Predictions Min                   -89.221
Log Pis Mean                         26.3837
Log Pis Std                          14.6011
Log Pis Max                          57.9274
Log Pis Min                          -4.67772
Policy mu Mean                       -4.3318
Policy mu Std                        31.2846
Policy mu Max                       140.372
Policy mu Min                      -185.876
Policy log std Mean                  -0.631639
Policy log std Std                    1.55954
Policy log std Max                    2
Policy log std Min                   -7.03297
_task0 Rewards Mean                 150.776
_task0 Rewards Std                  313.385
_task0 Rewards Max                 1679.09
_task0 Rewards Min                   -0.852246
_task0 Returns Mean               22616.4
_task0 Returns Std                44131.6
_task0 Returns Max               158488
_task0 Returns Min                 -105.826
_task0 Actions Mean                   0.0320609
_task0 Actions Std                    0.859361
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      822.692
Exploration_task0 Rewards Std      2417.3
Exploration_task0 Rewards Max     22441.9
Exploration_task0 Rewards Min        -9.34075
Exploration_task0 Returns Mean   124650
Exploration_task0 Returns Std    325740
Exploration_task0 Returns Max         2.45798e+06
Exploration_task0 Returns Min     -1206.6
Exploration_task0 Actions Mean       -0.0378759
Exploration_task0 Actions Std         0.903924
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              22616.4
AverageReturn_all_train_tasks     18674.1
AverageReturn_all_test_tasks      22616.4
Number of train steps total      295000
Number of env steps total             1.4751e+07
Number of rollouts total         107091
Train Time (s)                       98.8437
(Previous) Eval Time (s)             25.5988
Sample Time (s)                     106.24
Epoch Time (s)                      230.682
Total Train Time (s)              68531.7
Epoch                               294
------------------------------  -----------------
2019-06-27 19:35:04.483343 UTC | [dialturn] Iteration #294 | Epoch Duration: 230.52584600448608
2019-06-27 19:35:04.483538 UTC | [dialturn] Iteration #294 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000176349
Z variance train                      0.999639
KL Divergence                         6.37319e-06
KL Loss                               6.37319e-07
QF Loss                               2.1987e+09
VF Loss                               1.53663e+07
RF Loss                          168897
Policy Loss                     -249803
Q Predictions Mean               247191
Q Predictions Std                345052
Q Predictions Max                     1.02993e+06
Q Predictions Min                   680.541
V Predictions Mean               248648
V Predictions Std                346159
V Predictions Max                     1.02568e+06
V Predictions Min                   608.441
R Predictions Mean                  899.801
R Predictions Std                  2879.67
R Predictions Max                 21295.5
R Predictions Min                  -236.391
Log Pis Mean                         25.6805
Log Pis Std                          14.8487
Log Pis Max                          57.5899
Log Pis Min                          -3.232
Policy mu Mean                       -4.40244
Policy mu Std                        30.3317
Policy mu Max                       126.482
Policy mu Min                      -179.757
Policy log std Mean                  -0.600271
Policy log std Std                    1.54657
Policy log std Max                    2
Policy log std Min                   -7.1955
_task0 Rewards Mean                 105.123
_task0 Rewards Std                  281.73
_task0 Rewards Max                 1650.6
_task0 Rewards Min                   -0.870013
_task0 Returns Mean               15768.5
_task0 Returns Std                40127.6
_task0 Returns Max               164520
_task0 Returns Min                 -109.028
_task0 Actions Mean                  -0.0769875
_task0 Actions Std                    0.906704
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1250.36
Exploration_task0 Rewards Std      2940.54
Exploration_task0 Rewards Max     22538.8
Exploration_task0 Rewards Min        -9.36417
Exploration_task0 Returns Mean   189448
Exploration_task0 Returns Std    407903
Exploration_task0 Returns Max         2.15313e+06
Exploration_task0 Returns Min     -1295.4
Exploration_task0 Actions Mean       -0.0551909
Exploration_task0 Actions Std         0.883343
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15768.5
AverageReturn_all_train_tasks     27417.3
AverageReturn_all_test_tasks      15768.5
Number of train steps total      296000
Number of env steps total             1.4801e+07
Number of rollouts total         107454
Train Time (s)                       99.5907
(Previous) Eval Time (s)             25.4413
Sample Time (s)                     106.427
Epoch Time (s)                      231.459
Total Train Time (s)              68763
Epoch                               295
------------------------------  -----------------
2019-06-27 19:38:55.854851 UTC | [dialturn] Iteration #295 | Epoch Duration: 231.37115001678467
2019-06-27 19:38:55.855066 UTC | [dialturn] Iteration #295 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000516812
Z variance train                      1.00054
KL Divergence                         4.69348e-05
KL Loss                               4.69348e-06
QF Loss                               1.91235e+09
VF Loss                               1.70439e+07
RF Loss                          132440
Policy Loss                     -237315
Q Predictions Mean               233965
Q Predictions Std                338825
Q Predictions Max                     1.03008e+06
Q Predictions Min                 -1113.64
V Predictions Mean               235085
V Predictions Std                339851
V Predictions Max                     1.02399e+06
V Predictions Min                  -854.196
R Predictions Mean                  788.052
R Predictions Std                  2252.62
R Predictions Max                 17531.9
R Predictions Min                   -94.0126
Log Pis Mean                         25.5729
Log Pis Std                          15.2422
Log Pis Max                          57.0906
Log Pis Min                          -5.86795
Policy mu Mean                       -4.75717
Policy mu Std                        29.1866
Policy mu Max                       155.148
Policy mu Min                      -184.868
Policy log std Mean                  -0.616402
Policy log std Std                    1.53204
Policy log std Max                    2
Policy log std Min                   -7.19054
_task0 Rewards Mean                 145.884
_task0 Rewards Std                  418.754
_task0 Rewards Max                 2196.55
_task0 Rewards Min                   -0.903328
_task0 Returns Mean               21882.6
_task0 Returns Std                59741
_task0 Returns Max               226234
_task0 Returns Min                 -112.539
_task0 Actions Mean                  -0.135624
_task0 Actions Std                    0.879312
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1022
Exploration_task0 Rewards Std      2386.36
Exploration_task0 Rewards Max     20404.2
Exploration_task0 Rewards Min        -9.2797
Exploration_task0 Returns Mean   154848
Exploration_task0 Returns Std    331910
Exploration_task0 Returns Max         1.78714e+06
Exploration_task0 Returns Min     -1440.35
Exploration_task0 Actions Mean        0.0354861
Exploration_task0 Actions Std         0.899875
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              21882.6
AverageReturn_all_train_tasks     31797.4
AverageReturn_all_test_tasks      21882.6
Number of train steps total      297000
Number of env steps total             1.4851e+07
Number of rollouts total         107817
Train Time (s)                       98.7426
(Previous) Eval Time (s)             25.352
Sample Time (s)                     106.592
Epoch Time (s)                      230.687
Total Train Time (s)              68993.9
Epoch                               296
------------------------------  -----------------
2019-06-27 19:42:46.701424 UTC | [dialturn] Iteration #296 | Epoch Duration: 230.8461890220642
2019-06-27 19:42:46.701619 UTC | [dialturn] Iteration #296 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000352864
Z variance train                      0.999994
KL Divergence                         2.1499e-05
KL Loss                               2.1499e-06
QF Loss                               2.237e+09
VF Loss                               7.17631e+06
RF Loss                           97327.5
Policy Loss                     -245326
Q Predictions Mean               243158
Q Predictions Std                344846
Q Predictions Max                     1.03005e+06
Q Predictions Min                 -5848.13
V Predictions Mean               246266
V Predictions Std                348377
V Predictions Max                     1.0343e+06
V Predictions Min                 -6114.63
R Predictions Mean                  900.142
R Predictions Std                  2695.27
R Predictions Max                 22027.5
R Predictions Min                   -84.9726
Log Pis Mean                         25.85
Log Pis Std                          15.304
Log Pis Max                          58.1698
Log Pis Min                          -3.51381
Policy mu Mean                       -4.01054
Policy mu Std                        30.5183
Policy mu Max                       127.549
Policy mu Min                      -169.931
Policy log std Mean                  -0.61149
Policy log std Std                    1.57604
Policy log std Max                    2
Policy log std Min                   -7.53293
_task0 Rewards Mean                 198.024
_task0 Rewards Std                  397.368
_task0 Rewards Max                 1997.41
_task0 Rewards Min                   -0.806095
_task0 Returns Mean               29703.5
_task0 Returns Std                56356.9
_task0 Returns Max               192601
_task0 Returns Min                  -83.9537
_task0 Actions Mean                   0.00757947
_task0 Actions Std                    0.838375
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1379.99
Exploration_task0 Rewards Std      3801.17
Exploration_task0 Rewards Max     22951.5
Exploration_task0 Rewards Min        -9.95927
Exploration_task0 Returns Mean   209090
Exploration_task0 Returns Std    517969
Exploration_task0 Returns Max         2.65034e+06
Exploration_task0 Returns Min     -1426.76
Exploration_task0 Actions Mean       -0.00623317
Exploration_task0 Actions Std         0.895708
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              29703.5
AverageReturn_all_train_tasks     25755.6
AverageReturn_all_test_tasks      29703.5
Number of train steps total      298000
Number of env steps total             1.4901e+07
Number of rollouts total         108180
Train Time (s)                       99.7932
(Previous) Eval Time (s)             25.5098
Sample Time (s)                     106.556
Epoch Time (s)                      231.859
Total Train Time (s)              69225.9
Epoch                               297
------------------------------  -----------------
2019-06-27 19:46:38.694588 UTC | [dialturn] Iteration #297 | Epoch Duration: 231.99280858039856
2019-06-27 19:46:38.694788 UTC | [dialturn] Iteration #297 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000501397
Z variance train                      0.999786
KL Divergence                         2.71107e-05
KL Loss                               2.71107e-06
QF Loss                               2.28997e+09
VF Loss                               2.45798e+07
RF Loss                           53601.7
Policy Loss                     -248944
Q Predictions Mean               246417
Q Predictions Std                344277
Q Predictions Max                     1.03319e+06
Q Predictions Min                   666.298
V Predictions Mean               251806
V Predictions Std                350392
V Predictions Max                     1.04172e+06
V Predictions Min                   637.991
R Predictions Mean                  774.291
R Predictions Std                  1864.07
R Predictions Max                 11970.2
R Predictions Min                   -93.3436
Log Pis Mean                         26.1465
Log Pis Std                          15.1561
Log Pis Max                          60.7301
Log Pis Min                          -2.80968
Policy mu Mean                       -4.75688
Policy mu Std                        31.2466
Policy mu Max                       132.998
Policy mu Min                      -166.88
Policy log std Mean                  -0.555214
Policy log std Std                    1.57389
Policy log std Max                    2
Policy log std Min                   -6.60888
_task0 Rewards Mean                 163.931
_task0 Rewards Std                  436.293
_task0 Rewards Max                 2200.68
_task0 Rewards Min                   -0.882293
_task0 Returns Mean               24589.6
_task0 Returns Std                61511.7
_task0 Returns Max               219101
_task0 Returns Min                 -112.987
_task0 Actions Mean                   0.0852205
_task0 Actions Std                    0.917038
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1225.7
Exploration_task0 Rewards Std      2979.28
Exploration_task0 Rewards Max     23122
Exploration_task0 Rewards Min        -8.9467
Exploration_task0 Returns Mean   185711
Exploration_task0 Returns Std    407069
Exploration_task0 Returns Max         2.79927e+06
Exploration_task0 Returns Min     -1289.03
Exploration_task0 Actions Mean        0.00959955
Exploration_task0 Actions Std         0.893685
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              24589.6
AverageReturn_all_train_tasks      7280.45
AverageReturn_all_test_tasks      24589.6
Number of train steps total      299000
Number of env steps total             1.4951e+07
Number of rollouts total         108543
Train Time (s)                      100.041
(Previous) Eval Time (s)             25.6427
Sample Time (s)                     106.6
Epoch Time (s)                      232.284
Total Train Time (s)              69458.1
Epoch                               298
------------------------------  -----------------
2019-06-27 19:50:30.957840 UTC | [dialturn] Iteration #298 | Epoch Duration: 232.2628915309906
2019-06-27 19:50:30.958061 UTC | [dialturn] Iteration #298 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000533487
Z variance train                      1.00041
KL Divergence                         4.16278e-05
KL Loss                               4.16278e-06
QF Loss                               2.16456e+09
VF Loss                               2.39585e+07
RF Loss                          132838
Policy Loss                     -247121
Q Predictions Mean               244783
Q Predictions Std                344382
Q Predictions Max                     1.04276e+06
Q Predictions Min                 -4896.71
V Predictions Mean               244305
V Predictions Std                343745
V Predictions Max                     1.02899e+06
V Predictions Min                 -4112.09
R Predictions Mean                 1332.19
R Predictions Std                  3052.3
R Predictions Max                 17152.1
R Predictions Min                   -59.6144
Log Pis Mean                         25.6585
Log Pis Std                          15.44
Log Pis Max                          56.6349
Log Pis Min                          -3.4986
Policy mu Mean                       -5.12601
Policy mu Std                        30.712
Policy mu Max                       126.622
Policy mu Min                      -168.415
Policy log std Mean                  -0.588535
Policy log std Std                    1.53372
Policy log std Max                    2
Policy log std Min                   -6.82444
_task0 Rewards Mean                 181.237
_task0 Rewards Std                  440.841
_task0 Rewards Max                 2237.2
_task0 Rewards Min                   -0.928172
_task0 Returns Mean               27185.6
_task0 Returns Std                60869
_task0 Returns Max               211045
_task0 Returns Min                 -114.105
_task0 Actions Mean                  -0.032851
_task0 Actions Std                    0.873919
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1341.05
Exploration_task0 Rewards Std      3218.5
Exploration_task0 Rewards Max     22114.6
Exploration_task0 Rewards Min        -9.27886
Exploration_task0 Returns Mean   203189
Exploration_task0 Returns Std    446923
Exploration_task0 Returns Max         2.17152e+06
Exploration_task0 Returns Min     -1243.72
Exploration_task0 Actions Mean        0.0104731
Exploration_task0 Actions Std         0.889541
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27185.6
AverageReturn_all_train_tasks      3254.59
AverageReturn_all_test_tasks      27185.6
Number of train steps total      300000
Number of env steps total             1.5001e+07
Number of rollouts total         108906
Train Time (s)                      100.795
(Previous) Eval Time (s)             25.6197
Sample Time (s)                     107.192
Epoch Time (s)                      233.607
Total Train Time (s)              69691.7
Epoch                               299
------------------------------  -----------------
2019-06-27 19:54:24.515699 UTC | [dialturn] Iteration #299 | Epoch Duration: 233.5574290752411
2019-06-27 19:54:24.515919 UTC | [dialturn] Iteration #299 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000476048
Z variance train                      1.00003
KL Divergence                         5.82874e-05
KL Loss                               5.82874e-06
QF Loss                               1.4593e+09
VF Loss                               5.93923e+06
RF Loss                           44323
Policy Loss                     -251326
Q Predictions Mean               248261
Q Predictions Std                348325
Q Predictions Max                     1.03567e+06
Q Predictions Min                   -93.5218
V Predictions Mean               251997
V Predictions Std                352502
V Predictions Max                     1.04193e+06
V Predictions Min                 -1738.27
R Predictions Mean                 1165.75
R Predictions Std                  2537.86
R Predictions Max                 17562.4
R Predictions Min                   -85.9411
Log Pis Mean                         25.6394
Log Pis Std                          15.3921
Log Pis Max                          59.5359
Log Pis Min                          -4.70243
Policy mu Mean                       -4.71177
Policy mu Std                        30.9042
Policy mu Max                       132.167
Policy mu Min                      -176.549
Policy log std Mean                  -0.632234
Policy log std Std                    1.52333
Policy log std Max                    2
Policy log std Min                   -8.46743
_task0 Rewards Mean                  13.9728
_task0 Rewards Std                   44.2355
_task0 Rewards Max                  230.215
_task0 Rewards Min                   -0.874467
_task0 Returns Mean                2095.93
_task0 Returns Std                 6200.14
_task0 Returns Max                22293.8
_task0 Returns Min                 -108.579
_task0 Actions Mean                  -0.0115217
_task0 Actions Std                    0.922365
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1327.22
Exploration_task0 Rewards Std      3261.54
Exploration_task0 Rewards Max     23040.5
Exploration_task0 Rewards Min        -9.21579
Exploration_task0 Returns Mean   201094
Exploration_task0 Returns Std    441355
Exploration_task0 Returns Max         2.62184e+06
Exploration_task0 Returns Min     -1157.44
Exploration_task0 Actions Mean       -0.00993141
Exploration_task0 Actions Std         0.882135
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               2095.93
AverageReturn_all_train_tasks       228.61
AverageReturn_all_test_tasks       2095.93
Number of train steps total      301000
Number of env steps total             1.5051e+07
Number of rollouts total         109269
Train Time (s)                       99.5933
(Previous) Eval Time (s)             25.5692
Sample Time (s)                     107.575
Epoch Time (s)                      232.738
Total Train Time (s)              69924.7
Epoch                               300
------------------------------  -----------------
2019-06-27 19:58:17.536508 UTC | [dialturn] Iteration #300 | Epoch Duration: 233.02035212516785
2019-06-27 19:58:17.536721 UTC | [dialturn] Iteration #300 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000282793
Z variance train                      0.999669
KL Divergence                         1.87791e-05
KL Loss                               1.87791e-06
QF Loss                               1.78773e+09
VF Loss                               3.05422e+07
RF Loss                           73442.6
Policy Loss                     -251115
Q Predictions Mean               246902
Q Predictions Std                344497
Q Predictions Max                     1.03636e+06
Q Predictions Min                 -6559.69
V Predictions Mean               248346
V Predictions Std                346452
V Predictions Max                     1.03329e+06
V Predictions Min                -12064.2
R Predictions Mean                  777.562
R Predictions Std                  2441.04
R Predictions Max                 16433.6
R Predictions Min                  -157.496
Log Pis Mean                         26.1932
Log Pis Std                          15.0677
Log Pis Max                          58.8707
Log Pis Min                          -5.85295
Policy mu Mean                       -3.5658
Policy mu Std                        28.7447
Policy mu Max                       137.103
Policy mu Min                      -220.377
Policy log std Mean                  -0.658358
Policy log std Std                    1.50391
Policy log std Max                    2
Policy log std Min                   -8.67326
_task0 Rewards Mean                  79.2618
_task0 Rewards Std                  210.716
_task0 Rewards Max                 1127.79
_task0 Rewards Min                   -0.887995
_task0 Returns Mean               11889.3
_task0 Returns Std                29862.3
_task0 Returns Max               127124
_task0 Returns Min                 -114.604
_task0 Actions Mean                   0.0528755
_task0 Actions Std                    0.916775
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1917.12
Exploration_task0 Rewards Std      4195.84
Exploration_task0 Rewards Max     22511.1
Exploration_task0 Rewards Min       -11.4586
Exploration_task0 Returns Mean   290472
Exploration_task0 Returns Std    592439
Exploration_task0 Returns Max         2.34244e+06
Exploration_task0 Returns Min     -1344.56
Exploration_task0 Actions Mean       -1.85798e-05
Exploration_task0 Actions Std         0.882138
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11889.3
AverageReturn_all_train_tasks      4379.71
AverageReturn_all_test_tasks      11889.3
Number of train steps total      302000
Number of env steps total             1.5101e+07
Number of rollouts total         109632
Train Time (s)                       99.7963
(Previous) Eval Time (s)             25.8502
Sample Time (s)                     107.378
Epoch Time (s)                      233.025
Total Train Time (s)              70157.7
Epoch                               301
------------------------------  -----------------
2019-06-27 20:02:10.569997 UTC | [dialturn] Iteration #301 | Epoch Duration: 233.03311419487
2019-06-27 20:02:10.570194 UTC | [dialturn] Iteration #301 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000359611
Z variance train                      0.999596
KL Divergence                         1.92076e-05
KL Loss                               1.92076e-06
QF Loss                               1.24485e+09
VF Loss                               1.82902e+07
RF Loss                          138050
Policy Loss                     -256928
Q Predictions Mean               254159
Q Predictions Std                349856
Q Predictions Max                     1.04446e+06
Q Predictions Min                  -517.882
V Predictions Mean               259230
V Predictions Std                355604
V Predictions Max                     1.05031e+06
V Predictions Min                 -1889.24
R Predictions Mean                 1190.89
R Predictions Std                  3141.81
R Predictions Max                 22812.9
R Predictions Min                   -64.1313
Log Pis Mean                         25.6509
Log Pis Std                          14.8402
Log Pis Max                          56.2621
Log Pis Min                          -2.60834
Policy mu Mean                       -5.02704
Policy mu Std                        31.63
Policy mu Max                       121.472
Policy mu Min                      -189.143
Policy log std Mean                  -0.586417
Policy log std Std                    1.52355
Policy log std Max                    2
Policy log std Min                   -6.31444
_task0 Rewards Mean                  58.665
_task0 Rewards Std                  192.883
_task0 Rewards Max                 1497.35
_task0 Rewards Min                   -0.94513
_task0 Returns Mean                8799.75
_task0 Returns Std                27593.5
_task0 Returns Max               118956
_task0 Returns Min                 -111.578
_task0 Actions Mean                  -0.0236405
_task0 Actions Std                    0.932403
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1256.83
Exploration_task0 Rewards Std      3972.42
Exploration_task0 Rewards Max     22946.6
Exploration_task0 Rewards Min       -10.5716
Exploration_task0 Returns Mean   190428
Exploration_task0 Returns Std    564184
Exploration_task0 Returns Max         2.70351e+06
Exploration_task0 Returns Min     -1196.99
Exploration_task0 Actions Mean       -0.0299202
Exploration_task0 Actions Std         0.900713
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               8799.75
AverageReturn_all_train_tasks     26242.8
AverageReturn_all_test_tasks       8799.75
Number of train steps total      303000
Number of env steps total             1.5151e+07
Number of rollouts total         109995
Train Time (s)                       99.9414
(Previous) Eval Time (s)             25.8571
Sample Time (s)                     107.414
Epoch Time (s)                      233.212
Total Train Time (s)              70390.6
Epoch                               302
------------------------------  -----------------
2019-06-27 20:06:03.499723 UTC | [dialturn] Iteration #302 | Epoch Duration: 232.92937183380127
2019-06-27 20:06:03.499931 UTC | [dialturn] Iteration #302 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000137827
Z variance train                      1.00005
KL Divergence                         4.32443e-06
KL Loss                               4.32443e-07
QF Loss                               3.67524e+09
VF Loss                               1.01183e+07
RF Loss                          161542
Policy Loss                     -245381
Q Predictions Mean               242979
Q Predictions Std                346500
Q Predictions Max                     1.04942e+06
Q Predictions Min                 -3182.14
V Predictions Mean               246690
V Predictions Std                350776
V Predictions Max                     1.05065e+06
V Predictions Min                 -2849.02
R Predictions Mean                 1441.99
R Predictions Std                  3269.64
R Predictions Max                 16360.8
R Predictions Min                  -241.615
Log Pis Mean                         25.6242
Log Pis Std                          14.9885
Log Pis Max                          57.7944
Log Pis Min                          -2.53787
Policy mu Mean                       -5.27433
Policy mu Std                        32.5274
Policy mu Max                       145.12
Policy mu Min                      -187.429
Policy log std Mean                  -0.593396
Policy log std Std                    1.51894
Policy log std Max                    2
Policy log std Min                   -7.43481
_task0 Rewards Mean                 184.124
_task0 Rewards Std                  422.099
_task0 Rewards Max                 2190.36
_task0 Rewards Min                   -0.928532
_task0 Returns Mean               27618.7
_task0 Returns Std                59039.8
_task0 Returns Max               208142
_task0 Returns Min                 -107.65
_task0 Actions Mean                  -0.0221535
_task0 Actions Std                    0.822412
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1159.63
Exploration_task0 Rewards Std      2987.09
Exploration_task0 Rewards Max     23089.3
Exploration_task0 Rewards Min       -11.2144
Exploration_task0 Returns Mean   175702
Exploration_task0 Returns Std    415993
Exploration_task0 Returns Max         2.3918e+06
Exploration_task0 Returns Min     -1287.73
Exploration_task0 Actions Mean       -0.00618354
Exploration_task0 Actions Std         0.888088
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27618.7
AverageReturn_all_train_tasks     11584.4
AverageReturn_all_test_tasks      27618.7
Number of train steps total      304000
Number of env steps total             1.5201e+07
Number of rollouts total         110358
Train Time (s)                       99.7281
(Previous) Eval Time (s)             25.5731
Sample Time (s)                     107.64
Epoch Time (s)                      232.941
Total Train Time (s)              70623.8
Epoch                               303
------------------------------  -----------------
2019-06-27 20:09:56.673515 UTC | [dialturn] Iteration #303 | Epoch Duration: 233.1734037399292
2019-06-27 20:09:56.673716 UTC | [dialturn] Iteration #303 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000759721
Z variance train                      0.999914
KL Divergence                         0.000115721
KL Loss                               1.15721e-05
QF Loss                               1.489e+09
VF Loss                               2.5473e+07
RF Loss                           24267.5
Policy Loss                     -251971
Q Predictions Mean               249228
Q Predictions Std                347089
Q Predictions Max                     1.04862e+06
Q Predictions Min                   615.892
V Predictions Mean               254556
V Predictions Std                353898
V Predictions Max                     1.05899e+06
V Predictions Min                   173.764
R Predictions Mean                  578.331
R Predictions Std                  1650.76
R Predictions Max                 12051.3
R Predictions Min                   -82.4851
Log Pis Mean                         25.7536
Log Pis Std                          15.3109
Log Pis Max                          57.4711
Log Pis Min                          -2.9177
Policy mu Mean                       -5.53056
Policy mu Std                        34.2056
Policy mu Max                       143.147
Policy mu Min                      -205.592
Policy log std Mean                  -0.577792
Policy log std Std                    1.57553
Policy log std Max                    2
Policy log std Min                   -7.62482
_task0 Rewards Mean                 214.527
_task0 Rewards Std                  547.567
_task0 Rewards Max                 2303.43
_task0 Rewards Min                   -0.902295
_task0 Returns Mean               32179.1
_task0 Returns Std                78052.9
_task0 Returns Max               236310
_task0 Returns Min                  -98.2266
_task0 Actions Mean                  -0.0342759
_task0 Actions Std                    0.862724
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1327.09
Exploration_task0 Rewards Std      3173.08
Exploration_task0 Rewards Max     21546.8
Exploration_task0 Rewards Min       -12.1162
Exploration_task0 Returns Mean   201074
Exploration_task0 Returns Std    443444
Exploration_task0 Returns Max         2.28311e+06
Exploration_task0 Returns Min     -1366.63
Exploration_task0 Actions Mean        0.0142138
Exploration_task0 Actions Std         0.891376
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              32179.1
AverageReturn_all_train_tasks     26477.1
AverageReturn_all_test_tasks      32179.1
Number of train steps total      305000
Number of env steps total             1.5251e+07
Number of rollouts total         110721
Train Time (s)                       99.7423
(Previous) Eval Time (s)             25.8038
Sample Time (s)                     107.42
Epoch Time (s)                      232.966
Total Train Time (s)              70856.8
Epoch                               304
------------------------------  -----------------
2019-06-27 20:13:49.648552 UTC | [dialturn] Iteration #304 | Epoch Duration: 232.9746754169464
2019-06-27 20:13:49.648755 UTC | [dialturn] Iteration #304 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00090068
Z variance train                      0.999979
KL Divergence                         7.44755e-05
KL Loss                               7.44755e-06
QF Loss                               2.89297e+09
VF Loss                               4.74135e+06
RF Loss                          192849
Policy Loss                     -249944
Q Predictions Mean               247024
Q Predictions Std                345358
Q Predictions Max                     1.0554e+06
Q Predictions Min                 -6321.56
V Predictions Mean               249303
V Predictions Std                348237
V Predictions Max                     1.05061e+06
V Predictions Min                 -6712.81
R Predictions Mean                 1450.98
R Predictions Std                  3695.97
R Predictions Max                 20390.1
R Predictions Min                   -99.6753
Log Pis Mean                         25.8676
Log Pis Std                          15.2492
Log Pis Max                          60.195
Log Pis Min                          -4.29872
Policy mu Mean                       -5.18051
Policy mu Std                        33.542
Policy mu Max                       168.397
Policy mu Min                      -203.235
Policy log std Mean                  -0.547958
Policy log std Std                    1.54939
Policy log std Max                    2
Policy log std Min                   -6.48994
_task0 Rewards Mean                 155.521
_task0 Rewards Std                  413.003
_task0 Rewards Max                 2086.82
_task0 Rewards Min                   -0.899286
_task0 Returns Mean               23328.2
_task0 Returns Std                58654.8
_task0 Returns Max               226529
_task0 Returns Min                 -113.782
_task0 Actions Mean                  -0.00394651
_task0 Actions Std                    0.847463
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1576.94
Exploration_task0 Rewards Std      3852.34
Exploration_task0 Rewards Max     23118.8
Exploration_task0 Rewards Min       -10.6409
Exploration_task0 Returns Mean   238930
Exploration_task0 Returns Std    543436
Exploration_task0 Returns Max         2.5339e+06
Exploration_task0 Returns Min     -1490.58
Exploration_task0 Actions Mean        0.0249874
Exploration_task0 Actions Std         0.881262
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              23328.2
AverageReturn_all_train_tasks       194.975
AverageReturn_all_test_tasks      23328.2
Number of train steps total      306000
Number of env steps total             1.5301e+07
Number of rollouts total         111084
Train Time (s)                      100.311
(Previous) Eval Time (s)             25.8114
Sample Time (s)                     107.875
Epoch Time (s)                      233.997
Total Train Time (s)              71090.7
Epoch                               305
------------------------------  -----------------
2019-06-27 20:17:43.542681 UTC | [dialturn] Iteration #305 | Epoch Duration: 233.8937633037567
2019-06-27 20:17:43.542889 UTC | [dialturn] Iteration #305 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000512068
Z variance train                      0.999996
KL Divergence                         5.7464e-05
KL Loss                               5.7464e-06
QF Loss                               3.26045e+09
VF Loss                               3.51086e+07
RF Loss                          124360
Policy Loss                     -249534
Q Predictions Mean               246554
Q Predictions Std                346874
Q Predictions Max                     1.05373e+06
Q Predictions Min                    43.0673
V Predictions Mean               249965
V Predictions Std                351249
V Predictions Max                     1.05957e+06
V Predictions Min                 -1352.84
R Predictions Mean                  997.19
R Predictions Std                  2665.82
R Predictions Max                 17079.6
R Predictions Min                   -70.8156
Log Pis Mean                         25.7742
Log Pis Std                          15.125
Log Pis Max                          60.0724
Log Pis Min                          -4.84208
Policy mu Mean                       -5.56293
Policy mu Std                        31.9152
Policy mu Max                       153.447
Policy mu Min                      -197.965
Policy log std Mean                  -0.619197
Policy log std Std                    1.54781
Policy log std Max                    2
Policy log std Min                   -7.54087
_task0 Rewards Mean                  47.7115
_task0 Rewards Std                  121.666
_task0 Rewards Max                  651.782
_task0 Rewards Min                   -0.938175
_task0 Returns Mean                7156.72
_task0 Returns Std                17110.1
_task0 Returns Max                72171.9
_task0 Returns Min                 -123.324
_task0 Actions Mean                  -0.0408759
_task0 Actions Std                    0.895558
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      789.787
Exploration_task0 Rewards Std      2474.48
Exploration_task0 Rewards Max     22485.8
Exploration_task0 Rewards Min        -9.3808
Exploration_task0 Returns Mean   119665
Exploration_task0 Returns Std    337018
Exploration_task0 Returns Max         2.14576e+06
Exploration_task0 Returns Min     -1214.7
Exploration_task0 Actions Mean       -0.0454327
Exploration_task0 Actions Std         0.885264
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               7156.72
AverageReturn_all_train_tasks     10959.1
AverageReturn_all_test_tasks       7156.72
Number of train steps total      307000
Number of env steps total             1.5351e+07
Number of rollouts total         111447
Train Time (s)                      100.612
(Previous) Eval Time (s)             25.7067
Sample Time (s)                     107.749
Epoch Time (s)                      234.067
Total Train Time (s)              71324.8
Epoch                               306
------------------------------  -----------------
2019-06-27 20:21:37.631911 UTC | [dialturn] Iteration #306 | Epoch Duration: 234.0888650417328
2019-06-27 20:21:37.632136 UTC | [dialturn] Iteration #306 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000782985
Z variance train                      0.999961
KL Divergence                         0.000137334
KL Loss                               1.37334e-05
QF Loss                               1.6861e+09
VF Loss                               1.19995e+07
RF Loss                          102109
Policy Loss                     -251243
Q Predictions Mean               247921
Q Predictions Std                350306
Q Predictions Max                     1.05801e+06
Q Predictions Min                 -5803.19
V Predictions Mean               249954
V Predictions Std                352678
V Predictions Max                     1.0535e+06
V Predictions Min                 -5402.74
R Predictions Mean                  920.534
R Predictions Std                  2777.97
R Predictions Max                 16546.3
R Predictions Min                   -62.9404
Log Pis Mean                         25.5762
Log Pis Std                          14.8749
Log Pis Max                          58.5092
Log Pis Min                          -2.45894
Policy mu Mean                       -5.17586
Policy mu Std                        32.2921
Policy mu Max                       163.481
Policy mu Min                      -183.954
Policy log std Mean                  -0.618943
Policy log std Std                    1.53706
Policy log std Max                    2
Policy log std Min                   -6.79467
_task0 Rewards Mean                 100.778
_task0 Rewards Std                  252.203
_task0 Rewards Max                 1082.86
_task0 Rewards Min                   -0.907963
_task0 Returns Mean               15116.6
_task0 Returns Std                36604.9
_task0 Returns Max               127024
_task0 Returns Min                 -117.083
_task0 Actions Mean                  -0.0230041
_task0 Actions Std                    0.873305
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1175.42
Exploration_task0 Rewards Std      2828.84
Exploration_task0 Rewards Max     22730.5
Exploration_task0 Rewards Min        -9.65207
Exploration_task0 Returns Mean   178094
Exploration_task0 Returns Std    395835
Exploration_task0 Returns Max         2.59464e+06
Exploration_task0 Returns Min     -1225.36
Exploration_task0 Actions Mean       -0.0311024
Exploration_task0 Actions Std         0.870752
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              15116.6
AverageReturn_all_train_tasks     26208
AverageReturn_all_test_tasks      15116.6
Number of train steps total      308000
Number of env steps total             1.5401e+07
Number of rollouts total         111810
Train Time (s)                      100.665
(Previous) Eval Time (s)             25.7268
Sample Time (s)                     107.292
Epoch Time (s)                      233.684
Total Train Time (s)              71558.5
Epoch                               307
------------------------------  -----------------
2019-06-27 20:25:31.408337 UTC | [dialturn] Iteration #307 | Epoch Duration: 233.77601957321167
2019-06-27 20:25:31.408537 UTC | [dialturn] Iteration #307 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000402665
Z variance train                      1.00002
KL Divergence                         2.34706e-05
KL Loss                               2.34706e-06
QF Loss                               1.02751e+09
VF Loss                               9.40183e+06
RF Loss                           81266.4
Policy Loss                     -248088
Q Predictions Mean               245147
Q Predictions Std                349161
Q Predictions Max                     1.06132e+06
Q Predictions Min                 -3149.89
V Predictions Mean               249537
V Predictions Std                354334
V Predictions Max                     1.06486e+06
V Predictions Min                 -3931.15
R Predictions Mean                 1128.42
R Predictions Std                  3173.56
R Predictions Max                 17107.5
R Predictions Min                  -368.893
Log Pis Mean                         25.3734
Log Pis Std                          15.337
Log Pis Max                          59.5647
Log Pis Min                          -5.4872
Policy mu Mean                       -5.8557
Policy mu Std                        34.0404
Policy mu Max                       211.413
Policy mu Min                      -200.142
Policy log std Mean                  -0.645844
Policy log std Std                    1.57136
Policy log std Max                    2
Policy log std Min                   -6.87993
_task0 Rewards Mean                  98.4072
_task0 Rewards Std                  203.14
_task0 Rewards Max                  702.051
_task0 Rewards Min                   -0.936518
_task0 Returns Mean               14761.1
_task0 Returns Std                29376.9
_task0 Returns Max                75924.1
_task0 Returns Min                 -115.895
_task0 Actions Mean                  -0.0137835
_task0 Actions Std                    0.902633
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1552.76
Exploration_task0 Rewards Std      3557.73
Exploration_task0 Rewards Max     21888.6
Exploration_task0 Rewards Min        -9.43315
Exploration_task0 Returns Mean   235266
Exploration_task0 Returns Std    500243
Exploration_task0 Returns Max         2.33595e+06
Exploration_task0 Returns Min     -1369.03
Exploration_task0 Actions Mean        0.00682258
Exploration_task0 Actions Std         0.859566
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14761.1
AverageReturn_all_train_tasks     16229.7
AverageReturn_all_test_tasks      14761.1
Number of train steps total      309000
Number of env steps total             1.5451e+07
Number of rollouts total         112173
Train Time (s)                       99.6192
(Previous) Eval Time (s)             25.8178
Sample Time (s)                     107.647
Epoch Time (s)                      233.084
Total Train Time (s)              71791.5
Epoch                               308
------------------------------  -----------------
2019-06-27 20:29:24.367470 UTC | [dialturn] Iteration #308 | Epoch Duration: 232.95871019363403
2019-06-27 20:29:24.367663 UTC | [dialturn] Iteration #308 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000202666
Z variance train                      1.00012
KL Divergence                         5.90868e-06
KL Loss                               5.90868e-07
QF Loss                               2.09159e+09
VF Loss                               5.78259e+06
RF Loss                          133944
Policy Loss                     -248477
Q Predictions Mean               244797
Q Predictions Std                346709
Q Predictions Max                     1.05519e+06
Q Predictions Min                 -9180.14
V Predictions Mean               247866
V Predictions Std                350665
V Predictions Max                     1.05911e+06
V Predictions Min                -11098.6
R Predictions Mean                 1623.48
R Predictions Std                  3990.12
R Predictions Max                 19266.7
R Predictions Min                  -125.692
Log Pis Mean                         26.0415
Log Pis Std                          15.1935
Log Pis Max                          58.9376
Log Pis Min                          -4.82288
Policy mu Mean                       -5.98606
Policy mu Std                        35.3141
Policy mu Max                       168.995
Policy mu Min                      -194.05
Policy log std Mean                  -0.616667
Policy log std Std                    1.60466
Policy log std Max                    2
Policy log std Min                   -8.38472
_task0 Rewards Mean                  56.1641
_task0 Rewards Std                  164.002
_task0 Rewards Max                  748.363
_task0 Rewards Min                   -0.940087
_task0 Returns Mean                8424.62
_task0 Returns Std                23894.3
_task0 Returns Max                96178.2
_task0 Returns Min                 -114.043
_task0 Actions Mean                  -0.0454824
_task0 Actions Std                    0.871213
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1438.7
Exploration_task0 Rewards Std      3692.21
Exploration_task0 Rewards Max     22179.2
Exploration_task0 Rewards Min        -9.70258
Exploration_task0 Returns Mean   217985
Exploration_task0 Returns Std    517517
Exploration_task0 Returns Max         2.28449e+06
Exploration_task0 Returns Min     -1378.72
Exploration_task0 Actions Mean        0.0329648
Exploration_task0 Actions Std         0.869565
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               8424.62
AverageReturn_all_train_tasks       315.751
AverageReturn_all_test_tasks       8424.62
Number of train steps total      310000
Number of env steps total             1.5501e+07
Number of rollouts total         112536
Train Time (s)                      100.32
(Previous) Eval Time (s)             25.6908
Sample Time (s)                     107.802
Epoch Time (s)                      233.813
Total Train Time (s)              72025.3
Epoch                               309
------------------------------  -----------------
2019-06-27 20:33:18.161019 UTC | [dialturn] Iteration #309 | Epoch Duration: 233.79319405555725
2019-06-27 20:33:18.161222 UTC | [dialturn] Iteration #309 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000215258
Z variance train                      0.999738
KL Divergence                         9.36745e-06
KL Loss                               9.36745e-07
QF Loss                               3.49755e+09
VF Loss                               1.22597e+07
RF Loss                          115362
Policy Loss                     -257214
Q Predictions Mean               253730
Q Predictions Std                354058
Q Predictions Max                     1.062e+06
Q Predictions Min                    89.3692
V Predictions Mean               255453
V Predictions Std                356152
V Predictions Max                     1.05446e+06
V Predictions Min                   162.236
R Predictions Mean                  749.068
R Predictions Std                  2740.72
R Predictions Max                 19225.7
R Predictions Min                  -776.825
Log Pis Mean                         25.1272
Log Pis Std                          15.2013
Log Pis Max                          64.347
Log Pis Min                          -6.36773
Policy mu Mean                       -4.9926
Policy mu Std                        32.2742
Policy mu Max                       206.097
Policy mu Min                      -182.328
Policy log std Mean                  -0.602698
Policy log std Std                    1.56751
Policy log std Max                    2
Policy log std Min                   -7.3064
_task0 Rewards Mean                 180.8
_task0 Rewards Std                  387.028
_task0 Rewards Max                 1524.94
_task0 Rewards Min                   -0.929345
_task0 Returns Mean               27120
_task0 Returns Std                55599.5
_task0 Returns Max               165118
_task0 Returns Min                 -119.809
_task0 Actions Mean                  -0.0614515
_task0 Actions Std                    0.840783
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2178.04
Exploration_task0 Rewards Std      4895.73
Exploration_task0 Rewards Max     22994.4
Exploration_task0 Rewards Min        -9.6297
Exploration_task0 Returns Mean   330007
Exploration_task0 Returns Std    689103
Exploration_task0 Returns Max         2.693e+06
Exploration_task0 Returns Min     -1206.6
Exploration_task0 Actions Mean       -0.00538124
Exploration_task0 Actions Std         0.855276
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              27120
AverageReturn_all_train_tasks       925.762
AverageReturn_all_test_tasks      27120
Number of train steps total      311000
Number of env steps total             1.5551e+07
Number of rollouts total         112899
Train Time (s)                      100.844
(Previous) Eval Time (s)             25.6692
Sample Time (s)                     107.333
Epoch Time (s)                      233.846
Total Train Time (s)              72259.5
Epoch                               310
------------------------------  -----------------
2019-06-27 20:37:12.360928 UTC | [dialturn] Iteration #310 | Epoch Duration: 234.19954419136047
2019-06-27 20:37:12.361125 UTC | [dialturn] Iteration #310 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00012012
Z variance train                      1.00016
KL Divergence                         2.66384e-06
KL Loss                               2.66384e-07
QF Loss                               3.49736e+09
VF Loss                               1.78062e+07
RF Loss                          169923
Policy Loss                     -252530
Q Predictions Mean               249974
Q Predictions Std                351399
Q Predictions Max                     1.05498e+06
Q Predictions Min                   246.173
V Predictions Mean               250291
V Predictions Std                351953
V Predictions Max                     1.05099e+06
V Predictions Min                   118.511
R Predictions Mean                 1564.17
R Predictions Std                  3128.38
R Predictions Max                 21179.6
R Predictions Min                  -627.091
Log Pis Mean                         24.5779
Log Pis Std                          14.9542
Log Pis Max                          57.1126
Log Pis Min                          -2.07686
Policy mu Mean                       -6.19969
Policy mu Std                        33.9544
Policy mu Max                       205.019
Policy mu Min                      -197.204
Policy log std Mean                  -0.500492
Policy log std Std                    1.56607
Policy log std Max                    2
Policy log std Min                   -7.21916
_task0 Rewards Mean                  30.4921
_task0 Rewards Std                   97.8463
_task0 Rewards Max                 1022.01
_task0 Rewards Min                   -0.851393
_task0 Returns Mean                4573.81
_task0 Returns Std                12252.7
_task0 Returns Max                52340.5
_task0 Returns Min                 -110.775
_task0 Actions Mean                  -0.0779388
_task0 Actions Std                    0.854324
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1524.29
Exploration_task0 Rewards Std      4024.49
Exploration_task0 Rewards Max     22511
Exploration_task0 Rewards Min        -9.88272
Exploration_task0 Returns Mean   230952
Exploration_task0 Returns Std    567217
Exploration_task0 Returns Max         2.65364e+06
Exploration_task0 Returns Min     -1454.52
Exploration_task0 Actions Mean        0.0523497
Exploration_task0 Actions Std         0.868026
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               4573.81
AverageReturn_all_train_tasks     28475.4
AverageReturn_all_test_tasks       4573.81
Number of train steps total      312000
Number of env steps total             1.5601e+07
Number of rollouts total         113262
Train Time (s)                      101.282
(Previous) Eval Time (s)             26.0211
Sample Time (s)                     107.798
Epoch Time (s)                      235.101
Total Train Time (s)              72494.4
Epoch                               311
------------------------------  -----------------
2019-06-27 20:41:07.260805 UTC | [dialturn] Iteration #311 | Epoch Duration: 234.89952063560486
2019-06-27 20:41:07.261032 UTC | [dialturn] Iteration #311 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00126771
Z variance train                      0.999952
KL Divergence                         0.000204498
KL Loss                               2.04498e-05
QF Loss                               2.01226e+09
VF Loss                               1.3341e+07
RF Loss                          150287
Policy Loss                     -245451
Q Predictions Mean               242996
Q Predictions Std                350037
Q Predictions Max                     1.06467e+06
Q Predictions Min                 -9239.7
V Predictions Mean               244245
V Predictions Std                350966
V Predictions Max                     1.05382e+06
V Predictions Min                 -8468.22
R Predictions Mean                 1597.29
R Predictions Std                  3676.71
R Predictions Max                 20563
R Predictions Min                  -125.1
Log Pis Mean                         24.0433
Log Pis Std                          15.2521
Log Pis Max                          59.8259
Log Pis Min                          -3.16689
Policy mu Mean                       -5.01253
Policy mu Std                        32.9845
Policy mu Max                       226.137
Policy mu Min                      -220.499
Policy log std Mean                  -0.632399
Policy log std Std                    1.55948
Policy log std Max                    2
Policy log std Min                  -13.7303
_task0 Rewards Mean                 212.516
_task0 Rewards Std                  468.693
_task0 Rewards Max                 2271.27
_task0 Rewards Min                   -0.926686
_task0 Returns Mean               31877.4
_task0 Returns Std                66373.9
_task0 Returns Max               253722
_task0 Returns Min                 -117.395
_task0 Actions Mean                  -0.043751
_task0 Actions Std                    0.861332
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      974.542
Exploration_task0 Rewards Std      2854.77
Exploration_task0 Rewards Max     23086.5
Exploration_task0 Rewards Min        -9.81862
Exploration_task0 Returns Mean   147658
Exploration_task0 Returns Std    383041
Exploration_task0 Returns Max         2.75187e+06
Exploration_task0 Returns Min     -1236.12
Exploration_task0 Actions Mean       -0.0267708
Exploration_task0 Actions Std         0.873633
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              31877.4
AverageReturn_all_train_tasks     12901.6
AverageReturn_all_test_tasks      31877.4
Number of train steps total      313000
Number of env steps total             1.5651e+07
Number of rollouts total         113625
Train Time (s)                      100.655
(Previous) Eval Time (s)             25.8183
Sample Time (s)                     108.203
Epoch Time (s)                      234.676
Total Train Time (s)              72729
Epoch                               312
------------------------------  -----------------
2019-06-27 20:45:01.889334 UTC | [dialturn] Iteration #312 | Epoch Duration: 234.62815046310425
2019-06-27 20:45:01.889559 UTC | [dialturn] Iteration #312 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000228322
Z variance train                      0.999643
KL Divergence                         9.30509e-06
KL Loss                               9.30509e-07
QF Loss                               3.06409e+09
VF Loss                               2.88158e+07
RF Loss                          264640
Policy Loss                     -251198
Q Predictions Mean               247907
Q Predictions Std                351753
Q Predictions Max                     1.06389e+06
Q Predictions Min                   942.501
V Predictions Mean               253574
V Predictions Std                358565
V Predictions Max                     1.07143e+06
V Predictions Min                   823.299
R Predictions Mean                 1637.58
R Predictions Std                  3953.8
R Predictions Max                 20836.4
R Predictions Min                  -183.07
Log Pis Mean                         25.0329
Log Pis Std                          14.8493
Log Pis Max                          57.5687
Log Pis Min                          -4.51883
Policy mu Mean                       -6.09572
Policy mu Std                        34.0997
Policy mu Max                       202.44
Policy mu Min                      -221.489
Policy log std Mean                  -0.588889
Policy log std Std                    1.57238
Policy log std Max                    2
Policy log std Min                   -8.06173
_task0 Rewards Mean                  89.8516
_task0 Rewards Std                  193.501
_task0 Rewards Max                 1682.1
_task0 Rewards Min                   -0.899789
_task0 Returns Mean               13477.7
_task0 Returns Std                23009.9
_task0 Returns Max                79702.3
_task0 Returns Min                 -112.909
_task0 Actions Mean                  -0.00519578
_task0 Actions Std                    0.846175
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1260.47
Exploration_task0 Rewards Std      3132.4
Exploration_task0 Rewards Max     22741.5
Exploration_task0 Rewards Min       -11.9448
Exploration_task0 Returns Mean   190981
Exploration_task0 Returns Std    440264
Exploration_task0 Returns Max         2.68083e+06
Exploration_task0 Returns Min     -1176.17
Exploration_task0 Actions Mean        0.0354453
Exploration_task0 Actions Std         0.872209
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              13477.7
AverageReturn_all_train_tasks     11932.1
AverageReturn_all_test_tasks      13477.7
Number of train steps total      314000
Number of env steps total             1.5701e+07
Number of rollouts total         113988
Train Time (s)                      100.399
(Previous) Eval Time (s)             25.7686
Sample Time (s)                     107.471
Epoch Time (s)                      233.638
Total Train Time (s)              72962.6
Epoch                               313
------------------------------  -----------------
2019-06-27 20:48:55.502869 UTC | [dialturn] Iteration #313 | Epoch Duration: 233.613126039505
2019-06-27 20:48:55.503053 UTC | [dialturn] Iteration #313 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000916251
Z variance train                      1.00014
KL Divergence                         0.000126788
KL Loss                               1.26788e-05
QF Loss                               3.18776e+09
VF Loss                               1.65962e+07
RF Loss                           98871.1
Policy Loss                     -249446
Q Predictions Mean               246414
Q Predictions Std                353736
Q Predictions Max                     1.05283e+06
Q Predictions Min                   652.837
V Predictions Mean               251405
V Predictions Std                359994
V Predictions Max                     1.06493e+06
V Predictions Min                   765.673
R Predictions Mean                 1403.8
R Predictions Std                  3560.48
R Predictions Max                 21135.7
R Predictions Min                   -27.6306
Log Pis Mean                         25.2385
Log Pis Std                          14.9277
Log Pis Max                          56.8574
Log Pis Min                          -3.66553
Policy mu Mean                       -4.83037
Policy mu Std                        35.7782
Policy mu Max                       213.776
Policy mu Min                      -240.594
Policy log std Mean                  -0.630192
Policy log std Std                    1.64238
Policy log std Max                    2
Policy log std Min                   -8.06601
_task0 Rewards Mean                 175.886
_task0 Rewards Std                  364.53
_task0 Rewards Max                 1898.66
_task0 Rewards Min                   -0.9147
_task0 Returns Mean               26382.8
_task0 Returns Std                51489.4
_task0 Returns Max               191230
_task0 Returns Min                 -116.272
_task0 Actions Mean                   0.00105346
_task0 Actions Std                    0.82198
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2080.82
Exploration_task0 Rewards Std      4268.35
Exploration_task0 Rewards Max     22856.6
Exploration_task0 Rewards Min       -10.2061
Exploration_task0 Returns Mean   315276
Exploration_task0 Returns Std    600497
Exploration_task0 Returns Max         2.73489e+06
Exploration_task0 Returns Min     -1227.73
Exploration_task0 Actions Mean        0.0475397
Exploration_task0 Actions Std         0.85363
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26382.8
AverageReturn_all_train_tasks     32467.3
AverageReturn_all_test_tasks      26382.8
Number of train steps total      315000
Number of env steps total             1.5751e+07
Number of rollouts total         114351
Train Time (s)                      100.07
(Previous) Eval Time (s)             25.7423
Sample Time (s)                     107.258
Epoch Time (s)                      233.07
Total Train Time (s)              73195.7
Epoch                               314
------------------------------  -----------------
2019-06-27 20:52:48.651851 UTC | [dialturn] Iteration #314 | Epoch Duration: 233.14861345291138
2019-06-27 20:52:48.652114 UTC | [dialturn] Iteration #314 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000215951
Z variance train                      0.997247
KL Divergence                         0.000262115
KL Loss                               2.62115e-05
QF Loss                               1.63878e+09
VF Loss                               1.59322e+07
RF Loss                           94276.9
Policy Loss                     -252580
Q Predictions Mean               249286
Q Predictions Std                356336
Q Predictions Max                     1.06972e+06
Q Predictions Min                 -5730.04
V Predictions Mean               254532
V Predictions Std                362606
V Predictions Max                     1.07277e+06
V Predictions Min                 -5598.6
R Predictions Mean                 1341.45
R Predictions Std                  3029.25
R Predictions Max                 17410.3
R Predictions Min                  -170.069
Log Pis Mean                         25.009
Log Pis Std                          14.2491
Log Pis Max                          60.0301
Log Pis Min                          -6.24453
Policy mu Mean                       -5.7505
Policy mu Std                        35.8903
Policy mu Max                       352.655
Policy mu Min                      -246.002
Policy log std Mean                  -0.613281
Policy log std Std                    1.64432
Policy log std Max                    2
Policy log std Min                  -18.0439
_task0 Rewards Mean                 135.901
_task0 Rewards Std                  238.057
_task0 Rewards Max                  990.608
_task0 Rewards Min                   -0.911107
_task0 Returns Mean               20385.1
_task0 Returns Std                34481.2
_task0 Returns Max               101582
_task0 Returns Min                 -118.115
_task0 Actions Mean                  -0.13791
_task0 Actions Std                    0.874947
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1088.5
Exploration_task0 Rewards Std      2434.89
Exploration_task0 Rewards Max     22367
Exploration_task0 Rewards Min        -9.63791
Exploration_task0 Returns Mean   164924
Exploration_task0 Returns Std    334268
Exploration_task0 Returns Max         2.00917e+06
Exploration_task0 Returns Min     -1584.81
Exploration_task0 Actions Mean        0.027842
Exploration_task0 Actions Std         0.874933
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              20385.1
AverageReturn_all_train_tasks      4408.42
AverageReturn_all_test_tasks      20385.1
Number of train steps total      316000
Number of env steps total             1.5801e+07
Number of rollouts total         114714
Train Time (s)                      101.001
(Previous) Eval Time (s)             25.8193
Sample Time (s)                     107.122
Epoch Time (s)                      233.942
Total Train Time (s)              73429.7
Epoch                               315
------------------------------  -----------------
2019-06-27 20:56:42.559256 UTC | [dialturn] Iteration #315 | Epoch Duration: 233.90694546699524
2019-06-27 20:56:42.559482 UTC | [dialturn] Iteration #315 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000119154
Z variance train                      0.999933
KL Divergence                         2.88943e-06
KL Loss                               2.88943e-07
QF Loss                               1.84611e+09
VF Loss                               2.16161e+07
RF Loss                          157197
Policy Loss                     -253541
Q Predictions Mean               250225
Q Predictions Std                354746
Q Predictions Max                     1.07227e+06
Q Predictions Min                 -7532.31
V Predictions Mean               251176
V Predictions Std                355589
V Predictions Max                     1.06804e+06
V Predictions Min                 -6856.27
R Predictions Mean                 2023.95
R Predictions Std                  3856.78
R Predictions Max                 21694.8
R Predictions Min                   -73.9654
Log Pis Mean                         25.2416
Log Pis Std                          14.8394
Log Pis Max                          56.1174
Log Pis Min                          -3.37903
Policy mu Mean                       -5.42219
Policy mu Std                        37.5428
Policy mu Max                       266.028
Policy mu Min                      -255.432
Policy log std Mean                  -0.599751
Policy log std Std                    1.64854
Policy log std Max                    2
Policy log std Min                  -10.5283
_task0 Rewards Mean                 221.18
_task0 Rewards Std                  499.694
_task0 Rewards Max                 2273.66
_task0 Rewards Min                   -0.929499
_task0 Returns Mean               33177
_task0 Returns Std                70641.8
_task0 Returns Max               249216
_task0 Returns Min                 -122.231
_task0 Actions Mean                  -0.0266005
_task0 Actions Std                    0.854686
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1326.8
Exploration_task0 Rewards Std      2898.51
Exploration_task0 Rewards Max     23149.3
Exploration_task0 Rewards Min        -9.50938
Exploration_task0 Returns Mean   201030
Exploration_task0 Returns Std    393581
Exploration_task0 Returns Max         2.24065e+06
Exploration_task0 Returns Min     -1180.33
Exploration_task0 Actions Mean        0.0369987
Exploration_task0 Actions Std         0.87746
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              33177
AverageReturn_all_train_tasks     32281.8
AverageReturn_all_test_tasks      33177
Number of train steps total      317000
Number of env steps total             1.5851e+07
Number of rollouts total         115077
Train Time (s)                      100.428
(Previous) Eval Time (s)             25.7825
Sample Time (s)                     107.672
Epoch Time (s)                      233.882
Total Train Time (s)              73663.5
Epoch                               316
------------------------------  -----------------
2019-06-27 21:00:36.377456 UTC | [dialturn] Iteration #316 | Epoch Duration: 233.8177888393402
2019-06-27 21:00:36.377693 UTC | [dialturn] Iteration #316 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000629314
Z variance train                      0.999967
KL Divergence                         6.34586e-05
KL Loss                               6.34586e-06
QF Loss                               1.6451e+09
VF Loss                               2.07568e+07
RF Loss                           54953.8
Policy Loss                     -262578
Q Predictions Mean               259156
Q Predictions Std                364208
Q Predictions Max                     1.07961e+06
Q Predictions Min                 -2309.89
V Predictions Mean               264968
V Predictions Std                370901
V Predictions Max                     1.08673e+06
V Predictions Min                 -2764.94
R Predictions Mean                 1099.98
R Predictions Std                  2188.95
R Predictions Max                 13000.1
R Predictions Min                   -13.6235
Log Pis Mean                         25.5209
Log Pis Std                          14.2198
Log Pis Max                          56.3152
Log Pis Min                          -5.91719
Policy mu Mean                       -6.21493
Policy mu Std                        37.5317
Policy mu Max                       247.477
Policy mu Min                      -219.86
Policy log std Mean                  -0.489277
Policy log std Std                    1.61307
Policy log std Max                    2
Policy log std Min                   -9.7951
_task0 Rewards Mean                 177.798
_task0 Rewards Std                  334.044
_task0 Rewards Max                 1495.32
_task0 Rewards Min                   -0.915681
_task0 Returns Mean               26669.8
_task0 Returns Std                47295.9
_task0 Returns Max               155010
_task0 Returns Min                 -116.127
_task0 Actions Mean                   0.063954
_task0 Actions Std                    0.821403
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1710.6
Exploration_task0 Rewards Std      3655.35
Exploration_task0 Rewards Max     22578
Exploration_task0 Rewards Min       -10.0379
Exploration_task0 Returns Mean   259182
Exploration_task0 Returns Std    512737
Exploration_task0 Returns Max         2.32048e+06
Exploration_task0 Returns Min     -1757.81
Exploration_task0 Actions Mean        0.00406436
Exploration_task0 Actions Std         0.8859
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              26669.8
AverageReturn_all_train_tasks     36359.1
AverageReturn_all_test_tasks      26669.8
Number of train steps total      318000
Number of env steps total             1.5901e+07
Number of rollouts total         115440
Train Time (s)                      100.648
(Previous) Eval Time (s)             25.7167
Sample Time (s)                     107.69
Epoch Time (s)                      234.055
Total Train Time (s)              73897.7
Epoch                               317
------------------------------  -----------------
2019-06-27 21:04:30.653914 UTC | [dialturn] Iteration #317 | Epoch Duration: 234.27605962753296
2019-06-27 21:04:30.654111 UTC | [dialturn] Iteration #317 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000844193
Z variance train                      0.999765
KL Divergence                         6.06559e-05
KL Loss                               6.06559e-06
QF Loss                               1.99445e+09
VF Loss                               2.12471e+07
RF Loss                          207722
Policy Loss                     -256443
Q Predictions Mean               253131
Q Predictions Std                363524
Q Predictions Max                     1.07978e+06
Q Predictions Min                 -1994.95
V Predictions Mean               254128
V Predictions Std                364414
V Predictions Max                     1.07551e+06
V Predictions Min                 -2233.13
R Predictions Mean                 1575.74
R Predictions Std                  3589.36
R Predictions Max                 18939.4
R Predictions Min                   -60.3933
Log Pis Mean                         25.9263
Log Pis Std                          14.0601
Log Pis Max                          57.5671
Log Pis Min                          -3.38442
Policy mu Mean                       -7.27055
Policy mu Std                        36.8675
Policy mu Max                       207.462
Policy mu Min                      -243.088
Policy log std Mean                  -0.594066
Policy log std Std                    1.61117
Policy log std Max                    2
Policy log std Min                   -9.83987
_task0 Rewards Mean                  77.1832
_task0 Rewards Std                  182.496
_task0 Rewards Max                 1886.03
_task0 Rewards Min                   -0.885557
_task0 Returns Mean               11577.5
_task0 Returns Std                18533.1
_task0 Returns Max                62627.2
_task0 Returns Min                 -110.147
_task0 Actions Mean                   0.137464
_task0 Actions Std                    0.918498
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     2142.03
Exploration_task0 Rewards Std      4520.27
Exploration_task0 Rewards Max     23192
Exploration_task0 Rewards Min       -10.0392
Exploration_task0 Returns Mean   324550
Exploration_task0 Returns Std    637122
Exploration_task0 Returns Max         2.47342e+06
Exploration_task0 Returns Min     -1569.32
Exploration_task0 Actions Mean        0.0116589
Exploration_task0 Actions Std         0.869799
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              11577.5
AverageReturn_all_train_tasks     25742.5
AverageReturn_all_test_tasks      11577.5
Number of train steps total      319000
Number of env steps total             1.5951e+07
Number of rollouts total         115803
Train Time (s)                      100.104
(Previous) Eval Time (s)             25.9364
Sample Time (s)                     107.776
Epoch Time (s)                      233.816
Total Train Time (s)              74131.4
Epoch                               318
------------------------------  -----------------
2019-06-27 21:08:24.338983 UTC | [dialturn] Iteration #318 | Epoch Duration: 233.68469953536987
2019-06-27 21:08:24.339225 UTC | [dialturn] Iteration #318 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000407804
Z variance train                      1.00018
KL Divergence                         1.80221e-05
KL Loss                               1.80221e-06
QF Loss                               2.98011e+09
VF Loss                               8.46007e+06
RF Loss                          238592
Policy Loss                     -264200
Q Predictions Mean               260782
Q Predictions Std                368125
Q Predictions Max                     1.0968e+06
Q Predictions Min                -16154.5
V Predictions Mean               265259
V Predictions Std                374011
V Predictions Max                     1.09925e+06
V Predictions Min                -16399.7
R Predictions Mean                 1723.07
R Predictions Std                  3896.47
R Predictions Max                 20818.7
R Predictions Min                   -37.8016
Log Pis Mean                         26.1064
Log Pis Std                          14.2768
Log Pis Max                          64.4448
Log Pis Min                          -3.59863
Policy mu Mean                       -4.84184
Policy mu Std                        35.8154
Policy mu Max                       183.328
Policy mu Min                      -210.754
Policy log std Mean                  -0.597742
Policy log std Std                    1.62865
Policy log std Max                    2
Policy log std Min                  -10.5105
_task0 Rewards Mean                 146.96
_task0 Rewards Std                  307.036
_task0 Rewards Max                 1806.72
_task0 Rewards Min                   -0.873926
_task0 Returns Mean               22044
_task0 Returns Std                41827.8
_task0 Returns Max               141055
_task0 Returns Min                 -113.146
_task0 Actions Mean                  -0.0573609
_task0 Actions Std                    0.91479
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1949.1
Exploration_task0 Rewards Std      4213.58
Exploration_task0 Rewards Max     23081.5
Exploration_task0 Rewards Min       -10.7304
Exploration_task0 Returns Mean   295318
Exploration_task0 Returns Std    583900
Exploration_task0 Returns Max         2.41919e+06
Exploration_task0 Returns Min     -1389.35
Exploration_task0 Actions Mean        0.0816031
Exploration_task0 Actions Std         0.884608
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              22044
AverageReturn_all_train_tasks     23441.5
AverageReturn_all_test_tasks      22044
Number of train steps total      320000
Number of env steps total             1.6001e+07
Number of rollouts total         116166
Train Time (s)                       99.5768
(Previous) Eval Time (s)             25.8033
Sample Time (s)                     107.826
Epoch Time (s)                      233.206
Total Train Time (s)              74364.7
Epoch                               319
------------------------------  -----------------
2019-06-27 21:12:17.621630 UTC | [dialturn] Iteration #319 | Epoch Duration: 233.28222370147705
2019-06-27 21:12:17.621832 UTC | [dialturn] Iteration #319 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000132341
Z variance train                      1.00005
KL Divergence                         1.7415e-06
KL Loss                               1.7415e-07
QF Loss                               3.61463e+09
VF Loss                               1.14001e+07
RF Loss                          108077
Policy Loss                     -266559
Q Predictions Mean               263253
Q Predictions Std                368296
Q Predictions Max                     1.0976e+06
Q Predictions Min                 -6082.68
V Predictions Mean               266087
V Predictions Std                371256
V Predictions Max                     1.0915e+06
V Predictions Min                 -4947.6
R Predictions Mean                 1547.06
R Predictions Std                  2967.27
R Predictions Max                 21069.2
R Predictions Min                   -23.3323
Log Pis Mean                         25.8106
Log Pis Std                          14.6466
Log Pis Max                          77.2618
Log Pis Min                          -2.48786
Policy mu Mean                       -6.87092
Policy mu Std                        36.4535
Policy mu Max                       176.158
Policy mu Min                      -213.266
Policy log std Mean                  -0.50177
Policy log std Std                    1.61976
Policy log std Max                    2
Policy log std Min                  -12.8776
_task0 Rewards Mean                  31.101
_task0 Rewards Std                   66.4523
_task0 Rewards Max                  503.461
_task0 Rewards Min                   -0.908307
_task0 Returns Mean                4665.14
_task0 Returns Std                 8003.08
_task0 Returns Max                24575.3
_task0 Returns Min                 -109.678
_task0 Actions Mean                   0.0252044
_task0 Actions Std                    0.896966
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean      995.552
Exploration_task0 Rewards Std      2550.73
Exploration_task0 Rewards Max     22311.7
Exploration_task0 Rewards Min       -10.1471
Exploration_task0 Returns Mean   150841
Exploration_task0 Returns Std    355120
Exploration_task0 Returns Max         2.48455e+06
Exploration_task0 Returns Min     -1406.46
Exploration_task0 Actions Mean        0.0264697
Exploration_task0 Actions Std         0.911176
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               4665.14
AverageReturn_all_train_tasks     12112.4
AverageReturn_all_test_tasks       4665.14
Number of train steps total      321000
Number of env steps total             1.6051e+07
Number of rollouts total         116529
Train Time (s)                      101.151
(Previous) Eval Time (s)             25.878
Sample Time (s)                     107.961
Epoch Time (s)                      234.99
Total Train Time (s)              74599.7
Epoch                               320
------------------------------  -----------------
2019-06-27 21:16:12.655448 UTC | [dialturn] Iteration #320 | Epoch Duration: 235.0334587097168
2019-06-27 21:16:12.655654 UTC | [dialturn] Iteration #320 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000660529
Z variance train                      1.00006
KL Divergence                         6.7353e-05
KL Loss                               6.7353e-06
QF Loss                               3.02993e+09
VF Loss                               1.51528e+07
RF Loss                          236659
Policy Loss                     -277730
Q Predictions Mean               274866
Q Predictions Std                379688
Q Predictions Max                     1.10167e+06
Q Predictions Min                -14905.8
V Predictions Mean               279580
V Predictions Std                385033
V Predictions Max                     1.10297e+06
V Predictions Min                -14082.4
R Predictions Mean                 2070.02
R Predictions Std                  4530.54
R Predictions Max                 22637.4
R Predictions Min                   -16.2508
Log Pis Mean                         26.1771
Log Pis Std                          14.1289
Log Pis Max                          63.884
Log Pis Min                          -1.81398
Policy mu Mean                       -5.9462
Policy mu Std                        37.2833
Policy mu Max                       231.693
Policy mu Min                      -216.183
Policy log std Mean                  -0.561673
Policy log std Std                    1.63515
Policy log std Max                    2
Policy log std Min                  -14.9551
_task0 Rewards Mean                  63.1269
_task0 Rewards Std                  117.108
_task0 Rewards Max                  767.6
_task0 Rewards Min                   -0.871592
_task0 Returns Mean                9469.03
_task0 Returns Std                15178.4
_task0 Returns Max                53484.7
_task0 Returns Min                 -107.864
_task0 Actions Mean                   0.153597
_task0 Actions Std                    0.867051
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1912.84
Exploration_task0 Rewards Std      4047.53
Exploration_task0 Rewards Max     22930.9
Exploration_task0 Rewards Min       -11.1106
Exploration_task0 Returns Mean   289824
Exploration_task0 Returns Std    566864
Exploration_task0 Returns Max         2.41567e+06
Exploration_task0 Returns Min     -1515.4
Exploration_task0 Actions Mean       -0.0494345
Exploration_task0 Actions Std         0.880743
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0               9469.03
AverageReturn_all_train_tasks      6569.63
AverageReturn_all_test_tasks       9469.03
Number of train steps total      322000
Number of env steps total             1.6101e+07
Number of rollouts total         116892
Train Time (s)                      100.296
(Previous) Eval Time (s)             25.9202
Sample Time (s)                     107.461
Epoch Time (s)                      233.678
Total Train Time (s)              74833.4
Epoch                               321
------------------------------  -----------------
2019-06-27 21:20:06.347399 UTC | [dialturn] Iteration #321 | Epoch Duration: 233.69157886505127
2019-06-27 21:20:06.347623 UTC | [dialturn] Iteration #321 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000725325
Z variance train                      0.999888
KL Divergence                         0.00013617
KL Loss                               1.3617e-05
QF Loss                               2.43157e+09
VF Loss                               1.08152e+07
RF Loss                           98842.6
Policy Loss                     -282806
Q Predictions Mean               279442
Q Predictions Std                383836
Q Predictions Max                     1.09953e+06
Q Predictions Min                 -9868.03
V Predictions Mean               283352
V Predictions Std                388834
V Predictions Max                     1.10545e+06
V Predictions Min                 -7516.98
R Predictions Mean                 1404.46
R Predictions Std                  3137.24
R Predictions Max                 17278.1
R Predictions Min                   -81.3781
Log Pis Mean                         25.1786
Log Pis Std                          14.5818
Log Pis Max                          73.6127
Log Pis Min                          -5.28018
Policy mu Mean                       -4.79389
Policy mu Std                        33.8758
Policy mu Max                       192.013
Policy mu Min                      -236.321
Policy log std Mean                  -0.644495
Policy log std Std                    1.60828
Policy log std Max                    2
Policy log std Min                  -14.191
_task0 Rewards Mean                  82.3382
_task0 Rewards Std                  202.653
_task0 Rewards Max                 1651.15
_task0 Rewards Min                   -0.916139
_task0 Returns Mean               12350.7
_task0 Returns Std                27794.9
_task0 Returns Max               110400
_task0 Returns Min                 -114.212
_task0 Actions Mean                   0.0160717
_task0 Actions Std                    0.870551
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1315.75
Exploration_task0 Rewards Std      2876.1
Exploration_task0 Rewards Max     22164.5
Exploration_task0 Rewards Min       -10.3556
Exploration_task0 Returns Mean   199356
Exploration_task0 Returns Std    399636
Exploration_task0 Returns Max         2.51609e+06
Exploration_task0 Returns Min     -1574.86
Exploration_task0 Actions Mean        0.0552739
Exploration_task0 Actions Std         0.906062
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              12350.7
AverageReturn_all_train_tasks     13518.5
AverageReturn_all_test_tasks      12350.7
Number of train steps total      323000
Number of env steps total             1.6151e+07
Number of rollouts total         117255
Train Time (s)                      100.509
(Previous) Eval Time (s)             25.9329
Sample Time (s)                     107.356
Epoch Time (s)                      233.798
Total Train Time (s)              75067.2
Epoch                               322
------------------------------  -----------------
2019-06-27 21:24:00.120071 UTC | [dialturn] Iteration #322 | Epoch Duration: 233.772216796875
2019-06-27 21:24:00.120276 UTC | [dialturn] Iteration #322 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000775323
Z variance train                      1.00005
KL Divergence                         6.0136e-05
KL Loss                               6.0136e-06
QF Loss                               1.02489e+09
VF Loss                               3.8783e+06
RF Loss                          188986
Policy Loss                     -278771
Q Predictions Mean               274100
Q Predictions Std                380447
Q Predictions Max                     1.09814e+06
Q Predictions Min                 -2713.67
V Predictions Mean               278965
V Predictions Std                386303
V Predictions Max                     1.10603e+06
V Predictions Min                 -3662.62
R Predictions Mean                 1721.53
R Predictions Std                  3505.72
R Predictions Max                 18530
R Predictions Min                   -96.888
Log Pis Mean                         25.7613
Log Pis Std                          14.2083
Log Pis Max                          65.3575
Log Pis Min                          -3.06182
Policy mu Mean                       -5.97345
Policy mu Std                        35.5411
Policy mu Max                       258.802
Policy mu Min                      -231.04
Policy log std Mean                  -0.540408
Policy log std Std                    1.58576
Policy log std Max                    2
Policy log std Min                  -18.2625
_task0 Rewards Mean                 115.859
_task0 Rewards Std                  236.784
_task0 Rewards Max                 1154.17
_task0 Rewards Min                   -1.03556
_task0 Returns Mean               17378.9
_task0 Returns Std                33666.6
_task0 Returns Max               124512
_task0 Returns Min                 -119.212
_task0 Actions Mean                   0.0830083
_task0 Actions Std                    0.868175
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1329.89
Exploration_task0 Rewards Std      3234.95
Exploration_task0 Rewards Max     22802.5
Exploration_task0 Rewards Min       -12.5283
Exploration_task0 Returns Mean   201499
Exploration_task0 Returns Std    453858
Exploration_task0 Returns Max         2.25531e+06
Exploration_task0 Returns Min     -1664.79
Exploration_task0 Actions Mean        0.0585744
Exploration_task0 Actions Std         0.895582
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              17378.9
AverageReturn_all_train_tasks      2803.52
AverageReturn_all_test_tasks      17378.9
Number of train steps total      324000
Number of env steps total             1.6201e+07
Number of rollouts total         117618
Train Time (s)                      100.841
(Previous) Eval Time (s)             25.9057
Sample Time (s)                     107.947
Epoch Time (s)                      234.694
Total Train Time (s)              75301.7
Epoch                               323
------------------------------  -----------------
2019-06-27 21:27:54.595873 UTC | [dialturn] Iteration #323 | Epoch Duration: 234.47540497779846
2019-06-27 21:27:54.596082 UTC | [dialturn] Iteration #323 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000314323
Z variance train                      1.00019
KL Divergence                         1.91515e-05
KL Loss                               1.91515e-06
QF Loss                               2.47136e+09
VF Loss                               3.90406e+06
RF Loss                          108690
Policy Loss                     -272296
Q Predictions Mean               269337
Q Predictions Std                379023
Q Predictions Max                     1.10557e+06
Q Predictions Min                -13485.8
V Predictions Mean               272499
V Predictions Std                382843
V Predictions Max                     1.10796e+06
V Predictions Min                -13519.2
R Predictions Mean                 1280.01
R Predictions Std                  3361.98
R Predictions Max                 22500.7
R Predictions Min                   -21.3773
Log Pis Mean                         25.8927
Log Pis Std                          14.6786
Log Pis Max                          81.173
Log Pis Min                          -2.59311
Policy mu Mean                       -3.64121
Policy mu Std                        33.4429
Policy mu Max                       185.416
Policy mu Min                      -215.502
Policy log std Mean                  -0.492009
Policy log std Std                    1.57482
Policy log std Max                    2
Policy log std Min                  -15.8818
_task0 Rewards Mean                 157.673
_task0 Rewards Std                  310.786
_task0 Rewards Max                 1194
_task0 Rewards Min                   -0.899238
_task0 Returns Mean               23650.9
_task0 Returns Std                44228.6
_task0 Returns Max               146800
_task0 Returns Min                  -96.3268
_task0 Actions Mean                  -0.0527401
_task0 Actions Std                    0.867196
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1757.91
Exploration_task0 Rewards Std      3613.97
Exploration_task0 Rewards Max     23001.6
Exploration_task0 Rewards Min       -10.3558
Exploration_task0 Returns Mean   266351
Exploration_task0 Returns Std    510473
Exploration_task0 Returns Max         2.557e+06
Exploration_task0 Returns Min     -1394.43
Exploration_task0 Actions Mean        0.0350615
Exploration_task0 Actions Std         0.873924
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              23650.9
AverageReturn_all_train_tasks     11140.6
AverageReturn_all_test_tasks      23650.9
Number of train steps total      325000
Number of env steps total             1.6251e+07
Number of rollouts total         117981
Train Time (s)                       99.3247
(Previous) Eval Time (s)             25.686
Sample Time (s)                     107.765
Epoch Time (s)                      232.776
Total Train Time (s)              75534.5
Epoch                               324
------------------------------  -----------------
2019-06-27 21:31:47.451991 UTC | [dialturn] Iteration #324 | Epoch Duration: 232.85574984550476
2019-06-27 21:31:47.452294 UTC | [dialturn] Iteration #324 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000823504
Z variance train                      1.00029
KL Divergence                         7.63789e-05
KL Loss                               7.63789e-06
QF Loss                               4.39564e+09
VF Loss                               4.46961e+07
RF Loss                          100067
Policy Loss                     -267755
Q Predictions Mean               262962
Q Predictions Std                374535
Q Predictions Max                     1.10265e+06
Q Predictions Min                 -7701.6
V Predictions Mean               263897
V Predictions Std                375334
V Predictions Max                     1.09874e+06
V Predictions Min                 -6954.6
R Predictions Mean                 1530.93
R Predictions Std                  3090.53
R Predictions Max                 20443.8
R Predictions Min                  -211.063
Log Pis Mean                         25.2095
Log Pis Std                          14.5956
Log Pis Max                          58.2456
Log Pis Min                          -4.64301
Policy mu Mean                       -4.55992
Policy mu Std                        32.3163
Policy mu Max                       234.982
Policy mu Min                      -168.162
Policy log std Mean                  -0.477416
Policy log std Std                    1.5516
Policy log std Max                    2
Policy log std Min                  -20
_task0 Rewards Mean                  68.9017
_task0 Rewards Std                  156.653
_task0 Rewards Max                  978.739
_task0 Rewards Min                   -0.969393
_task0 Returns Mean               10335.2
_task0 Returns Std                20855.1
_task0 Returns Max                74439.8
_task0 Returns Min                 -112.617
_task0 Actions Mean                  -0.0262891
_task0 Actions Std                    0.93418
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1904.44
Exploration_task0 Rewards Std      4066.3
Exploration_task0 Rewards Max     23177.4
Exploration_task0 Rewards Min       -11.0336
Exploration_task0 Returns Mean   288551
Exploration_task0 Returns Std    561821
Exploration_task0 Returns Max         2.65696e+06
Exploration_task0 Returns Min     -1313.25
Exploration_task0 Actions Mean        0.0193366
Exploration_task0 Actions Std         0.890036
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              10335.2
AverageReturn_all_train_tasks      6784.56
AverageReturn_all_test_tasks      10335.2
Number of train steps total      326000
Number of env steps total             1.6301e+07
Number of rollouts total         118344
Train Time (s)                       99.6395
(Previous) Eval Time (s)             25.7642
Sample Time (s)                     107.777
Epoch Time (s)                      233.181
Total Train Time (s)              75767.4
Epoch                               325
------------------------------  -----------------
2019-06-27 21:35:40.356679 UTC | [dialturn] Iteration #325 | Epoch Duration: 232.9041666984558
2019-06-27 21:35:40.356908 UTC | [dialturn] Iteration #325 | Started Training: True
------------------------------  -----------------
Z mean train                          0.00088971
Z variance train                      0.999982
KL Divergence                         0.000161473
KL Loss                               1.61473e-05
QF Loss                               2.24475e+09
VF Loss                               2.09193e+07
RF Loss                          124648
Policy Loss                     -281226
Q Predictions Mean               277777
Q Predictions Std                387512
Q Predictions Max                     1.098e+06
Q Predictions Min                 -5285.06
V Predictions Mean               282492
V Predictions Std                393844
V Predictions Max                     1.10695e+06
V Predictions Min                 -4955.67
R Predictions Mean                 1136.28
R Predictions Std                  2586.36
R Predictions Max                 22015.2
R Predictions Min                  -147.314
Log Pis Mean                         25.2401
Log Pis Std                          14.7148
Log Pis Max                          60.4784
Log Pis Min                          -2.24311
Policy mu Mean                       -4.08009
Policy mu Std                        33.5526
Policy mu Max                       201.989
Policy mu Min                      -187.272
Policy log std Mean                  -0.531905
Policy log std Std                    1.56011
Policy log std Max                    2
Policy log std Min                   -9.85858
_task0 Rewards Mean                 168.295
_task0 Rewards Std                  339.601
_task0 Rewards Max                 1835.61
_task0 Rewards Min                   -0.957543
_task0 Returns Mean               25244.2
_task0 Returns Std                45352.1
_task0 Returns Max               153318
_task0 Returns Min                 -118.877
_task0 Actions Mean                   0.0956531
_task0 Actions Std                    0.87025
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1720.56
Exploration_task0 Rewards Std      4218.4
Exploration_task0 Rewards Max     22956.6
Exploration_task0 Rewards Min       -10.9488
Exploration_task0 Returns Mean   260691
Exploration_task0 Returns Std    581934
Exploration_task0 Returns Max         2.63049e+06
Exploration_task0 Returns Min     -1486.5
Exploration_task0 Actions Mean        0.0414356
Exploration_task0 Actions Std         0.914892
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              25244.2
AverageReturn_all_train_tasks     41002.3
AverageReturn_all_test_tasks      25244.2
Number of train steps total      327000
Number of env steps total             1.6351e+07
Number of rollouts total         118707
Train Time (s)                       99.8548
(Previous) Eval Time (s)             25.4861
Sample Time (s)                     107.46
Epoch Time (s)                      232.801
Total Train Time (s)              76000.5
Epoch                               326
------------------------------  -----------------
2019-06-27 21:39:33.443683 UTC | [dialturn] Iteration #326 | Epoch Duration: 233.08661890029907
2019-06-27 21:39:33.443902 UTC | [dialturn] Iteration #326 | Started Training: True
------------------------------  -----------------
Z mean train                          0.000875738
Z variance train                      0.99991
KL Divergence                         0.00011469
KL Loss                               1.1469e-05
QF Loss                               3.15968e+09
VF Loss                               5.61219e+06
RF Loss                          314109
Policy Loss                     -271035
Q Predictions Mean               267856
Q Predictions Std                383489
Q Predictions Max                     1.09766e+06
Q Predictions Min                 -6163.12
V Predictions Mean               271112
V Predictions Std                387455
V Predictions Max                     1.10545e+06
V Predictions Min                 -6914.18
R Predictions Mean                 1363.2
R Predictions Std                  3593.85
R Predictions Max                 21243.2
R Predictions Min                   -22.9339
Log Pis Mean                         26.8703
Log Pis Std                          14.7551
Log Pis Max                          62.3307
Log Pis Min                          -4.77079
Policy mu Mean                       -3.48401
Policy mu Std                        30.7317
Policy mu Max                       188.444
Policy mu Min                      -163.394
Policy log std Mean                  -0.521402
Policy log std Std                    1.55524
Policy log std Max                    2
Policy log std Min                  -13.2327
_task0 Rewards Mean                  94.2863
_task0 Rewards Std                  215.707
_task0 Rewards Max                 1878.43
_task0 Rewards Min                   -0.864823
_task0 Returns Mean               14142.9
_task0 Returns Std                25240.7
_task0 Returns Max                63031.9
_task0 Returns Min                  -83.9644
_task0 Actions Mean                  -0.0594066
_task0 Actions Std                    0.892241
_task0 Actions Max                    1
_task0 Actions Min                   -1
Num Paths                           363
Exploration_task0 Rewards Mean     1766.97
Exploration_task0 Rewards Std      4096.08
Exploration_task0 Rewards Max     22883.9
Exploration_task0 Rewards Min       -10.3752
Exploration_task0 Returns Mean   267723
Exploration_task0 Returns Std    581030
Exploration_task0 Returns Max         2.4901e+06
Exploration_task0 Returns Min     -1569.92
Exploration_task0 Actions Mean       -0.0229006
Exploration_task0 Actions Std         0.899828
Exploration_task0 Actions Max         1
Exploration_task0 Actions Min        -1
AverageReturn__task0              14142.9
AverageReturn_all_train_tasks      9663.32
AverageReturn_all_test_tasks      14142.9
Number of train steps total      328000
Number of env steps total             1.6401e+07
Number of rollouts total         119070
Train Time (s)                      100.381
(Previous) Eval Time (s)             25.7702
Sample Time (s)                     107.805
Epoch Time (s)                      233.957
Total Train Time (s)              76234.5
Epoch                               327
------------------------------  -----------------
2019-06-27 21:43:27.489624 UTC | [dialturn] Iteration #327 | Epoch Duration: 234.04553389549255
2019-06-27 21:43:27.489831 UTC | [dialturn] Iteration #327 | Started Training: True
